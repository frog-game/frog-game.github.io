[{"content":"1. 基础类型 定义 解释 LUA_TNONE 判断这个变量是否等于为空使用的，lua内部使用，注意不是和nil类型不等价 LUA_TNIL 全局变量没被复制就是nil类型，删除变量会被赋值成nil类型，nil类型就nil一个值，表示变量是否被赋值，变量赋值成nil也表示删除变量 LUA_TBOOLEAN false和nil为假 其他都为真(包括0) LUA_TLIGHTUSERDATA 见1.1 表 LUA_TNUMBER 所有数字，int float double 类型都为number类型 number类型可以和全是数字的字符串进行计算，字符串会进行类型转换 LUA_TSTRING 一但被赋值就不能被修改，可以通过方法string.gsub()来修改；分为长字符串和短字符串（小于等于40字符） LUA_TTABLE 数组容器 LUA_TFUNCTION 函数 LUA_TUSERDAT 见1.1 表 LUA_TTHREAD 协程，只是拷贝了一个栈空间 LUA_NUMTAGS tag 总数 1.1. LUA_TTHREAD 代表协程类型\n除了主线程以外，其它线程和其它Lua对象一样都是垃圾回收的对象。当新建一个线程时，线程会压入栈，这样能确保新线程不会成为垃圾\n每次调用lua_newstate的时候都会创建一个新的luastate,不同的luastate完全独立，之间不共享任何数据\n协程提供了新的api接口和lua_resetthread,coroutine.close 会使协程进入死亡状态,并且关闭所有的close变量\n1.2. full userdata和light userdata区别 区别 full userdata light userdata 作用 通常用来表示C中的结构体一小段固定的内存区域 通常用来表示C中的指针(void *) 内存管理 由Lua的垃圾回收器管理 使用者需要关心其内存 元表 有独立的元表 没有独立的元表 创建 void *lua_newuserdata(lua_State *L, size_t size) lua_pushlightuserdata(lua_State *L, void *p); 1.2.1. full userdata //c文件 //#include \u0026lt;string.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; } #include \u0026lt;iostream\u0026gt; using namespace std; static struct StudentTag { char *strName; // 学生姓名 char *strNum; // 学号 int iSex; // 学生性别 int iAge; // 学生年龄 }T; static int Student(lua_State *L) { size_t iBytes = sizeof(struct StudentTag); struct StudentTag *pStudent; pStudent = (struct StudentTag *)lua_newuserdata(L, iBytes); //设置元表 luaL_getmetatable(L, \u0026#34;Student\u0026#34;); lua_setmetatable(L, -2); //lua_pushnumber(L, 123); return 1; // 新的userdata已经在栈上了 } static int GetName(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); lua_pushstring(L, pStudent-\u0026gt;strName); return 1; } static int SetName(lua_State *L) { // 第一个参数是userdata struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); // 第二个参数是一个字符串 const char *pName = luaL_checkstring(L, 2); luaL_argcheck(L, pName != NULL \u0026amp;\u0026amp; pName != \u0026#34;\u0026#34;, 2, \u0026#34;Wrong Parameter\u0026#34;); pStudent-\u0026gt;strName =(char*) pName; return 0; } static int GetAge(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); lua_pushinteger(L, pStudent-\u0026gt;iAge); return 1; } static int SetAge(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); int iAge = luaL_checkinteger(L, 2); luaL_argcheck(L, iAge \u0026gt;= 6 \u0026amp;\u0026amp; iAge \u0026lt;= 100, 2, \u0026#34;Wrong Parameter\u0026#34;); pStudent-\u0026gt;iAge = iAge; return 0; } static int GetSex(lua_State *L) { // 这里由你来补充 return 1; } static int SetSex(lua_State *L) { // 这里由你来补充 return 0; } static int GetNum(lua_State *L) { // 这里由你来补充 return 1; } static int SetNum(lua_State *L) { // 这里由你来补充 return 0; } static luaL_Reg arrayFunc_meta[] = { { \u0026#34;getName\u0026#34;, GetName }, { \u0026#34;setName\u0026#34;, SetName }, { \u0026#34;getAge\u0026#34;, GetAge }, { \u0026#34;setAge\u0026#34;, SetAge }, { \u0026#34;getSex\u0026#34;, GetSex }, { \u0026#34;setSex\u0026#34;, SetSex }, { \u0026#34;getNum\u0026#34;, GetNum }, { \u0026#34;setNum\u0026#34;, SetNum }, { NULL, NULL } }; static luaL_Reg arrayFunc[] = { { \u0026#34;new\u0026#34;, Student}, { NULL, NULL } }; extern \u0026#34;C\u0026#34; _declspec(dllexport) int luaopen_mytestlib(lua_State *L) { // 创建一个新的元表 luaL_newmetatable(L, \u0026#34;Student\u0026#34;); // 元表.__index = 元表 lua_pushvalue(L, -1); lua_setfield(L, -2, \u0026#34;__index\u0026#34;); luaL_setfuncs(L, arrayFunc_meta, 0); luaL_newlib(L, arrayFunc); lua_pushvalue(L, -1); lua_setglobal(L, \u0026#34;Sdudent\u0026#34;); /* the module name */ return 1; } -- lua 文件 require \u0026#34;mytestlib\u0026#34; local objStudent = Sdudent.new() objStudent:setName(\u0026#34;果冻\u0026#34;) local strName = objStudent:getName() print(strName ) for k,v in pairs(getmetatable(objStudent)) do print(tostring(k),tostring(v)) end 1.2.2. light userdata //C文件 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; extern \u0026#34;C\u0026#34; { #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; } typedef struct { int x; int y; int z; }TData; static int getAttribute(lua_State* L) { TData *data = (TData*)lua_touserdata(L, 1); std::string attribute = luaL_checkstring(L, 2); int result = 0; if (attribute == \u0026#34;x\u0026#34;) { result = data-\u0026gt;x; } else if (attribute == \u0026#34;y\u0026#34;) { result = data-\u0026gt;y; } else { result = data-\u0026gt;z; } lua_pushnumber(L, result); return 1; } static luaL_Reg dataLib[] = { { \u0026#34;__index\u0026#34;, getAttribute }, { NULL, NULL } }; void getMetaTable(lua_State* L, luaL_Reg* methods) { lua_pushlightuserdata(L, methods); lua_gettable(L, LUA_REGISTRYINDEX); if (lua_isnil(L, -1)) { /* not found */ lua_pop(L, 1); lua_newtable(L); luaL_setfuncs(L, methods, 0); lua_pushlightuserdata(L, methods); lua_pushvalue(L, -2); lua_settable(L, LUA_REGISTRYINDEX); } } int main() { const char* filename = \u0026#34;test.lua\u0026#34;; lua_State *lua = luaL_newstate(); if (lua == NULL) { fprintf(stderr, \u0026#34;open lua failed\u0026#34;); return -1; } luaL_openlibs(lua); TData input = { 123, 231, 321 }; lua_pushlightuserdata(lua, \u0026amp;input); getMetaTable(lua, dataLib); lua_setmetatable(lua, -2); lua_setglobal(lua, \u0026#34;input\u0026#34;); if (luaL_dofile(lua, filename)) { //luaL_error(lua, \u0026#34;load file %s failed\u0026#34;, filename); } lua_getglobal(lua, \u0026#34;data\u0026#34;); int output = lua_tointeger(lua, -1); std::cout \u0026lt;\u0026lt; output \u0026lt;\u0026lt; std::endl; return 0; } --lua文件 data = input.x; print(data) 1.2.3. 需要注意地方 序号 注意项 1 Lua中变量没有预定义类型，每个变量可以包含任意类型的值，要用就直接赋值一种数据类型的值 2 nil类型就nil一个值，表示变量是否被赋值，变量赋值成nil也表示删除变量 3 使用Type(xxx变量) 可以获取该变量的数据类型 4 number 所有数字，int float double 类型等都为number类型了 5 字符串一旦赋值不能被修改，可以通过方法string.gsub()来修改，可以写成’xxas’单引号，但是建议用双引号”” 6 number类型可以和全是数字的字符串进行计算，字符串会进行类型转换 7 .. 连接符号 ，可以连接字符串类型，也可以连接整形的变量，但是如果直接使用真实的数字要在后面加个空格，因为系统会把 数字.. 看出2个浮点 如 1..2 （错误写法） 1 ..2 (正确写法) 8 类型不同，比较判断也不会相等,如number类型的123不等于string类型的123 9 计算运算符中取余可以和浮点数计算，可以精确到小数级别 10 关系运算符中~= 表示不等于，类似其他语言如c的 != 11 逻辑运算符 and ，or ，not 对应 \u0026amp;\u0026amp; ，|| , ！ 12 表达式：a and b a为假则返回a 否则返回b， a or b a为真返回a否则返回b ,简单理解and就是先判断a a正确就继续判断b，如果b也正确返回btrue，则if(a and b) 为true ，这实际上也是\u0026amp;\u0026amp;的使用原理一样 ，如果a为假就是false直接返回a if(a and b) 就是false了 。 or 同理 13 赋值方式一：多个变量同时赋值，多的变量(变量个数多于值个数)默认为nil，少的变量(变量个数少于值个数)不做处理，可以类型混搭 14 局部变量 用local修饰声明 ，内存在栈上，在一个函数，代码块{ }内 函数，代码块结束，内存自动释放 15 全局变量在堆上，可以随时创建，程序结束，内存自动释放 16 控制语句上，有if for where 没有switch结构 17 控制语句上，不需要写 () {} {指代 ：then } 指代 ： end 18 循环结构 while do end ,里面不能写() 以及 ++ – += 类似的运算符 19 循环结构 for 也不需要写() 也不在赋值除了对第一个赋值，其他都可以省略写默认写为 \u0026lt;= +xx 或 \u0026gt;= -xx 20 函数的返回值和其他语言一样可以返回个值，变量。但是不同的是可以同时返回多个变量，进行多个赋值 21 table可以有数组的形式，字典的形式，数组字典同时混合的形式 22 print()打印会默认换行 23 #号数组是计算数组容器table的下标个数，lua的数组容器下标从1开始计算递增，字典不包括key元素 24 ipairs 仅仅遍历值，按照索引升序遍历，索引中断停止遍历。不能返回 nil,如果遇到 nil 则退出。它只能遍历到集合中出现的第一个不是整数的 key。 pairs 能遍历集合的所有元素。即 pairs 可以遍历集合中所有的 key，并且除了迭代器本身以及遍历表本身还可以返回 nil。 25 lua 布尔类型只有两个取值false和true. 但要注意lua中所有的值都可以作为条件. 在控制结构的条件中除了false和nil为假, 其他值都为真。lua认为 0 和 空字符串都是真！！ 1.2.3.1. pairs和ipairs 例子比较 test = {[\u0026#34;xxx\u0026#34;] = nil , tt = \u0026#34;tabao\u0026#34;} for k , v in pairs(test) do print(k,v) end 输出： tt tabao test = {nil = xxxx , tt = \u0026#34;tabao\u0026#34;} for k , v in pairs(test) do print(k,v) end 输出：stdin:1: bad argument #1 to \u0026#39;for iterator\u0026#39; (table expected, got nil) stack traceback: [C]: in function \u0026#39;next\u0026#39; stdin:1: in main chunk [C]: in ? local tab = { [1] = \u0026#34;a\u0026#34;, [3] = \u0026#34;b\u0026#34;, [4] = \u0026#34;c\u0026#34; } for k, v in ipairs(tab) do print(k, v) end 输出：1 a ,在key等于2处断开 local tab= { [2] = \u0026#34;a\u0026#34;, [3] = \u0026#34;b\u0026#34;, [4] = \u0026#34;c\u0026#34; } for k, v in ipairs(tab) do print(k, v) end 输出：什么都没输出，为什么？因为控制变量初始值是按升序来遍历的，当key为1时，value为nil，此时便停止了遍历， 所有什么结果都没输出。 for k, v in pairs(tab) do print(k, v) end 输出：2 a, 3 b, 4 c local tab = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, [3] = \u0026#34;c\u0026#34;, [\u0026#34;two\u0026#34;] = \u0026#34;d\u0026#34;} for i,v in ipairs(tab) do print( tab [i] ) end 输出：a，b，c for i,v in pairs(tab) do print( tab [i] ) 输出：a，b，c，d。 2. lua 模块 import 和 require 差异 载入一个模块 import() 与 require() 功能相同，但具有一定程度的自动化特性。\nimport支持相对路径的写法，一个点表示当前目录，两个点表示上一级目录，以此类推。\nrequire 最好写成绝对路径的形式如：require \u0026quot;src.ui.common.FightPointAdd\u0026quot; or require \u0026quot;src/common/FightPointAdd\u0026quot;\nimport还有一个优势是假设：A/B/下有两个文件c.lua,d.lua，如果在c中用到了d话,require( \u0026quot;A/B/d\u0026quot;),import(\u0026quot;.d\u0026quot;) ，如果后面目录结构改了 ,c,d都到了A目录下,那对应的要修改require(\u0026quot;A/d) 而import可以不用修改。\n3. lua 正则表达式 测试工具地址:https://wiki.luatos.com/pages/emulator.html\n下面的表列出了Lua支持的所有字符类:\n. 任意字符 %a 字母 %c 控制字符 %d 数字 %l 小写字母 %p 标点字符 %s 空白符 %u 大写字母 %w 字母和数字 %x 十六进制数字 %z 代表0的字符 上面字符类的大写形式表示小写所代表的集合的补集。例如, %A非字母的字符:\nprint(string.gsub(\u0026#34;hello, up-down!\u0026#34;, \u0026#34;%A\u0026#34;, \u0026#34;.\u0026#34;)) --\u0026gt; hello..up.down. 4 数字4不是字符串结果的一部分，他是gsub返回的第二个结果，代表发生替换的次数.\nlua特殊字符\n( ) . % + - * ? [ ^ $ %用作特殊字符的转义字符，因此 %. 匹配点; %%匹配字符 % .转义字符%不仅可以用来转义特殊字符，还可以用于所有的非字母的字符。当对一个字符有疑问的时候，为安全起见请使用转义字符转义他。\n\\ 是lua的转义字符\n[%w_]将匹配字母数字和下划线\n[01]匹配二进制数字，[%[%]]匹配一对方括号\n第一个字符和最后一个字符之间用连字符-连接表示这两个字符之间范围内的字符集合\n%d表示 [0-9]\n%x表示[0-9a-fA-F]\n查找八进制数:[0-7]\n匹配任何非换行符户的字符: [^\\n]\n模式修饰符\n+ 匹配前一字符1次或多次 * 匹配前一字符0次或多次 - 匹配前一字符0次或多次 ? 匹配前一字符0次或1次 +匹配一个或多个字符，她总是进行最长的匹配. 比如，模式串 %a+匹配一个或多个字母或者一个单词 :\nprint(string.gsub(\u0026#34;one, and two; and three\u0026#34;, \u0026#34;%a+\u0026#34;, \u0026#34;word\u0026#34;)) --\u0026gt; word, word word; word word %d+匹配一个或多个数字 (整数):\ni, j = string.find(\u0026#34;the number 1298 is even\u0026#34;, \u0026#34;%d+\u0026#34;) print(i,j) --\u0026gt; 12 15 * 与 +类似, 但是他匹配一个字符0次或多次出现.一个典型的应用是匹配空白。比如，为了匹配一对圆括号()或者( )之间的空白，可以使用%(%s*%) ( '%s*用来匹配0个或多个空白,由于圆括号在模式中有特殊的含义，所以我们必须使用%转义他.) 再看一个例子，[_%a][_%w]*匹配Lua程序中的标示符：字母或者下划线开头的字母下划线数字序列。\n-与*一样，都匹配一个字符的0次或多次出现，但是他进行的是最短匹配。某些时候这两个用起来没有区别，但有些时候结果将截然不同。比如，如果你使用模式[_%a][_%w]-来查找标示符，你将只能找到第一个字母，因为[_%w]-永远匹配空。另一方面，假定你想查找C程序中的注释，很多人可能使用 /%*.*%*/ (也就是说 \u0026quot;/*\u0026quot; 后面跟着任意多个字符，然后跟着 \u0026quot;*/\u0026quot;) 然而，由于 .*进行的是最长匹配，这个模式将匹配程序中第一个\u0026quot;/*\u0026quot; 和最后一个\u0026quot;*/\u0026quot;之间所有部分:\ntest = \u0026#34;int x; /* x */ int y; /* y */\u0026#34; print(string.gsub(test, \u0026#34;/%*.*%*/\u0026#34;, \u0026#34;\u0026lt;COMMENT\u0026gt;\u0026#34;)) --\u0026gt; int x; \u0026lt;COMMENT\u0026gt; 然而模式 .-进行的是最短匹配，她会匹配\u0026quot;/*\u0026quot;开始到第一个\u0026quot;*/\u0026quot;之前的部分:\ntest = \u0026#34;int x; /* x */ int y; /* y */\u0026#34; print(string.gsub(test, \u0026#34;/%*.-%*/\u0026#34;, \u0026#34;\u0026lt;COMMENT\u0026gt;\u0026#34;)) --\u0026gt; int x; \u0026lt;COMMENT\u0026gt; int y; \u0026lt;COMMENT\u0026gt; ?匹配一个字符0次或1次.举个例子，假定我们想在一段文本内查找一个整数，整数可能带有正负号。 模式 [+-]?%d+符合我们的要求，她可以匹配 像 \u0026quot;-12\u0026quot;, \u0026quot;23\u0026quot; 和 \u0026quot;+1009\u0026quot;等数字. [+-] 是一个匹配+或者 -的字符类；接下来的 ?意思是匹配前面的字符类0次或者1次.\n与其他系统的模式不同的是，Lua中的修饰符不能用字符类；不能将模式分组然后使用修饰符作用这个分组。比如，没有一个模式可以匹配一个可选的单词(除非这个单词只有一个字母)。下面我将看到，通常你可以使用一些高级技术绕开这个限制。\n以^开头的模式只匹配目标串的开始部分，相似的，以$结尾的模式只匹配目标串的结尾部分。这不仅可以用来限制你要查找的模式，还可以定位(anchor)模式。比如：\nif string.find(s, \u0026#34;^%d\u0026#34;) then ... 符串s是否以数字开头，而 if string.find(s, \u0026#34;^[+-]?%d+$\u0026#34;) then ... 检查字符串s是否是一个整数。\n%b用来匹配对称的字符.常写为 %bxy,x和y是任意两个不同的字符；x作为匹配的开始,y作为匹配的结束。比如， %b()匹配以(开始， 以 )结束的字符串:\nprint(string.gsub(\u0026#34;a (enclosed (in) parentheses) line\u0026#34;, \u0026#34;%b()\u0026#34;, \u0026#34;\u0026#34;)) --\u0026gt; a line 常用的这种模式有： %b(), %b[], %b%{%},和 %b\u0026lt;\u0026gt;。你也可以使用任何字符作为分隔符。\n4. lua字符串管理 typedef struct TString { CommonHeader; // 字符串的子类型有两种：长字符串和短字符串 // 短字符串：extra表示Lua保留字的索引，如果为0就不是保留字 // 长字符串：extra标记是否已经计算哈希值，0表示还未计算 lu_byte extra; lu_byte shrlen; // 短字符串长度 unsigned int hash; // 字符串的哈希值 // 下面联合分两种情况： // 如果是长字符串则是长度lnglen // 如果是短字符串则是hnext，指向下一个短字符串对象，短字符串会用哈希表缓存， union { size_t lnglen; struct TString *hnext; } u; char contents[1];//真正的字符串存储在这里 } TString; 4.1. 字符串创建方式 4.1.1. 全局字符串表 typedef struct stringtable { TString **hash;//hash散列桶 int nuse; /* number of elements *///实际的使用元素 int size;//当前桶的大小 } stringtable; 4.1.2. 链表方式 相同hash字符串存储在 stringtable strt 链表结构上 一般短字符串会使用这种方式存储\n4.1.3. hashMap缓存方式 下图中N是数组行，M是数组列\ni的下标值通过unsigned int i = point2uint(str) % STRCACHE_Nhash求得\nj的最大值固定就是下面的宏函数 STRCACHE_M 2\n下面两个函数luaS_new luaS_newlstr是创建字符串的核心函数\n/* ** Create or reuse a zero-terminated string, first checking in the ** cache (using the string address as a key). The cache can contain ** only zero-terminated strings, so it is safe to use \u0026#39;strcmp\u0026#39; to ** check hits. 创建或重用一个以\u0026#39;0\u0026#39;结尾的字符串，首先查找 global_state 的 strcache 缓存是否已存在该字符串， 若存在则直接返回，否则创建一个新的，并加入到缓存中 */ TString *luaS_new (lua_State *L, const char *str) { //point2uint 指针转无符号整数 unsigned int i = point2uint(str) % STRCACHE_N; /* hash */ //求出strcache下标 STRCACHE_N等于53 int j; //在全局G中查找strcache里面查找是否有这个string TString **p = G(L)-\u0026gt;strcache[i]; for (j = 0; j \u0026lt; STRCACHE_M; j++) { if (strcmp(str, getstr(p[j])) == 0) /* hit? */ return p[j]; /* that is it */ } //如果没有找到创建新的Tstring,并放到第一个位置 //同时也意味着最后一个元素会被移除strcache /* normal route */ for (j = STRCACHE_M - 1; j \u0026gt; 0; j--) p[j] = p[j - 1]; /* move out last element */ /* new element is first in the list */ p[0] = luaS_newlstr(L, str, strlen(str));//创建新的Tstring return p[0]; } /* ** new string (with explicit length) 创建一个给定长度的字符串 */ TString *luaS_newlstr (lua_State *L, const char *str, size_t l) { if (l \u0026lt;= LUAI_MAXSHORTLEN) /* short string? */ //判断是不是短字符串 return internshrstr(L, str, l);//短字符串创建 else {//长字符串创建 TString *ts; if (l_unlikely(l \u0026gt;= (MAX_SIZE - sizeof(TString))/sizeof(char)))//如果字符串太长 创建失败 luaM_toobig(L); ts = luaS_createlngstrobj(L, l);//直接创建长字符串 memcpy(getstr(ts), str, l * sizeof(char));//拷贝字符串内容 return ts; } } /* ** Checks whether short string exists and reuses it or creates a new one. ** 检查短字符串是否已经存在，如果存在则复用，否则创建一个新的 */ static TString *internshrstr (lua_State *L, const char *str, size_t l) { TString *ts; global_State *g = G(L);//全局表 stringtable *tb = \u0026amp;g-\u0026gt;strt;//全局字符串表，lua所有的短字符串都存在这个里面 unsigned int h = luaS_hash(str, l, g-\u0026gt;seed);//求的hash值 TString **list = \u0026amp;tb-\u0026gt;hash[lmod(h, tb-\u0026gt;size)];//求得全局字符串表中对应hash位置的链表 lua_assert(str != NULL); /* otherwise \u0026#39;memcmp\u0026#39;/\u0026#39;memcpy\u0026#39; are undefined */ for (ts = *list; ts != NULL; ts = ts-\u0026gt;u.hnext) {//遍历链表查找是否有相同的字符串 if (l == ts-\u0026gt;shrlen \u0026amp;\u0026amp; (memcmp(str, getstr(ts), l * sizeof(char)) == 0)) { /* found! */ if (isdead(g, ts)) /* dead (but not collected yet)? *///如果找到，并且当前gc判断要被回收 changewhite(ts); /* resurrect it *///这个时候修改它为白色状态，表示不需要回收 return ts;//直接返回查找到的字符串 } } /* else must create a new string *///否则必须创建一个字符串 if (tb-\u0026gt;nuse \u0026gt;= tb-\u0026gt;size) { /* need to grow string table? *///容量不够需要扩容 growstrtab(L, tb);//扩容容量 list = \u0026amp;tb-\u0026gt;hash[lmod(h, tb-\u0026gt;size)]; /* rehash with new size *///重新计算全局字符串表中对应的hash位置的链表 } ts = createstrobj(L, l, LUA_VSHRSTR, h);//创建一个字符串对象 memcpy(getstr(ts), str, l * sizeof(char));//拷贝进去 ts-\u0026gt;shrlen = cast_byte(l);//赋值字符串大小，按无符号char大小求长度 ts-\u0026gt;u.hnext = *list;//添加到全局的字符串表中,此处是头插法插入数据 *list = ts; tb-\u0026gt;nuse++; return ts; } //创建一个长串 TString *luaS_createlngstrobj (lua_State *L, size_t l) { TString *ts = createstrobj(L, l, LUA_VLNGSTR, G(L)-\u0026gt;seed); ts-\u0026gt;u.lnglen = l; return ts; } /*创建一个长字符串或者短字符串 ** creates a new string object */ static TString *createstrobj (lua_State *L, size_t l, int tag, unsigned int h) { TString *ts; GCObject *o; size_t totalsize; /* total size of TString object */ totalsize = sizelstring(l);//得到真正字符串的大小 o = luaC_newobj(L, tag, totalsize);//创建一个GC对象 ts = gco2ts(o);//强制转换为Tsing结构 ts-\u0026gt;hash = h;//赋seed值也就是随机种子 ts-\u0026gt;extra = 0;//0表示还未计算真正的hash值 getstr(ts)[l] = \u0026#39;\\0\u0026#39;; /* ending 0 */ return ts; } 4.1.4. 函数调用过程 4.2. 字符串大小 字符串内容会在有效数据的结尾强制加上\\0，所以字符串对象的总大小为:\n头的大小加上字符串的空间+加上最后的\\0\n/* ** Size of a TString: Size of the header plus space for the string ** itself (including final \u0026#39;\\0\u0026#39;). */ #define sizelstring(l) (offsetof(TString, contents) + ((l) + 1) * sizeof(char)) //offsetof(TString, contents) contents成员相对于TString开头位置的偏移量，等价于头的大小 //((l) + 1) l是外部传进来长短字符串的大小 +1是最后\u0026#39;\\0\u0026#39;大小 4.3. 长短字符串 /* ** Maximum length for short strings, that is, strings that are ** internalized. (Cannot be smaller than reserved words or tags for ** metamethods, as these strings must be internalized; ** #(\u0026#34;function\u0026#34;) = 8, #(\u0026#34;__newindex\u0026#34;) = 10.) */ #if !defined(LUAI_MAXSHORTLEN) #define LUAI_MAXSHORTLEN\t40 #endif 4.3.1. 短字符串 定义:小于等于40个字节的字符串\n4.3.1.1. 比较大小 因为是重复利用的，所以直接比较指针地址就可以了\n/* ** equality for short strings, which are always internalized */ #define eqshrstr(a,b)\tcheck_exp((a)-\u0026gt;tt == LUA_VSHRSTR, (a) == (b)) 4.3.2. 长字符串 4.3.2.1. 计算hash值 长字符串不会马上计算哈希值，一般在调用luaS_hashlongstr 时候才会去计算\nunsigned int luaS_hashlongstr (TString *ts) { lua_assert(ts-\u0026gt;tt == LUA_VLNGSTR); if (ts-\u0026gt;extra == 0) { /* no hash? *///extra为0的时候才去计算hash值 size_t len = ts-\u0026gt;u.lnglen; ts-\u0026gt;hash = luaS_hash(getstr(ts), len, ts-\u0026gt;hash);//通过luaS_hash创建hash值 ts-\u0026gt;extra = 1; /* now it has its hash */ } return ts-\u0026gt;hash; } unsigned int luaS_hash (const char *str, size_t l, unsigned int seed) { unsigned int h = seed ^ cast_uint(l); for (; l \u0026gt; 0; l--) h ^= ((h\u0026lt;\u0026lt;5) + (h\u0026gt;\u0026gt;2) + cast_byte(str[l - 1])); return h; } 4.3.2.2. 比较大小 /* ** equality for long strings 长字符串的比较：先比较地址，再比较长度，最后比较内容 */ int luaS_eqlngstr (TString *a, TString *b) { size_t len = a-\u0026gt;u.lnglen; lua_assert(a-\u0026gt;tt == LUA_VLNGSTR \u0026amp;\u0026amp; b-\u0026gt;tt == LUA_VLNGSTR); return (a == b) || /* same instance or... */ ((len == b-\u0026gt;u.lnglen) \u0026amp;\u0026amp; /* equal length and ... */ (memcmp(getstr(a), getstr(b), len) == 0)); /* equal contents */ } 5. lua table 5.1. 值对象结构 /* ** Union of all Lua values 还有几种数据类型是不需要进行垃圾回收的, //Lua 中将GCObject 和它们一起放在了联合体Value 中: */ typedef union Value { struct GCObject *gc; /* collectable objects */ void *p; /* light userdata */ lua_CFunction f; /* light C functions */ lua_Integer i; /* integer numbers */ lua_Number n; /* float numbers */ } Value; 变量 说明 GCObject gc 用于垃圾回收 主要是为了连接垃圾回收对象的互相引用关系 void *p 为c中传入的指针，由c 分配和释放 light userdata lua_CFunction f 表示C导出给lua的函数指针，typedef int (*lua_CFunction) (lua_State *L) lua_Integer i 表示整数类型，typedef long long lua_Integer lua_Number n 表示双精度浮点类型，typedef double lua_Number 5.2. 非GC对象 从上面可以看到非GC的对象有4中\nlight userdata C函数 整型 浮点型 int b(lua 5.4 数字分为整数和浮点，而i正好也可以用作bool,所以把这个给**删除**,和 lua_Integer i 结合到一起了) 5.3. GC对象 union GCUnion { GCObject gc; /* common header */ struct TString ts; struct Udata u; union Closure cl; struct Table h; struct Proto p;// Proto主要存放二进制指令集Opcode Lua在解析函数的过程中，会将一条条语句逐个‘编译’成指令集 struct lua_State th; /* thread */ struct UpVal upv; }; 从上面的union结构体可以看到GC对象有6中\n字符串 userdata closure 闭包 table lua 函数原型(Proto主要存放二进制指令集Opcode) lua 线程 (其实就是协程) lua上值 5.4. CommonHeader类型 #define CommonHeader\tstruct GCObject *next; lu_byte tt; lu_byte marked next 指针 指向下一个GC对象 tt GC对象的实际类型(比如上面6中GC对象) marked 标识GC的状态(白1 白2 黑 final) 5.5. TValuefields 类型 #define TValuefields Value value_; int tt_ Value：存储具体数据的值 tt_：表示这个值的类型，即所有的基础数据类型 5.6. table 结构 typedef struct Table { CommonHeader; lu_byte flags; /* 1\u0026lt;\u0026lt;p means tagmethod(p) is not present *///用于表示cache在该表中实现了哪些元方法 lu_byte lsizenode; /* log2 of size of \u0026#39;node\u0026#39; array *///哈希部分的长度对数：1 \u0026lt;\u0026lt; lsizenode 才能得到实际的size unsigned int alimit; /* \u0026#34;limit\u0026#34; of \u0026#39;array\u0026#39; array *///数组部分的长度 TValue *array; /* array part *///数组部分 Node *node;//hash部分 闭散列方法解决hash冲突 Node *lastfree; /* any free position is before this position *///空闲槽位 struct Table *metatable;//元表 GCObject *gclist;//gc链表 } Table; typedef union Node { struct NodeKey { TValuefields; /* fields for value *///值域 lu_byte key_tt; /* key type *///key类型 int next; /* for chaining *///链表下一个节点索引 Value key_val; /* key value *///key值 } u; TValue i_val; /* direct access to node\u0026#39;s value as a proper \u0026#39;TValue\u0026#39; */ } Node; 5.7. hash解决冲突时候的两种方法 5.7.1. 闭散列 （即开放地址法）：当发生哈希冲突时，如果该哈希表还没有被填满，那么就把该元素放到哈希表的下一个空闲的位置\n优点：简单 易懂,当hash表已经没有空格的时候，lua就会resize这个hash表。这样做的好处主要是不用动态申请内存空间，hash表初始化的时候有多少内存空间就用多少，不够就resize这个hash表。\n缺点：一旦发生了哈希冲突，所有的冲突连接在一起，很容易产生数据”堆积”。即不同的数据占用可以利用的位置，就使得寻找其余数据的位置需要进行多次比较，就会导致查找的效率降低。\n5.7.2. 开散列 开散列法（哈希桶）：又名链地址法，先用哈希函数计算每个数据的散列地址，把具有相同地址的元素归于同一个集合之中，把该集合处理为一个链表，链表的头节点存储于哈希表之中。\n优点:解决了数据溢出的问题\n缺点:需要增加链接的指针，增加存储开销\n5.8. 新建一个table Table *luaH_new (lua_State *L) { GCObject *o = luaC_newobj(L, LUA_VTABLE, sizeof(Table)); Table *t = gco2t(o); t-\u0026gt;metatable = NULL;//初始设置metatable为null t-\u0026gt;flags = cast_byte(maskflags); /* table has no metamethod fields */ t-\u0026gt;array = NULL;//初始化数组大小 t-\u0026gt;alimit = 0;//数组长度 setnodevector(L, t, 0);//初始化哈希部分 return t; } static void setnodevector (lua_State *L, Table *t, unsigned int size) { //如果size是0：就是说整个table为空，那么就是初始化这些东西为零 if (size == 0) { /* no elements to hash part? */ t-\u0026gt;node = cast(Node *, dummynode); /* use common \u0026#39;dummynode\u0026#39; */ t-\u0026gt;lsizenode = 0; t-\u0026gt;lastfree = NULL; /* signal that it is using dummy node */ } //如果size不为零： else { int i; int lsize = luaO_ceillog2(size); //拿到 新的 真实的 哈希部分长度log2之后的结果 //如果新的长度超出了最大的哈希长度: if (lsize \u0026gt; MAXHBITS || (1u \u0026lt;\u0026lt; lsize) \u0026gt; MAXHSIZE) luaG_runerror(L, \u0026#34;table overflow\u0026#34;);//报错 size = twoto(lsize); //要保证分配的是以2的指数增长来进行扩容的 //创建了个大小为 size*sizeof(Node) 的内存块，然后初始化这块内存 t-\u0026gt;node = luaM_newvector(L, size, Node); for (i = 0; i \u0026lt; (int)size; i++) { Node *n = gnode(t, i); //将这块内存给初始化 gnext(n) = 0; setnilkey(n); setempty(gval(n)); } t-\u0026gt;lsizenode = cast_byte(lsize); t-\u0026gt;lastfree = gnode(t, size); /* all positions are free */ } } 5.9. 增加一个元素 /* 这个函数的主要功能将一个key插入哈希表，并返回key关联的value指针。 1. 首先通过key计算出主位置，如果主位置为空结点那最简单，将key设进该结点，然后返回结点的值指针。 2. 如果不是空结点就要分情况，看3和4两种情况 3.如果该结点就是主位置结点，那么要另找一个空闲位置，把Key放进去，和主结点链接起来， 然后返回新结点的值指针。 4.如果该结点不是主位置结点，把这个结点移到空闲位置去；然后我进驻这个位置，并返回结点的值指针。 */ TValue *luaH_newkey (lua_State *L, Table *t, const TValue *key) { Node *mp; TValue aux; if (unlikely(ttisnil(key))) //key是空值 报错 luaG_runerror(L, \u0026#34;table index is nil\u0026#34;); else if (ttisfloat(key)) { //key是float 转成int 不能就报错 lua_Number f = fltvalue(key);//得到float值 lua_Integer k; if (luaV_flttointeger(f, \u0026amp;k, F2Ieq)) { /* does key fit in an integer? *///如果能转成int setivalue(\u0026amp;aux, k); key = \u0026amp;aux; /* insert it as an integer *///插入一个int值 } else if (unlikely(luai_numisnan(f)))//如果是个nan数 luaG_runerror(L, \u0026#34;table index is NaN\u0026#34;); } mp = mainpositionTV(t, key);// mainposition函数通过key找到“主位置”的node桶 if (!isempty(gval(mp)) || isdummy(t)) { /* main position is taken? */// 主位置桶被占，或者哈希表部分为空 Node *othern; Node *f = getfreepos(t); /* get a free place */// 找空闲位置，这里还涉及到没空闲位置会重建哈希表的操作 if (f == NULL) { /* cannot find a free place? *///如果没空闲位置就重建table rehash(L, t, key); /* grow table */ //重建哈希表的操作 /* whatever called \u0026#39;newkey\u0026#39; takes care of TM cache */ return luaH_set(L, t, key); /* insert key into grown table */ } lua_assert(!isdummy(t)); othern = mainposition(t, keytt(mp), \u0026amp;keyval(mp));// 通过主位置这个结点的key，计算出本来的主位置结点 if (othern != mp) { /* is colliding node out of its main position? */ /* yes; move colliding node into free position */ while (othern + gnext(othern) != mp) /* find previous */// 这种就对应上面说的情况4的处理，把结点移到空闲位置去 othern += gnext(othern); gnext(othern) = cast_int(f - othern); /* rechain to point to \u0026#39;f\u0026#39; */// 移动之前，要先把链接结点的偏移调整一下 *f = *mp; /* copy colliding node into free pos. (mp-\u0026gt;next also goes) */// 把冲突结点移到空闲位置 if (gnext(mp) != 0) { // 如果冲突结点也有链接结点，也要调整过来 gnext(f) += cast_int(mp - f); /* correct \u0026#39;next\u0026#39; */ gnext(mp) = 0; /* now \u0026#39;mp\u0026#39; is free */ } setempty(gval(mp)); } else { /* colliding node is in its own main position */ /* new node will go into free position */ if (gnext(mp) != 0) gnext(f) = cast_int((mp + gnext(mp)) - f); /* chain new position */ else lua_assert(gnext(f) == 0); gnext(mp) = cast_int(f - mp); mp = f; } } setnodekey(L, mp, key); luaC_barrierback(L, obj2gco(t), key); lua_assert(isempty(gval(mp))); return gval(mp); } ","permalink":"https://frog-game.github.io/posts/blog/luayuanmashagnxi/","summary":"1. 基础类型 定义 解释 LUA_TNONE 判断这个变量是否等于为空使用的，lua内部使用，注意不是和nil类型不等价 LUA_TNIL 全局变量没被复制就是nil类型，删除变量会被","title":"lua源码赏析笔记"},{"content":"1. linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 2. 网络流程图 2.1 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Socket在Skynet内部对应一个Lua虚拟机和一个客户特定的消息队列per client mq。当客户特定消息队列中有消息时，该队列会挂载到全局队列global message queue上供工作线程worker Threads进行调度处理。\n一个Socket线程socket thread会轮询所有的Socket，当收到客户端请求后将请求打包成一个消息，发送到该Socket对应的客户特定消息队列per client mq中，然后将该消息队列挂到全局队列队尾。\n多个Worker工作线程worker threads从全局队列头部获取客户特定消息队列，从客户特定消息队列中取出一个消息进行处理，处理完毕后再将消息队列重新挂到全局队列队尾。\nskynet中不同服务是利用系统的多线程完全并行的，当你从服务A向服务B和服务C分别各自发送一条消息时，并不能保证先发的消息先被处理。而当你从服务A向服务B依次发送两条消息时，先发的消息一定会被服务B先处理。\n使用Lua实现的服务只是一个内嵌了Lua虚拟机的服务，也遵守上面的规则。如果服务B是一个Lua服务，当服务A向服务B发送两条消息x和y时，Skynet一定保证x先被服务B中的Lua虚拟机接收到，并为消息x生成要给协程X，并运行这个协程。然后才会接收到消息y，并重新生成一个新的协程Y并运行。\n2.2 同步问题 同步也是skynet存在的问题，当一个服务call其他服务时，当前协程会挂起，但是这个服务还可以接受并处理其他消息。如果多个协程改到同一个数据，你不做同步处理就无法确定这个数据会是多少。\n这样的例子特别常见，比如，服务正当处理玩家login请求，刚好遇到call挂起，这时候又有新的请求到来，比如logout，服务就会转去处理logout消息。那玩家究竟是login，还是logout？\n当然，同步问题也容易解决，加多一个state的标识和一个协程列表，操作执行时，将state置doing，其他协程判断state=doing时就将自己加到协程列表，然后 skynet.wait。在操作执行完后，重置state，然后遍历协程列表依次 skynet.wakeup(co) ，最后将协程列表置空。\n2.3 解释此队列 红黑树上的节点是所有监听的socket 黄色底的是interesting 队列 蓝色底是黄色底的子队列 也就是就绪队列 epoll_ctrl() 执行增加操作时候就是往interesting队列塞socket 当有读写事件时候，就会往蓝色底队列放入socket也就是塞入就绪队列 通过epoll_wait()把就绪队列的东西返回出来\n2.4 线程类型 socket thread : 线程进程消息收发\nmonitor thread : 线程监控服务是不是陷入死循环，消息是否堵住\ntime thread : 线程主要用于实现skynet的定时器\nwork thread 线程 对消息队列进行调度\n2.5 消息流转 先从全局队列 pop一个次级队列，然后从次级队列 pop一个消息调用回调函数进行逻辑处理 用完以后如果次级队列不为空或者堵塞，继续把次级队列放入全局队列 3. 启动流程 加载配置文件 配置文件存入lua的全局变量env 创建和启动c服务 logger 启动引导模块并启动第一个lua服务(bootstrap) 然后在通过 bootstrap配置去启动其他的微服务 4. cluster 两条tcp通道总结 \u0026lt;font color='red'\u0026gt;前提 \u0026lt;/font\u0026gt; 两端是严格分为请求方和回应方。比如 A---\u0026gt; B ，那么只能是A向B提出请求，B 回应它；如果 B-----\u0026gt;\u0026gt;A 需要由 B 向 A 再建立一条通道。\nTCP特性使得每个TCP连接可以得到均等的带宽。在多用户环境下，一个用户拥有越多TCP连接，获得的带宽越大\n1条连接 优点：链接少，对于没有接触过skynet，传统服务器人很容易这种方式连接方式，因为大部分很多都是cs结构程序员过来的 **缺点：**如果断了，数据就无法传输，得重新建立新的连接，上层业务逻辑写起来也麻烦，需要清楚那边是发送方，那边是接受方\n2条连接 **优点：**在前面前提的基础上，有两条连接，上层业务逻辑程序员不需要关心我这个时候是client，还是server，只需要通过 cluster.call，cluster.send，接口直接往里面塞数据就行了，多条连接也便于抢带宽 **缺点:**多了一条连接，对cs结构过来的程序员不太容易理解为什么这么弄有好处，或者是不知道有前面那个前提 为什么不在开辟更多的连接，因为开辟更多的链接意义不大，如果这台机器上弄了不少进程，连接数和机器的配置也是有关系的，多了，如果用不上也是一种浪费，同时对于业务程序员来说也逻辑混乱， 因为假如是4条，那么接受方还得区分是那条发过来的数据\n5. master / slave 组网过程 slave3发送 sync给 master，并启动自己的 listen master收到信息给已经连接上的 slave1，slave2发送 slave3请求连接的情况 master给 slave3发送当前已经连接上的 slave数量，并把 slave3加入节点组 slave1，slave3接收到 master发送的信息后，调用 connect去连接 slave3 6. master /slave 断网过程 master检测到 slave3失去连接，把 slave3连接 fd置成 0 master把失去连接的 slave3 id 广播给 slave1，slave2 slave1，slave2得到 slave3 id之后和 slave3断开连接 7. harbor 服务 每个节点都有一个 harborid，在发送消息的时候会把这个 harborid放到消息 id的\n高8位，所以通过高8位的对比就知道这个消息是远程消息，还是本地消息，如果是远程消息\n通过 harbor和远程的 harbor建立 tcp连接发送数据过去，如果是本地直接放入本地节点处理逻辑\n8. 消息处理方式 skeynet.send 非堵塞不需要应答 skynet.call 堵塞需要应答 skynet.ret 回应消息 skynet.response 请求和相应在不用协程处理 skynet.queue 串行化消息执行 9. 锁 互斥锁 适用于得到锁以后处理时间\u0026gt;线程切换时间场景 得到锁的线程会被唤醒处理逻辑，没有抢占到锁的线程会进入休眠状态\n互斥锁加锁失败以后，会从用户态变成内核态，线程就会释放 CPU 给其他线程,会有两次线程上下文的切换成本\n线程加锁失败时，内核会把线程的状态从 「运行」状态设置为 「睡眠」状态，然后把 CPU 切换给其他线程运行 接着，当锁被释放时，之前 「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 上下文切换的时间，大概在几十纳秒到几微妙之间，所以如果你能确认你被锁住的代码时间很短，那么就不应该用互斥锁，而应该用自旋锁\n9.2 自旋锁 没有获取到权限的的线程不会进入休眠状态一直自旋检测是否能获取资源，适用于得到锁以后处理时间\u0026lt; 线程切换时间的场景，得到锁处理逻辑最好别有IO操作或者文件流操作\n自旋锁是通过 cpu的 CAS函数，在用户态就完成了加锁和解锁操作，所以不会有上下文的切换，相比互斥锁来说，会快一点\n一般加锁的过程有两步\n查看锁的状态，如果锁是空闲的，那么执行第二步 将锁设置为当前线程持有 自旋锁加锁失败以后线程会 忙等待，直到它能 拿到锁\n9.3 读写锁 实现在 rwlock.h中\n读锁是 共享锁概念，其他锁去读的时候读取的是共享的资源，\n写锁是 独占概念，其他锁只能等待抢占到的锁释放资源，适用于读多写少场景\n所以更具场景可以分为 读优先锁和 写优先锁\n9.3.1 读优先锁 读优先锁对于读线程并发性更好，但是也不是没有问题，我们试想一下，如果一直有 读线程获取锁，那么 写线程就会被饿死\n9.3.2 写优先锁 写优先锁可以保证 写线程不被饿死，但是如果一直有 写线程获取，那么 读线程也会被饿死\n所以不管是优先读锁还是写锁，对方都可能被饿死，所以我们不偏袒任何一方，搞个 公平读写锁\n9.3.3 公平读写锁 用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的规则加锁，这样读线程一样能并发，也不会出现饥饿现象\n9.4 乐观锁和悲观锁区别 悲观锁做事比较悲观，他认为多线程同时修改共享资源的概率比较高，所以在访问资源之前都会先上一把锁。\n乐观锁正好相反，他认为多线程同时修改共享资源的概率比较低，所以会让先修改完资源，然后在判断是不是有冲突，有没有其他的线程在修改资源，如果有的话就直接放弃本次操作，\n互斥锁、自旋锁、读写锁，都是属于 悲观锁\n9.5 重入锁 就是能一条线程上能重复获取的锁，而不导致死锁\n10. cluster 模式 在每个 skynet 节点（单个进程）内，启动一个叫 clusterd 的服务。所有需要跨进程的消息投递都先把消息投递到这个服务上，再由它来转发到网络。\n首选通过 clustername.lua配置表配置好全部的 cluster节点 在所有要发现的节点上执行 require\u0026quot;skynet.cluster\u0026quot; 用 cluster.open建立自己的监听好让别的节点和自己建立 tcp通道连接 通过 cluster.register注册 create的 service 远程节点利用 cluster.query()来得到注册过的节点 通过 cluster.call skynet.call cluster.send skynet.send来调用远程 function1 function2函数 11 简易的mmo 架构 12 网关服务 main.lua 建立 watchdog watchdog 通过 skynet.start() 创建 gateService gateService并通过 rpc调用 watchdogService socket.open 函数 watchdogService 通过 socket.open 创建 agenService agenService 把 fd forward给 gateService client 发送请求给 gateService gateService 把请求重定向给 agentService agentService 把处理结果返回给 client 13 协程 coroutine 实现 详细代码见 lcorolib.c\n13.1 派发消息 function skynet.dispatch_message(...) -- 当前消息处理 local succ, err = pcall(raw_dispatch_message,...) while true do -- 顺序执行skynet.fork 创建的协程 if fork_queue.h \u0026gt; fork_queue.t then -- queue is empty fork_queue.h = 1 fork_queue.t = 0 break end -- pop queue local h = fork_queue.h local co = fork_queue[h] fork_queue[h] = nil fork_queue.h = h + 1 local fork_succ, fork_err = pcall(suspend,co,coroutine_resume(co)) if not fork_succ then if succ then succ = false err = tostring(fork_err) else err = tostring(err) .. \u0026#34;\\n\u0026#34; .. tostring(fork_err) end end end assert(succ, tostring(err)) end 13.2 处理当前消息 local function raw_dispatch_message(prototype, msg, sz, session, source) -- skynet.PTYPE_RESPONSE = 1, read skynet.h if prototype == 1 then -- 对回应类型的包处理 local co = session_id_coroutine[session] if co == \u0026#34;BREAK\u0026#34; then session_id_coroutine[session] = nil elseif co == nil then unknown_response(session, source, msg, sz) else local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;resume\u0026#34;) end session_id_coroutine[session] = nil suspend(co, coroutine_resume(co, true, msg, sz, session)) end else local p = proto[prototype] -- 找到对应的解析协议 if p == nil then if prototype == skynet.PTYPE_TRACE then -- trace next request trace_source[source] = c.tostring(msg,sz) elseif session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, prototype) end return end local f = p.dispatch -- 获取处理的函数 if f then local co = co_create(f) -- 获取协程 session_coroutine_id[co] = session session_coroutine_address[co] = source local traceflag = p.trace if traceflag == false then -- force off trace_source[source] = nil session_coroutine_tracetag[co] = false else local tag = trace_source[source] if tag then trace_source[source] = nil c.trace(tag, \u0026#34;request\u0026#34;) session_coroutine_tracetag[co] = tag elseif traceflag then -- set running_thread for trace running_thread = co skynet.trace() end end suspend(co, coroutine_resume(co, session,source, p.unpack(msg,sz))) else trace_source[source] = nil if session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, proto[prototype].name) end end end end 13.3 创建协程 local function co_create(f) local co = tremove(coroutine_pool) -- 从协程池中获取协程 if co == nil then --如果没有了 co = coroutine_create(function(...) -- 创建新的 f(...) --执行回调函数，不会立马执行只会调用coroutine.resume时候才会执行 while true do -- 为了能够复用刚创建的协成，下面需要对协程进行初始化和回收 local session = session_coroutine_id[co] if session and session ~= 0 then local source = debug.getinfo(f,\u0026#34;S\u0026#34;) skynet.error(string.format(\u0026#34;Maybe forgot response session %s from %s : %s:%d\u0026#34;, session, skynet.address(session_coroutine_address[co]), source.source, source.linedefined)) end -- coroutine exit local tag = session_coroutine_tracetag[co] if tag ~= nil then if tag then c.trace(tag, \u0026#34;end\u0026#34;) end session_coroutine_tracetag[co] = nil end local address = session_coroutine_address[co] if address then session_coroutine_id[co] = nil session_coroutine_address[co] = nil end -- recycle co into pool f = nil coroutine_pool[#coroutine_pool+1] = co -- recv new main function f f = coroutine_yield \u0026#34;SUSPEND\u0026#34; f(coroutine_yield()) end end) else -- pass the main function f to coroutine, and restore running thread local running = running_thread coroutine_resume(co, f) running_thread = running end return co end 13.4 协程挂起 -- suspend is local function function suspend(co, result, command) if not result then -- 执行co失败以后的处理 local session = session_coroutine_id[co] if session then -- coroutine may fork by others (session is nil) local addr = session_coroutine_address[co] if session ~= 0 then -- only call response error local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;error\u0026#34;) end c.send(addr, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) end session_coroutine_id[co] = nil end session_coroutine_address[co] = nil session_coroutine_tracetag[co] = nil skynet.fork(function() end) -- trigger command \u0026#34;SUSPEND\u0026#34; local tb = traceback(co,tostring(command)) coroutine.close(co) error(tb) end if command == \u0026#34;SUSPEND\u0026#34; then -- 挂起操作 return dispatch_wakeup() -- 如果有能够被唤醒的协程，就wakeup elseif command == \u0026#34;QUIT\u0026#34; then coroutine.close(co) -- service exit return elseif command == \u0026#34;USER\u0026#34; then -- See skynet.coutine for detail error(\u0026#34;Call skynet.coroutine.yield out of skynet.coroutine.resume\\n\u0026#34; .. traceback(co)) elseif command == nil then -- debug trace return else error(\u0026#34;Unknown command : \u0026#34; .. command .. \u0026#34;\\n\u0026#34; .. traceback(co)) end end\t13.5 协程销毁 主要是因为这种基础类型 LUA_TTHREAD来决定怎么销毁\nLUA_TTHREAD 介绍:\n除了主线程以外，其它线程和其它 Lua对象一样都是垃圾回收的对象。等待GC回收，当新建一个线程时，线程会压入栈，这样能确保新线程不会成为垃圾\n每次调用 lua_newstate的时候都会创建一个新的 luastate,不同的 luastate完全独立，之间不共享任何数据\n创建一个线程就拥有一个独立的执行栈了，但是它与其线程共用虚拟机的全局状态\n协程提供了新的 api接口和 lua_resetthread, coroutine.close 会使协程进入死亡状态,并且关闭所有的 close变量\n14 send.call 流程 15 API 相关 15.1 cluster cluster.call(node, address, ...) --远程调用node中的addr cluster.send(node, address, ...) --send调用远程node的addr cluster.open(port) --本地打开(监听)一个cluster结点，使其能在cluster中的其他结点发现 cluster.reload(config) --重载远程结点配置表，表中的cluster结点都open过，则可以通讯 cluster.proxy(node, name) --设置远程结点的代理，使得可以像调用本地RPC一样调用远程结点 cluster.snax(node, name, address) --生成一个远程的snax服务对象 cluster.register(name, addr) --注册一个cluster结点 cluster.query(node, name) --查找远程结点中注册过的结点是否存在 15.2 harbor harbor.link(id) --用来监控一个 slave 是否断开。如果 harbor id 对应的 slave 正常，这个 api 将阻塞。当 slave 断开时，会立刻返回。 harbor.linkmaster() --用来在 slave 上监控和 master 的连接是否正常。这个 api 多用于异常时的安全退出（因为当 slave 和 master 断开后，没有手段可以恢复）。 harbor.connect(id) --和 harbor.link 相反。如果 harbor id 对应的 slave 没有连接，这个 api 将阻塞，一直到它连上来才返回。 harbor.queryname(name) --可以用来查询全局名字或本地名字对应的服务地址。它是一个阻塞调用。 harbor.globalname(name, handle) --注册一个全局名字。如果 handle 为空，则注册自己。skynet.name 和 skynet.register 是用其实现的。 15.3 构建服务的一些基础接口 skynet.getenv(varName) --conf配置信息已经写入到注册表中，通过该函数获取注册表的变量值 skynet.setenv(varName, varValue) --设置注册表信息，varValue一般是number或string，但是不能设置已经存在的varname skynet.error(...) --打印函数 skynet.start(func) --用 func 函数初始化服务，并将消息处理函数注册到 C 层，让该服务可以工作。 skynet.init(func) --若服务尚未初始化完成，则注册一个函数等服务初始化阶段再执行；若服务已经初始化完成，则立刻运行该函数。 skynet.exit() --结束当前服务 skynet.self() --获取当前服务的句柄handler skynet.address(handler) --将handle转换成字符串 skynet.abort() --退出skynet进程 skynet.kill(address) ----强制杀死其他服务。可以用来强制关闭别的服务。但强烈不推荐这样做。因为对象会在任意一条消息处理完毕后，毫无征兆的退出。所以推荐的做法是，发送一条消息，让对方自己善后以及调用 skynet.exit 。注：skynet.kill(skynet.self()) 不完全等价于 skynet.exit() ，后者更安全。\t15.4 普通服务 skynet.newservice(luaServerName, ...) 15.5 全局唯一服务 skynet.uniqueservice(servicename, ...) --当前的skynet节点全局唯一 skynet.uniqueservice(true, servicename, ...) --所有的节点全局唯一 skynet.queryservice(servicename, ...) --当前的skynet节点中查找 skynet.queryservice(true, servicename, ...) --所有的节点中查找 15.6 别名 别名分两种：\n本地别名 代表只能在当前 skynet节点使用，本地别名用 .开头 全局别名 可以在所有的 skynet中使用 全局别名不能以 . 开头 skynet.register(aliasname) --给当前服务定一个别名，可以是全局别名，也可以是本地别名 skynet.name(aliasname, servicehandler) --给指定servicehandler的服务定一个别名，可以是全局别名，也可以是本地别名 --[[ 查询别名为aliasname的服务,可以是全局别名也可以是本地别名， 1、当查询本地别名时，返回servicehandler，不存在就返回nil 2、当查询全局别名时，返回servicehandler，不存在就阻塞等待到该服务初始化完成 ]]-- skynet.harbor.queryname(aliasname) skynet.localname(aliasname) --查询本地别名为aliasname的服务，返回servicehandler，不存在就返回nil skynet.kill(handle) --杀死带别名服务 15.7 服务调度 skynet.sleep(time) --让当前的任务等待 time * 0.01s 。 skynet.fork(func, ...) --启动一个新的任务去执行函数 func , 其实就是开了一个协程，函数调用完成将返回线程句柄 虽然你也可以使用原生的coroutine.create来创建协程，但是会打乱skynet的工作流程 skynet.yield() --让出当前的任务执行流程，使本服务内其它任务有机会执行，随后会继续运行。 skynet.wait() --让出当前的任务执行流程，直到用 wakeup 唤醒它。 skynet.wakeup(co) --唤醒用 wait 或 sleep 处于等待状态的任务。 skynet.timeout(time, func) --设定一个定时触发函数 func ，在 time * 0.01s 后触发。 skynet.starttime() --返回当前进程的启动 UTC 时间（秒）。 skynet.now() --返回当前进程启动后经过的时间 (0.01 秒) 。 skynet.time() --通过 starttime 和 now 计算出当前 UTC 时间（秒）。 15.8 消息类型 #define PTYPE_TEXT 0 --文本 #define PTYPE_RESPONSE 1 --表示一个回应包 #define PTYPE_MULTICAST 2 --广播消息 #define PTYPE_CLIENT 3 --用来处理网络客户端的请求消息 #define PTYPE_SYSTEM 4 --系统消息 #define PTYPE_HARBOR 5 --集群内其他的 skynet 节点发来的消息 #define PTYPE_SOCKET 6 --套接字消息 #define PTYPE_ERROR 7 --错误消息，一般服务退出的时候会发送error消息给关联的服务 #define PTYPE_QUEUE 8 --队列方式 #define PTYPE_DEBUG 9 --调试 #define PTYPE_LUA 10 --lua类型的消息，最常用 #define PTYPE_SNAX 11 --snax服务消息 #define PTYPE_TAG_DONTCOPY 0x10000 --禁止拷贝 #define PTYPE_TAG_ALLOCSESSION 0x20000 --分配新的 session 15.9 打包解包 skynet.pack(...) --打包 skynet.unpack(msg, sz) --解包 15.10 发送消息 -- 发送无需响应的消息 skynet.send(addr, type, ...) --用 type 类型向 addr 发送未打包的消息。该函数会自动把...参数列表进行打包，默认情况下lua消息使用skynet.pack打包。addr可以是服务句柄也可以是别名。自动打包与解包。） skynet.rawsend(addr, type, msg, sz) --用 type 类型向 addr 发送一个打包好的消息。addr可以是服务句柄也可以是别名。（需要自己打包与解包） -- 发送必须响应的消息 skynet.call(addr, type, ...) --用默认函数打包消息，向addr发送type类型的消息并等待返回响应，并对回应信息进行解包。（自动打包与解包。） skynet.rawcall(addr, type, msg, sz) --直接向addr发送type类型的msg,sz并等待返回响应，不对回应信息解包。（需要自己打包与解包） 15.11 响应消息 -- 同一个协成处理 skynet.ret() --目标服务消息处理后需要通过该函数将结果返回 skynet.retpack(...) --将消息用skynet.pack 打包，并调用 ret 回应。 --不在一个协成处理 local response = skynet.response(pack)--参数pack指定应答打包函数，不填默认使用skynet.pack, 必须根据接收到消息的打包函数一致 返回值是一个闭包函数 response(ok, ...) --参数ok的值可以是 \u0026#34;test\u0026#34;、true、false，为\u0026#34;test\u0026#34;时表示检查接收响应的服务是否存在，为true时表示发送应答PTYPE_RESPONSE，为false时表示发送PTYPE_ERROR错误消息。 15.12 消息冲入时序问题 skynet.queue() --帮助你回避这些服务重入或者伪并发引起的复杂性,但是明显降低了服务的并发处理能力，所以使用执行队列的时候尽量缩小临界区的颗粒度大小 15.13 协议转换 skynet.forward_type() --需要提供一张消息转换映射表forward_map, 其他的方法与skynet.start一样 15.14 伪造消息 skynet.redirect(dest,source,typename, session, msg, sz) --使用source服务地址，发送typename类型的消息给dest服务，不需要接收响应，（source，dest只能是服务ID）msg sz一般使用skynet.pack打包生成 15.15 组播 skynet.multicast -- 当组播的数据量较大时候可以节省内部的带宽 15.16 socket --建立一个 TCP 连接。返回一个数字 id 。 socket.open(address, port) --关闭一个连接，这个 API 有可能阻塞住执行流。因为如果有其它 coroutine --正在阻塞读这个 id 对应的连接，会先驱使读操作结束，close 操作才返回。 socket.close(id) --在极其罕见的情况下，需要粗暴的直接关闭某个连接，而避免 socket.close 的阻塞等待流程，可以使用它。 socket.close_fd(id) --强行关闭一个连接。和 close 不同的是，它不会等待可能存在的其它 coroutine 的读操作。 --一般不建议使用这个 API ，但如果你需要在 __gc 元方法中关闭连接的话， --shutdown 是一个比 close 更好的选择（因为在 gc 过程中无法切换 coroutine）。与close_fd类似 socket.shutdown(id) --[[ 从一个 socket 上读 sz 指定的字节数。 如果读到了指定长度的字符串，它把这个字符串返回。 如果连接断开导致字节数不够，将返回一个 false 加上读到的字符串。 如果 sz 为 nil ，则返回尽可能多的字节数，但至少读一个字节（若无新数据，会阻塞）。 --]] socket.read(id, sz) --从一个 socket 上读所有的数据，直到 socket 主动断开，或在其它 coroutine 用 socket.close 关闭它。 socket.readall(id) --从一个 socket 上读一行数据。sep 指行分割符。默认的 sep 为 \u0026#34;\\n\u0026#34;。读到的字符串是不包含这个分割符的。 --如果另外一端就关闭了，那么这个时候会返回一个nil，如果buffer中有未读数据则作为第二个返回值返回。 socket.readline(id, sep) --等待一个 socket 可读。 socket.block(id) --把一个字符串置入正常的写队列，skynet 框架会在 socket 可写时发送它。 socket.write(id, str) --把字符串写入低优先级队列。如果正常的写队列还有写操作未完成时，低优先级队列上的数据永远不会被发出。 --只有在正常写队列为空时，才会处理低优先级队列。但是，每次写的字符串都可以看成原子操作。 --不会只发送一半，然后转去发送正常写队列的数据。 socket.lwrite(id, str) --监听一个端口，返回一个 id ，供 start 使用。 socket.listen(address, port) --[[ accept 是一个函数。每当一个监听的 id 对应的 socket 上有连接接入的时候，都会调用 accept 函数。 这个函数会得到接入连接的 id 以及 ip 地址。你可以做后续操作。 每当 accept 函数获得一个新的 socket id 后，并不会立即收到这个 socket 上的数据。 这是因为，我们有时会希望把这个 socket 的操作权转让给别的服务去处理。accept(id, addr) ]]-- socket.start(id , accept) --[[ 任何一个服务只有在调用 socket.start(id) 之后，才可以读到这个 socket 上的数据。 向一个 socket id 写数据也需要先调用 start 。 socket 的 id 对于整个 skynet 节点都是公开的。也就是说，你可以把 id 这个数字 通过消息发送给其它服务，其他服务也可以去操作它。skynet 框架是根据调用 start 这个 api 的位置来决定把对应 socket 上的数据转发到哪里去的。 --]] socket.start(id) --清除 socket id 在本服务内的数据结构，但并不关闭这个 socket 。 --这可以用于你把 id 发送给其它服务，以转交 socket 的控制权。 socket.abandon(id) --[[ 当 id 对应的 socket 上待发的数据超过 1M 字节后，系统将回调 callback 以示警告。 function callback(id, size) 回调函数接收两个参数 id 和 size ，size 的单位是 K 。 如果你不设回调，那么将每增加 64K 利用 skynet.error 写一行错误信息。 --]] socket.warning(id, callback) 15.17 socketChannel 用来支持双向传输，异步非堵塞处理数据 15.18 dns skynet.dns --调用了系统 api getaddrinfo ，有可能阻塞住整个 socket 线程 所以skynet封装了这个接口来解决dns查询时候造成的线程堵塞问题 16 skynet 的通信调试pack 客户端按大小端打包成二进制\nlocal result = string.pack(\u0026#34;\u0026gt;s2\u0026#34;,\u0026#34;string2pack\u0026#34;) pack \u0026gt; 表示按大端顺序。s2 表示按照2个字节打包。 我们知道string由char组成。1个char 是 0-255 之间的数，2^8 ,1char=8byte 需要注意的是，他除了被打包的部分之外，还会在前面加2个字节，表示长度。 如果要打包一个数字则需要转换。由2种办法 string.pack(\u0026#34;I2\u0026#34;,number)，会在前面二进制加2位表示长度的东西。 socket发送\nsocket.send 服务端接收\ngateserver已经有接收的代码了。 注意的是，socket会自动按pack的数据分段接收。也就是会根据pack的前面2位得到size。根据size去接收后面的数据。然后向上传递一份message。 接收到的message已经是去掉了前面2位的数据。 客户端接收\n户端接收到的数据目前我是用skynet提供的“client.socket”.没有netpack可用。 接收到的数据需要自行去除前面的2个字节的数据（string.pack产生的）。 ","permalink":"https://frog-game.github.io/posts/blog/skynet/","summary":"1. linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 2. 网络流程图 2.1 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Soc","title":"skynet赏析"},{"content":" 演示\n安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana\n1. zabbix 6.0 1.1. 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 1.2. 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 1.3. 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-sql-scripts zabbix-agent 1.4. 创建初始数据库 mysql -uroot -p123456 mysql\u0026gt; create database zabbix character set utf8mb4 collate utf8mb4_bin; mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@`%`; mysql\u0026gt; quit; 1.5. 导入初始架构和数据，系统将提示您输入新创建的密码[默认密码现在设置为 123456 zcat /usr/share/doc/zabbix-sql-scripts/mysql/server.sql.gz | mysql -uzabbix -p -h10.40.38.67 zabbix # 指定本地的IP地址，不默认就会指向本地localhost 如果报ERROR 2003 (HY000): Can't connect to MySQL server on '10.40.38.67:3306' (111) 看第5章mysql操作指导，多半是因为权限和密码问题\n为Zabbix server配置数据库 sudo vim /etc/zabbix/zabbix_server.conf 修改 DBPassword=123456 1.6. 启动Zabbix server和agent进程 sudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server sudo systemctl enable zabbix-server zabbix-agent apache2 grafana-server 1.7. 连接web前端[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http://10.40.38.67/zabbix 默认的用户名是Admin(A是大写)，Password：zabbix 1.8. 修改时区 sudo vi /etc/apache2/conf-enabled/zabbix.conf 修改标准时区为 Asia/Shanghai 1.9. 中文显示 sudo apt install language-pack-zh-hans #安装中文语言包 sudo vim /etc/locale.gen #找到zh_CN.UTF-8 UTF-8 并取消#号注释，然后保存并退出 sudo locale-gen #编译语言包 sudo vim /etc/default/locale #修改默认语言为中文，将原来的内容改为 LANG=zh_CN.UTF-8 1.10. 安装出现的问题 1.10.1. Minimum required size of PHP post is 16M (configuration option \u0026ldquo;post_max_size\u0026rdquo;). 解决步骤：\nsudo vi /etc/php/8.1/apache2/php.ini post_max_size8M 16M\nmax_execution_time30 300\nmax_input_time60 300\ndate.timezone = Asia/Shanghai\nsudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server 1.10.2. ERROR 1396 (HY000): Operation CREATE USER failed for 'zabbix'@'%' mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; ERROR 1396 (HY000): Operation CREATE USER failed for \u0026#39;zabbix\u0026#39;@\u0026#39;%\u0026#39; 原因分析：\n已经存在了zabbix用户 在执行删除zabbix用户的时候没有删除干净 解决方法：\n重新进行删除。\ndrop user zabbix@\u0026#39;%\u0026#39;; flush privileges; 1.11. 卸载 zabbix 删除软件\nsudo apt-get --purge remove zabbix-server-mysql -y sudo apt-get autoremove zabbix-server-mysql -y sudo apt-get --purge remove zabbix-frontend-php -y sudo apt-get autoremove zabbix-frontend-php -y sudo apt-get --purge remove abbix-apache-conf -y sudo apt-get autoremove abbix-apache-conf -y sudo apt-get --purge remove zabbix-agent -y #删除软件其配置 sudo apt-get autoremove zabbix-agent -y #删除软件依赖包 清理数据\nsudo dpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 删除以上apt-get下载的软件包\nsudo apt-get autoclean 删除缓存的所有软件包\nsudo apt-get clean 删除其他软件依赖的但现在已不用的软件包（保留配置文件）\n```sh sudo apt-get autoremove ``` 查询出冗余文件并删除\nsudo find / -name zabbix 执行rm-rf 删除冗余文件\nsudo rm -rf /run/zabbix sudo rm -rf /etc/zabbix sudo rm -rf /usr/share/zabbix sudo rm -rf /var/log/zabbix sudo rm -rf /var/lib/mysql/zabbix 删除包含zabbix关键字的文件或者文件夹\n```sh sudo find / -name \u0026quot;zabbix*\u0026quot; | sudo xargs rm -rf ``` grafana 1.12. 下载grafana deb安装包 sudo apt-get install -y adduser libfontconfig1 sudo wget https://dl.grafana.com/enterprise/release/grafana-enterprise_8.5.4_amd64.deb sudo dpkg -i grafana-enterprise_8.5.4_amd64.deb 1.13. 启动grafana-server sudo systemctl restart grafana-server sudo systemctl enable grafana-server 安装zabbix插件 grafana-cli plugins list-remote sudo grafana-cli plugins install alexanderzobnin-zabbix-app #重启grafana-server sudo systemctl restart grafana-server 也可以在grafana-\u0026gt;plugins这里安装\n1.14. 登录grafana服务器[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http:/10.40.38.67:3000/ #默认用户名和密码为admin、admin 1.15. grafana 配置zabbix数据源 1.16. grafana 配置zabbix监控面板 在点击完new dashboard 按钮以后 按ctrl + s 保存一个自己定义的仪表盘\n1.17. grafana增加主题 安装插件：grafana-cli plugins install yesoreyeram-boomtheme-panel grafana主题地址：https://github.com/charles1503/grafana-theme/tree/master/CSS/themes/grafanas grafana更改主题教程：https://www.bilibili.com/read/cv7004400 视频教程：https://cloud.tencent.com/developer/video/11330 http://10.40.38.67:3000/public/themes/aquamarine.css 具体操作步骤：\n创建一个目录，用于存放下载对应主题的css文件\nsudo mkdir /usr/share/grafana/public/themes/ cd /usr/share/grafana/public/themes/ 使用一个for 循环下载对应的所有主题css文件\nfor f in grafana-base.css aquamarine.css hotline.css dark.css plex.css space-gray.css organizr-dashboard.css;do wget https://raw.githubusercontent.com/505384662/grafana-theme/master/CSS/themes/grafana/$f;done 为Grafana安装社区插件Boom Theme\nsudo grafana-cli plugins install yesoreyeram-boomtheme-panel sudo systemctl restart grafana-server 在Dashboard中添加Boom Theme\n1.18. grafana 主题修改地址 cd /usr/share/grafana/public/themes 1.19. grafana 加时钟 grafana-cli plugins install grafana-clock-panel systemctl restart grafana-server 1.20. grafana flowcharting安装 sudo grafana-cli plugins install agenty-flowcharting-panel sudo systemctl restart grafana-server grafana 修改模板地址 https://grafana.com/grafana/dashboards zabbix 修改配置地址：http://192.168.70.130/zabbix/setup.php zabbix 展示地址：http://192.168.70.130/zabbix/zabbix.php?action=dashboard.view grafana 展示地址: http://192.168.70.130:3000/d/tYxzFya7z/test_zabbix?orgId=1 1.21. Grafana 匿名访问（免登录） 修改Grafana配置文件\n在Grafana的配置文件 /etc/grafana/grafana.ini 中，找到 [auth.anonymous] 配置块，将其下的匿名访问控制 enabled 设置为 true，组织权限设置为 Viewer\nViewer:**只读**模式\nEditor:**可编辑**模式\nAdmin:**管理员**模式\n#################################### Anonymous Auth ###################### # Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false disable_login_form = true [auth.anonymous] # enable anonymous access enabled = true # specify organization name that should be used for unauthenticated users org_name = Main Org. # specify role for unauthenticated users org_role = Viewer 重启Grafana服务\n修改完配置文件，重启Grafana服务，命令如下：\nsudo systemctl restart grafana-server 1.22. 卸载 grafana 查找到安装软件名\nsudo dpkg -l | grep grafana 删除软件\n```sh sudo dpkg -r grafana-enterprise ``` 查询出冗余文件并删除\nfind / -name grafana 用rm-rf 命令删除\nrm -rf /etc/grafana rm -rf /usr/share/grafana rm -rf /usr/share/grafana/public/themes/grafana-theme/CSS/themes/grafana rm -rf /var/log/grafana rm -rf /var/lib/grafana 2. apache2 2.1. apache2启动报错 大致意思没有导入apache 环境变量 解决办法:\nsource /etc/apache2/envvars 还是报错\n大致意思是80端口被占用了 我选择的方法是kill占用进程在重启\nroot@hls:/root# netstat -lnp|grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 950/nginx: master p tcp6 0 0 :::80 :::* LISTEN 950/nginx: master p unix 2 [ ACC ] STREAM LISTENING 41930 1228/zabbix-plugin_ /tmp/plugin835680808 root@hls:/root# kill -9 950 root@hls:/root# systemctl restart zabbix-server zabbix-agent apache2 2.2. 卸载apache2 删除软件\n//1. 删除apache sudo apt-get --purge remove apache2 sudo apt-get --purge remove apache2.2-common //2.找到没有删除掉的配置文件，一并删除 sudo find /etc -name \u0026#34;*apache*\u0026#34; |xargs rm -rf sudo rm -rf /var/www sudo rm -rf /etc/libapache2-mod-jk //3.删除关联，这样就可以再次用apt-get install apache2 重装了 #dpkg -l |grep apache2|awk \u0026#39;{print $2}\u0026#39;|xargs dpkg -P//注意：这一步可能会报错，但也没关系 查询出冗余文件并删除\nsudo find / -name apache2 用rm -rf 命令删除\n3. Nginx 3.1. 官网下载地址 http://nginx.org/en/download.html 3.2. 一些环境准备 安装编译工具\nsudo apt-get install build-essential 安装编译工具 安装gcc什么的好便于下面编译安装 安装pcre包\nsudo apt-get update sudo apt-get install libpcre3 libpcre3-dev sudo apt-get install openssl libssl-dev 安装 zlib 库\nsudo apt install zlib1g-dev 3.3. 下载安装Nginx sudo wget http://nginx.org/download/nginx-1.21.6.tar.gz sudo tar -xzvf nginx-1.21.6.tar.gz cd nginx-1.21.6 sudo ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-stream --with-mail=dynamic #最好用 --prefix指定路径，便于后面删除[只需要删除prefix指定的文件夹就行了]，不指定的话后面删除比较麻烦 sudo make sudo make install 3.4. 制作软连接 ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 3.5. 配置环境变量 编辑/etc/profile并且追加Nginx的环境变量 export NGINX_HOME=/usr/local/nginx export PATH=$PATH:$NGINX_HOME/sbin 3.5.1. 生效环境变量 source /etc/profile 3.6. 测试是否安装成功 nginx -v 3.7. 启动Nginx sudo nginx 3.8. 强制停止Nginx sudo pkill -9 nginx 3.9. 查看Nginx进程 ps aux|grep nginx 3.10. 配置防火墙 sudo ufw allow \u0026#39;Nginx Full\u0026#39; 3.11. 验证防火墙是否允许 出现下面两种情况都认为可以 Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere Nginx Full ALLOW Anywhere 22/tcp (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) sudo ufw status 状态：不活动 3.12. 测试访问 http://192.168.70.132:7000 3.13. Nginx 相关文件位置 nginx path prefix: \u0026#34;/usr/local/nginx\u0026#34; nginx binary file: \u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; nginx modules path: \u0026#34;/usr/local/nginx/modules\u0026#34; nginx configuration prefix: \u0026#34;/usr/local/nginx/conf\u0026#34; nginx configuration file: \u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; nginx pid file: \u0026#34;/usr/local/nginx/logs/nginx.pid\u0026#34; nginx error log file: \u0026#34;/usr/local/nginx/logs/error.log\u0026#34; nginx http access log file: \u0026#34;/usr/local/nginx/logs/access.log\u0026#34; nginx http client request body temporary files: \u0026#34;client_body_temp\u0026#34; nginx http proxy temporary files: \u0026#34;proxy_temp\u0026#34; nginx http fastcgi temporary files: \u0026#34;fastcgi_temp\u0026#34; nginx http uwsgi temporary files: \u0026#34;uwsgi_temp\u0026#34; nginx http scgi temporary files: \u0026#34;scgi_temp\u0026#34; 卸载 Nginx sudo rm -rf /usr/local/nginx sudo rm -rf /usr/local/nginx/sbin/nginx #软连接也记得删除 如果想完全干净，/etc/profile 配置文件中指定的环境变量也可以删除 4. mysql 4.1. 安装mysql sudo apt update sudo apt install mysql-server 安装完成后，MySQL服务将自动启动。要验证MySQL服务器正在运行，请输入：\nsudo systemctl status mysql 彻底卸载mysql方法 查看依赖包\ndpkg --list | grep mysql 先依次执行以下命令\nsudo apt-get remove mysql-common sudo apt-get autoremove --purge mysql-server-5.0 # 卸载 MySQL 5.x 使用, 非5.x版本可跳过该步骤 sudo apt-get autoremove --purge mysql-server 然后再用\ndpkg --list | grep mysql 查看一下依赖包最后用下面命令清除残留数据\ndpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 查看从MySQL APT安装的软件列表, 执行后没有显示列表, 证明MySQL服务已完全卸载\ndpkg -l | grep mysql | grep i 博客地址\nhttps://blog.csdn.net/PY0312/article/details/89481421 MySQL在Ubuntu上启动出错Could not open ‘abstractions/mysql‘ rm -rf /etc/apparmor.d/abstractions/mysql rm -rf /etc/apparmor.d/cache/usr.sbin.mysqld find / -name \u0026#39;mysql*\u0026#39; -exec rm -rf {} \\; 4.2. 连接MySql报错“can\u0026rsquo;t connect to local mysql server through socket \u0026lsquo;/var/run/mysqld/mysqld.sock\u0026rsquo; cd /etc/init.d sudo service mysql stop sudo service mysql start mysql Ubuntu 20.04 Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost 首先输入以下指令 获取密码：\nsudo cat /etc/mysql/debian.cnf 再输入以下指令进入mysql\n查询user关键字段\nselect user, authentication_string,plugin,Host from mysql.user; 修改密码格式\nuse mysql; update user set plugin=\u0026#39;mysql_native_password\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 修改密码\nuse mysql; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; flush privileges; 输入\nmysql -uroot -p123456; 查看效果 让别的ip能连上wsl数据库\nuse mysql; update user set Host=\u0026#39;%\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 输入\nselect user, authentication_string,plugin,Host from mysql.user; 查看效果\n开启远程访问\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf # 注释 bind-address = 127.0.0.1 重启mysql\nsudo service mysql restart 效果\n5. ELK 5.1. 一些准备 5.1.1. 官网地址 https://www.elastic.co/guide/en/elasticsearch/reference/8.0/deb.html#deb-repo 5.1.2. 虚拟机 想要多开最好是克隆一份出来 比如2就是克隆的1的镜像\n修改 克隆的虚拟机网卡地址\nsudo vim /etc/netplan/00-installer-config.yaml 修改内容:\nnetwork: ethernets: ens33: #配置的网卡的名称 addresses: [192.168.70.130/24] #配置的静态ip地址和掩码 dhcp4: no #关闭DHCP，如果需要打开DHCP则写yes optional: true gateway4: 192.168.70.2 #网关地址 nameservers: addresses: [192.168.70.2,114.114.114.114] #DNS服务器地址，多个DNS服务器地址需要用英文逗号分隔开 version: 2 renderer: networkd #指定后端采用systemd-networkd或者Network Manager，可不填写则默认使用systemd-workd 使配置生效\nsudo netplan apply 注意事项\n1、ip地址和DNS服务器地址需要用[]括起来，但是网关地址不需要 2、注意每个冒号后边都要先加一个空格 3、注意每一层前边的缩进，至少比上一层多两个空格 5.1.3. 安装java环境 安装java sudo apt install openjdk-8-jdk 查看java 版本\nsudo java -version 查看 java 路径\nsudo which java ls -l /usr/bin/java 看看这是否是个软连接，找出这个软连接指向的路径\nls -l /usr/bin/java 的确为软连接，继续往下找指向的路径\n至此，java 的安装路径即为 /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n配置 java 环境\nsudo vim /etc/profile 在弹出的 vim 编辑器中输入\n# JAVA JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH esc 退出编辑模式，输入 :x后，单击回车退出。\n在终端输入\nsource /etc/profile 使之前的配置生效。\n验证\njava -version\n$JAVA_HOME/bin/java -version\n5.1.4. python3 [不是必须装主要是想使用 json.tool 格式化输出]\n安装python3.8\nsudo apt-get install python3.8 建立软连接\nsudo ln -s /usr/bin/python3.8 /usr/bin/python 如果想要删除软连接\nsudo rm -rf /usr/bin/python 格式化输出\ncurl -XGET http://192.168.70.131:9200/_mapping | python -m json.tool 5.2. Elasticsearch 5.2.1. 基础知识 和关系型数据库的比较 DBMS Elasticsearch database Index table type(在7.0之后type为固定值_doc) Row Document Column Field Schema Mapping SQL DSL(Descriptor Structure Language) 安装Elasticsearch deb包安装方式\nsudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb sudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb.sha512 shasum -a 512 -c elasticsearch-8.2.2-amd64.deb.sha512 sudo dpkg -i elasticsearch-8.2.2-amd64.deb 执行**sudo dpkg -i elasticsearch-8.2.2-amd64.deb** 回生成超级用户密码 0NgzdrlHquc1YdXrQout\n--------------------------- Security autoconfiguration information ------------------------------ Authentication and authorization are enabled. TLS for the transport and HTTP layers is enabled and configured. The generated password for the elastic built-in superuser is : 0NgzdrlHquc1YdXrQout If this node should join an existing cluster, you can reconfigure this with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token \u0026lt;token-here\u0026gt;\u0026#39; after creating an enrollment token on your existing cluster. You can complete the following actions at any time: Reset the password of the elastic built-in superuser with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\u0026#39;. Generate an enrollment token for Kibana instances with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\u0026#39;. Generate an enrollment token for Elasticsearch nodes with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\u0026#39;. ------------------------------------------------------------------------------------------------- 生成 ca 、生成 证书\n# 生成 ca # 根据提示： # 输入 ca 的密码（密码不要忘记，后面生成证书需要） # 输入生成 ca 的文件名（默认会让你输入 elastic-stack-ca.p12，这里就按照默认的来） sudo /usr/share/elasticsearch/bin/elasticsearch-certutil ca # 生成证书 # 根据提示： # 输入之前 ca 的密码 # 输入生成证书的文件名（默认让你输入 elastic-certificates.p12，这里就按照默认的来） # 输入生成证书的密码（密码不要忘记，这个密码在配置 ES keystore 的时候需要） # --ca 后面的文件是上面步骤生成的 elastic-stack-ca.p12 文件，如果修改了的话，这里也需要修改 sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 ​\t为了方便管理，一般将 ca 与证书放到 ~/.config/certs 目录下\n# 创建目录并移动 ca 与证书 sudo mkdir -p ~/.config/certs \u0026amp;\u0026amp; sudo mv /usr/share/elasticsearch/elastic-stack-ca.p12 /usr/share/elasticsearch/elastic-certificates.p12 ~/.config/certs 5.2.2. 启动 Elasticsearch ​\t[为了安全考虑Elasticsearch不允许使用root用户来启动]\n打开 elasticsearch 配置文件\nsudo vim /etc/elasticsearch/elasticsearch.yml #打开配置文件 修改 netWork.host, http.port 字段\nnetwork.host: 10.40.38.66 #注意 network.host:和10.40.38.66 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 http.port: 9200 #注意 http.port:和9200 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 因为是内网测试暂时关闭 xpack 安全验证方面选项,以后需要再去开启\n启动Elasticsearch\nsudo systemctl start elasticsearch.service 开机启动elasticsearch\nsudo systemctl enable elasticsearch.service 5.2.3. 连接grafana 5.2.4. Elasticsearch 操作命令 用jps命令关闭Elasticsearch\n$ jps | grep Elasticsearch 14542 Elasticsearch kill -9 14542 查看 Elasticsearch 端口\nsudo netstat -tnlp |grep java 检测是否启动成功\ncurl -XGET \u0026#39;http://192.168.70.131:9200/\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; 用journal 查看系统日志\nsudo journalctl -f 用 journal 查看elasticsearch 服务日志\nsudo journalctl --unit elasticsearch 用journal 查看elasticsearch 指定时间范围的日志\nsudo journalctl --unit elasticsearch --since \u0026#34;2022-02-01 18:17:16\u0026#34; 查看 elasticsearch.log\nsudo vim /var/log/elasticsearch/elasticsearch.log 5.2.5. Elasticsearch 卸载 # 查看安装的软件 sudo dpkg -l | grep elasticsearch #查看安装关联 sudo dpkg -L elasticsearch #移除安装软件 sudo dpkg -P elasticsearch #继续查看未卸载的目录和文件 sudo find / -name elasticsearch #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/elasticsearch.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/log/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /usr/share/elasticsearch #在此查看是否有关联的目录和文件 sudo find / -name elasticsearch 5.3. Logstash 5.3.1. 安装 Logstash 下载安装公共签名\nsudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Elasticsearch了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install logstash 5.3.2. 插件地址 https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html 5.3.3. 配置表字段解释 https://blog.csdn.net/weixin_42073629/article/details/110154037?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-110154037.pc_agg_new_rank\u0026amp;utm_term=logstash%E5%8F%82%E6%95%B0convert\u0026amp;spm=1000.2123.3001.4430 5.3.4. 查看安装的插件 sudo /usr/share/logstash/bin/logstash-plugin list 启动Lostash 修改 logstash.yml 配置\nsudo vim /etc/logstash/logstash.yml 5.3.5. 导入数据[利用logstash 直接分析movies.csv 传送给elasticsearch方式] ​\t收集流程: movies.csv-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n下载ml-latest.zip 数据\nsudo wget https://files.grouplens.org/datasets/movielens/ml-latest.zip 解压 ml-latest.zip\nsudo unzip ml-latest.zip 在/etc/logstash 目录下创建logstash.conf 文件\nsudo vim /etc/logstash/logstash.conf 把以下内容写入logstash.conf\ninput { file { #监听文件的路径 path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/movies.csv\u0026#34; #监听文件的起始位置，默认是end start_position =\u0026gt; \u0026#34;beginning\u0026#34; #监听文件读取信息记录的位置 sincedb_path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/db_path.log\u0026#34; } } filter { csv { separator =\u0026gt; \u0026#34;,\u0026#34; columns =\u0026gt; [\u0026#34;id\u0026#34;,\u0026#34;content\u0026#34;,\u0026#34;genre\u0026#34;,\u0026#34;@timestamp\u0026#34;] } mutate { # split =\u0026gt; { \u0026#34;genre\u0026#34; =\u0026gt; \u0026#34;|\u0026#34; } # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;] #删除无用字段 } mutate { split =\u0026gt; [\u0026#34;content\u0026#34;, \u0026#34;(\u0026#34;] #左括号分割 add_field =\u0026gt; { \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;%{[content][0]}\u0026#34;} #增加字段 add_field =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;%{[content][1]}\u0026#34;} #增加字段 } mutate { convert =\u0026gt; { #year 转换成整型 \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;integer\u0026#34; } strip =\u0026gt; [\u0026#34;title\u0026#34;] #去掉字段首尾的空格 # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;,\u0026#34;content\u0026#34;] #删除无用字段 } } output { elasticsearch { # 双引号中的内容为ES的地址，视实际情况而定 hosts =\u0026gt; \u0026#34;http://192.168.70.131:9200\u0026#34; index =\u0026gt; \u0026#34;movies\u0026#34; document_id =\u0026gt; \u0026#34;%{id}\u0026#34; #docId 等价于_id 字段 } stdout {} } 如果需要重新导入，先删除db_path.log 文件\nsudo rm -rf /var/lib/logstash/.lock sudo rm -rf /home/hls/downs/ml-latest/db_path.log sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf 报错\n执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults 那么就创建软连接\ncd /usr/share/logstash sudo ln -s /etc/logstash ./config 执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nLogstash could not be started because there is already another instance using the configured data directory. If you wish to run multiple instances, you must change the \u0026#34;path.data\u0026#34; setting. 那么就去 logstash.yml 中path.data 指定的路径上去删除.lock文件\ncd /var/lib/logstash sudo ls -a sudo rm -rf .lock 或者直接一句话\nsudo rm -rf /var/lib/logstash/.lock 5.3.6. 强制查看输出 logstash.conf 修改成你自己的文件 sudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --verbose --debug 5.3.7. 查看数据 用Kibana的命令行工具执行 GET _cat/indices 命令，就能看见导入到Elasticsearch的索引\n用kibana的命令行工具执行**GET /lua_cpu_monitor-2022.06.03/_search**命令,就能看见导入到Elasticsearch的数据\n5.3.8. 自动重新加载配置命令 logstash.conf 修改成你自己的文件\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.automatic 默认检测时间是**3**秒 可以通过下列命令修改 把\u0026lt;\u0026gt;号里面的2换成你想要的时间\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.interval \u0026lt;2\u0026gt; 5.3.9. 卸载Logstash # 查看安装的软件 sudo dpkg -l | grep logstash #查看安装关联 sudo dpkg -L logstash #移除安装软件 sudo dpkg -P logstash #继续查看未卸载的目录和文件 sudo find / -name logstash #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/logstash \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/logstash.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/logstash \u0026amp;\u0026amp; sudo rm -rf /var/log/logstash \u0026amp;\u0026amp; sudo rm -rf /usr/share/logstash #在此查看是否有关联的目录和文件 sudo find / -name logstash 5.4. Kibana 5.4.1. 安装Kibana 下载安装公共签名\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Kibana了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install kibana 5.4.2. 启动Kibana 打开kibana.yml 文档\nsudo vim /etc/kibana/kibana.yml 修改 server.port,server.host 字段\n启动\nsudo systemctl start kibana.service 自启动\nsudo systemctl enable kibana.service 查看 kibana日志\nsudo vim /var/log/kibana 用谷歌或者微软自带浏览器打开地址\nhttp://10.40.38.66:5601 5.4.3. 卸载Kibana # 查看安装的软件 sudo dpkg -l | grep kibana #查看安装关联 sudo dpkg -L kibana #移除安装软件 sudo dpkg -P kibana #继续查看未卸载的目录和文件 sudo find / -name kibana #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/kibana \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/kibana.* \u0026amp;\u0026amp; sudo rm -rf /etc/kibana #在此查看是否有关联的目录和文件 sudo find / -name kibana 5.5. Filebeat 搭配filebeat主要使用收集nginx数据, 和上面的利用logstash解析movies.csv，然后收集数据给elasticsearch的方式不一样\n收集流程: nginx-\u0026gt;filebeat-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n5.5.1. 安装Filebeat sudo curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.2.2-amd64.deb sudo dpkg -i filebeat-8.2.2-amd64.deb 5.5.2. 修改 filebat.yml 配置文件 sudo vim /etc/filebeat/filebeat.yml 修改下列几项\n# ============================== Filebeat inputs =============================== filebeat.inputs: - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_cpu_monitor.log tags: [\u0026#34;lua_cpu_monitor_log\u0026#34;] - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_mem_monitor.log tags: [\u0026#34;lua_mem_monitor_log\u0026#34;] # ============================== Filebeat modules ============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 1 # ------------------------------ Logstash Output ------------------------------- output.logstash: # The Logstash hosts hosts: [\u0026#34;10.40.38.66:5555\u0026#34;] # ================================= Processors ================================= processors: - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 6.5.3. 测试filebeat启动后，查看相关输出信息 sudo filebeat -e -c /etc/filebeat/filebeat.yml -d \u0026#34;publish\u0026#34; 6.5.4. 后台方式启动filebeat nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; #将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出 nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt; filebeat.log \u0026amp; 6.5.5. 停止filebeat ps -ef | grep filebeat kill -9 进程号 6.5.6. 启动出现的问题 执行命令systemctl start filebeat.service就能够启动了。而后执行ps -ef|grep filebeat查看一下\n能够看到已经启动胜利了，如果你发现没有启动成功，那么就执行 cd /usr/bin，在这个目录下执行./filebeat -c /etc/filebeat/filebeat.yml -e，这样会提醒具体的错误信息。而用systemctl start filebeat.service启动的时候没有任何提醒，连在 /var/log/filebeat/ 和 /var/lib/filebeat/registry/filebeat/ 都没找到错误信息，这里属实有点坑。\n重新启动命令systemctl restart filebeat.service\n6.5.7 去安装logstash的机器启动logstash 增加 logstash_filebeat.conf 文档\nsudo vim /etc/logstash/conf.d/logstash_filebeat.conf 把以下内容粘贴上保存\ninput { beats { port =\u0026gt; 5555 #这个地址不能和logstash.yml 里面的api.http.host: 9600 一样，要不会出现地址已经被绑定的错误 } } output { if \u0026#34;lua_cpu_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_cpu_monitor-%{+YYYY.MM.dd}\u0026#34; } } if \u0026#34;lua_men_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_men_monitor-%{+YYYY.MM.dd}\u0026#34; } } } 重新加载新的配置并启动logstash\n先启动logstash，然后在启动filebeat，不然的话filebeat会找不到beats插件的:5555端口\nsudo rm -rf /var/lib/logstash/.lock sudo /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash_filebeat.conf --verbose --debug 6.5.8. 用filebeat 监控 nginx 修改 nginx conf 配置表\nsudo vim /usr/local/nginx/conf/nginx.conf 加入如下日志格式\nlog_format main \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;@source\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;hostname\u0026#34;:\u0026#34;$hostname\u0026#34;,\u0026#39; \u0026#39;\u0026#34;ip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_method\u0026#34;:\u0026#34;$request_method\u0026#34;,\u0026#39; \u0026#39;\u0026#34;scheme\u0026#34;:\u0026#34;$scheme\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$server_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request_uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;args\u0026#34;:\u0026#34;$args\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamaddr\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;https\u0026#34;:\u0026#34;$https\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; 对比修改下图对应的3个红框地方\n重启 nginx\nsudo pkill -9 nginx \u0026amp;\u0026amp; sudo nginx 用 http:192.168.70.132:7000 登录nginx 网站生成登录日志，然后打开 access.log 日志\nsudo vim /usr/local/nginx/logs/access.log sudo tail -f /usr/local/nginx/logs/access.log 6.5.9. 卸载Filebeat # 查看安装的软件 sudo dpkg -l | grep filebeat #查看安装关联 sudo dpkg -L filebeat #移除安装软件 sudo dpkg -P filebeat #继续查看未卸载的目录和文件 sudo find / -name filebeat #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat \u0026amp;\u0026amp; sudo rm -rf /usr/share/filebeat #在此查看是否有关联的目录和文件 sudo find / -name filebeat ","permalink":"https://frog-game.github.io/posts/blog/zabbix-mysql8.0/","summary":"演示 安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana 1. zabbix 6.0 1.1. 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 1.2. 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 1.3. 安装Zabbix server，Web前端，agent sudo apt","title":"zabbix游戏监控日志系统部署"},{"content":"1. luadebug 实现多虚拟机原理 先从luahook原理说起\n在lua.h 当中我们有 lua_sethook函数来给们设置钩子\nLUA_API void (lua_sethook) (lua_State *L, lua_Hook func, int mask, int count); lua_State *L :虚拟机的地址\nlua_Hook func:我们设定的钩子回调函数\nmask: 状态掩码可以组合操作\nLUA_MASKCALL : 调用函数时回调 LUA_MASKRET :函数返回时回调 LUA_MASKLINE :执行一行代码时候回调 LUA_MASKCOUNT :每执行count条指令时候回调 count：只有掩码包含LUA_MASKCOUNT 这个状态时候才有效果，代表执行count次才会回调一次钩子函数\n\u0026lt;font color='orange'\u0026gt;LUA_MASKCALL 会在调用函数时回调 \u0026lt;/font\u0026gt; 我们在追踪lua源码，可以发现在每次调用函数之前都回**\u0026lt;font color='red'\u0026gt;ldo.c \u0026lt;/font\u0026gt;去调用 \u0026lt;font color='red'\u0026gt;luaD_precall \u0026lt;/font\u0026gt;函数并检测是否设置了掩码标识，如果设置了 \u0026lt;font color='red'\u0026gt;LUA_MASKCALL \u0026lt;/font\u0026gt;**掩码状态，就会调用 \u0026lt;font color='red'\u0026gt;luaD_hook \u0026lt;/font\u0026gt;这个回调函数\n\u0026lt;font color='orange'\u0026gt;LUA_MASKRET :会在函数返回时回调 \u0026lt;/font\u0026gt; 我们在追踪lua源码，可以发现在每次函数返回时候都会去**\u0026lt;font color='red'\u0026gt;ldo.c \u0026lt;/font\u0026gt;** 里面调用**\u0026lt;font color='red'\u0026gt;luaD_poscall \u0026lt;/font\u0026gt;** 里面的**\u0026lt;font color='red'\u0026gt;rethook \u0026lt;/font\u0026gt;函数 如果设置了就会调用 \u0026lt;font color='red'\u0026gt;LUA_MASKRET \u0026lt;/font\u0026gt;**掩码状态 ， 就会调用 \u0026lt;font color='red'\u0026gt;luaD_hook \u0026lt;/font\u0026gt;这个回调函数\n\u0026lt;font color='orange'\u0026gt;LUA_MASKLINE :执行一行代码时候回调 \u0026lt;/font\u0026gt; 我们在追踪lua源码，可以发现在每次执行一行指令都会去**\u0026lt;font color='red'\u0026gt;ldebug.c \u0026lt;/font\u0026gt;** 去调用 \u0026lt;font color='red'\u0026gt;luaG_traceexec \u0026lt;/font\u0026gt;函数 如果设置了**\u0026lt;font color='red'\u0026gt;LUA_MASKLINE \u0026lt;/font\u0026gt;** 掩码状态 那么久会调用**\u0026lt;font color='red'\u0026gt;luaD_hook \u0026lt;/font\u0026gt;**函数\n\u0026lt;font color='orange'\u0026gt;LUA_MASKCOUNT :执行count条指令时候回调 \u0026lt;/font\u0026gt; 我们在追踪lua源码，可以发现每次执行一行指令都会去**\u0026lt;font color='red'\u0026gt;ldebug.c \u0026lt;/font\u0026gt;** 去调用 \u0026lt;font color='red'\u0026gt;luaG_traceexec \u0026lt;/font\u0026gt;函数 这个函数需要和**\u0026lt;font color='red'\u0026gt;count \u0026lt;/font\u0026gt;参数配合才能发挥效果，可以看到如果 \u0026lt;font color='red'\u0026gt;L-\u0026gt;hookcount \u0026lt;/font\u0026gt;在一次次递减之后等于 \u0026lt;font color='red'\u0026gt;0 \u0026lt;/font\u0026gt;了就会调用 \u0026lt;font color='red'\u0026gt;luaD_hook \u0026lt;/font\u0026gt;**函数\n综合上述我们看到最终都会调用到**\u0026lt;font color='red'\u0026gt;luaD_hook \u0026lt;/font\u0026gt;函数，仔细看源码观察可以看到在经过一系列判断以后会回调我们设置好的 \u0026lt;font color='red'\u0026gt;L-\u0026gt;hook \u0026lt;/font\u0026gt;**函数\n回到我们第**\u0026lt;font color='red'\u0026gt;2 \u0026lt;/font\u0026gt;**个参数\n/* Functions to be called by the debugger in specific events */ typedef void(*lua_Hook) (lua_State *L, lua_Debug *ar); 可以看到返回了一个**\u0026lt;font color='red'\u0026gt;lua_Debug \u0026lt;/font\u0026gt;**结构体 我们进入这个结构体\n这里为了兼容每个不同的lua版本，弄了个**\u0026lt;font color='red'\u0026gt;union \u0026lt;/font\u0026gt;联合体 写在了 \u0026lt;font color='red'\u0026gt;lua_api_loder.h \u0026lt;/font\u0026gt;**里面\n我们进入 **\u0026lt;font color='red'\u0026gt;lua_Debug_54 \u0026lt;/font\u0026gt;**结构体里面\n可以发现这里有许多的信息\n结构变量 解释 event Event codes 事件类型标识如下几种 \u0026lt;font color='red'\u0026gt;[LUA_HOOKCALL,LUA_HOOKRET,LUA_HOOKLINE,LUA_HOOKCOUNT,LUA_HOOKTAILCALL]\u0026lt;/font\u0026gt; name 函数名字 namewhat 作用域的含义，比如是global，local，method，field 或者\u0026quot;\u0026quot; \u0026ldquo;\u0026ldquo;代表没有找到这个函数 what \u0026lt;span style=\u0026quot;display:inline-block;width: 600px\u0026quot;\u0026gt;函数的类型 一般为\u0026quot;lua\u0026rdquo; source 函数定义的位置，如果是loadstring载入的，source是string 如果是在一个文件中source标识带有前缀的@文件名字 srclen source的长度 currentline 当前函数所在的行 linedefined 函数定义的首行地址 \u0026lt;span style=\u0026quot;display:inline-block;width: 120px\u0026quot;\u0026gt; lastlinedefined 函数定义的最后一行的行号 nups 上值的个数 nparams 参数数量 isvararg 是不是可变参数 istailcall 是不是最后一个函数是一个函数调用 形如**\u0026lt;font color='red'\u0026gt;function f(x) return g(x) end \u0026lt;/font\u0026gt;** ftransfer 与第一个转移值的偏移量 主要用call/return方式 ntransfer 传输的值 主要用call/return方式 short_src source 的简短表示 i_ci 记录一个函数调用涉及到的栈引用，lua在调用函数的时候会把每个callinfo用双向链表串起来 综合上述原理我们可以看到每一个lua_sethook 被调用时候通过hook返回的信息有这么多，而且每一个lua_state 都是沙盒隔离，所以我们可以利用沙盒原理，通过在进程中创建一个debuggerManager的管理器把所有生成的lua_state的指针保存在这个管理器里面，这样在每次lua调用pcall执行脚本的时候都会去触发自己相对应的lua_sethook设置的hook函数，在里面获取当时触发的时候的上表返回的信息，然后给客服端显示\nluadebug 实现修改变量值 首先需要创建一个protobuf的cmd命令\n\u0026lt;font color='red'\u0026gt;MessageCMD::SetVariableReq \u0026lt;/font\u0026gt; //修改变量\n客服端设置变量逻辑\n服务器接收到请求逻辑核心逻辑如下\n第一步: 将此lua定义check 用luaL_dostring 进行load执行\nconst char* loadstr = \u0026#34;function dlua_setvarvalue (name, frame, val, level)\\n\u0026#34; \u0026#34; local found\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; -- try local variables\\n\u0026#34; \u0026#34; local i = 1\\n\u0026#34; \u0026#34; while true do\\n\u0026#34; \u0026#34; local n, v = debug.getlocal(frame + level, i)\\n\u0026#34; \u0026#34; if not n then\\n\u0026#34; \u0026#34; break\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if n == name then\\n\u0026#34; \u0026#34; debug.setlocal(frame + level, i, val)\\n\u0026#34; \u0026#34; found = true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; i = i + 1\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if found then\\n\u0026#34; \u0026#34; return true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; -- try upvalues\\n\u0026#34; \u0026#34; local func = debug.getinfo(frame + level).func\\n\u0026#34; \u0026#34; i = 1\\n\u0026#34; \u0026#34; while true do\\n\u0026#34; \u0026#34; local n, v = debug.getupvalue(func, i)\\n\u0026#34; \u0026#34; if not n then\\n\u0026#34; \u0026#34; break\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if n == name then\\n\u0026#34; \u0026#34; debug.setupvalue(func, i, val)\\n\u0026#34; \u0026#34; return true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; i = i + 1\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; return false\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; luaL_dostring(L, loadstr); 如果是set a=1类型\nstd::string loadstr = \u0026#34;if not dlua_setvarvalue(\\\u0026#34;\u0026#34; + val + \u0026#34;\\\u0026#34;,\u0026#34; + std::to_string(currentFrameId) + \u0026#34;,\u0026#34; + input + \u0026#34;, 3\u0026#34; + \u0026#34;) then\\n\u0026#34;; loadstr += val + \u0026#34;=\u0026#34; + input + \u0026#34;\\n\u0026#34;; loadstr += \u0026#34;end\\n\u0026#34;; int status = luaL_dostring(L, loadstr.c_str()); if (status != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } 如果是set [t1] t1.a=1 类型\nstd::string loadstr = \u0026#34;function dlua_set_val(\u0026#34;; for (auto it = inputval.begin(); it != inputval.end();) { loadstr = loadstr + it-\u0026gt;first; it++; if (it != inputval.end()) { loadstr = loadstr + \u0026#34;,\u0026#34;; } } loadstr = loadstr + \u0026#34;)\\n\u0026#34; + val + \u0026#34;=\u0026#34; + input + \u0026#34;\\n\u0026#34;; loadstr = loadstr + \u0026#34;return \u0026#34;; for (auto it = inputval.begin(); it != inputval.end();) { loadstr = loadstr + it-\u0026gt;first; it++; if (it != inputval.end()) { loadstr = loadstr + \u0026#34;,\u0026#34;; } } loadstr = loadstr + \u0026#34;\\n end\\n\u0026#34;; int status = luaL_dostring(L, loadstr.c_str()); if (status != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } lua_settop(L, oldn); lua_getglobal(L, \u0026#34;dlua_set_val\u0026#34;); if (!lua_isfunction(L, -1)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, \u0026#34;get dlua_set_val fail\u0026#34;); return -1; } for (auto it = inputval.begin(); it != inputval.end(); it++) { if (!FindAndPushVal(L, it-\u0026gt;first, currentFrameId)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, (std::string(\u0026#34;can not find val \u0026#34;) + it-\u0026gt;first).c_str()); return -1; } } int ret = lua_pcall(L, inputval.size(), inputval.size(), 0); if (ret != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } int index = -inputval.size(); for (auto it = inputval.begin(); it != inputval.end(); it++) { std::string name = it-\u0026gt;first; int curoldn = lua_gettop(L); lua_getglobal(L, \u0026#34;dlua_setvarvalue\u0026#34;); if (!lua_isfunction(L, -1)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, \u0026#34;get dlua_setvarvalue fail\u0026#34;); return -1; } lua_pushstring(L, name.c_str()); lua_pushinteger(L,currentFrameId); lua_pushnil(L); lua_pushinteger(L, 2); lua_copy(L, index - 5, -2); ret = lua_pcall(L, 4, 1, 0); if (ret != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } bool suc = lua_toboolean(L, -1); if (!suc) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, (std::string(\u0026#34;dlua_setvarvalue set \u0026#34;) + name + \u0026#34; fail\u0026#34;).c_str()); return -1; } lua_settop(L, curoldn); index++; } 图片效果 3. 真机调试 adb forward 原理 要想知道怎么真机调试我们首先应该知道adb调试的原理\n比如我现在调试安卓时候的使用的命令: adb forward tcp:8888 tcp:9966\n通过此端口转发我们就可以做到吧电脑tcp端口的消息转发到真机里面tcp9966端口上\n4. 条件断点 条件断点分为\n1：表达式 2：命中次数\n3：日志断点\n首先需要在此结构中定义3个变量用于处理3中类型，然后通过vscode设置条件端点类型\n部分核心代码\nbool Debugger::ProcessBreakPoint(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { if (!bp-\u0026gt;condition.empty()) { auto ctx = std::make_shared\u0026lt;EvalContext\u0026gt;(); ctx-\u0026gt;expr = bp-\u0026gt;condition; ctx-\u0026gt;depth = 1; bool suc = DoEval(ctx); return suc \u0026amp;\u0026amp; ctx-\u0026gt;result-\u0026gt;valueType == LUA_TBOOLEAN \u0026amp;\u0026amp; ctx-\u0026gt;result-\u0026gt;value == \u0026#34;true\u0026#34;; } if (!bp-\u0026gt;logMessage.empty()) { DoLogMessage(bp); return false; } if (!bp-\u0026gt;hitCondition.empty()) { bp-\u0026gt;hitCount++; return DoHitCondition(bp); } return true; } bool Debugger::DoEval(std::shared_ptr\u0026lt;EvalContext\u0026gt; evalContext) { if (!currentL || !evalContext) { return false; } auto L = currentL; //auto* const L = L; // From \u0026#34;cacheId\u0026#34; if (evalContext-\u0026gt;cacheId \u0026gt; 0) { lua_getfield(L, LUA_REGISTRYINDEX, CACHE_TABLE_NAME); // 1: cacheTable|nil if (lua_type(L, -1) == LUA_TTABLE) { lua_getfield(L, -1, std::to_string(evalContext-\u0026gt;cacheId).c_str()); // 1: cacheTable, 2: value GetVariable(evalContext-\u0026gt;result, -1, evalContext-\u0026gt;depth); lua_pop(L, 2); return true; } lua_pop(L, 1); } // LOAD AS \u0026#34;return expr\u0026#34; std::string statement = \u0026#34;return \u0026#34;; statement.append(evalContext-\u0026gt;expr); int r = luaL_loadstring(L, statement.c_str()); if (r == LUA_ERRSYNTAX) { evalContext-\u0026gt;error = \u0026#34;syntax err: \u0026#34;; evalContext-\u0026gt;error.append(evalContext-\u0026gt;expr); return false; } // call const int fIdx = lua_gettop(L); // create env if (!CreateEnv(evalContext-\u0026gt;stackLevel)) return false; // setup env #ifndef EMMY_USE_LUA_SOURCE lua_setfenv(L, fIdx); #elif defined(EMMY_LUA_51) || defined(EMMY_LUA_JIT) lua_setfenv(L, fIdx); #else //52 \u0026amp; 53 lua_setupvalue(L, fIdx, 1); #endif assert(lua_gettop(L) == fIdx); // call function() return expr end r = lua_pcall(L, 0, 1, 0); if (r == LUA_OK) { evalContext-\u0026gt;result-\u0026gt;name = evalContext-\u0026gt;expr; GetVariable(evalContext-\u0026gt;result, -1, evalContext-\u0026gt;depth); lua_pop(L, 1); return true; } if (r == LUA_ERRRUN) { evalContext-\u0026gt;error = lua_tostring(L, -1); } return false; } void Debugger::DoLogMessage(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { std::string\u0026amp; logMessage = bp-\u0026gt;logMessage; // 为什么不用regex? // 因为gcc 4.8 regex还是空实现 // 而且后续版本的gcc中正则表达式行为似乎也不太正常 enum class ParseState { Normal, LeftBrace, RightBrace } state = ParseState::Normal; std::vector\u0026lt;LogMessageReplaceExpress\u0026gt; replaceExpresses; std::size_t leftBraceBegin = 0; std::size_t rightBraceBegin = 0; // 如果在表达式中出现左大括号 std::size_t exprLeftCount = 0; for (std::size_t index = 0; index != logMessage.size(); index++) { char ch = logMessage[index]; switch (state) { case ParseState::Normal: { if (ch == \u0026#39;{\u0026#39;) { state = ParseState::LeftBrace; leftBraceBegin = index; exprLeftCount = 0; } else if (ch == \u0026#39;}\u0026#39;) { state = ParseState::RightBrace; rightBraceBegin = index; } break; } case ParseState::LeftBrace: { if (ch == \u0026#39;{\u0026#39;) { // 认为是左双大括号转义为可见的\u0026#39;{\u0026#39; if (index == leftBraceBegin + 1) { replaceExpresses.emplace_back(\u0026#34;{\u0026#34;, leftBraceBegin, index, false); state = ParseState::Normal; } else { exprLeftCount++; } } else if (ch == \u0026#39;}\u0026#39;) { // 认为是表达式内的大括号 if (exprLeftCount \u0026gt; 0) { exprLeftCount--; continue; } replaceExpresses.emplace_back(logMessage.substr(leftBraceBegin + 1, index - leftBraceBegin - 1), leftBraceBegin, index, true); state = ParseState::Normal; } break; } case ParseState::RightBrace: { if (ch == \u0026#39;}\u0026#39; \u0026amp;\u0026amp; (index == rightBraceBegin + 1)) { replaceExpresses.emplace_back(\u0026#34;}\u0026#34;, rightBraceBegin, index, false); } else { //认为左右大括号失配，之前的不做处理，退格一位回去重新判断 index--; } state = ParseState::Normal; break; } } } std::stringstream message; if (replaceExpresses.empty()) { message \u0026lt;\u0026lt; logMessage; } else { // 拼接字符串 // 怎么replace 函数都没有啊 std::size_t start = 0; for (std::size_t index = 0; index != replaceExpresses.size(); index++) { auto\u0026amp; replaceExpress = replaceExpresses[index]; if (start \u0026lt; replaceExpress.StartIndex) { auto fragment = logMessage.substr(start, replaceExpress.StartIndex - start); message \u0026lt;\u0026lt; fragment; start = replaceExpress.StartIndex; } if (replaceExpress.NeedEval) { auto ctx = std::make_shared\u0026lt;EvalContext\u0026gt;(); ctx-\u0026gt;expr = std::move(replaceExpress.Expr); ctx-\u0026gt;depth = 1; bool succeed = DoEval(ctx); if (succeed) { message \u0026lt;\u0026lt; ctx-\u0026gt;result-\u0026gt;value; } else { message \u0026lt;\u0026lt; ctx-\u0026gt;error; } } else { message \u0026lt;\u0026lt; replaceExpress.Expr; } start = replaceExpress.EndIndex + 1; } if (start \u0026lt; logMessage.size()) { auto fragment = logMessage.substr(start, logMessage.size() - start); message \u0026lt;\u0026lt; fragment; } } std::string baseName = BaseName(bp-\u0026gt;file); EmmyFacade::Get().SendLog(LogType::Info, \u0026#34;[%s:%d] %s\u0026#34;, baseName.c_str(), bp-\u0026gt;line, message.str().c_str()); } bool Debugger::DoHitCondition(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { auto\u0026amp; hitCondition = bp-\u0026gt;hitCondition; enum class ParseState { ExpectedOperator, // 大于 Gt, // 小于 Le, // 单等号 Eq, ExpectedHitTimes, ParseDigit, ParseFinish } state = ParseState::ExpectedOperator; enum class Operator { // 大于 Gt, // 小于 Le, // 小于等于 LeEq, // 大于等于 GtEq, // 双等号 EqEq, } evalOperator = Operator::EqEq; unsigned long long hitTimes = 0; for (std::size_t index = 0; index != hitCondition.size(); index++) { char ch = hitCondition[index]; switch (state) { case ParseState::ExpectedOperator: { if (ch == \u0026#39; \u0026#39;) { continue; } if (ch == \u0026#39;=\u0026#39;) { state = ParseState::Eq; } else if (ch == \u0026#39;\u0026lt;\u0026#39;) { state = ParseState::Le; } else if (ch == \u0026#39;\u0026gt;\u0026#39;) { state = ParseState::Gt; } else { return false; } break; } case ParseState::Eq: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::EqEq; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::Gt: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::GtEq; state = ParseState::ExpectedHitTimes; } else if (isdigit(ch)) { evalOperator = Operator::Gt; hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else if (ch == \u0026#39; \u0026#39;) { evalOperator = Operator::Gt; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::Le: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::LeEq; state = ParseState::ExpectedHitTimes; } else if (isdigit(ch)) { evalOperator = Operator::Le; hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else if (ch == \u0026#39; \u0026#39;) { evalOperator = Operator::Gt; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::ExpectedHitTimes: { if (ch == \u0026#39; \u0026#39;) { continue; } else if (isdigit(ch)) { hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else { return false; } break; } case ParseState::ParseDigit: { if (isdigit(ch)) { hitTimes = hitTimes * 10 + (ch - \u0026#39;0\u0026#39;); } else if (ch == \u0026#39; \u0026#39;) { state = ParseState::ParseFinish; } else { return false; } break; } case ParseState::ParseFinish: { if (ch == \u0026#39; \u0026#39;) { break; } else { return false; } break; } } } switch (evalOperator) { case Operator::EqEq: { return bp-\u0026gt;hitCount == hitTimes; } case Operator::Gt: { return bp-\u0026gt;hitCount \u0026gt; hitTimes; } case Operator::GtEq: { return bp-\u0026gt;hitCount \u0026gt;= hitTimes; } case Operator::Le: { return bp-\u0026gt;hitCount \u0026lt; hitTimes; } case Operator::LeEq: { return bp-\u0026gt;hitCount \u0026lt;= hitTimes; } } return false; } 4.1. 视频效果展示 4.1.1. 多虚拟机测试 4.1.2. linux测试 4.1.3. 真机测试 4.1.4. 插件下载地址 针对skynet这种微服器框架和自己从 0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店进行\n下载使用，有任何问题可以加QQ私聊\n","permalink":"https://frog-game.github.io/posts/blog/vscode-lua-chajian/","summary":"1. luadebug 实现多虚拟机原理 先从luahook原理说起 在lua.h 当中我们有 lua_sethook函数来给们设置钩子 LUA_API void (lua_sethook) (lua_State *L, lua_Hook func, int mask, int count); lua_State *L :虚拟","title":"微服务lua调试器"},{"content":"1. 前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑做不到，手机就更加不用说了 这类大地图，在客服端都是分区域进行加载，也就是会进行切割，比如像绝地求生这样的游戏，大概80公里左右大的地图，会被切割成100 *100 个格子，大概每个格子800米左右，每个格子会打上索引标记，当客服端在进行移动的时候就会根据视野，一般都是九宫格区域，然后根据视野新旧对地图块进行预加载和删除。 在绝地求生跳伞阶段，其实是整张地图进行加载的，但是这个时候不是加载的高精度地图块，而是一个经过简化的地图，而且这种地图块不会只有一份，一般会有多份，这种也叫多层LOD，也就是随着你跳伞以后，距离地面越来越近，程序会给你切换不同的地图块，这也就是为什么有时候你在跳伞的过程中有时候会看到闪烁情况，其实这个时候是程序在给你切换不同的地图块 2. 构建大世界地图 2.1. 利用bspTree原理对地图进行动态切割 分裂条件：\n人数达到上线 区域大小必须超过多大，比如必须达到50 *50 大小才能分裂 1.场景管理服务器启动以后会创建一个全局的space，假设大小是100 * 100，同时也创建一个同样大小的cell1\n假如按宽10进行分割，会形成 10 * 100,90 * 100 两个长方形\n假如按长90来对剩下的3进行分割\n一直往下切割的话，左边会越来越多，右儿子会越来越少，从而达到负载均衡的效果但是也有分割也有条件\n兄弟两都为叶子节点 左二子被分割后的大小不应该大于右儿子 2.2. 利用bspTree原理对地图进行动态合并 合并条件:\nCell区域小于100(可配) 人数小于指定人数(可配) 待合并的2个结点必须是叶子结点 删除待合并的两个儿子结点，修改父亲结点的场景区域 合并前\n合并后\n当不管是分割还是合并发现他的实体已经不再当前cell了那么实体应该迁移到他合适的地方去\n3. 边缝处理 假设我们现在有3个cellServer进程管理着各自的ABC3个cell块\n当上面的a角色到达边界的时候，我们这个时候就需要进行real和ghost的数据同步，开始在重叠区域进行转换，进行转换的区域一般要比自己的视野范围要大，比如现在的重叠转换区域就是那个红色圈，大于自己的视野黑色圈\n在entity aoi范围内，又不在同一cell的，在这个cell上创建同坐标的一个ghost 镜像，也就是上面的暗红色和绿色星星就是BC cell上面的ghost镜像 ghost 只能是只读的，每次去修改只能先修改real实体然后在去同步ghost属性 4. 新的边缝处理方法 比如现在有A B两个cell 这个时候黄色的角色从A走向了B 现在过了边界，但是我们现在不用创建镜像和实体的方法来实现无缝地图，而是用传送的方式，传送触发的实际就是那根绿色线和边界的距离，比如5米，当玩家走到了这个触发范围我们就开始直接把人传送到B，这样也不用处理ghost和real之间定时同步，还有异步技能带来的各种异常情况，bug查找\n5. 技能处理 攻击方一定要是real实体，被攻击方可以是real实体，也可以是ghost实体\n下方的数据同步可以写到核心框架，也就是定时同步real实体的信息到ghost实体上\n6. 寻路 因为世界地图很大，所以我们可以用**路点+ 小段距离A星或者jps算法**来实现寻路\n先求路点，比如如下的地铁图，我们可以根据权重值或者时间的组合，通过**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法求出最短路径，这些路径可以离线先求出来，等使用的时候直接使用 还是以上面这图为例子现在你在红色小人那个位置也就是关庄下面小人的位置，这个时候如果障碍物多，你可以骑单车过来也就是用**A星算法寻路到惠新西街南口，如果障碍物少，那么你可以打车，或者坐大巴也就是jps算法到彗新西街南口，到了起始点之后，你就可以坐地铁也就是前面用Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算出的离线路径直接到达下面的地跌目的地南锣鼓巷\n到了南锣鼓巷以后，同样你也可以按2步骤，选择是**a星还是jps算法**到达公司\n如果地图超大，其实在用**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算地铁图的时候我们可以分几块区域算出各自地铁路线图，然后连接起来，举个栗子，比如可以划分，彗星西街南口到北土城是一个区域，北土城到鼓楼大街是个区域，鼓楼大街到南锣鼓巷是个区域，这3个区域各自算好，各自存储好，到时拼接起来就是惠新西街南口到南锣鼓巷的整条离线路线，如下图红，黑，黄三个框，代表3个区域\n","permalink":"https://frog-game.github.io/posts/blog/wufengdashijie/","summary":"1. 前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电","title":"无缝大世界"},{"content":"1. 图解释 2. 结构体 typedef struct byteQueue_s { char*\tpBuffer;//数据 size_t\tnCapacity;//容量 size_t\tnReadIndex;//读指针索引 size_t\tnWriteIndex;//写指针索引 } byteQueue_tt; 3. 初始 结构体 假设要申请的空间 环形buff结构体大小为8\nnWriteIndex 写指针索引 nReadIndex 读指针索引 环形buff初始化\nvoid byteQueue_init(byteQueue_tt* pByteQueue,size_t nCapacity = /* = 8*/) { pByteQueue-\u0026gt;nReadIndex = nCapacity;//读指针索引位置设置为8,放到末尾 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置成0，放到开头 pByteQueue-\u0026gt;nCapacity = nCapacity;//容量 if( nCapacity != 0 ) { pByteQueue-\u0026gt;pBuffer = mem_malloc(nCapacity);//申请空间 } else { pByteQueue-\u0026gt;pBuffer = NULL;//置空 } } 4. 清空结构体 void byteQueue_clear(byteQueue_tt* pByteQueue) { pByteQueue-\u0026gt;nReadIndex = 0;//读指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nCapacity = 0;//容量设置为0 if(pByteQueue-\u0026gt;pBuffer) { mem_free(pByteQueue-\u0026gt;pBuffer);//如果有数据进行释放 pByteQueue-\u0026gt;pBuffer = NULL;//并且置空 } } 5. 获取剩余全部可写空间 static inline size_t byteQueue_getBytesWritable(byteQueue_tt* pByteQueue) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex )//写指针和读指针重合，或者在读指针前面 { return pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//直接读指针 - 写指针 就是 写入了多少内容 } else//写指针在读指针后面 { return pByteQueue-\u0026gt;nReadIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex); //读指针位置 + (容量 - 写指针位置) } } 5.1. 写指针在读指针前面[求得是蓝色块数据] 5.2. 写指针在读指针后面[求得是蓝色块数据] 6. 获取剩余全部可读空间 static inline size_t byteQueue_getBytesReadable(byteQueue_tt* pByteQueue) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex) //读指针在写指针前面 { return pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//直接写指针 - 读指针 就是可以读多少数据 } else //读指针和写指针重合,或者读指针在写指针后面 { return pByteQueue-\u0026gt;nWriteIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex); //写指针 + (容量 - 读指针位置) } } 6.1. 写指针在读指针后面[求的是红色块的数据] 6.2. 写指针在读指针前面[求的是红色块的数据] 7. 查看连续的可写空间 //查看连续的可写空间 //size_t* pWriteBytes 能连续写入的大小 static inline char* byteQueue_peekContiguousBytesWrite(byteQueue_tt* pByteQueue, size_t* pWriteBytes) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex)//读指针在写指针后面 { *pWriteBytes = pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } else//读指针在写指针前面 { *pWriteBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nWriteIndex;//开始连续写入指针的起始位置 } 7.1. 写指针在读指针前面[求得连续可写的空间] 7.2. 写指针在读指针后面[求得连续可写的空间] 8. 查看连续可读空间 //查看连续的可读空间 //size_t* pWriteBytes 能连续读取的大小 static inline char* byteQueue_peekContiguousBytesRead(byteQueue_tt* pByteQueue, size_t* pReadBytes) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex)//写指针在读指针后面 { *pReadBytes = pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } else { *pReadBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nReadIndex;//开始连续读入指针的起始位置 } 8.1. 写指针在读指针后面[求得连续可读的空间] 8.2. 写指针在读指针前面[求得连续可读的空间] 9. 写入一个字符[空间不足按256的倍数自动扩展] void byteQueue_writeChar(byteQueue_tt* pByteQueue, const char c) { if(pByteQueue-\u0026gt;nCapacity == 0) { //初始化容量,buffer大小，可读索引 pByteQueue-\u0026gt;nCapacity = 256;//初始化容量大小[256] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取获取剩余全部可写空间 if (1 \u0026gt; nBytesWritable) { //align_size 将size按align大小整数倍提升,用于内存对齐 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + 1,256); char* pBuffer = mem_malloc(nNewCapacity); if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//说明还有数据没有读走 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//获取剩余全部可读的空间 size_t nReadBytes = 0;//连续可读的空间的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取数据的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//如果连续可读的空间的大小!=剩余全部可读的空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//到了新空间需要重新移动读指针 pByteQueue-\u0026gt;nWriteIndex = nWritten;//到了新空间需要重新移动写指针 } else //没有数据需要读取直接初始化指针位置 { pByteQueue-\u0026gt;nReadIndex = nNewCapacity; pByteQueue-\u0026gt;nWriteIndex = 0; } pByteQueue-\u0026gt;nCapacity = nNewCapacity; mem_free(pByteQueue-\u0026gt;pBuffer); pByteQueue-\u0026gt;pBuffer = pBuffer; } } pByteQueue-\u0026gt;pBuffer[pByteQueue-\u0026gt;nWriteIndex] = c;//赋值 pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + 1) % pByteQueue-\u0026gt;nCapacity;//索引位移一位 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity)//如果读索引在尾部 { pByteQueue-\u0026gt;nReadIndex = 0;//把读索引放到头部 } } 10. 写入指定大小空间的数据[空间不足按256的倍数自动扩展] void byteQueue_write(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = align_size(nLength,256);//初始化容量大小[256的倍数] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取剩余可写空间 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写空间 { //数据进行扩展 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + (nLength-nBytesWritable),256); char* pBuffer = mem_malloc(nNewCapacity);//申请空间大小 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity )//还有数据可读 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读空间 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始连续读入指针的起始位置 memcpy(pBuffer,pRead,nReadBytes);//把连续可读的空间写入新buffer空间 if( nReadBytes != nWritten )//如果连续可读的空间!=剩余全部可读空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;////重置容量大小 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧buff空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//重置指针到新buff空间 } } size_t nWriteBytes = 0;//连续可写的空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//开始写入的指针位置 if (nWriteBytes \u0026gt;= nLength)//如果连续写入的空间能够满足需要写入的空间大小 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入的空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//再把剩余要写入的大小空间写入 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置读索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置写索引 } } 10. 写入指定大小空间的数据[空间不足按剩余需要空间大小申请] void byteQueue_writeBytes(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = nLength;//初始化容量大小[需要空间大小] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//剩余可写的全部空间大小 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写入的空间大小 { size_t nNewCapacity = pByteQueue-\u0026gt;nCapacity + (nLength - nBytesWritable);//开辟正好大小的空间 char* pBuffer = mem_malloc(nNewCapacity);//申请空间 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//还有空间可读需要把这段空间赋值到新空间 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余可读的全部空间 size_t nReadBytes = 0;//连续可读的空间 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取空间的起始位置 memcpy(pBuffer,pRead,nReadBytes);//拷贝到新空间 if( nReadBytes != nWritten )//连续可读的空间!=剩余可读的全部空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余数据到新空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;//重置容量 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间指针指向旧空间指针 } } size_t nWriteBytes = 0;//连续可写入空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//可写入开始指针 if (nWriteBytes \u0026gt;= nLength)//容量足够 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//剩余的在直接拷贝 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置写索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 } } 10. 读取数据 bool byteQueue_readBytes(byteQueue_tt* pByteQueue, void* pOutBytes, size_t nMaxLengthToRead, bool bPeek /*= false*/ ) { size_t nBytesWritten = byteQueue_getBytesReadable(pByteQueue);//可读的空间大小 size_t nBytesToRead = nBytesWritten \u0026lt; nMaxLengthToRead ? nBytesWritten : nMaxLengthToRead;//得到可读取的大小 if (nBytesToRead == 0) { return false; } size_t nReadBytes = 0;//连续可读的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始索引 if( nReadBytes \u0026gt;= nBytesToRead )//满足可读大小需求 { memcpy(pOutBytes,pRead,nBytesToRead);//直接读取 } else { memcpy(pOutBytes,pRead,nReadBytes);//直接连续可读的空间大小 memcpy((char*)pOutBytes+nReadBytes,pByteQueue-\u0026gt;pBuffer,nBytesToRead-nReadBytes);//读取剩余需要读取的大小 } if (!bPeek)//不是探测 byteQueue_readOffset(pByteQueue,nBytesToRead);//直接移动指针 return true; } 10. 重置容量 void byteQueue_reserve(byteQueue_tt* pByteQueue, size_t nCapacity) { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读大小 if(nWritten \u0026gt; nCapacity)//如果全部可读的大小大于要重置的容量大小 { return; } if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//有剩余需要读取的空间数据 { char* pBuffer = mem_malloc(nCapacity);//申请新的重置空间大小 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//还有剩余要拷贝的空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余要拷贝的数据 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间的指针指向旧空间指针 } else { pByteQueue-\u0026gt;pBuffer = mem_realloc(pByteQueue-\u0026gt;pBuffer,nCapacity);//直接指向申请空间的大小 pByteQueue-\u0026gt;nReadIndex = nCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nCapacity;//重置容量 } ","permalink":"https://frog-game.github.io/posts/blog/ringbuff/","summary":"1. 图解释 2. 结构体 typedef struct byteQueue_s { char* pBuffer;//数据 size_t nCapacity;//容量 size_t nReadIndex;//读指针索引 size_t nWriteInde","title":"环形buff"},{"content":"1. 网络编程流程 2. 堵塞IO 3. 非堵塞IO 4. 信号驱动IO 5. 异步io模型 6. 多路复用 7. 单reactor 代表作：redis 内存数据库\n注意：redis 6.0 以后是多线程\n8. 单reactor 多进程模型 代表：nginx\n9. 单reactor模型 + 任务队列 + 线程池 代表作:skynet\n10. 主从 reactor 代表作：netty\n11. 多reactor + 多线程 代表作：memcache\n12. 多reactor + 多线程 +协程池 ","permalink":"https://frog-game.github.io/posts/blog/wangluo_io_zhongjie/","summary":"1. 网络编程流程 2. 堵塞IO 3. 非堵塞IO 4. 信号驱动IO 5. 异步io模型 6. 多路复用 7. 单reactor 代表作：redis 内存数据库 注意：redis 6.0 以","title":"网络IO模型总结"},{"content":"1. tcp 握手挥手 序列号: 在建立连接的时候有计算机生成的随机数并作为初始值，通过syn包传给接收端主机，每发一次数据，就累加一次该数据字节数的大小，主要是用来解决网络包乱序问题\n确认应答号:指下一次期望收到的数据的序列号，发送端收到这个确认应答以后可以认为这个序号之前的数据都被正常接收了，主要用来解决不丢包的问题\n控制位:\nACK: 该位为1的时候，确认应答字段变得有效，该字段规定除了最初开始建立连接时候syn包之外，改为必须设置为1\nRST:该位为1的时候，标识TCP连接中出现异常必须强制断开连接\nSYN:该为位1时候，表示希望建立连接，并在序列号的字段进行序列号初始值的设定\nFIN:该位为1的时候，表示今后不会再有数据发送，希望断开连接，当通讯结束希望端口连接时,通讯双方的主机之间可以相互交互FIN 位为1的TCP段\n1.1. 为什么需要tcp协议，tcp工作在那一层 ​\tIP层是不可靠的，他不保证网络包的交互，不保证网络报的按序交互，也不保证网络包中的数据的完整性，如果需要保证数据的完整性那么就需要TCP层来负责\n1.2. TCP有哪些特性 面向连接的，可靠的，基于字节流的\n1.3. 建立一个tcp连接需要达成哪些共识 socket：由ip地址和端口号组成\n序列号：主要用来解决乱序问题\n窗口大小：主要用来做流量控制\n1.4. TCP四元组 1.5. 有一个ip的服务器监听了一个端口，他的TCP的最大连接数是多少 ​\t对于IP4来说，客服端ip最多为2的32次方(4 294 967 296) 客服端的端口最多为2的16次方(65536) 也就是服务器单机最大的TCP链接数，约为2的48次方\n最大tcp链接数 = 客服端ip数 * 客服端的端口数\n1.6. 如果服务器不能达到理想数，一般是因为什么原因 首先是文件描述符的限制，Socket都是文件，所以首先要通过 ulimit 配置文件描述符的数目\n另一个就是内存限制，每个tcp链接都要占用一定的内存，操作系统的内存是有限的\n1.7. udp和tcp的区别 目标和源端口号：主要是告诉udp协议应该吧报文发给那个进程\n包长度：保存了UDP首部的长度跟数据的长度之和\n校验和：主要是位了提供可靠的udp首部和数据而设计的\n区别\n连接\nTCP是面向连接的传输层,传输数据前先要建立链接\nUDP是不需要连接的，即可传输数据\n服务对象\nTCP是一对一的两点服务器，即一条连接只有两个端点\nUDP是支持一对一，一对多，多对多的交互通信\n可靠性\nTCP是可交互数据的，可以无差错，不丢失，不重复，按需到达\nUDP是尽自己最大的努力交互，不保证可靠交互数据\n拥塞控制，流量控制\nTCP有拥塞控制和流量控制机制，保证数据传输的安全性\nUDP则没有，即使网络非常堵塞，也不会影响UDP的发送速率\n首部开销\nTCP首部长度较长，会有一定的开销，首部在没有使用选项的时候都能达到20字节，如果使用了选项则会变长 UDP首部只有8个字节，并且是固定不变的，开销较小\n传输方式\nTCP是流失传输，没有边界，但是保证顺序和可靠\nUDP是一个包一个包发送，是有边界的，但是可能会丢包和乱序\n分片不同\nMSS就是TCP报文段所允许传送的最大数据部分的长度，主机一般默认MSS为536字节(576IP最大字节数-20字节TCP协议头-20字节IP协议头=536字节)\nMTU 最大传输单元,一般1500\nTCP数据大小如果大于MSS大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装TCP数据包，如果中途丢失了一个分片，只需传输丢失的这个分片\nUDP的数据大小如果大于MTU大小，则会在IP层进行分片，目标主机在收到后，在IP进行组装数据，接着在传给传输层，但是如果中途丢了一个分片，在实现可靠传输的UDP时则需要重传所有的数据包，这样传输效率非常差，所以通常UDP的报文，应该小于MTU\n为什么UDP头部没有首部字段，而TCP头部有\n原因TCP有可变长的选项字段，而UDP头部长度则不会变化，无需多一个字节去记录UDP的首部长度\n为什么UDP头部有包长度，而tcp没有\nTCP数据的长度 = IP总长度 - IP首部长度 - TCP首部长度\n其中 IP 总⻓度 和 IP ⾸部⻓度，在 IP ⾸部格式是已知的。TCP ⾸部⻓度，则是在 TCP ⾸部格式已知的，所以就 可以求得 TCP 数据的⻓度。 ⼤家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据⻓度也可以通过这个公式计算呀？ 为何还要有 「包⻓度」呢？” 这么⼀问，确实感觉 UDP 「包⻓度」是冗余的。 因为为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 44 字节的整数倍。 如果去掉 UDP 「包⻓度」字段，那 UDP ⾸部⻓度就不是 4 字节的整数倍了，所以觉得这可能是为了补全 UDP ⾸部⻓度是 4 字节的整数倍，才补充了「包⻓度」字段\n为什么MTU是1500\n其实一个标准的以太网数据帧大小是：1518，头信息有14字节，尾部校验和FCS占了4字节，所以真正留给上层协议传输数据的大小就是：1518 - 14 - 4 = 1500，那么，1518这个值又是从哪里来的呢？\n最根本原因\n问题就出在路由器拨号，如果是PC拨号，那么PC会进行PPPoE的封装，会按照MTU:1492来进行以太网帧的封装，即使通过路由器，路由器这时候也只是转发而已，不会进行拆包。\n而当用路由器拨号时，PC并不知道路由器的通信方式，会以网卡的设置，默认1500的MTU来进行以太网帧的封装，到达路由器时，由于路由器需要进行PPPoE协议的封装，加上8字节的头信息，这样一来，就必须进行拆包，路由器把这一帧的内容拆成两帧发送，一帧是1492，一帧是8，然后分别加上PPPoE的头进行发送。\n平时玩游戏不卡，是因为数据量路由器还处理得过来，而当进行群怪AOE的时候，由于短时间数据量过大，路由器处理不过来，就会发生丢包卡顿的情况，也就掉线了。\n帖子里面提到的1480，猜测可能是尽量设小一点，避免二次拨号带来的又一次PPPoE的封装，因为时间久远，没办法回到当时的场景再去抓包了。\n1.8. TCP 连接建立(3次握手) 一开始客户端和服务器都处于close状态\n服务开始监听端口，这个时候服务器处于listen状态\n客户端会随机初始化序列号 client_isn，然后把这个初始值付给tcp首部的序列号字段，并把标识位syn设置成1，代表这是一个syn包，此包不包含应用层数据，发送出去以后，客服端处于sys_sent状态\n​\t三次握手第一个报文 SYN 报文\n服务器收到客户端报文，首先服务器会随机初始化自己的server_isn ,将server _isn号存入序列号中，并把客服端的client_isn +1 存入确认应答号中，同时吧SYN和ACK标志位置为1，此包不会包含应用层数据，发送出去以后服务器进入syc_rcvd状态\n​\t三次握手第二个报文 SYN + ACK报文\n客服端收到服务器发送的syn + ack 报文以后，最后还会向服务器发送一个ACK确认报文，并把server_isn 序列号 + 1 存入确认应答号，然后把ACK标志位设置成1，此包这个时候可以带应用层数据发过去，这个时候客户端进入进入established状态，服务器收到ACK确认应答包以后也进入established状态\n从这一步可以看出前两步是不带数据的，第三步可以带数据发送\n1.9. 为什么握手是3次，不是2次,4次 主要是3个方面\n可以防止重复历史链接数\n同步双方初始序列号 四次握手其实也能够可靠的同步双方的初始化序号，但是由于第二步和第一步可以优化成一步，所以就成了3次握手，\n而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方序列号都能被确认接收\n避免资源浪费\n如果只有两次握手，当客服端的syn请求连接在网络中堵塞，客服端没有接收到ACK报文，就会重新发送syn，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送链接的ack确认信号，所以只能自己创建链接，\n如果多次堵塞，多次发送syn，那么服务器就会多次创建，造成冗余的链接。\n总结：为什么不使用两次握手或者四次握手\n两次握手：无法防止历史链接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号\n四次握手：三次握手就已经理论上最少可靠链接建立，所以不需要使用更多的通信次数\n1.10. 为什么客服端和服务器的isn号不相同 如果一个已经失效的历史报文残留在网络中，那么如果isn号码相同那么无法分辨到底是不是历史报文，如果历史报文被接受了那么就有可能产生数据错乱，所以每次建立连接前都会初始化一个序列号，好让分辨出来是不是历史报文，好丢弃掉 还有一个方面是为了安全，防止黑客伪造相同的tcp报文被对方接收 1.11. syn攻击 我们知道tcp链接需要3次握手，假设攻击者短时间内，伪造不同的ip地址syn报文，服务器每接收一个就进入syn_rcvd 状态，但服务器发送出去的ack + syn报文，无法得知位置ip主机的ack应答，久而久之就会占满服务器syn接收队列（未连接队列）使得服务器不能为正常用户服务\n解决办法一\n控制接收队列大小\nnet.core.netdev_max_backlog SYN_RCVD 状态连接的最大个数\nnet.ipv4.tcp_max_syn_backlog 超出处理能力时候对于新的syn 直接发送RST 丢弃链接\nnet.ipv4.tcp_max_syn_backlog ​\t解决方法二\n​\t首先是正常的3次握手流程\n1.12. TCP 连接断开 客服端，打算关闭连接，此时会发送一个tcp首部FIN标志为1的报文，之后客户端进入fin_wait1状态\n服务器收到fin报文之后然后发送ack确认码给客服端，开始进入close_wait状态，\n客服端收到ack确认码以后进入fin_wait2状态\n服务器处理完数据发送fin报文给客服以后进入last_ack阶段\n客服端收到fin报文以后发送ack确认码给服务器开始进入time_wait状态\n服务器接到ack应答报文开始进入close状态\n客服端经过2msl时间自动进入close状态\n你可以看到每个方向都有fin报文和ack应答码，所以简称四次挥手\n只有主动关闭的一方才会进入time_wait 状态\n1.12.1. 为什么挥手需要四次 客服端发送fin链接的时候，仅仅表示客户端不在发送数据，但是还能接收数据\n服务器收到fin报文以后，先回一个ack码，而服务器还有数据需要处理和发送，等服务器不在发送数据\n的时候才发送fin报文给客服端\n从上可知，因为要等待服务器处理完数据，所以服务器的ack和fin码会分开发\n1.12.2. 为什么time_wait是2ML MSL是报文生存最大时间，他在任何报文在网络中存在的最大时间，超过这个时间，报文会被丢弃，因为tcp是基于\nIP协议的，在IP协议中有一个TTL字段，是IP层经过的最大路由器数，每经过一个处理，就会减1，一直到0，就把这\n个数据包进行丢弃，同时发送icmp报文通知主机\nMSL和TTL区别\nMSL单位是时间 TTL是路由跳数，所以MSL应该大于TTL消耗为0的时间，以保证报文是自然消亡\nTIME_WAIT等于2倍，是因为网络中可能存在发送方发过来的数据包，当这些发送方的数据包被接收方处理后，又会向对方发送响应，所以一来一回需要等待2倍的时间\n比如被动关闭方没有收到断开连接的最后的ACK报文，就会触发重发fin报文，另一方收到fin报文后，会重发ack应答码\n一来一回正好2ML\n2ML是客服端接受到FIN包以后发送ACK码开始计时的，如果在2ML时间内，服务器没有收到ACK确认码，重发了fin报文，那么这个时候客服端会重发ACK码并重新进入2ML计时\n1.12.3. 2ML一般多长 linux 中一般设置为60s 也就是一个msl是30秒\n#define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT state, about 60 seconds */ 1.12.4. time_wait 相关 1.12.4.1. time_wait 过多原因 大量高并发的短连接 程序错误，没有调用close关闭连接 ack码丢失，导致服务器重新发送fin报文，让time_wait重新进入计时，不会进入close 1.12.4.2. 为什么需要time_wait状态 防止旧链接的数据包\n如上图的sql =301的包被网络延迟了，这个时候time_wait设置的时间很短，或者没有，上次的链接的被关闭\n这个时候如果重新建立相同端口号的连接被重用，而网络中还有seq =301的消息包这个时候抵达，那么这个\n时候客服端收到了旧的数据包，这个时候数据就会错乱，造成问题\n如果这个时候有2ML的time_wait时间，那么足够保证在建立新的相同端口连接时候，网络中旧的数据包消亡\n保证连接正确关闭\n如果最后的ack丢失了，服务器就会一直处于last_ack状态，如果这个时候客服端发起新的连接，那么这个时候服务器因为处于last_ack状态，所以会发送rst报文给客服端，让客服端直接终止链接\n1.12.4.3. time_wait过多会怎么样 如果服务器有处于time_wait状态的tcp 那么说明是服务器主动发起的端开请求\n内存资源的占用 端口资源的占用，端口资源也是有限的 所以如果发起连接的一方time_wait状态过多，占满了所有资源端口，则会导致无法创建新的连接\n客户端 time_wait多的话，因为端口资源的限制，就会导致端口资源被占用，被占满就会导致无法创建新的链接\n服务器time_wait过多的话，因为系统资源的限制，由于一个四元组表示一个tcp连接，理论上服务器可以创建很多连接，服务器确实也可以监听一个端口，但是这些连接会扔给处理线程，理论上监听的端口可以被继续监听，但是线程池处理不了那么多的一直不断的连接，所以当出现大量time_wait的时候，系统资源就会被占满，导致处理不了新的连接\n1.12.4.4. 怎么优化time_wait 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项\ntcp_tw_reuse 功能只能⽤客户端（连接发起⽅），因为开启了该功能，在调⽤ connect() 函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复⽤\nnet.ipv4.tcp_max_tw_buckets\n这个值默认为 18000，当系统中处于 TIME_WAIT 的连接⼀旦超过这个值时，系统就会将后⾯的 TIME_WAIT 连接 状态重置\n程序中使⽤ SO_LINGER ，应⽤强制使⽤ RST 关闭。\n1.12.5. close_wait 相关 1.12.5.1. close_wait 多的原因 一般都是程序逻辑造成，在client发送fin过来的时候，这边进入了close_wait状态，但是因为程序逻辑问题，迟迟没有调用close()，或者shutdown函数进行关闭，导致close_wait超多\n1.12.6. 如果已经建⽴了连接，但是客户端突然出现故障了怎么办 net.ipv4.tcp_keepalive_time=7200 #表示保活时间是 7200 秒（2⼩时），也就 2 ⼩时内如果没有任何连接相关的活 动，则会启动保活机制 net.ipv4.tcp_keepalive_intvl=75 #表示每次检测间隔 75 秒 net.ipv4.tcp_keepalive_probes=9 #表示检测 9 次⽆响应，认为对⽅是不可达的，从⽽中断本次的连接 主要是tcp的保活机制，如果在一段时间内，没有任何的连接相关的活动，tcp就会启动保活机制，每隔一段时间发送一个探测包，这个探测包数据量很小，如果连续几个探测包发过去都没有反应，那么就可以认为tcp连接已经死亡了\n开启了tcp保活机制以后，需要考虑一下几种情况\n对端程序正常工作，当tcp保活的探测包到达对方以后，对方正常响应，这个时候保活机制就会被重置 对端程序奔溃并重启，当tcp保活的探测包到达以后，由于对方没有相关的tcp连接信息，这个时候会发送rst报文给对方，这样很快就可以发现tcp连接已经重置了 如果对方一直奔溃，当tcp报文一直发送，发送几次后没有反馈，那么这个时候就可以认为tcp连接已经死亡 1.12.7. 服务器主动关闭 服务器调用close(),不管什么数据一缕发送rst报文进行强制关闭 服务器调用shutdown() ，如果是正常数据还是走正常数据接收流程，一直到数据发送完毕，然后发送fin报文正常关闭\n2. tcp重传 2.1. 超时重传 指的是我们在发送数据的时候，会设定一个定时器，当超过定时器设定的时间，我们在没有收到对方的ack确认码之后就会触发重传机制\n2.1.1. 触发超时重传条件 数据包丢失，因为数据包丢失，所以B无法发送ack确认码下去，A无法收到ACK确认码，无法知道服务器是否收到数据就会在特定时间间隔内，触发重传\n确认应答丢失\n2.1.2. 超时重传时间设置多少最好 RTT 包的往返时间\n时间设置的过长过短发生的情况\n当RTO较大时候，重发就满，丢了老半天才重发，没有效率，性能差\n当RTO较小时候，可能是因为波动大，然后设置RTO又短，这个时候触发了重传，但是旧包却很快恢复了传输\n所有综合上述，所以我们应该 RTO应该略大于RTT\n2.2. 快速重传 这个不是以时间为驱动，而是以数据为驱动\n如上发了1，2，3，4，5 共5份数据\n1号数据发过去了，这个时候ACK变成了2\n2号数据这个时候丢失了，\n3号数据这个时候进行了发送，但是接收端回复ACK的时候不会是3而会还是原来丢包的那个ACK2\n4号数据这个时候进行了发送，还是发送ACK2\n5号数据这个时候进行了发送，还是发送ACK2\n这个时候发送端发现有3次相同的ack码就会触发重传，这个是seq2会在定时器过期之前重传过去了，这个时候接收端\n发现了seq2，3，4，5都收到了，那么就会把ACK设置成6\n2.2.1. SACK 解决快速重传应该重传所有还是重传丢失者问题\nSACK方法[如果能支持SACK，那么必须双方都打开]\nLeft Edge:代表已收到的第一个不连续的第一个序号\n​\tRight Edge:表示已收到的不连续块的最后一个序号+1\n​\t即左闭右开区间，通过ACK和sack发送方就能很快的确定接收方有哪些数据没有被收到\n如果上面触发了重传会这样处理\n直接重传300 -499丢失的块，然后把ack变成700再次触发快速重传把700 -899补上\n2.2.2. DACK 主要是告诉发送方，主要通过SACK告诉发送方有哪些数据被重复接受了\nACK 丢包\n接收方发送给发送方的2个ack都丢失了，所以发送方超时后，重传了第一个数据包3000 - 3499\n接收方发现数据是收到的是重复数据，于是回了一个sack= 3000 - 3500 告诉发送方3000 - 3500的\n数据早就被接受了，因为现在ack已经到了4000 所以意味着这个sack代表的是dack\n这样发送方就知道了数据其实没有丢，只是接收方的ack确认报文丢失了\n网络延迟\n数据包 1000- 1499 被网络延迟了，导致发送方没有收到ack1500的确认报文\n而后面收到了3个相同的ack报文，触发了快速重传，但是在重传以后，网络延迟的1000 -1499也抵达了接收方\n所以接收方回了一个ack3000 和sack 1000 -1500 所以这个时候sack代表的就是dack，代表这是一个重复的报文\n这样发送方就知道快速重传的原因不是发数据丢了，也不是ack丢了，只是网络延迟了\n可见dack有这么几个好处\n可以让发送方知道是包丢了\n还是接收方的ack丢了\n还是发送方的数据包被网络延迟了\n可以知道网络中是不是把发送方的数据包给复制了\n3. 滑动窗口 我们知道TCP每发送一个数据，就会进行一次确认应答，当上一个数据包收到了应答，在发送下一个，这个模式有点像\n两个人聊天，你发一句，然后我给你个ack报文，我发一句，然后你给我一个ack报文，这样其实效率很低的。\n如果你说完一句话，我在处理别的事情，没有及时给你回复ack报文，那么你就只能干等着，一直等到我处理完事情，\t然后给你回复ack码，这样处理的话效率太低了，如果是这个逻辑，那么tcp协议也就不用在完了\n所以这样的传输方式很大的弊端：就是包的往返时间越长，网络的吞吐就越大\n为了解决这样的问题，TCP发明了一个牛逼的概念：滑动窗口\n如果有了滑动窗口，那么就可以指定窗口的大小，窗口的大小无需等待对方的确认应答，就可以继续发送数据的最大值\n上面ack300 即使丢了，但是因为我们收到了ack400 那么我们就可以认为400之前的数据都收到了，这种方式我们称为累计确认\n3.1. 窗口大小由哪一方决定 tcp头里面有个字段叫window 也就是窗口大小\n这个字段是接收方告诉发送方自己还有多少缓冲区可以接受数据，于是发送方就靠这个字段来知道接收方能接收多少数据，而不会导致接收方接收不过来\n所以窗口的大小，一般由接收方窗口的大小来决定\n发送方，发送的数据不能超过接收方窗口的大小，否则接收方就无法接受数据\n3.2. 发送窗口 SND.WND : 表示发送窗口的大小,由接收窗口控制\nSND.UNA : 表示已发送但未确认ack报文的空间的第一个字节位置\nSND.NET : 表示未发送但是还在接收窗口可处理空间的第一个字节位置\n可用窗口大小 = SND.WND - (SND.NXT - SND.UNA)\n3.2.1. 发送端窗口大小怎么控制的 取决于接收端的大小[rwnd]和拥塞窗口[cwnd]的大小\n发送窗口 = min{rwnd,cwnd}\n3.3. 接收窗口 RCV.NXT : 希望从发送方发过来的下一个字节数据的序列号\nRCV.WND : 接收窗口的大小，会通过tcp头部报文里面的window字段，通知发送窗口大小\n3.3.1. 接收窗口大小怎么控制的 接收窗口的大小系统，网速，未处理数据的大小都有关系\n3.4. 发送窗口大小和接收窗口大小一样吗 不完全相等，一般接收窗口略等于发送窗口\n4. 流量控制 发送方不是无脑的一直发送数据给接收方的，也要考虑接收方的接收能力。\n如果一直无脑的发数据给对方，但对方处理不过来，就会触发重传机制，从而导致网络流量的无端浪费\n为了解决这个问题，引入了流量控制\n4.1. 固定窗口大小场景 假设接收端和发送端窗口相同，都为200 假设两个设备在传输过程中都保证窗口大小不变，不收外界影响 4.2. 动态变化窗口大小场景 当发送方变成窗口变成0的时候其实发送方还会定时的发送探测报文，以便知道接收方改变了窗口\n4.3. 丢包情况 当服务端系统资源⾮常紧张的时候，操⼼系统可能会直接减少了接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓 存数据，那么这时候就有严᯿的事情发⽣了，会出现数据包丢失的现象。\n为了避免这种情况 TCP规定不允许系统收缩缓存的时候同时减少窗口大小，而是采用先收缩窗口，过段时间在减少缓存的办法\n4.4. 窗口关闭死锁问题 4.5. 如果解决这种死锁问题 为了解决这种死锁问题，TCP为每个连接设有与一个持续定时器如果定时器超时就会发送窗口探测报文\n如果接收窗⼝仍然为 0，那么收到这个报⽂的⼀⽅就会᯿新启动持续计时器； 如果接收窗⼝不是 0，那么死锁的局⾯就可以被打破了。 窗⼝探测的次数⼀般为 3 次，每次⼤约 30-60 秒（不同的实现可能会不⼀样）。如果 3 次过后接收窗⼝还是 0 的 话，有的 TCP 实现就会发 RST 报⽂来中断连接。\n4.6. 糊涂窗口综合症 于是，要解决糊涂窗⼝综合症，就解决上⾯两个问题就可以了\n让接收⽅不通告⼩窗⼝给发送⽅ 让发送⽅避免发送⼩数据 怎么让接收⽅不通告⼩窗⼝呢？ 接收⽅通常的策略\n当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 ) ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通 告窗⼝为 0 ，也就阻⽌了发送⽅再发数据过来。 等到接收⽅处理了⼀些数据后，窗⼝⼤⼩ \u0026gt;= MSS，或者接收⽅缓存空间有⼀半可以使⽤，就可以把窗⼝打开让发 送⽅发送数据过来。\n怎么让发送⽅避免发送⼩数据呢？\n发送方策略\n使⽤ Nagle 算法，该算法的思路是延时处理，它满⾜以下两个条件中的⼀条才可以发送数据：\n要等到窗⼝⼤⼩ \u0026gt;= MSS 或是 数据⼤⼩ \u0026gt;= MSS\n收到之前发送数据的 ack 回包\n5. 拥塞控制 前面的流量控制主要是为了解决发送方到接收方的缓存，但是不知道网络中发生了什么\n一般来说，计算机网络是个共享的环境，因此也有可能会因为其他主机之间的通信，而是网络堵塞\n如果在网络堵塞的时候继续发送大量的数据包，那么就可能导致数据包的时延，丢失等，这个时候tcp就会重传数据，但是一重传，就会导致网络的负担更重，于是就会导致更大的延迟和丢包，甚至进入恶性循环\n于是现在就有了拥塞控制手段，这个手段主要控制的是控制发送方数据充满网络\n为了让发送方控制发送数据的量，于是就有了拥塞窗口的概念\n5.1. 拥塞窗口和发送窗口的关系 拥塞窗口cwnd是发送方维护的一个状态变量，他会根据网络动态变化\n前面我们提到的swnd和rwnd是约等于的关系，那么假如cwnd概念以后，此时发送窗口的值是\nswnd = min(cwnd,rwnd)\n5.2. 拥塞窗口的变化规则 只要网络中没有堵塞，那么就加大cwnd的数值 如果网络中出现了拥塞，cwnd就减少 5.3. 怎么知道当前网络出现了拥塞 只要发送方在没有规定的时间内接受到ack确认码，也就是发生了超时重传，就认为网络中出现了拥塞\n5.4. 拥塞控制有哪些算法 慢启动\n拥塞避免\n拥塞发生\n快速恢复\n5.4.1. 慢启动 慢启动的算法就是，当发送方每收到一个ack，拥塞窗口cwnd的大小就加1\n那么慢启动什么时候是个头呢，\n有一个叫慢启动的门限ssthresh\n当 cwnd \u0026lt; ssthresh 时使用慢启动\n当 cwnd \u0026gt;= sssthresh 时启动拥塞避免\n5.4.2. 拥塞避免 它的规则是：每当收到⼀个 ACK 时，cwnd 增加 1/cwnd\n拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓ 速度缓慢了⼀些。 就这么⼀直增⻓着后，⽹络就会慢慢进⼊了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进 ⾏᯿传。 当触发了᯿传机制，也就进⼊了**拥塞发⽣算法**。\n5.4.3. 拥塞发生 其实这个时候就是写的tcp重传机制主要是两种\n超时重传\n因为想途中的cwnd从12突然变到了1，然后开始慢启动，可以看到此种方法很容易马上回到解放前，方法也很激进，容易造成网络卡顿，那么发生这种情况我们还有没有更好的办法呢，其实有的也就是前面写的快速重传\n在收到3次相同的ack码的时候我们可以在超时重传还没发生之前就重传数据过去，而不必等到超时重传\n这个时候tcp认为这中情况也不是很严重那么我们可以这样设置参数\ncwnd = cwnd/2 ，也就是设置为原来的⼀半 ssthresh = cwnd 进⼊快速恢复算法 5.4.4. 快速恢复 由于进入快速恢复之前 cwnd和ssthresh已经进行了更新\ncwnd = cwnd/2 ，也就是设置为原来的⼀半\nssthresh = cwnd\n快速恢复算法如下\n拥塞窗口 cwnd = ssthresh + 3 3的意思代表确认有3个数据包已经收到了 重传丢失的数据包 如果在收到重复的数据包那么cwnd + 1 如果收到新数据的ack 那么吧cwnd 设置成第一个不的ssthresh的值，原因是该ack已经确认了新的数据，说明从dack时候的数据已经都收到了，该恢复过程已经结束，那么就可以恢复到之前的状态了，也就是可以再次进入拥塞避免状态 6. 粘包 粘包的问题是不知道消息的边界在哪里，如果知道边界在哪里就好办了。所以有如下3种方法解决\n6.1. 固定长度 就是规定每一个包固定的长度，比如20KB，当收到了20KB的数据满了之后，就认为是一个包,但是这种方法灵活性不高，用的很少\n6.2. 特殊字符做边界 比如像HTTP这种直接在尾部加回车，换行来作为数据的边界，但是这种方法有个问题，就是如果特殊字符是内容，那么就需要对这个数据做特殊处理\n6.3. 自定义消息结构 我们可以自己定义消息结构，由包头 + 数据组成 在包头里面有一个字段是用来表示数据包的大小的，如下:\nstruct { int32 message_length; char message_data[]; } message; 这样当客服端可以先解析包头里面消息的长度，然后在读满这个长度大小的数据，就可以认为收到了一个完整的包\n7. RST 标识 7.1. 收到RST应用层处理情况 如果应用层尝试去读，比如recv 应用层就会收到 Connection reset by peer 意思是连接被重置 如果应用层尝试去写，比如send 应用层就会收到 Broken pipe 意思是这个通道已经坏了 7.2. RST出现的场景 RST 一般出现在异常情况，一般为对端的端口不可用和socket 提前关闭\n7.2.1. 端口不可用 端口未监听\n服务器Listen方法会创建一个sock放入全局的哈希表中，当客服端来连接的时候，会根据ip和端口从这个hash表中去获取sock\n7.2.1.1. 端口未监听一定会发送RST吗 不一定因为在知道服务器没有listen过，不会立马发送RST报文，而是会进行校验和检查,只有在校验和没有问题的时候才会发RST给对端\n校验和可以验证数据从端到端是否出现了异常，由发送端计算，然后接收端效验，计算范围覆盖数据包的tcp首部和tcp数据\n7.2.1.2. 为什么一定要先进行效验和，通过以后才发送RST 一般校验和出现了问题这个时候一般都是包被篡改了，或者是一个数据紊乱伪造的包\n在网络的5层协议中，如果出现这中问题，一般的做法都是丢弃，而不是傻乎乎的恢复一个包给对方\n如果是TCP协议，因为是可靠的，所以丢了也没有事情，当没有接到对端的ACK的时候，会重传\n如果是UDP协议，因为是不可靠传输的，接收端已经接收了不可靠的这中情况，那么丢了就丢了\n7.2.2. 程序启动了但是崩了 这个和端口未监听差不多，因为程序崩了，资源就会释放，那么就会进入Close状态，重启了以后，客服端新的连接进来的时候去全局的hash表根据IP地址和端口查找，却找不到Sock这个时候如果校验和通过了，那么也会发送RST报文过去\n7.2.3. socket提前关闭 7.2.3.1. 本端提前关闭 如果本端socket接收缓冲区还有数据，此时提前close() socket 那么本端会先把接收缓冲区的数据清空，然后给远端一个RST\n7.2.3.2. 远端提前关闭 远端已经close()这个时候本地还尝试给远端发送数据，这个时候远端会给本端回一个RST\n大家知道，TCP是全双工通信，意思是发送数据的同时，还可以接收数据。\nClose()的含义是，此时要同时关闭发送和接收消息的功能。\n客户端执行close()， 正常情况下，会发出第一次挥手FIN，然后服务端回第二次挥手ACK。如果在第二次和第三次挥手之间，如果服务方还尝试传数据给客户端，那么客户端不仅不收这个消息，还会发一个RST消息到服务端。直接结束掉这次连接。\n7.3. RST包丢了怎么办 RST丢了，问题不大，比如说上方的图，服务器发了RST之后，就认为服务器连接不可用了\n如果发送RST之前，客服端发送了数据，客服端没有等到ACK确认码，这个时候就会重发，重发的时候，服务器也会返回RST包\n如果在发送RST之前，客服端没有发送数据，那么因为有keepalive 机制，会定期发送探活包，这种数据到了服务器，可以触发一个RST包\n7.4. 收到RST一定会端开吗 不一定会端开，因为在收到RST之后，会进行检查seq是否合法，其实也是看这个seq是不是在合法的接收范围内，如果不在就丢弃这个RST包\n至于这个接收窗口是啥，如下图\n7.5. 为什么一定要校验在范围内 因为如果不校验的话，不怀好意的第三方伪造了seq的包，这个时候就会让客服端或者服务断开连接，如果效验的话毕竟因为窗口是在不断变化的，seq也在不断的变化，所以在范围内的seq很难被伪造出来\n7.6. socket recv和send 情况 7.7. 如果接收缓冲区有数据，这个时候close 如果接收缓冲区还有数据未读，会先把接收缓冲区的数据清空，然后给对端发送一个RST\n如果接收缓存区是空的，那么就会发送FIN，开始正常的四次挥手过程\n7.8. 如果发送缓冲区有数据，这个时候close socket 是个先进先出的队列，这个时候内核会把最后一块数据的标识置位FIN，然后安静的等待内核把数据都发出去\n8. UDP 8.1. udp有发送缓冲区吗 udp也是socket， 只要是socket就会有发和收两个缓冲区，和什么协议无关\n8.2. udp用发送缓冲区吗 一般情况下，会把数据拷贝到发送缓存区后直接发送\n9. 一些网络异常回答 9.1. 在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。 即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手\n如果有数据传输，那么就的分两种情况\n客户端宕机，然后立马重启。\n在客户宕机的时候，服务器一直接不到ACK确认码，这个时候就会触发重传\n如果客户端没有进程监听这个TCP报文的目标端口号，由于找不到目标端口号，那么客服端就会发送RST包，重置改连接\n如果客户端有进程监听这个TCP报文，这个时候重启，之前的TCP连接的socket结构体数据都会丢失，这个时候客户端找不到该TCP相关的socket数据，也会发送RST包\n客户端宕机，一直没有重启\n服务器就会触发超时重传报文机制，一般15次，不过tcp超时重传不止基于15次判断，还会基于最大超时时间来判定，也就是先达到最大超传次数或者最大超时时间，就会判定TCP有问题，就会停止重传\n","permalink":"https://frog-game.github.io/posts/blog/wangluozongjie/","summary":"1. tcp 握手挥手 序列号: 在建立连接的时候有计算机生成的随机数并作为初始值，通过syn包传给接收端主机，每发一次数据，就累加一次该数据字节数的大小","title":"网络底层总结"},{"content":" frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： frog\u0026rsquo;s Blog 网址： https://frog-game.github.io/ 描述 一个记录生活，技术的博客 ","permalink":"https://frog-game.github.io/links/","summary":"frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： frog\u0026rsquo;s Blog 网址： https://frog-game.github.io/ 描述 一个记录生活，技术的博客","title":"🤝友链"},{"content":"关于我\n英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山 ","permalink":"https://frog-game.github.io/about/","summary":"关于我 英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️关于"}]