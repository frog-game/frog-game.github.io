[{"content":"1. linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 2. 网络流程图 2.1 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Socket在Skynet内部对应一个Lua虚拟机和一个客户特定的消息队列per client mq。当客户特定消息队列中有消息时，该队列会挂载到全局队列global message queue上供工作线程worker Threads进行调度处理。\n一个Socket线程socket thread会轮询所有的Socket，当收到客户端请求后将请求打包成一个消息，发送到该Socket对应的客户特定消息队列per client mq中，然后将该消息队列挂到全局队列队尾。\n多个Worker工作线程worker threads从全局队列头部获取客户特定消息队列，从客户特定消息队列中取出一个消息进行处理，处理完毕后再将消息队列重新挂到全局队列队尾。\nskynet中不同服务是利用系统的多线程完全并行的，当你从服务A向服务B和服务C分别各自发送一条消息时，并不能保证先发的消息先被处理。而当你从服务A向服务B依次发送两条消息时，先发的消息一定会被服务B先处理。\n使用Lua实现的服务只是一个内嵌了Lua虚拟机的服务，也遵守上面的规则。如果服务B是一个Lua服务，当服务A向服务B发送两条消息x和y时，Skynet一定保证x先被服务B中的Lua虚拟机接收到，并为消息x生成要给协程X，并运行这个协程。然后才会接收到消息y，并重新生成一个新的协程Y并运行。\n2.2 同步问题 同步也是skynet存在的问题，当一个服务call其他服务时，当前协程会挂起，但是这个服务还可以接受并处理其他消息。如果多个协程改到同一个数据，你不做同步处理就无法确定这个数据会是多少。\n这样的例子特别常见，比如，服务正当处理玩家login请求，刚好遇到call挂起，这时候又有新的请求到来，比如logout，服务就会转去处理logout消息。那玩家究竟是login，还是logout？\n当然，同步问题也容易解决，加多一个state的标识和一个协程列表，操作执行时，将state置doing，其他协程判断state=doing时就将自己加到协程列表，然后 skynet.wait。在操作执行完后，重置state，然后遍历协程列表依次 skynet.wakeup(co) ，最后将协程列表置空。\n2.3 解释此队列 红黑树上的节点是所有监听的socket 黄色底的是interesting 队列 蓝色底是黄色底的子队列 也就是就绪队列 epoll_ctrl() 执行增加操作时候就是往interesting队列塞socket 当有读写事件时候，就会往蓝色底队列放入socket也就是塞入就绪队列 通过epoll_wait()把就绪队列的东西返回出来\n2.4 线程类型 socket thread : 线程进程消息收发\nmonitor thread : 线程监控服务是不是陷入死循环，消息是否堵住\ntime thread : 线程主要用于实现skynet的定时器\nwork thread 线程 对消息队列进行调度\n2.5 消息流转 先从全局队列 pop一个次级队列，然后从次级队列 pop一个消息调用回调函数进行逻辑处理 用完以后如果次级队列不为空或者堵塞，继续把次级队列放入全局队列 3. 启动流程 加载配置文件 配置文件存入lua的全局变量env 创建和启动c服务 logger 启动引导模块并启动第一个lua服务(bootstrap) 然后在通过 bootstrap配置去启动其他的微服务 4. cluster 两条tcp通道总结 \u0026lt;font color='red'\u0026gt;前提 \u0026lt;/font\u0026gt; 两端是严格分为请求方和回应方。比如 A---\u0026gt; B ，那么只能是A向B提出请求，B 回应它；如果 B-----\u0026gt;\u0026gt;A 需要由 B 向 A 再建立一条通道。\nTCP特性使得每个TCP连接可以得到均等的带宽。在多用户环境下，一个用户拥有越多TCP连接，获得的带宽越大\n1条连接 优点：链接少，对于没有接触过skynet，传统服务器人很容易这种方式连接方式，因为大部分很多都是cs结构程序员过来的 **缺点：**如果断了，数据就无法传输，得重新建立新的连接，上层业务逻辑写起来也麻烦，需要清楚那边是发送方，那边是接受方\n2条连接 **优点：**在前面前提的基础上，有两条连接，上层业务逻辑程序员不需要关心我这个时候是client，还是server，只需要通过 cluster.call，cluster.send，接口直接往里面塞数据就行了，多条连接也便于抢带宽 **缺点:**多了一条连接，对cs结构过来的程序员不太容易理解为什么这么弄有好处，或者是不知道有前面那个前提 为什么不在开辟更多的连接，因为开辟更多的链接意义不大，如果这台机器上弄了不少进程，连接数和机器的配置也是有关系的，多了，如果用不上也是一种浪费，同时对于业务程序员来说也逻辑混乱， 因为假如是4条，那么接受方还得区分是那条发过来的数据\n5. master / slave 组网过程 slave3发送 sync给 master，并启动自己的 listen master收到信息给已经连接上的 slave1，slave2发送 slave3请求连接的情况 master给 slave3发送当前已经连接上的 slave数量，并把 slave3加入节点组 slave1，slave3接收到 master发送的信息后，调用 connect去连接 slave3 6. master /slave 断网过程 master检测到 slave3失去连接，把 slave3连接 fd置成 0 master把失去连接的 slave3 id 广播给 slave1，slave2 slave1，slave2得到 slave3 id之后和 slave3断开连接 7. harbor 服务 每个节点都有一个 harborid，在发送消息的时候会把这个 harborid放到消息 id的\n高8位，所以通过高8位的对比就知道这个消息是远程消息，还是本地消息，如果是远程消息\n通过 harbor和远程的 harbor建立 tcp连接发送数据过去，如果是本地直接放入本地节点处理逻辑\n8. 消息处理方式 skeynet.send 非堵塞不需要应答 skynet.call 堵塞需要应答 skynet.ret 回应消息 skynet.response 请求和相应在不用协程处理 skynet.queue 串行化消息执行 9. 锁 互斥锁 适用于得到锁以后处理时间\u0026gt;线程切换时间场景 得到锁的线程会被唤醒处理逻辑，没有抢占到锁的线程会进入休眠状态\n互斥锁加锁失败以后，会从用户态变成内核态，线程就会释放 CPU 给其他线程,会有两次线程上下文的切换成本\n线程加锁失败时，内核会把线程的状态从 「运行」状态设置为 「睡眠」状态，然后把 CPU 切换给其他线程运行 接着，当锁被释放时，之前 「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 上下文切换的时间，大概在几十纳秒到几微妙之间，所以如果你能确认你被锁住的代码时间很短，那么就不应该用互斥锁，而应该用自旋锁\n9.2 自旋锁 没有获取到权限的的线程不会进入休眠状态一直自旋检测是否能获取资源，适用于得到锁以后处理时间\u0026lt; 线程切换时间的场景，得到锁处理逻辑最好别有IO操作或者文件流操作\n自旋锁是通过 cpu的 CAS函数，在用户态就完成了加锁和解锁操作，所以不会有上下文的切换，相比互斥锁来说，会快一点\n一般加锁的过程有两步\n查看锁的状态，如果锁是空闲的，那么执行第二步 将锁设置为当前线程持有 自旋锁加锁失败以后线程会 忙等待，直到它能 拿到锁\n9.3 读写锁 实现在 rwlock.h中\n读锁是 共享锁概念，其他锁去读的时候读取的是共享的资源，\n写锁是 独占概念，其他锁只能等待抢占到的锁释放资源，适用于读多写少场景\n所以更具场景可以分为 读优先锁和 写优先锁\n9.3.1 读优先锁 读优先锁对于读线程并发性更好，但是也不是没有问题，我们试想一下，如果一直有 读线程获取锁，那么 写线程就会被饿死\n9.3.2 写优先锁 写优先锁可以保证 写线程不被饿死，但是如果一直有 写线程获取，那么 读线程也会被饿死\n所以不管是优先读锁还是写锁，对方都可能被饿死，所以我们不偏袒任何一方，搞个 公平读写锁\n9.3.3 公平读写锁 用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的规则加锁，这样读线程一样能并发，也不会出现饥饿现象\n9.4 乐观锁和悲观锁区别 悲观锁做事比较悲观，他认为多线程同时修改共享资源的概率比较高，所以在访问资源之前都会先上一把锁。\n乐观锁正好相反，他认为多线程同时修改共享资源的概率比较低，所以会让先修改完资源，然后在判断是不是有冲突，有没有其他的线程在修改资源，如果有的话就直接放弃本次操作，\n互斥锁、自旋锁、读写锁，都是属于 悲观锁\n9.5 重入锁 就是能一条线程上能重复获取的锁，而不导致死锁\n10. cluster 模式 在每个 skynet 节点（单个进程）内，启动一个叫 clusterd 的服务。所有需要跨进程的消息投递都先把消息投递到这个服务上，再由它来转发到网络。\n首选通过 clustername.lua配置表配置好全部的 cluster节点 在所有要发现的节点上执行 require\u0026quot;skynet.cluster\u0026quot; 用 cluster.open建立自己的监听好让别的节点和自己建立 tcp通道连接 通过 cluster.register注册 create的 service 远程节点利用 cluster.query()来得到注册过的节点 通过 cluster.call skynet.call cluster.send skynet.send来调用远程 function1 function2函数 11 简易的mmo 架构 12 网关服务 main.lua 建立 watchdog watchdog 通过 skynet.start() 创建 gateService gateService并通过 rpc调用 watchdogService socket.open 函数 watchdogService 通过 socket.open 创建 agenService agenService 把 fd forward给 gateService client 发送请求给 gateService gateService 把请求重定向给 agentService agentService 把处理结果返回给 client 13 协程 coroutine 实现 详细代码见 lcorolib.c\n13.1 派发消息 function skynet.dispatch_message(...) -- 当前消息处理 local succ, err = pcall(raw_dispatch_message,...) while true do -- 顺序执行skynet.fork 创建的协程 if fork_queue.h \u0026gt; fork_queue.t then -- queue is empty fork_queue.h = 1 fork_queue.t = 0 break end -- pop queue local h = fork_queue.h local co = fork_queue[h] fork_queue[h] = nil fork_queue.h = h + 1 local fork_succ, fork_err = pcall(suspend,co,coroutine_resume(co)) if not fork_succ then if succ then succ = false err = tostring(fork_err) else err = tostring(err) .. \u0026#34;\\n\u0026#34; .. tostring(fork_err) end end end assert(succ, tostring(err)) end 13.2 处理当前消息 local function raw_dispatch_message(prototype, msg, sz, session, source) -- skynet.PTYPE_RESPONSE = 1, read skynet.h if prototype == 1 then -- 对回应类型的包处理 local co = session_id_coroutine[session] if co == \u0026#34;BREAK\u0026#34; then session_id_coroutine[session] = nil elseif co == nil then unknown_response(session, source, msg, sz) else local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;resume\u0026#34;) end session_id_coroutine[session] = nil suspend(co, coroutine_resume(co, true, msg, sz, session)) end else local p = proto[prototype] -- 找到对应的解析协议 if p == nil then if prototype == skynet.PTYPE_TRACE then -- trace next request trace_source[source] = c.tostring(msg,sz) elseif session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, prototype) end return end local f = p.dispatch -- 获取处理的函数 if f then local co = co_create(f) -- 获取协程 session_coroutine_id[co] = session session_coroutine_address[co] = source local traceflag = p.trace if traceflag == false then -- force off trace_source[source] = nil session_coroutine_tracetag[co] = false else local tag = trace_source[source] if tag then trace_source[source] = nil c.trace(tag, \u0026#34;request\u0026#34;) session_coroutine_tracetag[co] = tag elseif traceflag then -- set running_thread for trace running_thread = co skynet.trace() end end suspend(co, coroutine_resume(co, session,source, p.unpack(msg,sz))) else trace_source[source] = nil if session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, proto[prototype].name) end end end end 13.3 创建协程 local function co_create(f) local co = tremove(coroutine_pool) -- 从协程池中获取协程 if co == nil then --如果没有了 co = coroutine_create(function(...) -- 创建新的 f(...) --执行回调函数，不会立马执行只会调用coroutine.resume时候才会执行 while true do -- 为了能够复用刚创建的协成，下面需要对协程进行初始化和回收 local session = session_coroutine_id[co] if session and session ~= 0 then local source = debug.getinfo(f,\u0026#34;S\u0026#34;) skynet.error(string.format(\u0026#34;Maybe forgot response session %s from %s : %s:%d\u0026#34;, session, skynet.address(session_coroutine_address[co]), source.source, source.linedefined)) end -- coroutine exit local tag = session_coroutine_tracetag[co] if tag ~= nil then if tag then c.trace(tag, \u0026#34;end\u0026#34;) end session_coroutine_tracetag[co] = nil end local address = session_coroutine_address[co] if address then session_coroutine_id[co] = nil session_coroutine_address[co] = nil end -- recycle co into pool f = nil coroutine_pool[#coroutine_pool+1] = co -- recv new main function f f = coroutine_yield \u0026#34;SUSPEND\u0026#34; f(coroutine_yield()) end end) else -- pass the main function f to coroutine, and restore running thread local running = running_thread coroutine_resume(co, f) running_thread = running end return co end 13.4 协程挂起 -- suspend is local function function suspend(co, result, command) if not result then -- 执行co失败以后的处理 local session = session_coroutine_id[co] if session then -- coroutine may fork by others (session is nil) local addr = session_coroutine_address[co] if session ~= 0 then -- only call response error local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;error\u0026#34;) end c.send(addr, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) end session_coroutine_id[co] = nil end session_coroutine_address[co] = nil session_coroutine_tracetag[co] = nil skynet.fork(function() end) -- trigger command \u0026#34;SUSPEND\u0026#34; local tb = traceback(co,tostring(command)) coroutine.close(co) error(tb) end if command == \u0026#34;SUSPEND\u0026#34; then -- 挂起操作 return dispatch_wakeup() -- 如果有能够被唤醒的协程，就wakeup elseif command == \u0026#34;QUIT\u0026#34; then coroutine.close(co) -- service exit return elseif command == \u0026#34;USER\u0026#34; then -- See skynet.coutine for detail error(\u0026#34;Call skynet.coroutine.yield out of skynet.coroutine.resume\\n\u0026#34; .. traceback(co)) elseif command == nil then -- debug trace return else error(\u0026#34;Unknown command : \u0026#34; .. command .. \u0026#34;\\n\u0026#34; .. traceback(co)) end end\t13.5 协程销毁 主要是因为这种基础类型 LUA_TTHREAD来决定怎么销毁\nLUA_TTHREAD 介绍:\n除了主线程以外，其它线程和其它 Lua对象一样都是垃圾回收的对象。等待GC回收，当新建一个线程时，线程会压入栈，这样能确保新线程不会成为垃圾\n每次调用 lua_newstate的时候都会创建一个新的 luastate,不同的 luastate完全独立，之间不共享任何数据\n创建一个线程就拥有一个独立的执行栈了，但是它与其线程共用虚拟机的全局状态\n协程提供了新的 api接口和 lua_resetthread, coroutine.close 会使协程进入死亡状态,并且关闭所有的 close变量\n14 send.call 流程 15 API 相关 15.1 cluster cluster.call(node, address, ...) --远程调用node中的addr cluster.send(node, address, ...) --send调用远程node的addr cluster.open(port) --本地打开(监听)一个cluster结点，使其能在cluster中的其他结点发现 cluster.reload(config) --重载远程结点配置表，表中的cluster结点都open过，则可以通讯 cluster.proxy(node, name) --设置远程结点的代理，使得可以像调用本地RPC一样调用远程结点 cluster.snax(node, name, address) --生成一个远程的snax服务对象 cluster.register(name, addr) --注册一个cluster结点 cluster.query(node, name) --查找远程结点中注册过的结点是否存在 15.2 harbor harbor.link(id) --用来监控一个 slave 是否断开。如果 harbor id 对应的 slave 正常，这个 api 将阻塞。当 slave 断开时，会立刻返回。 harbor.linkmaster() --用来在 slave 上监控和 master 的连接是否正常。这个 api 多用于异常时的安全退出（因为当 slave 和 master 断开后，没有手段可以恢复）。 harbor.connect(id) --和 harbor.link 相反。如果 harbor id 对应的 slave 没有连接，这个 api 将阻塞，一直到它连上来才返回。 harbor.queryname(name) --可以用来查询全局名字或本地名字对应的服务地址。它是一个阻塞调用。 harbor.globalname(name, handle) --注册一个全局名字。如果 handle 为空，则注册自己。skynet.name 和 skynet.register 是用其实现的。 15.3 构建服务的一些基础接口 skynet.getenv(varName) --conf配置信息已经写入到注册表中，通过该函数获取注册表的变量值 skynet.setenv(varName, varValue) --设置注册表信息，varValue一般是number或string，但是不能设置已经存在的varname skynet.error(...) --打印函数 skynet.start(func) --用 func 函数初始化服务，并将消息处理函数注册到 C 层，让该服务可以工作。 skynet.init(func) --若服务尚未初始化完成，则注册一个函数等服务初始化阶段再执行；若服务已经初始化完成，则立刻运行该函数。 skynet.exit() --结束当前服务 skynet.self() --获取当前服务的句柄handler skynet.address(handler) --将handle转换成字符串 skynet.abort() --退出skynet进程 skynet.kill(address) ----强制杀死其他服务。可以用来强制关闭别的服务。但强烈不推荐这样做。因为对象会在任意一条消息处理完毕后，毫无征兆的退出。所以推荐的做法是，发送一条消息，让对方自己善后以及调用 skynet.exit 。注：skynet.kill(skynet.self()) 不完全等价于 skynet.exit() ，后者更安全。\t15.4 普通服务 skynet.newservice(luaServerName, ...) 15.5 全局唯一服务 skynet.uniqueservice(servicename, ...) --当前的skynet节点全局唯一 skynet.uniqueservice(true, servicename, ...) --所有的节点全局唯一 skynet.queryservice(servicename, ...) --当前的skynet节点中查找 skynet.queryservice(true, servicename, ...) --所有的节点中查找 15.6 别名 别名分两种：\n本地别名 代表只能在当前 skynet节点使用，本地别名用 .开头 全局别名 可以在所有的 skynet中使用 全局别名不能以 . 开头 skynet.register(aliasname) --给当前服务定一个别名，可以是全局别名，也可以是本地别名 skynet.name(aliasname, servicehandler) --给指定servicehandler的服务定一个别名，可以是全局别名，也可以是本地别名 --[[ 查询别名为aliasname的服务,可以是全局别名也可以是本地别名， 1、当查询本地别名时，返回servicehandler，不存在就返回nil 2、当查询全局别名时，返回servicehandler，不存在就阻塞等待到该服务初始化完成 ]]-- skynet.harbor.queryname(aliasname) skynet.localname(aliasname) --查询本地别名为aliasname的服务，返回servicehandler，不存在就返回nil skynet.kill(handle) --杀死带别名服务 15.7 服务调度 skynet.sleep(time) --让当前的任务等待 time * 0.01s 。 skynet.fork(func, ...) --启动一个新的任务去执行函数 func , 其实就是开了一个协程，函数调用完成将返回线程句柄 虽然你也可以使用原生的coroutine.create来创建协程，但是会打乱skynet的工作流程 skynet.yield() --让出当前的任务执行流程，使本服务内其它任务有机会执行，随后会继续运行。 skynet.wait() --让出当前的任务执行流程，直到用 wakeup 唤醒它。 skynet.wakeup(co) --唤醒用 wait 或 sleep 处于等待状态的任务。 skynet.timeout(time, func) --设定一个定时触发函数 func ，在 time * 0.01s 后触发。 skynet.starttime() --返回当前进程的启动 UTC 时间（秒）。 skynet.now() --返回当前进程启动后经过的时间 (0.01 秒) 。 skynet.time() --通过 starttime 和 now 计算出当前 UTC 时间（秒）。 15.8 消息类型 #define PTYPE_TEXT 0 --文本 #define PTYPE_RESPONSE 1 --表示一个回应包 #define PTYPE_MULTICAST 2 --广播消息 #define PTYPE_CLIENT 3 --用来处理网络客户端的请求消息 #define PTYPE_SYSTEM 4 --系统消息 #define PTYPE_HARBOR 5 --集群内其他的 skynet 节点发来的消息 #define PTYPE_SOCKET 6 --套接字消息 #define PTYPE_ERROR 7 --错误消息，一般服务退出的时候会发送error消息给关联的服务 #define PTYPE_QUEUE 8 --队列方式 #define PTYPE_DEBUG 9 --调试 #define PTYPE_LUA 10 --lua类型的消息，最常用 #define PTYPE_SNAX 11 --snax服务消息 #define PTYPE_TAG_DONTCOPY 0x10000 --禁止拷贝 #define PTYPE_TAG_ALLOCSESSION 0x20000 --分配新的 session 15.9 打包解包 skynet.pack(...) --打包 skynet.unpack(msg, sz) --解包 15.10 发送消息 -- 发送无需响应的消息 skynet.send(addr, type, ...) --用 type 类型向 addr 发送未打包的消息。该函数会自动把...参数列表进行打包，默认情况下lua消息使用skynet.pack打包。addr可以是服务句柄也可以是别名。自动打包与解包。） skynet.rawsend(addr, type, msg, sz) --用 type 类型向 addr 发送一个打包好的消息。addr可以是服务句柄也可以是别名。（需要自己打包与解包） -- 发送必须响应的消息 skynet.call(addr, type, ...) --用默认函数打包消息，向addr发送type类型的消息并等待返回响应，并对回应信息进行解包。（自动打包与解包。） skynet.rawcall(addr, type, msg, sz) --直接向addr发送type类型的msg,sz并等待返回响应，不对回应信息解包。（需要自己打包与解包） 15.11 响应消息 -- 同一个协成处理 skynet.ret() --目标服务消息处理后需要通过该函数将结果返回 skynet.retpack(...) --将消息用skynet.pack 打包，并调用 ret 回应。 --不在一个协成处理 local response = skynet.response(pack)--参数pack指定应答打包函数，不填默认使用skynet.pack, 必须根据接收到消息的打包函数一致 返回值是一个闭包函数 response(ok, ...) --参数ok的值可以是 \u0026#34;test\u0026#34;、true、false，为\u0026#34;test\u0026#34;时表示检查接收响应的服务是否存在，为true时表示发送应答PTYPE_RESPONSE，为false时表示发送PTYPE_ERROR错误消息。 15.12 消息冲入时序问题 skynet.queue() --帮助你回避这些服务重入或者伪并发引起的复杂性,但是明显降低了服务的并发处理能力，所以使用执行队列的时候尽量缩小临界区的颗粒度大小 15.13 协议转换 skynet.forward_type() --需要提供一张消息转换映射表forward_map, 其他的方法与skynet.start一样 15.14 伪造消息 skynet.redirect(dest,source,typename, session, msg, sz) --使用source服务地址，发送typename类型的消息给dest服务，不需要接收响应，（source，dest只能是服务ID）msg sz一般使用skynet.pack打包生成 15.15 组播 skynet.multicast -- 当组播的数据量较大时候可以节省内部的带宽 15.16 socket --建立一个 TCP 连接。返回一个数字 id 。 socket.open(address, port) --关闭一个连接，这个 API 有可能阻塞住执行流。因为如果有其它 coroutine --正在阻塞读这个 id 对应的连接，会先驱使读操作结束，close 操作才返回。 socket.close(id) --在极其罕见的情况下，需要粗暴的直接关闭某个连接，而避免 socket.close 的阻塞等待流程，可以使用它。 socket.close_fd(id) --强行关闭一个连接。和 close 不同的是，它不会等待可能存在的其它 coroutine 的读操作。 --一般不建议使用这个 API ，但如果你需要在 __gc 元方法中关闭连接的话， --shutdown 是一个比 close 更好的选择（因为在 gc 过程中无法切换 coroutine）。与close_fd类似 socket.shutdown(id) --[[ 从一个 socket 上读 sz 指定的字节数。 如果读到了指定长度的字符串，它把这个字符串返回。 如果连接断开导致字节数不够，将返回一个 false 加上读到的字符串。 如果 sz 为 nil ，则返回尽可能多的字节数，但至少读一个字节（若无新数据，会阻塞）。 --]] socket.read(id, sz) --从一个 socket 上读所有的数据，直到 socket 主动断开，或在其它 coroutine 用 socket.close 关闭它。 socket.readall(id) --从一个 socket 上读一行数据。sep 指行分割符。默认的 sep 为 \u0026#34;\\n\u0026#34;。读到的字符串是不包含这个分割符的。 --如果另外一端就关闭了，那么这个时候会返回一个nil，如果buffer中有未读数据则作为第二个返回值返回。 socket.readline(id, sep) --等待一个 socket 可读。 socket.block(id) --把一个字符串置入正常的写队列，skynet 框架会在 socket 可写时发送它。 socket.write(id, str) --把字符串写入低优先级队列。如果正常的写队列还有写操作未完成时，低优先级队列上的数据永远不会被发出。 --只有在正常写队列为空时，才会处理低优先级队列。但是，每次写的字符串都可以看成原子操作。 --不会只发送一半，然后转去发送正常写队列的数据。 socket.lwrite(id, str) --监听一个端口，返回一个 id ，供 start 使用。 socket.listen(address, port) --[[ accept 是一个函数。每当一个监听的 id 对应的 socket 上有连接接入的时候，都会调用 accept 函数。 这个函数会得到接入连接的 id 以及 ip 地址。你可以做后续操作。 每当 accept 函数获得一个新的 socket id 后，并不会立即收到这个 socket 上的数据。 这是因为，我们有时会希望把这个 socket 的操作权转让给别的服务去处理。accept(id, addr) ]]-- socket.start(id , accept) --[[ 任何一个服务只有在调用 socket.start(id) 之后，才可以读到这个 socket 上的数据。 向一个 socket id 写数据也需要先调用 start 。 socket 的 id 对于整个 skynet 节点都是公开的。也就是说，你可以把 id 这个数字 通过消息发送给其它服务，其他服务也可以去操作它。skynet 框架是根据调用 start 这个 api 的位置来决定把对应 socket 上的数据转发到哪里去的。 --]] socket.start(id) --清除 socket id 在本服务内的数据结构，但并不关闭这个 socket 。 --这可以用于你把 id 发送给其它服务，以转交 socket 的控制权。 socket.abandon(id) --[[ 当 id 对应的 socket 上待发的数据超过 1M 字节后，系统将回调 callback 以示警告。 function callback(id, size) 回调函数接收两个参数 id 和 size ，size 的单位是 K 。 如果你不设回调，那么将每增加 64K 利用 skynet.error 写一行错误信息。 --]] socket.warning(id, callback) 15.17 socketChannel 用来支持双向传输，异步非堵塞处理数据 15.18 dns skynet.dns --调用了系统 api getaddrinfo ，有可能阻塞住整个 socket 线程 所以skynet封装了这个接口来解决dns查询时候造成的线程堵塞问题 16 skynet 的通信调试pack 客户端按大小端打包成二进制\nlocal result = string.pack(\u0026#34;\u0026gt;s2\u0026#34;,\u0026#34;string2pack\u0026#34;) pack \u0026gt; 表示按大端顺序。s2 表示按照2个字节打包。 我们知道string由char组成。1个char 是 0-255 之间的数，2^8 ,1char=8byte 需要注意的是，他除了被打包的部分之外，还会在前面加2个字节，表示长度。 如果要打包一个数字则需要转换。由2种办法 string.pack(\u0026#34;I2\u0026#34;,number)，会在前面二进制加2位表示长度的东西。 socket发送\nsocket.send 服务端接收\ngateserver已经有接收的代码了。 注意的是，socket会自动按pack的数据分段接收。也就是会根据pack的前面2位得到size。根据size去接收后面的数据。然后向上传递一份message。 接收到的message已经是去掉了前面2位的数据。 客户端接收\n户端接收到的数据目前我是用skynet提供的“client.socket”.没有netpack可用。 接收到的数据需要自行去除前面的2个字节的数据（string.pack产生的）。 ","permalink":"https://frog-game.github.io/posts/blog/skynet/","summary":"1. linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 2. 网络流程图 2.1 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Soc","title":"skynet赏析"},{"content":" 演示\n安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana\n1. zabbix 6.0 1.1. 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 1.2. 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 1.3. 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-sql-scripts zabbix-agent 1.4. 创建初始数据库 mysql -uroot -p123456 mysql\u0026gt; create database zabbix character set utf8mb4 collate utf8mb4_bin; mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@`%`; mysql\u0026gt; quit; 1.5. 导入初始架构和数据，系统将提示您输入新创建的密码[默认密码现在设置为 123456 zcat /usr/share/doc/zabbix-sql-scripts/mysql/server.sql.gz | mysql -uzabbix -p -h10.40.38.67 zabbix # 指定本地的IP地址，不默认就会指向本地localhost 如果报ERROR 2003 (HY000): Can't connect to MySQL server on '10.40.38.67:3306' (111) 看第5章mysql操作指导，多半是因为权限和密码问题\n为Zabbix server配置数据库 sudo vim /etc/zabbix/zabbix_server.conf 修改 DBPassword=123456 1.6. 启动Zabbix server和agent进程 sudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server sudo systemctl enable zabbix-server zabbix-agent apache2 grafana-server 1.7. 连接web前端[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http://10.40.38.67/zabbix 默认的用户名是Admin(A是大写)，Password：zabbix 1.8. 修改时区 sudo vi /etc/apache2/conf-enabled/zabbix.conf 修改标准时区为 Asia/Shanghai 1.9. 中文显示 sudo apt install language-pack-zh-hans #安装中文语言包 sudo vim /etc/locale.gen #找到zh_CN.UTF-8 UTF-8 并取消#号注释，然后保存并退出 sudo locale-gen #编译语言包 sudo vim /etc/default/locale #修改默认语言为中文，将原来的内容改为 LANG=zh_CN.UTF-8 1.10. 安装出现的问题 1.10.1. Minimum required size of PHP post is 16M (configuration option \u0026ldquo;post_max_size\u0026rdquo;). 解决步骤：\nsudo vi /etc/php/8.1/apache2/php.ini post_max_size8M 16M\nmax_execution_time30 300\nmax_input_time60 300\ndate.timezone = Asia/Shanghai\nsudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server 1.10.2. ERROR 1396 (HY000): Operation CREATE USER failed for 'zabbix'@'%' mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; ERROR 1396 (HY000): Operation CREATE USER failed for \u0026#39;zabbix\u0026#39;@\u0026#39;%\u0026#39; 原因分析：\n已经存在了zabbix用户 在执行删除zabbix用户的时候没有删除干净 解决方法：\n重新进行删除。\ndrop user zabbix@\u0026#39;%\u0026#39;; flush privileges; 1.11. 卸载 zabbix 删除软件\nsudo apt-get --purge remove zabbix-server-mysql -y sudo apt-get autoremove zabbix-server-mysql -y sudo apt-get --purge remove zabbix-frontend-php -y sudo apt-get autoremove zabbix-frontend-php -y sudo apt-get --purge remove abbix-apache-conf -y sudo apt-get autoremove abbix-apache-conf -y sudo apt-get --purge remove zabbix-agent -y #删除软件其配置 sudo apt-get autoremove zabbix-agent -y #删除软件依赖包 清理数据\nsudo dpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 删除以上apt-get下载的软件包\nsudo apt-get autoclean 删除缓存的所有软件包\nsudo apt-get clean 删除其他软件依赖的但现在已不用的软件包（保留配置文件）\n```sh sudo apt-get autoremove ``` 查询出冗余文件并删除\nsudo find / -name zabbix 执行rm-rf 删除冗余文件\nsudo rm -rf /run/zabbix sudo rm -rf /etc/zabbix sudo rm -rf /usr/share/zabbix sudo rm -rf /var/log/zabbix sudo rm -rf /var/lib/mysql/zabbix 删除包含zabbix关键字的文件或者文件夹\n```sh sudo find / -name \u0026quot;zabbix*\u0026quot; | sudo xargs rm -rf ``` grafana 1.12. 下载grafana deb安装包 sudo apt-get install -y adduser libfontconfig1 sudo wget https://dl.grafana.com/enterprise/release/grafana-enterprise_8.5.4_amd64.deb sudo dpkg -i grafana-enterprise_8.5.4_amd64.deb 1.13. 启动grafana-server sudo systemctl restart grafana-server sudo systemctl enable grafana-server 安装zabbix插件 grafana-cli plugins list-remote sudo grafana-cli plugins install alexanderzobnin-zabbix-app #重启grafana-server sudo systemctl restart grafana-server 也可以在grafana-\u0026gt;plugins这里安装\n1.14. 登录grafana服务器[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http:/10.40.38.67:3000/ #默认用户名和密码为admin、admin 1.15. grafana 配置zabbix数据源 1.16. grafana 配置zabbix监控面板 在点击完new dashboard 按钮以后 按ctrl + s 保存一个自己定义的仪表盘\n1.17. grafana增加主题 安装插件：grafana-cli plugins install yesoreyeram-boomtheme-panel grafana主题地址：https://github.com/charles1503/grafana-theme/tree/master/CSS/themes/grafanas grafana更改主题教程：https://www.bilibili.com/read/cv7004400 视频教程：https://cloud.tencent.com/developer/video/11330 http://10.40.38.67:3000/public/themes/aquamarine.css 具体操作步骤：\n创建一个目录，用于存放下载对应主题的css文件\nsudo mkdir /usr/share/grafana/public/themes/ cd /usr/share/grafana/public/themes/ 使用一个for 循环下载对应的所有主题css文件\nfor f in grafana-base.css aquamarine.css hotline.css dark.css plex.css space-gray.css organizr-dashboard.css;do wget https://raw.githubusercontent.com/505384662/grafana-theme/master/CSS/themes/grafana/$f;done 为Grafana安装社区插件Boom Theme\nsudo grafana-cli plugins install yesoreyeram-boomtheme-panel sudo systemctl restart grafana-server 在Dashboard中添加Boom Theme\n1.18. grafana 主题修改地址 cd /usr/share/grafana/public/themes 1.19. grafana 加时钟 grafana-cli plugins install grafana-clock-panel systemctl restart grafana-server 1.20. grafana flowcharting安装 sudo grafana-cli plugins install agenty-flowcharting-panel sudo systemctl restart grafana-server grafana 修改模板地址 https://grafana.com/grafana/dashboards zabbix 修改配置地址：http://192.168.70.130/zabbix/setup.php zabbix 展示地址：http://192.168.70.130/zabbix/zabbix.php?action=dashboard.view grafana 展示地址: http://192.168.70.130:3000/d/tYxzFya7z/test_zabbix?orgId=1 1.21. Grafana 匿名访问（免登录） 修改Grafana配置文件\n在Grafana的配置文件 /etc/grafana/grafana.ini 中，找到 [auth.anonymous] 配置块，将其下的匿名访问控制 enabled 设置为 true，组织权限设置为 Viewer\nViewer:**只读**模式\nEditor:**可编辑**模式\nAdmin:**管理员**模式\n#################################### Anonymous Auth ###################### # Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false disable_login_form = true [auth.anonymous] # enable anonymous access enabled = true # specify organization name that should be used for unauthenticated users org_name = Main Org. # specify role for unauthenticated users org_role = Viewer 重启Grafana服务\n修改完配置文件，重启Grafana服务，命令如下：\nsudo systemctl restart grafana-server 1.22. 卸载 grafana 查找到安装软件名\nsudo dpkg -l | grep grafana 删除软件\n```sh sudo dpkg -r grafana-enterprise ``` 查询出冗余文件并删除\nfind / -name grafana 用rm-rf 命令删除\nrm -rf /etc/grafana rm -rf /usr/share/grafana rm -rf /usr/share/grafana/public/themes/grafana-theme/CSS/themes/grafana rm -rf /var/log/grafana rm -rf /var/lib/grafana 2. apache2 2.1. apache2启动报错 大致意思没有导入apache 环境变量 解决办法:\nsource /etc/apache2/envvars 还是报错\n大致意思是80端口被占用了 我选择的方法是kill占用进程在重启\nroot@hls:/root# netstat -lnp|grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 950/nginx: master p tcp6 0 0 :::80 :::* LISTEN 950/nginx: master p unix 2 [ ACC ] STREAM LISTENING 41930 1228/zabbix-plugin_ /tmp/plugin835680808 root@hls:/root# kill -9 950 root@hls:/root# systemctl restart zabbix-server zabbix-agent apache2 2.2. 卸载apache2 删除软件\n//1. 删除apache sudo apt-get --purge remove apache2 sudo apt-get --purge remove apache2.2-common //2.找到没有删除掉的配置文件，一并删除 sudo find /etc -name \u0026#34;*apache*\u0026#34; |xargs rm -rf sudo rm -rf /var/www sudo rm -rf /etc/libapache2-mod-jk //3.删除关联，这样就可以再次用apt-get install apache2 重装了 #dpkg -l |grep apache2|awk \u0026#39;{print $2}\u0026#39;|xargs dpkg -P//注意：这一步可能会报错，但也没关系 查询出冗余文件并删除\nsudo find / -name apache2 用rm -rf 命令删除\n3. Nginx 3.1. 官网下载地址 http://nginx.org/en/download.html 3.2. 一些环境准备 安装编译工具\nsudo apt-get install build-essential 安装编译工具 安装gcc什么的好便于下面编译安装 安装pcre包\nsudo apt-get update sudo apt-get install libpcre3 libpcre3-dev sudo apt-get install openssl libssl-dev 安装 zlib 库\nsudo apt install zlib1g-dev 3.3. 下载安装Nginx sudo wget http://nginx.org/download/nginx-1.21.6.tar.gz sudo tar -xzvf nginx-1.21.6.tar.gz cd nginx-1.21.6 sudo ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-stream --with-mail=dynamic #最好用 --prefix指定路径，便于后面删除[只需要删除prefix指定的文件夹就行了]，不指定的话后面删除比较麻烦 sudo make sudo make install 3.4. 制作软连接 ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 3.5. 配置环境变量 编辑/etc/profile并且追加Nginx的环境变量 export NGINX_HOME=/usr/local/nginx export PATH=$PATH:$NGINX_HOME/sbin 3.5.1. 生效环境变量 source /etc/profile 3.6. 测试是否安装成功 nginx -v 3.7. 启动Nginx sudo nginx 3.8. 强制停止Nginx sudo pkill -9 nginx 3.9. 查看Nginx进程 ps aux|grep nginx 3.10. 配置防火墙 sudo ufw allow \u0026#39;Nginx Full\u0026#39; 3.11. 验证防火墙是否允许 出现下面两种情况都认为可以 Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere Nginx Full ALLOW Anywhere 22/tcp (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) sudo ufw status 状态：不活动 3.12. 测试访问 http://192.168.70.132:7000 3.13. Nginx 相关文件位置 nginx path prefix: \u0026#34;/usr/local/nginx\u0026#34; nginx binary file: \u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; nginx modules path: \u0026#34;/usr/local/nginx/modules\u0026#34; nginx configuration prefix: \u0026#34;/usr/local/nginx/conf\u0026#34; nginx configuration file: \u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; nginx pid file: \u0026#34;/usr/local/nginx/logs/nginx.pid\u0026#34; nginx error log file: \u0026#34;/usr/local/nginx/logs/error.log\u0026#34; nginx http access log file: \u0026#34;/usr/local/nginx/logs/access.log\u0026#34; nginx http client request body temporary files: \u0026#34;client_body_temp\u0026#34; nginx http proxy temporary files: \u0026#34;proxy_temp\u0026#34; nginx http fastcgi temporary files: \u0026#34;fastcgi_temp\u0026#34; nginx http uwsgi temporary files: \u0026#34;uwsgi_temp\u0026#34; nginx http scgi temporary files: \u0026#34;scgi_temp\u0026#34; 卸载 Nginx sudo rm -rf /usr/local/nginx sudo rm -rf /usr/local/nginx/sbin/nginx #软连接也记得删除 如果想完全干净，/etc/profile 配置文件中指定的环境变量也可以删除 4. mysql 4.1. 安装mysql sudo apt update sudo apt install mysql-server 安装完成后，MySQL服务将自动启动。要验证MySQL服务器正在运行，请输入：\nsudo systemctl status mysql 彻底卸载mysql方法 查看依赖包\ndpkg --list | grep mysql 先依次执行以下命令\nsudo apt-get remove mysql-common sudo apt-get autoremove --purge mysql-server-5.0 # 卸载 MySQL 5.x 使用, 非5.x版本可跳过该步骤 sudo apt-get autoremove --purge mysql-server 然后再用\ndpkg --list | grep mysql 查看一下依赖包最后用下面命令清除残留数据\ndpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 查看从MySQL APT安装的软件列表, 执行后没有显示列表, 证明MySQL服务已完全卸载\ndpkg -l | grep mysql | grep i 博客地址\nhttps://blog.csdn.net/PY0312/article/details/89481421 MySQL在Ubuntu上启动出错Could not open ‘abstractions/mysql‘ rm -rf /etc/apparmor.d/abstractions/mysql rm -rf /etc/apparmor.d/cache/usr.sbin.mysqld find / -name \u0026#39;mysql*\u0026#39; -exec rm -rf {} \\; 4.2. 连接MySql报错“can\u0026rsquo;t connect to local mysql server through socket \u0026lsquo;/var/run/mysqld/mysqld.sock\u0026rsquo; cd /etc/init.d sudo service mysql stop sudo service mysql start mysql Ubuntu 20.04 Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost 首先输入以下指令 获取密码：\nsudo cat /etc/mysql/debian.cnf 再输入以下指令进入mysql\n查询user关键字段\nselect user, authentication_string,plugin,Host from mysql.user; 修改密码格式\nuse mysql; update user set plugin=\u0026#39;mysql_native_password\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 修改密码\nuse mysql; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; flush privileges; 输入\nmysql -uroot -p123456; 查看效果 让别的ip能连上wsl数据库\nuse mysql; update user set Host=\u0026#39;%\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 输入\nselect user, authentication_string,plugin,Host from mysql.user; 查看效果\n开启远程访问\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf # 注释 bind-address = 127.0.0.1 重启mysql\nsudo service mysql restart 效果\n5. ELK 5.1. 一些准备 5.1.1. 官网地址 https://www.elastic.co/guide/en/elasticsearch/reference/8.0/deb.html#deb-repo 5.1.2. 虚拟机 想要多开最好是克隆一份出来 比如2就是克隆的1的镜像\n修改 克隆的虚拟机网卡地址\nsudo vim /etc/netplan/00-installer-config.yaml 修改内容:\nnetwork: ethernets: ens33: #配置的网卡的名称 addresses: [192.168.70.130/24] #配置的静态ip地址和掩码 dhcp4: no #关闭DHCP，如果需要打开DHCP则写yes optional: true gateway4: 192.168.70.2 #网关地址 nameservers: addresses: [192.168.70.2,114.114.114.114] #DNS服务器地址，多个DNS服务器地址需要用英文逗号分隔开 version: 2 renderer: networkd #指定后端采用systemd-networkd或者Network Manager，可不填写则默认使用systemd-workd 使配置生效\nsudo netplan apply 注意事项\n1、ip地址和DNS服务器地址需要用[]括起来，但是网关地址不需要 2、注意每个冒号后边都要先加一个空格 3、注意每一层前边的缩进，至少比上一层多两个空格 5.1.3. 安装java环境 安装java sudo apt install openjdk-8-jdk 查看java 版本\nsudo java -version 查看 java 路径\nsudo which java ls -l /usr/bin/java 看看这是否是个软连接，找出这个软连接指向的路径\nls -l /usr/bin/java 的确为软连接，继续往下找指向的路径\n至此，java 的安装路径即为 /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n配置 java 环境\nsudo vim /etc/profile 在弹出的 vim 编辑器中输入\n# JAVA JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH esc 退出编辑模式，输入 :x后，单击回车退出。\n在终端输入\nsource /etc/profile 使之前的配置生效。\n验证\njava -version\n$JAVA_HOME/bin/java -version\n5.1.4. python3 [不是必须装主要是想使用 json.tool 格式化输出]\n安装python3.8\nsudo apt-get install python3.8 建立软连接\nsudo ln -s /usr/bin/python3.8 /usr/bin/python 如果想要删除软连接\nsudo rm -rf /usr/bin/python 格式化输出\ncurl -XGET http://192.168.70.131:9200/_mapping | python -m json.tool 5.2. Elasticsearch 5.2.1. 基础知识 和关系型数据库的比较 DBMS Elasticsearch database Index table type(在7.0之后type为固定值_doc) Row Document Column Field Schema Mapping SQL DSL(Descriptor Structure Language) 安装Elasticsearch deb包安装方式\nsudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb sudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb.sha512 shasum -a 512 -c elasticsearch-8.2.2-amd64.deb.sha512 sudo dpkg -i elasticsearch-8.2.2-amd64.deb 执行**sudo dpkg -i elasticsearch-8.2.2-amd64.deb** 回生成超级用户密码 0NgzdrlHquc1YdXrQout\n--------------------------- Security autoconfiguration information ------------------------------ Authentication and authorization are enabled. TLS for the transport and HTTP layers is enabled and configured. The generated password for the elastic built-in superuser is : 0NgzdrlHquc1YdXrQout If this node should join an existing cluster, you can reconfigure this with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token \u0026lt;token-here\u0026gt;\u0026#39; after creating an enrollment token on your existing cluster. You can complete the following actions at any time: Reset the password of the elastic built-in superuser with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\u0026#39;. Generate an enrollment token for Kibana instances with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\u0026#39;. Generate an enrollment token for Elasticsearch nodes with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\u0026#39;. ------------------------------------------------------------------------------------------------- 生成 ca 、生成 证书\n# 生成 ca # 根据提示： # 输入 ca 的密码（密码不要忘记，后面生成证书需要） # 输入生成 ca 的文件名（默认会让你输入 elastic-stack-ca.p12，这里就按照默认的来） sudo /usr/share/elasticsearch/bin/elasticsearch-certutil ca # 生成证书 # 根据提示： # 输入之前 ca 的密码 # 输入生成证书的文件名（默认让你输入 elastic-certificates.p12，这里就按照默认的来） # 输入生成证书的密码（密码不要忘记，这个密码在配置 ES keystore 的时候需要） # --ca 后面的文件是上面步骤生成的 elastic-stack-ca.p12 文件，如果修改了的话，这里也需要修改 sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 ​\t为了方便管理，一般将 ca 与证书放到 ~/.config/certs 目录下\n# 创建目录并移动 ca 与证书 sudo mkdir -p ~/.config/certs \u0026amp;\u0026amp; sudo mv /usr/share/elasticsearch/elastic-stack-ca.p12 /usr/share/elasticsearch/elastic-certificates.p12 ~/.config/certs 5.2.2. 启动 Elasticsearch ​\t[为了安全考虑Elasticsearch不允许使用root用户来启动]\n打开 elasticsearch 配置文件\nsudo vim /etc/elasticsearch/elasticsearch.yml #打开配置文件 修改 netWork.host, http.port 字段\nnetwork.host: 10.40.38.66 #注意 network.host:和10.40.38.66 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 http.port: 9200 #注意 http.port:和9200 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 因为是内网测试暂时关闭 xpack 安全验证方面选项,以后需要再去开启\n启动Elasticsearch\nsudo systemctl start elasticsearch.service 开机启动elasticsearch\nsudo systemctl enable elasticsearch.service 5.2.3. 连接grafana 5.2.4. Elasticsearch 操作命令 用jps命令关闭Elasticsearch\n$ jps | grep Elasticsearch 14542 Elasticsearch kill -9 14542 查看 Elasticsearch 端口\nsudo netstat -tnlp |grep java 检测是否启动成功\ncurl -XGET \u0026#39;http://192.168.70.131:9200/\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; 用journal 查看系统日志\nsudo journalctl -f 用 journal 查看elasticsearch 服务日志\nsudo journalctl --unit elasticsearch 用journal 查看elasticsearch 指定时间范围的日志\nsudo journalctl --unit elasticsearch --since \u0026#34;2022-02-01 18:17:16\u0026#34; 查看 elasticsearch.log\nsudo vim /var/log/elasticsearch/elasticsearch.log 5.2.5. Elasticsearch 卸载 # 查看安装的软件 sudo dpkg -l | grep elasticsearch #查看安装关联 sudo dpkg -L elasticsearch #移除安装软件 sudo dpkg -P elasticsearch #继续查看未卸载的目录和文件 sudo find / -name elasticsearch #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/elasticsearch.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/log/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /usr/share/elasticsearch #在此查看是否有关联的目录和文件 sudo find / -name elasticsearch 5.3. Logstash 5.3.1. 安装 Logstash 下载安装公共签名\nsudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Elasticsearch了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install logstash 5.3.2. 插件地址 https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html 5.3.3. 配置表字段解释 https://blog.csdn.net/weixin_42073629/article/details/110154037?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-110154037.pc_agg_new_rank\u0026amp;utm_term=logstash%E5%8F%82%E6%95%B0convert\u0026amp;spm=1000.2123.3001.4430 5.3.4. 查看安装的插件 sudo /usr/share/logstash/bin/logstash-plugin list 启动Lostash 修改 logstash.yml 配置\nsudo vim /etc/logstash/logstash.yml 5.3.5. 导入数据[利用logstash 直接分析movies.csv 传送给elasticsearch方式] ​\t收集流程: movies.csv-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n下载ml-latest.zip 数据\nsudo wget https://files.grouplens.org/datasets/movielens/ml-latest.zip 解压 ml-latest.zip\nsudo unzip ml-latest.zip 在/etc/logstash 目录下创建logstash.conf 文件\nsudo vim /etc/logstash/logstash.conf 把以下内容写入logstash.conf\ninput { file { #监听文件的路径 path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/movies.csv\u0026#34; #监听文件的起始位置，默认是end start_position =\u0026gt; \u0026#34;beginning\u0026#34; #监听文件读取信息记录的位置 sincedb_path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/db_path.log\u0026#34; } } filter { csv { separator =\u0026gt; \u0026#34;,\u0026#34; columns =\u0026gt; [\u0026#34;id\u0026#34;,\u0026#34;content\u0026#34;,\u0026#34;genre\u0026#34;,\u0026#34;@timestamp\u0026#34;] } mutate { # split =\u0026gt; { \u0026#34;genre\u0026#34; =\u0026gt; \u0026#34;|\u0026#34; } # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;] #删除无用字段 } mutate { split =\u0026gt; [\u0026#34;content\u0026#34;, \u0026#34;(\u0026#34;] #左括号分割 add_field =\u0026gt; { \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;%{[content][0]}\u0026#34;} #增加字段 add_field =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;%{[content][1]}\u0026#34;} #增加字段 } mutate { convert =\u0026gt; { #year 转换成整型 \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;integer\u0026#34; } strip =\u0026gt; [\u0026#34;title\u0026#34;] #去掉字段首尾的空格 # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;,\u0026#34;content\u0026#34;] #删除无用字段 } } output { elasticsearch { # 双引号中的内容为ES的地址，视实际情况而定 hosts =\u0026gt; \u0026#34;http://192.168.70.131:9200\u0026#34; index =\u0026gt; \u0026#34;movies\u0026#34; document_id =\u0026gt; \u0026#34;%{id}\u0026#34; #docId 等价于_id 字段 } stdout {} } 如果需要重新导入，先删除db_path.log 文件\nsudo rm -rf /var/lib/logstash/.lock sudo rm -rf /home/hls/downs/ml-latest/db_path.log sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf 报错\n执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults 那么就创建软连接\ncd /usr/share/logstash sudo ln -s /etc/logstash ./config 执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nLogstash could not be started because there is already another instance using the configured data directory. If you wish to run multiple instances, you must change the \u0026#34;path.data\u0026#34; setting. 那么就去 logstash.yml 中path.data 指定的路径上去删除.lock文件\ncd /var/lib/logstash sudo ls -a sudo rm -rf .lock 或者直接一句话\nsudo rm -rf /var/lib/logstash/.lock 5.3.6. 强制查看输出 logstash.conf 修改成你自己的文件 sudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --verbose --debug 5.3.7. 查看数据 用Kibana的命令行工具执行 GET _cat/indices 命令，就能看见导入到Elasticsearch的索引\n用kibana的命令行工具执行**GET /lua_cpu_monitor-2022.06.03/_search**命令,就能看见导入到Elasticsearch的数据\n5.3.8. 自动重新加载配置命令 logstash.conf 修改成你自己的文件\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.automatic 默认检测时间是**3**秒 可以通过下列命令修改 把\u0026lt;\u0026gt;号里面的2换成你想要的时间\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.interval \u0026lt;2\u0026gt; 5.3.9. 卸载Logstash # 查看安装的软件 sudo dpkg -l | grep logstash #查看安装关联 sudo dpkg -L logstash #移除安装软件 sudo dpkg -P logstash #继续查看未卸载的目录和文件 sudo find / -name logstash #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/logstash \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/logstash.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/logstash \u0026amp;\u0026amp; sudo rm -rf /var/log/logstash \u0026amp;\u0026amp; sudo rm -rf /usr/share/logstash #在此查看是否有关联的目录和文件 sudo find / -name logstash 5.4. Kibana 5.4.1. 安装Kibana 下载安装公共签名\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Kibana了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install kibana 5.4.2. 启动Kibana 打开kibana.yml 文档\nsudo vim /etc/kibana/kibana.yml 修改 server.port,server.host 字段\n启动\nsudo systemctl start kibana.service 自启动\nsudo systemctl enable kibana.service 查看 kibana日志\nsudo vim /var/log/kibana 用谷歌或者微软自带浏览器打开地址\nhttp://10.40.38.66:5601 5.4.3. 卸载Kibana # 查看安装的软件 sudo dpkg -l | grep kibana #查看安装关联 sudo dpkg -L kibana #移除安装软件 sudo dpkg -P kibana #继续查看未卸载的目录和文件 sudo find / -name kibana #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/kibana \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/kibana.* \u0026amp;\u0026amp; sudo rm -rf /etc/kibana #在此查看是否有关联的目录和文件 sudo find / -name kibana 5.5. Filebeat 搭配filebeat主要使用收集nginx数据, 和上面的利用logstash解析movies.csv，然后收集数据给elasticsearch的方式不一样\n收集流程: nginx-\u0026gt;filebeat-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n5.5.1. 安装Filebeat sudo curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.2.2-amd64.deb sudo dpkg -i filebeat-8.2.2-amd64.deb 5.5.2. 修改 filebat.yml 配置文件 sudo vim /etc/filebeat/filebeat.yml 修改下列几项\n# ============================== Filebeat inputs =============================== filebeat.inputs: - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_cpu_monitor.log tags: [\u0026#34;lua_cpu_monitor_log\u0026#34;] - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_mem_monitor.log tags: [\u0026#34;lua_mem_monitor_log\u0026#34;] # ============================== Filebeat modules ============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 1 # ------------------------------ Logstash Output ------------------------------- output.logstash: # The Logstash hosts hosts: [\u0026#34;10.40.38.66:5555\u0026#34;] # ================================= Processors ================================= processors: - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 6.5.3. 测试filebeat启动后，查看相关输出信息 sudo filebeat -e -c /etc/filebeat/filebeat.yml -d \u0026#34;publish\u0026#34; 6.5.4. 后台方式启动filebeat nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; #将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出 nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt; filebeat.log \u0026amp; 6.5.5. 停止filebeat ps -ef | grep filebeat kill -9 进程号 6.5.6. 启动出现的问题 执行命令systemctl start filebeat.service就能够启动了。而后执行ps -ef|grep filebeat查看一下\n能够看到已经启动胜利了，如果你发现没有启动成功，那么就执行 cd /usr/bin，在这个目录下执行./filebeat -c /etc/filebeat/filebeat.yml -e，这样会提醒具体的错误信息。而用systemctl start filebeat.service启动的时候没有任何提醒，连在 /var/log/filebeat/ 和 /var/lib/filebeat/registry/filebeat/ 都没找到错误信息，这里属实有点坑。\n重新启动命令systemctl restart filebeat.service\n6.5.7 去安装logstash的机器启动logstash 增加 logstash_filebeat.conf 文档\nsudo vim /etc/logstash/conf.d/logstash_filebeat.conf 把以下内容粘贴上保存\ninput { beats { port =\u0026gt; 5555 #这个地址不能和logstash.yml 里面的api.http.host: 9600 一样，要不会出现地址已经被绑定的错误 } } output { if \u0026#34;lua_cpu_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_cpu_monitor-%{+YYYY.MM.dd}\u0026#34; } } if \u0026#34;lua_men_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_men_monitor-%{+YYYY.MM.dd}\u0026#34; } } } 重新加载新的配置并启动logstash\n先启动logstash，然后在启动filebeat，不然的话filebeat会找不到beats插件的:5555端口\nsudo rm -rf /var/lib/logstash/.lock sudo /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash_filebeat.conf --verbose --debug 6.5.8. 用filebeat 监控 nginx 修改 nginx conf 配置表\nsudo vim /usr/local/nginx/conf/nginx.conf 加入如下日志格式\nlog_format main \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;@source\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;hostname\u0026#34;:\u0026#34;$hostname\u0026#34;,\u0026#39; \u0026#39;\u0026#34;ip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_method\u0026#34;:\u0026#34;$request_method\u0026#34;,\u0026#39; \u0026#39;\u0026#34;scheme\u0026#34;:\u0026#34;$scheme\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$server_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request_uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;args\u0026#34;:\u0026#34;$args\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamaddr\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;https\u0026#34;:\u0026#34;$https\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; 对比修改下图对应的3个红框地方\n重启 nginx\nsudo pkill -9 nginx \u0026amp;\u0026amp; sudo nginx 用 http:192.168.70.132:7000 登录nginx 网站生成登录日志，然后打开 access.log 日志\nsudo vim /usr/local/nginx/logs/access.log sudo tail -f /usr/local/nginx/logs/access.log 6.5.9. 卸载Filebeat # 查看安装的软件 sudo dpkg -l | grep filebeat #查看安装关联 sudo dpkg -L filebeat #移除安装软件 sudo dpkg -P filebeat #继续查看未卸载的目录和文件 sudo find / -name filebeat #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat \u0026amp;\u0026amp; sudo rm -rf /usr/share/filebeat #在此查看是否有关联的目录和文件 sudo find / -name filebeat ","permalink":"https://frog-game.github.io/posts/blog/zabbix-mysql8.0/","summary":"演示 安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana 1. zabbix 6.0 1.1. 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 1.2. 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 1.3. 安装Zabbix server，Web前端，agent sudo apt","title":"zabbix游戏监控日志系统部署"},{"content":"1. 微服务器框架lua调试器 针对skynet这种微服器框架和自己从 0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店进行\n下载使用有问题欢迎留言交流\n2. 多虚拟机测试 3. linux测试 4. 真机测试 ","permalink":"https://frog-game.github.io/posts/blog/vscode-lua-chajian/","summary":"1. 微服务器框架lua调试器 针对skynet这种微服器框架和自己从 0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店","title":"微服务lua调试器"},{"content":"1. 前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑做不到，手机就更加不用说了 这类大地图，在客服端都是分区域进行加载，也就是会进行切割，比如像绝地求生这样的游戏，大概80公里左右大的地图，会被切割成100 *100 个格子，大概每个格子800米左右，每个格子会打上索引标记，当客服端在进行移动的时候就会根据视野，一般都是九宫格区域，然后根据视野新旧对地图块进行预加载和删除。 在绝地求生跳伞阶段，其实是整张地图进行加载的，但是这个时候不是加载的高精度地图块，而是一个经过简化的地图，而且这种地图块不会只有一份，一般会有多份，这种也叫多层LOD，也就是随着你跳伞以后，距离地面越来越近，程序会给你切换不同的地图块，这也就是为什么有时候你在跳伞的过程中有时候会看到闪烁情况，其实这个时候是程序在给你切换不同的地图块 2. 构建大世界地图 2.1. 利用bspTree原理对地图进行动态切割 分裂条件：\n人数达到上线 区域大小必须超过多大，比如必须达到50 *50 大小才能分裂 1.场景管理服务器启动以后会创建一个全局的space，假设大小是100 * 100，同时也创建一个同样大小的cell1\n假如按宽10进行分割，会形成 10 * 100,90 * 100 两个长方形\n假如按长90来对剩下的3进行分割\n一直往下切割的话，左边会越来越多，右儿子会越来越少，从而达到负载均衡的效果但是也有分割也有条件\n兄弟两都为叶子节点 左二子被分割后的大小不应该大于右儿子 2.2. 利用bspTree原理对地图进行动态合并 合并条件:\nCell区域小于100(可配) 人数小于指定人数(可配) 待合并的2个结点必须是叶子结点 删除待合并的两个儿子结点，修改父亲结点的场景区域 合并前\n合并后\n当不管是分割还是合并发现他的实体已经不再当前cell了那么实体应该迁移到他合适的地方去\n3. 边缝处理 假设我们现在有3个cellServer进程管理着各自的ABC3个cell块\n当上面的a角色到达边界的时候，我们这个时候就需要进行real和ghost的数据同步，开始在重叠区域进行转换，进行转换的区域一般要比自己的视野范围要大，比如现在的重叠转换区域就是那个红色圈，大于自己的视野黑色圈\n在entity aoi范围内，又不在同一cell的，在这个cell上创建同坐标的一个ghost 镜像，也就是上面的暗红色和绿色星星就是BC cell上面的ghost镜像 ghost 只能是只读的，每次去修改只能先修改real实体然后在去同步ghost属性 4. 新的边缝处理方法 比如现在有A B两个cell 这个时候黄色的角色从A走向了B 现在过了边界，但是我们现在不用创建镜像和实体的方法来实现无缝地图，而是用传送的方式，传送触发的实际就是那根绿色线和边界的距离，比如5米，当玩家走到了这个触发范围我们就开始直接把人传送到B，这样也不用处理ghost和real之间定时同步，还有异步技能带来的各种异常情况，bug查找\n5. 技能处理 攻击方一定要是real实体，被攻击方可以是real实体，也可以是ghost实体\n下方的数据同步可以写到核心框架，也就是定时同步real实体的信息到ghost实体上\n6. 寻路 因为世界地图很大，所以我们可以用**路点+ 小段距离A星或者jps算法**来实现寻路\n先求路点，比如如下的地铁图，我们可以根据权重值或者时间的组合，通过**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法求出最短路径，这些路径可以离线先求出来，等使用的时候直接使用 还是以上面这图为例子现在你在红色小人那个位置也就是关庄下面小人的位置，这个时候如果障碍物多，你可以骑单车过来也就是用**A星算法寻路到惠新西街南口，如果障碍物少，那么你可以打车，或者坐大巴也就是jps算法到彗新西街南口，到了起始点之后，你就可以坐地铁也就是前面用Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算出的离线路径直接到达下面的地跌目的地南锣鼓巷\n到了南锣鼓巷以后，同样你也可以按2步骤，选择是**a星还是jps算法**到达公司\n如果地图超大，其实在用**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算地铁图的时候我们可以分几块区域算出各自地铁路线图，然后连接起来，举个栗子，比如可以划分，彗星西街南口到北土城是一个区域，北土城到鼓楼大街是个区域，鼓楼大街到南锣鼓巷是个区域，这3个区域各自算好，各自存储好，到时拼接起来就是惠新西街南口到南锣鼓巷的整条离线路线，如下图红，黑，黄三个框，代表3个区域\n","permalink":"https://frog-game.github.io/posts/blog/wufengdashijie/","summary":"1. 前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电","title":"无缝大世界"},{"content":"1. 图解释 2. 结构体 typedef struct byteQueue_s { char*\tpBuffer;//数据 size_t\tnCapacity;//容量 size_t\tnReadIndex;//读指针索引 size_t\tnWriteIndex;//写指针索引 } byteQueue_tt; 3. 初始 结构体 假设要申请的空间 环形buff结构体大小为8\nnWriteIndex 写指针索引 nReadIndex 读指针索引 环形buff初始化\nvoid byteQueue_init(byteQueue_tt* pByteQueue,size_t nCapacity = /* = 8*/) { pByteQueue-\u0026gt;nReadIndex = nCapacity;//读指针索引位置设置为8,放到末尾 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置成0，放到开头 pByteQueue-\u0026gt;nCapacity = nCapacity;//容量 if( nCapacity != 0 ) { pByteQueue-\u0026gt;pBuffer = mem_malloc(nCapacity);//申请空间 } else { pByteQueue-\u0026gt;pBuffer = NULL;//置空 } } 4. 清空结构体 void byteQueue_clear(byteQueue_tt* pByteQueue) { pByteQueue-\u0026gt;nReadIndex = 0;//读指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nCapacity = 0;//容量设置为0 if(pByteQueue-\u0026gt;pBuffer) { mem_free(pByteQueue-\u0026gt;pBuffer);//如果有数据进行释放 pByteQueue-\u0026gt;pBuffer = NULL;//并且置空 } } 5. 获取剩余全部可写空间 static inline size_t byteQueue_getBytesWritable(byteQueue_tt* pByteQueue) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex )//写指针和读指针重合，或者在读指针前面 { return pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//直接读指针 - 写指针 就是 写入了多少内容 } else//写指针在读指针后面 { return pByteQueue-\u0026gt;nReadIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex); //读指针位置 + (容量 - 写指针位置) } } 5.1. 写指针在读指针前面[求得是蓝色块数据] 5.2. 写指针在读指针后面[求得是蓝色块数据] 6. 获取剩余全部可读空间 static inline size_t byteQueue_getBytesReadable(byteQueue_tt* pByteQueue) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex) //读指针在写指针前面 { return pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//直接写指针 - 读指针 就是可以读多少数据 } else //读指针和写指针重合,或者读指针在写指针后面 { return pByteQueue-\u0026gt;nWriteIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex); //写指针 + (容量 - 读指针位置) } } 6.1. 写指针在读指针后面[求的是红色块的数据] 6.2. 写指针在读指针前面[求的是红色块的数据] 7. 查看连续的可写空间 //查看连续的可写空间 //size_t* pWriteBytes 能连续写入的大小 static inline char* byteQueue_peekContiguousBytesWrite(byteQueue_tt* pByteQueue, size_t* pWriteBytes) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex)//读指针在写指针后面 { *pWriteBytes = pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } else//读指针在写指针前面 { *pWriteBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nWriteIndex;//开始连续写入指针的起始位置 } 7.1. 写指针在读指针前面[求得连续可写的空间] 7.2. 写指针在读指针后面[求得连续可写的空间] 8. 查看连续可读空间 //查看连续的可读空间 //size_t* pWriteBytes 能连续读取的大小 static inline char* byteQueue_peekContiguousBytesRead(byteQueue_tt* pByteQueue, size_t* pReadBytes) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex)//写指针在读指针后面 { *pReadBytes = pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } else { *pReadBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nReadIndex;//开始连续读入指针的起始位置 } 8.1. 写指针在读指针后面[求得连续可读的空间] 8.2. 写指针在读指针前面[求得连续可读的空间] 9. 写入一个字符[空间不足按256的倍数自动扩展] void byteQueue_writeChar(byteQueue_tt* pByteQueue, const char c) { if(pByteQueue-\u0026gt;nCapacity == 0) { //初始化容量,buffer大小，可读索引 pByteQueue-\u0026gt;nCapacity = 256;//初始化容量大小[256] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取获取剩余全部可写空间 if (1 \u0026gt; nBytesWritable) { //align_size 将size按align大小整数倍提升,用于内存对齐 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + 1,256); char* pBuffer = mem_malloc(nNewCapacity); if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//说明还有数据没有读走 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//获取剩余全部可读的空间 size_t nReadBytes = 0;//连续可读的空间的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取数据的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//如果连续可读的空间的大小!=剩余全部可读的空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//到了新空间需要重新移动读指针 pByteQueue-\u0026gt;nWriteIndex = nWritten;//到了新空间需要重新移动写指针 } else //没有数据需要读取直接初始化指针位置 { pByteQueue-\u0026gt;nReadIndex = nNewCapacity; pByteQueue-\u0026gt;nWriteIndex = 0; } pByteQueue-\u0026gt;nCapacity = nNewCapacity; mem_free(pByteQueue-\u0026gt;pBuffer); pByteQueue-\u0026gt;pBuffer = pBuffer; } } pByteQueue-\u0026gt;pBuffer[pByteQueue-\u0026gt;nWriteIndex] = c;//赋值 pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + 1) % pByteQueue-\u0026gt;nCapacity;//索引位移一位 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity)//如果读索引在尾部 { pByteQueue-\u0026gt;nReadIndex = 0;//把读索引放到头部 } } 10. 写入指定大小空间的数据[空间不足按256的倍数自动扩展] void byteQueue_write(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = align_size(nLength,256);//初始化容量大小[256的倍数] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取剩余可写空间 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写空间 { //数据进行扩展 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + (nLength-nBytesWritable),256); char* pBuffer = mem_malloc(nNewCapacity);//申请空间大小 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity )//还有数据可读 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读空间 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始连续读入指针的起始位置 memcpy(pBuffer,pRead,nReadBytes);//把连续可读的空间写入新buffer空间 if( nReadBytes != nWritten )//如果连续可读的空间!=剩余全部可读空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;////重置容量大小 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧buff空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//重置指针到新buff空间 } } size_t nWriteBytes = 0;//连续可写的空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//开始写入的指针位置 if (nWriteBytes \u0026gt;= nLength)//如果连续写入的空间能够满足需要写入的空间大小 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入的空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//再把剩余要写入的大小空间写入 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置读索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置写索引 } } 10. 写入指定大小空间的数据[空间不足按剩余需要空间大小申请] void byteQueue_writeBytes(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = nLength;//初始化容量大小[需要空间大小] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//剩余可写的全部空间大小 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写入的空间大小 { size_t nNewCapacity = pByteQueue-\u0026gt;nCapacity + (nLength - nBytesWritable);//开辟正好大小的空间 char* pBuffer = mem_malloc(nNewCapacity);//申请空间 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//还有空间可读需要把这段空间赋值到新空间 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余可读的全部空间 size_t nReadBytes = 0;//连续可读的空间 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取空间的起始位置 memcpy(pBuffer,pRead,nReadBytes);//拷贝到新空间 if( nReadBytes != nWritten )//连续可读的空间!=剩余可读的全部空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余数据到新空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;//重置容量 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间指针指向旧空间指针 } } size_t nWriteBytes = 0;//连续可写入空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//可写入开始指针 if (nWriteBytes \u0026gt;= nLength)//容量足够 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//剩余的在直接拷贝 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置写索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 } } 10. 读取数据 bool byteQueue_readBytes(byteQueue_tt* pByteQueue, void* pOutBytes, size_t nMaxLengthToRead, bool bPeek /*= false*/ ) { size_t nBytesWritten = byteQueue_getBytesReadable(pByteQueue);//可读的空间大小 size_t nBytesToRead = nBytesWritten \u0026lt; nMaxLengthToRead ? nBytesWritten : nMaxLengthToRead;//得到可读取的大小 if (nBytesToRead == 0) { return false; } size_t nReadBytes = 0;//连续可读的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始索引 if( nReadBytes \u0026gt;= nBytesToRead )//满足可读大小需求 { memcpy(pOutBytes,pRead,nBytesToRead);//直接读取 } else { memcpy(pOutBytes,pRead,nReadBytes);//直接连续可读的空间大小 memcpy((char*)pOutBytes+nReadBytes,pByteQueue-\u0026gt;pBuffer,nBytesToRead-nReadBytes);//读取剩余需要读取的大小 } if (!bPeek)//不是探测 byteQueue_readOffset(pByteQueue,nBytesToRead);//直接移动指针 return true; } 10. 重置容量 void byteQueue_reserve(byteQueue_tt* pByteQueue, size_t nCapacity) { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读大小 if(nWritten \u0026gt; nCapacity)//如果全部可读的大小大于要重置的容量大小 { return; } if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//有剩余需要读取的空间数据 { char* pBuffer = mem_malloc(nCapacity);//申请新的重置空间大小 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//还有剩余要拷贝的空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余要拷贝的数据 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间的指针指向旧空间指针 } else { pByteQueue-\u0026gt;pBuffer = mem_realloc(pByteQueue-\u0026gt;pBuffer,nCapacity);//直接指向申请空间的大小 pByteQueue-\u0026gt;nReadIndex = nCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nCapacity;//重置容量 } ","permalink":"https://frog-game.github.io/posts/blog/ringbuff/","summary":"1. 图解释 2. 结构体 typedef struct byteQueue_s { char* pBuffer;//数据 size_t nCapacity;//容量 size_t nReadIndex;//读指针索引 size_t nWriteInde","title":"环形buff"},{"content":"1. 网络编程流程 2. 堵塞IO 3. 非堵塞IO 4. 信号驱动IO 5. 异步io模型 6. 多路复用 7. 单reactor 代表作：redis 内存数据库\n注意：redis 6.0 以后是多线程\n8. 单reactor 多进程模型 代表：nginx\n9. 单reactor模型 + 任务队列 + 线程池 代表作:skynet\n10. 主从 reactor 代表作：netty\n11. 多reactor + 多线程 代表作：memcache\n12. 多reactor + 多线程 +协程池 ","permalink":"https://frog-game.github.io/posts/blog/wangluo_io_zhongjie/","summary":"1. 网络编程流程 2. 堵塞IO 3. 非堵塞IO 4. 信号驱动IO 5. 异步io模型 6. 多路复用 7. 单reactor 代表作：redis 内存数据库 注意：redis 6.0 以","title":"网络IO模型总结"},{"content":" frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： frog\u0026rsquo;s Blog 网址： https://frog-game.github.io/ 描述 一个记录生活，技术的博客 ","permalink":"https://frog-game.github.io/links/","summary":"frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： frog\u0026rsquo;s Blog 网址： https://frog-game.github.io/ 描述 一个记录生活，技术的博客","title":"🤝友链"},{"content":"关于我\n英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山 ","permalink":"https://frog-game.github.io/about/","summary":"关于我 英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️关于"}]