[{"content":" 利用bspTree原理对地图进行动态切割\n演示\n安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana\n1. zabbix 6.0 1.1. 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 1.2. 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 1.3. 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-sql-scripts zabbix-agent 1.4. 创建初始数据库 mysql -uroot -p123456 mysql\u0026gt; create database zabbix character set utf8mb4 collate utf8mb4_bin; mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@`%`; mysql\u0026gt; quit; 1.5. 导入初始架构和数据，系统将提示您输入新创建的密码[默认密码现在设置为 123456 zcat /usr/share/doc/zabbix-sql-scripts/mysql/server.sql.gz | mysql -uzabbix -p -h10.40.38.67 zabbix # 指定本地的IP地址，不默认就会指向本地localhost 如果报ERROR 2003 (HY000): Can't connect to MySQL server on '10.40.38.67:3306' (111) 看第5章mysql操作指导，多半是因为权限和密码问题\n为Zabbix server配置数据库 sudo vim /etc/zabbix/zabbix_server.conf 修改 DBPassword=123456 1.6. 启动Zabbix server和agent进程 sudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server sudo systemctl enable zabbix-server zabbix-agent apache2 grafana-server 1.7. 连接web前端[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http://10.40.38.67/zabbix 默认的用户名是Admin(A是大写)，Password：zabbix 1.8. 修改时区 sudo vi /etc/apache2/conf-enabled/zabbix.conf 修改标准时区为 Asia/Shanghai 1.9. 中文显示 sudo apt install language-pack-zh-hans #安装中文语言包 sudo vim /etc/locale.gen #找到zh_CN.UTF-8 UTF-8 并取消#号注释，然后保存并退出 sudo locale-gen #编译语言包 sudo vim /etc/default/locale #修改默认语言为中文，将原来的内容改为 LANG=zh_CN.UTF-8 1.10. 安装出现的问题 1.10.1. Minimum required size of PHP post is 16M (configuration option \u0026ldquo;post_max_size\u0026rdquo;). 解决步骤：\nsudo vi /etc/php/8.1/apache2/php.ini post_max_size8M 16M\nmax_execution_time30 300\nmax_input_time60 300\ndate.timezone = Asia/Shanghai\nsudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server 1.10.2. ERROR 1396 (HY000): Operation CREATE USER failed for 'zabbix'@'%' mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; ERROR 1396 (HY000): Operation CREATE USER failed for \u0026#39;zabbix\u0026#39;@\u0026#39;%\u0026#39; 原因分析：\n已经存在了zabbix用户 在执行删除zabbix用户的时候没有删除干净 解决方法：\n重新进行删除。\ndrop user zabbix@\u0026#39;%\u0026#39;; flush privileges; 1.11. 卸载 zabbix 删除软件\nsudo apt-get --purge remove zabbix-server-mysql -y sudo apt-get autoremove zabbix-server-mysql -y sudo apt-get --purge remove zabbix-frontend-php -y sudo apt-get autoremove zabbix-frontend-php -y sudo apt-get --purge remove abbix-apache-conf -y sudo apt-get autoremove abbix-apache-conf -y sudo apt-get --purge remove zabbix-agent -y #删除软件其配置 sudo apt-get autoremove zabbix-agent -y #删除软件依赖包 清理数据\nsudo dpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 删除以上apt-get下载的软件包\nsudo apt-get autoclean 删除缓存的所有软件包\nsudo apt-get clean 删除其他软件依赖的但现在已不用的软件包（保留配置文件）\n```sh sudo apt-get autoremove ``` 查询出冗余文件并删除\nsudo find / -name zabbix 执行rm-rf 删除冗余文件\nsudo rm -rf /run/zabbix sudo rm -rf /etc/zabbix sudo rm -rf /usr/share/zabbix sudo rm -rf /var/log/zabbix sudo rm -rf /var/lib/mysql/zabbix 删除包含zabbix关键字的文件或者文件夹\n```sh sudo find / -name \u0026quot;zabbix*\u0026quot; | sudo xargs rm -rf ``` grafana 1.12. 下载grafana deb安装包 sudo apt-get install -y adduser libfontconfig1 sudo wget https://dl.grafana.com/enterprise/release/grafana-enterprise_8.5.4_amd64.deb sudo dpkg -i grafana-enterprise_8.5.4_amd64.deb 1.13. 启动grafana-server sudo systemctl restart grafana-server sudo systemctl enable grafana-server 安装zabbix插件 grafana-cli plugins list-remote sudo grafana-cli plugins install alexanderzobnin-zabbix-app #重启grafana-server sudo systemctl restart grafana-server 也可以在grafana-\u0026gt;plugins这里安装\n1.14. 登录grafana服务器[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http:/10.40.38.67:3000/ #默认用户名和密码为admin、admin 1.15. grafana 配置zabbix数据源 1.16. grafana 配置zabbix监控面板 在点击完new dashboard 按钮以后 按ctrl + s 保存一个自己定义的仪表盘\n1.17. grafana增加主题 安装插件：grafana-cli plugins install yesoreyeram-boomtheme-panel grafana主题地址：https://github.com/charles1503/grafana-theme/tree/master/CSS/themes/grafanas grafana更改主题教程：https://www.bilibili.com/read/cv7004400 视频教程：https://cloud.tencent.com/developer/video/11330 http://10.40.38.67:3000/public/themes/aquamarine.css 具体操作步骤：\n创建一个目录，用于存放下载对应主题的css文件\nsudo mkdir /usr/share/grafana/public/themes/ cd /usr/share/grafana/public/themes/ 使用一个for 循环下载对应的所有主题css文件\nfor f in grafana-base.css aquamarine.css hotline.css dark.css plex.css space-gray.css organizr-dashboard.css;do wget https://raw.githubusercontent.com/505384662/grafana-theme/master/CSS/themes/grafana/$f;done 为Grafana安装社区插件Boom Theme\nsudo grafana-cli plugins install yesoreyeram-boomtheme-panel sudo systemctl restart grafana-server 在Dashboard中添加Boom Theme\n1.18. grafana 主题修改地址 cd /usr/share/grafana/public/themes 1.19. grafana 加时钟 grafana-cli plugins install grafana-clock-panel systemctl restart grafana-server 1.20. grafana flowcharting安装 sudo grafana-cli plugins install agenty-flowcharting-panel sudo systemctl restart grafana-server grafana 修改模板地址 https://grafana.com/grafana/dashboards zabbix 修改配置地址：http://192.168.70.130/zabbix/setup.php zabbix 展示地址：http://192.168.70.130/zabbix/zabbix.php?action=dashboard.view grafana 展示地址: http://192.168.70.130:3000/d/tYxzFya7z/test_zabbix?orgId=1 1.21. Grafana 匿名访问（免登录） 修改Grafana配置文件\n在Grafana的配置文件 /etc/grafana/grafana.ini 中，找到 [auth.anonymous] 配置块，将其下的匿名访问控制 enabled 设置为 true，组织权限设置为 Viewer\nViewer:**只读**模式\nEditor:**可编辑**模式\nAdmin:**管理员**模式\n#################################### Anonymous Auth ###################### # Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false disable_login_form = true [auth.anonymous] # enable anonymous access enabled = true # specify organization name that should be used for unauthenticated users org_name = Main Org. # specify role for unauthenticated users org_role = Viewer 重启Grafana服务\n修改完配置文件，重启Grafana服务，命令如下：\nsudo systemctl restart grafana-server 1.22. 卸载 grafana 查找到安装软件名\nsudo dpkg -l | grep grafana 删除软件\n```sh sudo dpkg -r grafana-enterprise ``` 查询出冗余文件并删除\nfind / -name grafana 用rm-rf 命令删除\nrm -rf /etc/grafana rm -rf /usr/share/grafana rm -rf /usr/share/grafana/public/themes/grafana-theme/CSS/themes/grafana rm -rf /var/log/grafana rm -rf /var/lib/grafana 2. apache2 2.1. apache2启动报错 大致意思没有导入apache 环境变量 解决办法:\nsource /etc/apache2/envvars 还是报错\n大致意思是80端口被占用了 我选择的方法是kill占用进程在重启\nroot@hls:/root# netstat -lnp|grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 950/nginx: master p tcp6 0 0 :::80 :::* LISTEN 950/nginx: master p unix 2 [ ACC ] STREAM LISTENING 41930 1228/zabbix-plugin_ /tmp/plugin835680808 root@hls:/root# kill -9 950 root@hls:/root# systemctl restart zabbix-server zabbix-agent apache2 2.2. 卸载apache2 删除软件\n//1. 删除apache sudo apt-get --purge remove apache2 sudo apt-get --purge remove apache2.2-common //2.找到没有删除掉的配置文件，一并删除 sudo find /etc -name \u0026#34;*apache*\u0026#34; |xargs rm -rf sudo rm -rf /var/www sudo rm -rf /etc/libapache2-mod-jk //3.删除关联，这样就可以再次用apt-get install apache2 重装了 #dpkg -l |grep apache2|awk \u0026#39;{print $2}\u0026#39;|xargs dpkg -P//注意：这一步可能会报错，但也没关系 查询出冗余文件并删除\nsudo find / -name apache2 用rm -rf 命令删除\n3. Nginx 3.1. 官网下载地址 http://nginx.org/en/download.html 3.2. 一些环境准备 安装编译工具\nsudo apt-get install build-essential 安装编译工具 安装gcc什么的好便于下面编译安装 安装pcre包\nsudo apt-get update sudo apt-get install libpcre3 libpcre3-dev sudo apt-get install openssl libssl-dev 安装 zlib 库\nsudo apt install zlib1g-dev 3.3. 下载安装Nginx sudo wget http://nginx.org/download/nginx-1.21.6.tar.gz sudo tar -xzvf nginx-1.21.6.tar.gz cd nginx-1.21.6 sudo ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-stream --with-mail=dynamic #最好用 --prefix指定路径，便于后面删除[只需要删除prefix指定的文件夹就行了]，不指定的话后面删除比较麻烦 sudo make sudo make install 3.4. 制作软连接 ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 3.5. 配置环境变量 编辑/etc/profile并且追加Nginx的环境变量 export NGINX_HOME=/usr/local/nginx export PATH=$PATH:$NGINX_HOME/sbin 3.5.1. 生效环境变量 source /etc/profile 3.6. 测试是否安装成功 nginx -v 3.7. 启动Nginx sudo nginx 3.8. 强制停止Nginx sudo pkill -9 nginx 3.9. 查看Nginx进程 ps aux|grep nginx 3.10. 配置防火墙 sudo ufw allow \u0026#39;Nginx Full\u0026#39; 3.11. 验证防火墙是否允许 出现下面两种情况都认为可以 Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere Nginx Full ALLOW Anywhere 22/tcp (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) sudo ufw status 状态：不活动 3.12. 测试访问 http://192.168.70.132:7000 3.13. Nginx 相关文件位置 nginx path prefix: \u0026#34;/usr/local/nginx\u0026#34; nginx binary file: \u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; nginx modules path: \u0026#34;/usr/local/nginx/modules\u0026#34; nginx configuration prefix: \u0026#34;/usr/local/nginx/conf\u0026#34; nginx configuration file: \u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; nginx pid file: \u0026#34;/usr/local/nginx/logs/nginx.pid\u0026#34; nginx error log file: \u0026#34;/usr/local/nginx/logs/error.log\u0026#34; nginx http access log file: \u0026#34;/usr/local/nginx/logs/access.log\u0026#34; nginx http client request body temporary files: \u0026#34;client_body_temp\u0026#34; nginx http proxy temporary files: \u0026#34;proxy_temp\u0026#34; nginx http fastcgi temporary files: \u0026#34;fastcgi_temp\u0026#34; nginx http uwsgi temporary files: \u0026#34;uwsgi_temp\u0026#34; nginx http scgi temporary files: \u0026#34;scgi_temp\u0026#34; 卸载 Nginx sudo rm -rf /usr/local/nginx sudo rm -rf /usr/local/nginx/sbin/nginx #软连接也记得删除 如果想完全干净，/etc/profile 配置文件中指定的环境变量也可以删除 4. mysql 4.1. 安装mysql sudo apt update sudo apt install mysql-server 安装完成后，MySQL服务将自动启动。要验证MySQL服务器正在运行，请输入：\nsudo systemctl status mysql 彻底卸载mysql方法 查看依赖包\ndpkg --list | grep mysql 先依次执行以下命令\nsudo apt-get remove mysql-common sudo apt-get autoremove --purge mysql-server-5.0 # 卸载 MySQL 5.x 使用, 非5.x版本可跳过该步骤 sudo apt-get autoremove --purge mysql-server 然后再用\ndpkg --list | grep mysql 查看一下依赖包最后用下面命令清除残留数据\ndpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 查看从MySQL APT安装的软件列表, 执行后没有显示列表, 证明MySQL服务已完全卸载\ndpkg -l | grep mysql | grep i 博客地址\nhttps://blog.csdn.net/PY0312/article/details/89481421 MySQL在Ubuntu上启动出错Could not open ‘abstractions/mysql‘ rm -rf /etc/apparmor.d/abstractions/mysql rm -rf /etc/apparmor.d/cache/usr.sbin.mysqld find / -name \u0026#39;mysql*\u0026#39; -exec rm -rf {} \\; 4.2. 连接MySql报错“can\u0026rsquo;t connect to local mysql server through socket \u0026lsquo;/var/run/mysqld/mysqld.sock\u0026rsquo; cd /etc/init.d sudo service mysql stop sudo service mysql start mysql Ubuntu 20.04 Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost 首先输入以下指令 获取密码：\nsudo cat /etc/mysql/debian.cnf 再输入以下指令进入mysql\n查询user关键字段\nselect user, authentication_string,plugin,Host from mysql.user; 修改密码格式\nuse mysql; update user set plugin=\u0026#39;mysql_native_password\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 修改密码\nuse mysql; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; flush privileges; 输入\nmysql -uroot -p123456; 查看效果 让别的ip能连上wsl数据库\nuse mysql; update user set Host=\u0026#39;%\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 输入\nselect user, authentication_string,plugin,Host from mysql.user; 查看效果\n开启远程访问\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf # 注释 bind-address = 127.0.0.1 重启mysql\nsudo service mysql restart 效果\n5. ELK 5.1. 一些准备 5.1.1. 官网地址 https://www.elastic.co/guide/en/elasticsearch/reference/8.0/deb.html#deb-repo 5.1.2. 虚拟机 想要多开最好是克隆一份出来 比如2就是克隆的1的镜像\n修改 克隆的虚拟机网卡地址\nsudo vim /etc/netplan/00-installer-config.yaml 修改内容:\nnetwork: ethernets: ens33: #配置的网卡的名称 addresses: [192.168.70.130/24] #配置的静态ip地址和掩码 dhcp4: no #关闭DHCP，如果需要打开DHCP则写yes optional: true gateway4: 192.168.70.2 #网关地址 nameservers: addresses: [192.168.70.2,114.114.114.114] #DNS服务器地址，多个DNS服务器地址需要用英文逗号分隔开 version: 2 renderer: networkd #指定后端采用systemd-networkd或者Network Manager，可不填写则默认使用systemd-workd 使配置生效\nsudo netplan apply 注意事项\n1、ip地址和DNS服务器地址需要用[]括起来，但是网关地址不需要 2、注意每个冒号后边都要先加一个空格 3、注意每一层前边的缩进，至少比上一层多两个空格 5.1.3. 安装java环境 安装java sudo apt install openjdk-8-jdk 查看java 版本\nsudo java -version 查看 java 路径\nsudo which java ls -l /usr/bin/java 看看这是否是个软连接，找出这个软连接指向的路径\nls -l /usr/bin/java 的确为软连接，继续往下找指向的路径\n至此，java 的安装路径即为 /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n配置 java 环境\nsudo vim /etc/profile 在弹出的 vim 编辑器中输入\n# JAVA JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH esc 退出编辑模式，输入 :x后，单击回车退出。\n在终端输入\nsource /etc/profile 使之前的配置生效。\n验证\njava -version\n$JAVA_HOME/bin/java -version\n5.1.4. python3 [不是必须装主要是想使用 json.tool 格式化输出]\n安装python3.8\nsudo apt-get install python3.8 建立软连接\nsudo ln -s /usr/bin/python3.8 /usr/bin/python 如果想要删除软连接\nsudo rm -rf /usr/bin/python 格式化输出\ncurl -XGET http://192.168.70.131:9200/_mapping | python -m json.tool 5.2. Elasticsearch 5.2.1. 基础知识 和关系型数据库的比较 DBMS Elasticsearch database Index table type(在7.0之后type为固定值_doc) Row Document Column Field Schema Mapping SQL DSL(Descriptor Structure Language) 安装Elasticsearch deb包安装方式\nsudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb sudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb.sha512 shasum -a 512 -c elasticsearch-8.2.2-amd64.deb.sha512 sudo dpkg -i elasticsearch-8.2.2-amd64.deb 执行**sudo dpkg -i elasticsearch-8.2.2-amd64.deb** 回生成超级用户密码 0NgzdrlHquc1YdXrQout\n--------------------------- Security autoconfiguration information ------------------------------ Authentication and authorization are enabled. TLS for the transport and HTTP layers is enabled and configured. The generated password for the elastic built-in superuser is : 0NgzdrlHquc1YdXrQout If this node should join an existing cluster, you can reconfigure this with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token \u0026lt;token-here\u0026gt;\u0026#39; after creating an enrollment token on your existing cluster. You can complete the following actions at any time: Reset the password of the elastic built-in superuser with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\u0026#39;. Generate an enrollment token for Kibana instances with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\u0026#39;. Generate an enrollment token for Elasticsearch nodes with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\u0026#39;. ------------------------------------------------------------------------------------------------- 生成 ca 、生成 证书\n# 生成 ca # 根据提示： # 输入 ca 的密码（密码不要忘记，后面生成证书需要） # 输入生成 ca 的文件名（默认会让你输入 elastic-stack-ca.p12，这里就按照默认的来） sudo /usr/share/elasticsearch/bin/elasticsearch-certutil ca # 生成证书 # 根据提示： # 输入之前 ca 的密码 # 输入生成证书的文件名（默认让你输入 elastic-certificates.p12，这里就按照默认的来） # 输入生成证书的密码（密码不要忘记，这个密码在配置 ES keystore 的时候需要） # --ca 后面的文件是上面步骤生成的 elastic-stack-ca.p12 文件，如果修改了的话，这里也需要修改 sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 ​\t为了方便管理，一般将 ca 与证书放到 ~/.config/certs 目录下\n# 创建目录并移动 ca 与证书 sudo mkdir -p ~/.config/certs \u0026amp;\u0026amp; sudo mv /usr/share/elasticsearch/elastic-stack-ca.p12 /usr/share/elasticsearch/elastic-certificates.p12 ~/.config/certs 5.2.2. 启动 Elasticsearch ​\t[为了安全考虑Elasticsearch不允许使用root用户来启动]\n打开 elasticsearch 配置文件\nsudo vim /etc/elasticsearch/elasticsearch.yml #打开配置文件 修改 netWork.host, http.port 字段\nnetwork.host: 10.40.38.66 #注意 network.host:和10.40.38.66 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 http.port: 9200 #注意 http.port:和9200 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 因为是内网测试暂时关闭 xpack 安全验证方面选项,以后需要再去开启\n启动Elasticsearch\nsudo systemctl start elasticsearch.service 开机启动elasticsearch\nsudo systemctl enable elasticsearch.service 5.2.3. 连接grafana 5.2.4. Elasticsearch 操作命令 用jps命令关闭Elasticsearch\n$ jps | grep Elasticsearch 14542 Elasticsearch kill -9 14542 查看 Elasticsearch 端口\nsudo netstat -tnlp |grep java 检测是否启动成功\ncurl -XGET \u0026#39;http://192.168.70.131:9200/\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; 用journal 查看系统日志\nsudo journalctl -f 用 journal 查看elasticsearch 服务日志\nsudo journalctl --unit elasticsearch 用journal 查看elasticsearch 指定时间范围的日志\nsudo journalctl --unit elasticsearch --since \u0026#34;2022-02-01 18:17:16\u0026#34; 查看 elasticsearch.log\nsudo vim /var/log/elasticsearch/elasticsearch.log 5.2.5. Elasticsearch 卸载 # 查看安装的软件 sudo dpkg -l | grep elasticsearch #查看安装关联 sudo dpkg -L elasticsearch #移除安装软件 sudo dpkg -P elasticsearch #继续查看未卸载的目录和文件 sudo find / -name elasticsearch #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/elasticsearch.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/log/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /usr/share/elasticsearch #在此查看是否有关联的目录和文件 sudo find / -name elasticsearch 5.3. Logstash 5.3.1. 安装 Logstash 下载安装公共签名\nsudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Elasticsearch了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install logstash 5.3.2. 插件地址 https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html 5.3.3. 配置表字段解释 https://blog.csdn.net/weixin_42073629/article/details/110154037?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-110154037.pc_agg_new_rank\u0026amp;utm_term=logstash%E5%8F%82%E6%95%B0convert\u0026amp;spm=1000.2123.3001.4430 5.3.4. 查看安装的插件 sudo /usr/share/logstash/bin/logstash-plugin list 启动Lostash 修改 logstash.yml 配置\nsudo vim /etc/logstash/logstash.yml 5.3.5. 导入数据[利用logstash 直接分析movies.csv 传送给elasticsearch方式] ​\t收集流程: movies.csv-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n下载ml-latest.zip 数据\nsudo wget https://files.grouplens.org/datasets/movielens/ml-latest.zip 解压 ml-latest.zip\nsudo unzip ml-latest.zip 在/etc/logstash 目录下创建logstash.conf 文件\nsudo vim /etc/logstash/logstash.conf 把以下内容写入logstash.conf\ninput { file { #监听文件的路径 path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/movies.csv\u0026#34; #监听文件的起始位置，默认是end start_position =\u0026gt; \u0026#34;beginning\u0026#34; #监听文件读取信息记录的位置 sincedb_path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/db_path.log\u0026#34; } } filter { csv { separator =\u0026gt; \u0026#34;,\u0026#34; columns =\u0026gt; [\u0026#34;id\u0026#34;,\u0026#34;content\u0026#34;,\u0026#34;genre\u0026#34;,\u0026#34;@timestamp\u0026#34;] } mutate { # split =\u0026gt; { \u0026#34;genre\u0026#34; =\u0026gt; \u0026#34;|\u0026#34; } # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;] #删除无用字段 } mutate { split =\u0026gt; [\u0026#34;content\u0026#34;, \u0026#34;(\u0026#34;] #左括号分割 add_field =\u0026gt; { \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;%{[content][0]}\u0026#34;} #增加字段 add_field =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;%{[content][1]}\u0026#34;} #增加字段 } mutate { convert =\u0026gt; { #year 转换成整型 \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;integer\u0026#34; } strip =\u0026gt; [\u0026#34;title\u0026#34;] #去掉字段首尾的空格 # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;,\u0026#34;content\u0026#34;] #删除无用字段 } } output { elasticsearch { # 双引号中的内容为ES的地址，视实际情况而定 hosts =\u0026gt; \u0026#34;http://192.168.70.131:9200\u0026#34; index =\u0026gt; \u0026#34;movies\u0026#34; document_id =\u0026gt; \u0026#34;%{id}\u0026#34; #docId 等价于_id 字段 } stdout {} } 如果需要重新导入，先删除db_path.log 文件\nsudo rm -rf /var/lib/logstash/.lock sudo rm -rf /home/hls/downs/ml-latest/db_path.log sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf 报错\n执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults 那么就创建软连接\ncd /usr/share/logstash sudo ln -s /etc/logstash ./config 执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nLogstash could not be started because there is already another instance using the configured data directory. If you wish to run multiple instances, you must change the \u0026#34;path.data\u0026#34; setting. 那么就去 logstash.yml 中path.data 指定的路径上去删除.lock文件\ncd /var/lib/logstash sudo ls -a sudo rm -rf .lock 或者直接一句话\nsudo rm -rf /var/lib/logstash/.lock 5.3.6. 强制查看输出 logstash.conf 修改成你自己的文件 sudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --verbose --debug 5.3.7. 查看数据 用Kibana的命令行工具执行 GET _cat/indices 命令，就能看见导入到Elasticsearch的索引\n用kibana的命令行工具执行**GET /lua_cpu_monitor-2022.06.03/_search**命令,就能看见导入到Elasticsearch的数据\n5.3.8. 自动重新加载配置命令 logstash.conf 修改成你自己的文件\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.automatic 默认检测时间是**3**秒 可以通过下列命令修改 把\u0026lt;\u0026gt;号里面的2换成你想要的时间\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.interval \u0026lt;2\u0026gt; 5.3.9. 卸载Logstash # 查看安装的软件 sudo dpkg -l | grep logstash #查看安装关联 sudo dpkg -L logstash #移除安装软件 sudo dpkg -P logstash #继续查看未卸载的目录和文件 sudo find / -name logstash #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/logstash \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/logstash.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/logstash \u0026amp;\u0026amp; sudo rm -rf /var/log/logstash \u0026amp;\u0026amp; sudo rm -rf /usr/share/logstash #在此查看是否有关联的目录和文件 sudo find / -name logstash 5.4. Kibana 5.4.1. 安装Kibana 下载安装公共签名\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Kibana了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install kibana 5.4.2. 启动Kibana 打开kibana.yml 文档\nsudo vim /etc/kibana/kibana.yml 修改 server.port,server.host 字段\n启动\nsudo systemctl start kibana.service 自启动\nsudo systemctl enable kibana.service 查看 kibana日志\nsudo vim /var/log/kibana 用谷歌或者微软自带浏览器打开地址\nhttp://10.40.38.66:5601 5.4.3. 卸载Kibana # 查看安装的软件 sudo dpkg -l | grep kibana #查看安装关联 sudo dpkg -L kibana #移除安装软件 sudo dpkg -P kibana #继续查看未卸载的目录和文件 sudo find / -name kibana #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/kibana \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/kibana.* \u0026amp;\u0026amp; sudo rm -rf /etc/kibana #在此查看是否有关联的目录和文件 sudo find / -name kibana 5.5. Filebeat 搭配filebeat主要使用收集nginx数据, 和上面的利用logstash解析movies.csv，然后收集数据给elasticsearch的方式不一样\n收集流程: nginx-\u0026gt;filebeat-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n5.5.1. 安装Filebeat sudo curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.2.2-amd64.deb sudo dpkg -i filebeat-8.2.2-amd64.deb 5.5.2. 修改 filebat.yml 配置文件 sudo vim /etc/filebeat/filebeat.yml 修改下列几项\n# ============================== Filebeat inputs =============================== filebeat.inputs: - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_cpu_monitor.log tags: [\u0026#34;lua_cpu_monitor_log\u0026#34;] - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_mem_monitor.log tags: [\u0026#34;lua_mem_monitor_log\u0026#34;] # ============================== Filebeat modules ============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 1 # ------------------------------ Logstash Output ------------------------------- output.logstash: # The Logstash hosts hosts: [\u0026#34;10.40.38.66:5555\u0026#34;] # ================================= Processors ================================= processors: - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 6.5.3. 测试filebeat启动后，查看相关输出信息 sudo filebeat -e -c /etc/filebeat/filebeat.yml -d \u0026#34;publish\u0026#34; 6.5.4. 后台方式启动filebeat nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; #将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出 nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt; filebeat.log \u0026amp; 6.5.5. 停止filebeat ps -ef | grep filebeat kill -9 进程号 6.5.6. 启动出现的问题 执行命令systemctl start filebeat.service就能够启动了。而后执行ps -ef|grep filebeat查看一下\n能够看到已经启动胜利了，如果你发现没有启动成功，那么就执行 cd /usr/bin，在这个目录下执行./filebeat -c /etc/filebeat/filebeat.yml -e，这样会提醒具体的错误信息。而用systemctl start filebeat.service启动的时候没有任何提醒，连在 /var/log/filebeat/ 和 /var/lib/filebeat/registry/filebeat/ 都没找到错误信息，这里属实有点坑。\n重新启动命令systemctl restart filebeat.service\n6.5.7 去安装logstash的机器启动logstash 增加 logstash_filebeat.conf 文档\nsudo vim /etc/logstash/conf.d/logstash_filebeat.conf 把以下内容粘贴上保存\ninput { beats { port =\u0026gt; 5555 #这个地址不能和logstash.yml 里面的api.http.host: 9600 一样，要不会出现地址已经被绑定的错误 } } output { if \u0026#34;lua_cpu_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_cpu_monitor-%{+YYYY.MM.dd}\u0026#34; } } if \u0026#34;lua_men_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_men_monitor-%{+YYYY.MM.dd}\u0026#34; } } } 重新加载新的配置并启动logstash\n先启动logstash，然后在启动filebeat，不然的话filebeat会找不到beats插件的:5555端口\nsudo rm -rf /var/lib/logstash/.lock sudo /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash_filebeat.conf --verbose --debug 6.5.8. 用filebeat 监控 nginx 修改 nginx conf 配置表\nsudo vim /usr/local/nginx/conf/nginx.conf 加入如下日志格式\nlog_format main \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;@source\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;hostname\u0026#34;:\u0026#34;$hostname\u0026#34;,\u0026#39; \u0026#39;\u0026#34;ip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_method\u0026#34;:\u0026#34;$request_method\u0026#34;,\u0026#39; \u0026#39;\u0026#34;scheme\u0026#34;:\u0026#34;$scheme\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$server_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request_uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;args\u0026#34;:\u0026#34;$args\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamaddr\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;https\u0026#34;:\u0026#34;$https\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; 对比修改下图对应的3个红框地方\n重启 nginx\nsudo pkill -9 nginx \u0026amp;\u0026amp; sudo nginx 用 http:192.168.70.132:7000 登录nginx 网站生成登录日志，然后打开 access.log 日志\nsudo vim /usr/local/nginx/logs/access.log sudo tail -f /usr/local/nginx/logs/access.log 6.5.9. 卸载Filebeat # 查看安装的软件 sudo dpkg -l | grep filebeat #查看安装关联 sudo dpkg -L filebeat #移除安装软件 sudo dpkg -P filebeat #继续查看未卸载的目录和文件 sudo find / -name filebeat #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat \u0026amp;\u0026amp; sudo rm -rf /usr/share/filebeat #在此查看是否有关联的目录和文件 sudo find / -name filebeat ","permalink":"https://frog-game.github.io/posts/blog/zabbix-mysql8.0/","summary":"利用bspTree原理对地图进行动态切割 演示 安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana 1. zabbix 6.0 1.1. 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 1.2. 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 1.3. 安装Zabbix","title":"zabbix游戏监控日志系统部署"},{"content":"1. 前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑做不到，手机就更加不用说了 这类大地图，在客服端都是分区域进行加载，也就是会进行切割，比如像绝地求生这样的游戏，大概80公里左右大的地图，会被切割成100 *100 个格子，大概每个格子800米左右，每个格子会打上索引标记，当客服端在进行移动的时候就会根据视野，一般都是九宫格区域，然后根据视野新旧对地图块进行预加载和删除。 在绝地求生跳伞阶段，其实是整张地图进行加载的，但是这个时候不是加载的高精度地图块，而是一个经过简化的地图，而且这种地图块不会只有一份，一般会有多份，这种也叫多层LOD，也就是随着你跳伞以后，距离地面越来越近，程序会给你切换不同的地图块，这也就是为什么有时候你在跳伞的过程中有时候会看到闪烁情况，其实这个时候是程序在给你切换不同的地图块 2. 构建大世界地图 2.1. 利用bspTree原理对地图进行动态切割 分裂条件：\n人数达到上线 区域大小必须超过多大，比如必须达到50 *50 大小才能分裂 1.场景管理服务器启动以后会创建一个全局的space，假设大小是100 * 100，同时也创建一个同样大小的cell1\n假如按宽10进行分割，会形成 10 * 100,90 * 100 两个长方形\n假如按长90来对剩下的3进行分割\n一直往下切割的话，左边会越来越多，右儿子会越来越少，从而达到负载均衡的效果但是也有分割也有条件\n兄弟两都为叶子节点 左二子被分割后的大小不应该大于右儿子 2.2. 利用bspTree原理对地图进行动态合并 合并条件:\nCell区域小于100(可配) 人数小于指定人数(可配) 待合并的2个结点必须是叶子结点 删除待合并的两个儿子结点，修改父亲结点的场景区域 合并前\n合并后\n当不管是分割还是合并发现他的实体已经不再当前cell了那么实体应该迁移到他合适的地方去\n3. 边缝处理 假设我们现在有3个cellServer进程管理着各自的ABC3个cell块\n当上面的a角色到达边界的时候，我们这个时候就需要进行real和ghost的数据同步，开始在重叠区域进行转换，进行转换的区域一般要比自己的视野范围要大，比如现在的重叠转换区域就是那个红色圈，大于自己的视野黑色圈\n在entity aoi范围内，又不在同一cell的，在这个cell上创建同坐标的一个ghost 镜像，也就是上面的暗红色和绿色星星就是BC cell上面的ghost镜像 ghost 只能是只读的，每次去修改只能先修改real实体然后在去同步ghost属性 4. 新的边缝处理方法 比如现在有A B两个cell 这个时候黄色的角色从A走向了B 现在过了边界，但是我们现在不用创建镜像和实体的方法来实现无缝地图，而是用传送的方式，传送触发的实际就是那根绿色线和边界的距离，比如5米，当玩家走到了这个触发范围我们就开始直接把人传送到B，这样也不用处理ghost和real之间定时同步，还有异步技能带来的各种异常情况，bug查找\n5. 技能处理 攻击方一定要是real实体，被攻击方可以是real实体，也可以是ghost实体\n下方的数据同步可以写到核心框架，也就是定时同步real实体的信息到ghost实体上\n6. 寻路 因为世界地图很大，所以我们可以用**路点+ 小段距离A星或者jps算法**来实现寻路\n先求路点，比如如下的地铁图，我们可以根据权重值或者时间的组合，通过**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法求出最短路径，这些路径可以离线先求出来，等使用的时候直接使用 还是以上面这图为例子现在你在红色小人那个位置也就是关庄下面小人的位置，这个时候如果障碍物多，你可以骑单车过来也就是用**A星算法寻路到惠新西街南口，如果障碍物少，那么你可以打车，或者坐大巴也就是jps算法到彗新西街南口，到了起始点之后，你就可以坐地铁也就是前面用Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算出的离线路径直接到达下面的地跌目的地南锣鼓巷\n到了南锣鼓巷以后，同样你也可以按2步骤，选择是**a星还是jps算法**到达公司\n如果地图超大，其实在用**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算地铁图的时候我们可以分几块区域算出各自地铁路线图，然后连接起来，举个栗子，比如可以划分，彗星西街南口到北土城是一个区域，北土城到鼓楼大街是个区域，鼓楼大街到南锣鼓巷是个区域，这3个区域各自算好，各自存储好，到时拼接起来就是惠新西街南口到南锣鼓巷的整条离线路线，如下图红，黑，黄三个框，代表3个区域\n","permalink":"https://frog-game.github.io/posts/blog/wufengdashijie/","summary":"1. 前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电","title":"无缝大世界"},{"content":"1. 图解释 2. 结构体 typedef struct byteQueue_s { char*\tpBuffer;//数据 size_t\tnCapacity;//容量 size_t\tnReadIndex;//读指针索引 size_t\tnWriteIndex;//写指针索引 } byteQueue_tt; 3. 初始 结构体 假设要申请的空间 环形buff结构体大小为8\nnWriteIndex 写指针索引 nReadIndex 读指针索引 环形buff初始化\nvoid byteQueue_init(byteQueue_tt* pByteQueue,size_t nCapacity = /* = 8*/) { pByteQueue-\u0026gt;nReadIndex = nCapacity;//读指针索引位置设置为8,放到末尾 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置成0，放到开头 pByteQueue-\u0026gt;nCapacity = nCapacity;//容量 if( nCapacity != 0 ) { pByteQueue-\u0026gt;pBuffer = mem_malloc(nCapacity);//申请空间 } else { pByteQueue-\u0026gt;pBuffer = NULL;//置空 } } 4. 清空结构体 void byteQueue_clear(byteQueue_tt* pByteQueue) { pByteQueue-\u0026gt;nReadIndex = 0;//读指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nCapacity = 0;//容量设置为0 if(pByteQueue-\u0026gt;pBuffer) { mem_free(pByteQueue-\u0026gt;pBuffer);//如果有数据进行释放 pByteQueue-\u0026gt;pBuffer = NULL;//并且置空 } } 5. 获取剩余全部可写空间 static inline size_t byteQueue_getBytesWritable(byteQueue_tt* pByteQueue) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex )//写指针和读指针重合，或者在读指针前面 { return pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//直接读指针 - 写指针 就是 写入了多少内容 } else//写指针在读指针后面 { return pByteQueue-\u0026gt;nReadIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex); //读指针位置 + (容量 - 写指针位置) } } 5.1. 写指针在读指针前面[求得是蓝色块数据] 5.2. 写指针在读指针后面[求得是蓝色块数据] 6. 获取剩余全部可读空间 static inline size_t byteQueue_getBytesReadable(byteQueue_tt* pByteQueue) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex) //读指针在写指针前面 { return pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//直接写指针 - 读指针 就是可以读多少数据 } else //读指针和写指针重合,或者读指针在写指针后面 { return pByteQueue-\u0026gt;nWriteIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex); //写指针 + (容量 - 读指针位置) } } 6.1. 写指针在读指针后面[求的是红色块的数据] 6.2. 写指针在读指针前面[求的是红色块的数据] 7. 查看连续的可写空间 //查看连续的可写空间 //size_t* pWriteBytes 能连续写入的大小 static inline char* byteQueue_peekContiguousBytesWrite(byteQueue_tt* pByteQueue, size_t* pWriteBytes) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex)//读指针在写指针后面 { *pWriteBytes = pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } else//读指针在写指针前面 { *pWriteBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nWriteIndex;//开始连续写入指针的起始位置 } 7.1. 写指针在读指针前面[求得连续可写的空间] 7.2. 写指针在读指针后面[求得连续可写的空间] 8. 查看连续可读空间 //查看连续的可读空间 //size_t* pWriteBytes 能连续读取的大小 static inline char* byteQueue_peekContiguousBytesRead(byteQueue_tt* pByteQueue, size_t* pReadBytes) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex)//写指针在读指针后面 { *pReadBytes = pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } else { *pReadBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nReadIndex;//开始连续读入指针的起始位置 } 8.1. 写指针在读指针后面[求得连续可读的空间] 8.2. 写指针在读指针前面[求得连续可读的空间] 9. 写入一个字符[空间不足按256的倍数自动扩展] void byteQueue_writeChar(byteQueue_tt* pByteQueue, const char c) { if(pByteQueue-\u0026gt;nCapacity == 0) { //初始化容量,buffer大小，可读索引 pByteQueue-\u0026gt;nCapacity = 256;//初始化容量大小[256] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取获取剩余全部可写空间 if (1 \u0026gt; nBytesWritable) { //align_size 将size按align大小整数倍提升,用于内存对齐 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + 1,256); char* pBuffer = mem_malloc(nNewCapacity); if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//说明还有数据没有读走 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//获取剩余全部可读的空间 size_t nReadBytes = 0;//连续可读的空间的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取数据的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//如果连续可读的空间的大小!=剩余全部可读的空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//到了新空间需要重新移动读指针 pByteQueue-\u0026gt;nWriteIndex = nWritten;//到了新空间需要重新移动写指针 } else //没有数据需要读取直接初始化指针位置 { pByteQueue-\u0026gt;nReadIndex = nNewCapacity; pByteQueue-\u0026gt;nWriteIndex = 0; } pByteQueue-\u0026gt;nCapacity = nNewCapacity; mem_free(pByteQueue-\u0026gt;pBuffer); pByteQueue-\u0026gt;pBuffer = pBuffer; } } pByteQueue-\u0026gt;pBuffer[pByteQueue-\u0026gt;nWriteIndex] = c;//赋值 pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + 1) % pByteQueue-\u0026gt;nCapacity;//索引位移一位 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity)//如果读索引在尾部 { pByteQueue-\u0026gt;nReadIndex = 0;//把读索引放到头部 } } 10. 写入指定大小空间的数据[空间不足按256的倍数自动扩展] void byteQueue_write(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = align_size(nLength,256);//初始化容量大小[256的倍数] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取剩余可写空间 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写空间 { //数据进行扩展 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + (nLength-nBytesWritable),256); char* pBuffer = mem_malloc(nNewCapacity);//申请空间大小 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity )//还有数据可读 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读空间 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始连续读入指针的起始位置 memcpy(pBuffer,pRead,nReadBytes);//把连续可读的空间写入新buffer空间 if( nReadBytes != nWritten )//如果连续可读的空间!=剩余全部可读空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;////重置容量大小 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧buff空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//重置指针到新buff空间 } } size_t nWriteBytes = 0;//连续可写的空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//开始写入的指针位置 if (nWriteBytes \u0026gt;= nLength)//如果连续写入的空间能够满足需要写入的空间大小 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入的空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//再把剩余要写入的大小空间写入 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置读索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置写索引 } } 10. 写入指定大小空间的数据[空间不足按剩余需要空间大小申请] void byteQueue_writeBytes(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = nLength;//初始化容量大小[需要空间大小] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//剩余可写的全部空间大小 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写入的空间大小 { size_t nNewCapacity = pByteQueue-\u0026gt;nCapacity + (nLength - nBytesWritable);//开辟正好大小的空间 char* pBuffer = mem_malloc(nNewCapacity);//申请空间 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//还有空间可读需要把这段空间赋值到新空间 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余可读的全部空间 size_t nReadBytes = 0;//连续可读的空间 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取空间的起始位置 memcpy(pBuffer,pRead,nReadBytes);//拷贝到新空间 if( nReadBytes != nWritten )//连续可读的空间!=剩余可读的全部空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余数据到新空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;//重置容量 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间指针指向旧空间指针 } } size_t nWriteBytes = 0;//连续可写入空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//可写入开始指针 if (nWriteBytes \u0026gt;= nLength)//容量足够 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//剩余的在直接拷贝 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置写索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 } } 10. 读取数据 bool byteQueue_readBytes(byteQueue_tt* pByteQueue, void* pOutBytes, size_t nMaxLengthToRead, bool bPeek /*= false*/ ) { size_t nBytesWritten = byteQueue_getBytesReadable(pByteQueue);//可读的空间大小 size_t nBytesToRead = nBytesWritten \u0026lt; nMaxLengthToRead ? nBytesWritten : nMaxLengthToRead;//得到可读取的大小 if (nBytesToRead == 0) { return false; } size_t nReadBytes = 0;//连续可读的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始索引 if( nReadBytes \u0026gt;= nBytesToRead )//满足可读大小需求 { memcpy(pOutBytes,pRead,nBytesToRead);//直接读取 } else { memcpy(pOutBytes,pRead,nReadBytes);//直接连续可读的空间大小 memcpy((char*)pOutBytes+nReadBytes,pByteQueue-\u0026gt;pBuffer,nBytesToRead-nReadBytes);//读取剩余需要读取的大小 } if (!bPeek)//不是探测 byteQueue_readOffset(pByteQueue,nBytesToRead);//直接移动指针 return true; } 10. 重置容量 void byteQueue_reserve(byteQueue_tt* pByteQueue, size_t nCapacity) { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读大小 if(nWritten \u0026gt; nCapacity)//如果全部可读的大小大于要重置的容量大小 { return; } if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//有剩余需要读取的空间数据 { char* pBuffer = mem_malloc(nCapacity);//申请新的重置空间大小 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//还有剩余要拷贝的空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余要拷贝的数据 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间的指针指向旧空间指针 } else { pByteQueue-\u0026gt;pBuffer = mem_realloc(pByteQueue-\u0026gt;pBuffer,nCapacity);//直接指向申请空间的大小 pByteQueue-\u0026gt;nReadIndex = nCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nCapacity;//重置容量 } ","permalink":"https://frog-game.github.io/posts/blog/ringbuff/","summary":"1. 图解释 2. 结构体 typedef struct byteQueue_s { char* pBuffer;//数据 size_t nCapacity;//容量 size_t nReadIndex;//读指针索引 size_t nWriteInde","title":"环形buff"},{"content":"1. 网络编程流程 2. 堵塞IO 3. 非堵塞IO 4. 信号驱动IO 5. 异步io模型 6. 多路复用 7. 单reactor 代表作：redis 内存数据库\n注意：redis 6.0 以后是多线程\n8. 单reactor 多进程模型 代表：nginx\n9. 单reactor模型 + 任务队列 + 线程池 代表作:skynet\n10. 主从 reactor 代表作：netty\n11. 多reactor + 多线程 代表作：memcache\n12. 多reactor + 多线程 +协程池 ","permalink":"https://frog-game.github.io/posts/blog/wangluo_io_zhongjie/","summary":"1. 网络编程流程 2. 堵塞IO 3. 非堵塞IO 4. 信号驱动IO 5. 异步io模型 6. 多路复用 7. 单reactor 代表作：redis 内存数据库 注意：redis 6.0 以","title":"网络IO模型总结"},{"content":" frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： frog\u0026rsquo;s Blog 网址： https://frog-game.github.io/ 描述 一个记录生活，技术的博客 ","permalink":"https://frog-game.github.io/links/","summary":"frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 名称： frog\u0026rsquo;s Blog 网址： https://frog-game.github.io/ 描述 一个记录生活，技术的博客","title":"🤝友链"},{"content":"关于我\n英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山 ","permalink":"https://frog-game.github.io/about/","summary":"关于我 英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️关于"},{"content":"1. 微服务器框架lua调试器 针对skynet这种微服器框架和自己从0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店进行\n下载使用有问题欢迎留言交流\n2. 多虚拟机测试 3. linux测试 4. 真机测试 ","permalink":"https://frog-game.github.io/posts/blog/vscode-lua-chajian/","summary":"1. 微服务器框架lua调试器 针对skynet这种微服器框架和自己从0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店","title":""}]