[{"content":"GC由来简介\nc,c++的话基本都是手动管理内存,优点是效率很高,毕竟不需要去找出那些是垃圾,需要被清理这种逻辑处理,也不需要在gc清理的时候,把主线程暂停,等等操作造成卡顿,但是这种手动管理的也有一定的问题,那就是内存碎片,还有内存重复复用,所以会利用内存池管理这种技术来尽量规避这种情况\n比如不使用内存池分配技术,只使用Malloc,free申请空间就很容易造成如下图的内存碎片\n内碎片\n内碎片是已经被分配出去的内存[进程已经拿到手上了],但是进程已经利用不上了\n如下图,当时进程我需要申请了14KB的内存,然后因为linux伙伴算法导致返回了16KB内存,因为伙伴算法是按接近最大的2的幂返回内存空间,导致了2KB的冗余,因为这2KB非常小,很有可能内部进程使用不到,如果一直这样请求,就会导致了很多细小的不连续的内部休闲空间[碎片],当内部进程需要分配一大片连续的内存的时候,即使有很多细小的空间组合起来能大于需要申请的空间,但是因为不连续也就无能为力,不能满足要求,这样就造成了内碎片\n外碎片\n外部碎片指的是还没有被分配出去[进程还没有拿到手],但由于太小了无法分配给申请内存空间的新进程的内存空闲区域。\n主要原因还是频繁的申请释放导致了外碎片的存在\n如下图我开始申请了16KB的资源,然后又申请了16KB的,这个时候把我第一块的16KB给free掉,他就不属于任何进程,然后进程又来了许多个请求,一直需要18KB的内存,因为第一块只有16KB,而且因为伙伴算法的释放规则是相邻的地址才能进行合并释放,但是第2块内存一直被进程占着,所以第一块和第二块也合并不了,一直利用不上,导致了外碎片的存在\n为了解决外碎片linux使用了伙伴算法\n为了解决内碎片linux使用了slab算法,其实slab算法内部实现就是一个内存池逻辑结构\n利用上面的办法虽然对内存的管控已经几乎完美,但是因为还是程序员直接内存裸操纵,还是难以避免开发的时候,造成内存的崩溃,野指针,内存泄露,溢出,各种异常问题,于是为了解决这些问题,同时提升开发效率,不用程序员太关心内存处理,于是就有了现在的GC机制[智能指针是另外一回事]\n现在有了GC机制,但是内部没有合理的回收机制释放管理这些内存空间,比如如果因为申请和释放规则的不合理,一直申请内存,缓慢释放内存,就有可能造成像人一样吃的太饱,撑的不行,导致人思维缓慢(垃圾不需要内存过多,机器查找需要的内存查找不过来),甚至撑死(再也没有内存申请挂了 撑死的时候不一定会产生coredump文件)\n题外话为什么不一定产生coredump文件\n\u0026gt;`dump`文件只有在程序崩溃时才会生成,如果程序没有奔溃,那么可能是如下情况导致 \u0026gt; \u0026gt;主要是因为`linux`有一个叫做`OOM-killer(Out Of Memory killer)`的机制,`OOM killer`会 在系统内存耗尽的情况下触发,选择性的干掉一些进程,以求释放一些内存 \u0026gt; \u0026gt;当发生这种崩了,但是没有产生`coredump`的情况,可以去系统日志文件`/var/log/messages`看看里面 有没有相关日志记录,你是因为被`OOM-killer`机制给杀掉了进程 总之一句话来说:GC主要解决的就是内存过多,怎么合理回收垃圾内存的这些事儿\nGC怎么回收内存 LuaGC,java gc等等其他语言GC发展历史就不详细描述了,主要还是讲讲Lua5.4GC回收原理\n主要有两种一种是分代GC,一种是增量GC\n能被GC回收的对象 union GCUnion { GCObject gc; /* common header */ struct TString ts;//字符串 struct Udata u;//用户数据 union Closure cl;//闭包 struct Table h;//表 struct Proto p;//函数原型:存放函数字节码信息 struct lua_State th; /* thread *///线程 struct UpVal upv;//上值 }; 关于回收对象更详细的一些内容在这里就不详细的叙述了,想要了解的可以去我的博客下面地址了解\nGC对象\n颜色处理 从上图中我们可以看出lua为了效率和内存着想用的是一个字节8个bit位之间的相互作用来标识颜色,和分代GC的年龄情况\n颜色bit位索引 颜色 简介 宏运算 二进制 注解 WHITE0BIT 3 白0 bitmask(3) 1000 bit第3位设置成1 WHITE1BIT 4 白1 bitmask(4) 10000 bit第4位设置成1 BLACKBIT 5 黑色 bitmask(5) 100000 bit第5位设置成1 FINALIZEDBIT 6 用于标记userdata bitmask(6) 1000000 bit第6位设置成1 WHITEBITS 白色 bit2mask(WHITE0BIT, WHITE1BIT) 11000 bit第3,4位设置成1 为啥lua5.4要把白色分成两个标识呢,主要是因为如果对象在GC标记阶段之后创建对象,这个时候假如只有一个白色标识位,那么新创建的对象就会设置成白色,设置成功以后接下来到了回收阶段,因为白色是表示可回收的,那么新创建的对象会被认为没有引用而被删除了,这个逻辑肯定是不对的,不合理是的\n所以为了解决这种不合理情况lua创造了白0 白1两种状态来进行乒乓切换,其实也就是当前白和非当前白状态的乒乓切换\n特别注意并没有固定设置白0就是当前白,白1就是非当前白,是不是当前白是由当前GC使用的白色是啥决定\n当GC来到了回收阶段的时候,如果发现对象标识的颜色不是当前白,那么就会认为是没有引用而直接回收,而刚标识阶段和回收阶段之间创建的对象是当前白,就不会参与这次``GC回收,而到下一次GC回收才回收掉,毕竟因为乒乓切换,当前白到下一次GC`也会变成其它白状态\n颜色bit位检测 iswhite(x) 是不是白色 如果bit位第 3,4位中任意一位是1那么就认为他是白色标识\nisblack(x) 是不是黑色 如果bit位第5位是1,那么就认为是黑色标识\nisgray(x) 是不是灰色 如果bit位第3,4,,5位都是0,那么就认为是灰色标识\ntofinalize(x)是不是标识了userdata 如果bit位第6位是1,那么就认为标识了userdata,注意并没有红色颜色这个标识,只是我为了区分其他颜色涂上的\n主要还是userdata类型不同于其他类型,用户可以自己传入数据,设置gc元方法,自定义释放内存,所以 当 userdata 确认不被引用,则设置上这个标记,后面统一管理释放资源\n黑色,白色位控制 注意到白色位是乒乓效应的,也就是3,4号位是互斥状态\notherwhite(g) 非当前白 宏公式((g)-\u0026gt;currentwhite ^ WHITEBITS)\n表示非当前GC将要回收的白色类型 比如\n如果(g)-\u0026gt;currentwhite是1000 1000 ^ 11000 = 10000\n如果(g)-\u0026gt;currentwhite的值是10000的话, 10000 ^ 11000 = 1000\n结果正好相反\nluaC_white(g) 当前白 宏公式cast_byte((g)-\u0026gt;currentwhite \u0026amp; WHITEBITS)\n表示得到当前的要回收的白色类型 比如\n如果(g)-\u0026gt;currentwhite是1000 1000 \u0026amp; 11000 = 01000, 1000 \u0026amp; 11000还是1000\n如果(g)-\u0026gt;currentwhite是10000 10000 \u0026amp; 11000 = 10000, 10000 \u0026amp;11000还是10000\nchangewhite(x) 改变当前白色位 宏公式((x)-\u0026gt;marked ^= WHITEBITS) 比如如果现在((x)-\u0026gt;marked是101000\n这个时候执行了一下changewhite(x) 101000 ^ 11000 = 110000 因为是异或逻辑\n0和任何数异或是本身\n1和任何数异或是他相反的bit位\n所以我们得到了如下图结果\n比如如果现在((x)-\u0026gt;marked是110000\n这个时候执行了一下changewhite(x) 110000 ^ 11000 = 101000 因为是异或逻辑\n0和任何数异或是本身\n1和任何数异或是他相反的bit位\n所以我们得到了如下图结果\nnw2black(x) 设置成黑色 当bit 3,4位都是0然后就可以设成把5号位设置成黑色了\n颜色是否可被回收 颜色 状态 当前GC回收阶段是否回收 当前白 下次GC回收状态 不回收 其他白 回收状态 回收 灰色 当前对象为待标记状态 不回收 黑色 当前对象为已标记状态 不回收 年龄处理 年龄bit位索引 age使用的位mask,age只使用了marked的0,1,2位置\n青年对象\n宏定义 二进制 注解 G_NEW 0 000 本次cycle创建的新对象(没有引用任何old对象) G_SURVIVAL 1 001 当前gc存活下来的对象 G_OLD0 2 010 当前gc循环被barrier forward的节点,如果被插入的节点为isold()为true的节点 老年对象\n宏定义 二进制 注解 G_OLD1 3 011 活过了一次完整的gc G_OLD 4 100 活过了两次完整的gc,标记为G_OLD,不再被访问 G_TOUCHED1 5 101 old节点被插入新节点 G_TOUCHED2 6 110 G_TOUCHED1节点经过一次完整的gc还没有新的节点插入 getage(o) 获取年龄 宏公式((o)-\u0026gt;marked \u0026amp; AGEBITS)\n主要是利用了和#define AGEBITS 7 也就是二进制111的与运算得到当前的年龄毕竟与运算逻辑是\n1 \u0026amp; 1 = 1 0 \u0026amp; 1 = 0 等价于留下了低3位的数据\nsetage(o,a) 设置年龄 宏公式((o)-\u0026gt;marked = cast_byte(((o)-\u0026gt;marked \u0026amp; (~AGEBITS)) | a))\n~AGEBITS 等价于低3位是000 其他位都是1 比如64位系统得到结果是这样\n1111111111111111111111111111111111111111111111111111111111111000\n(o)-\u0026gt;marked \u0026amp; (~AGEBITS)) 进行与运算以后等价于高3位以上都会留下来毕竟与运算逻辑是\n1 \u0026amp; 1 = 1 0 \u0026amp; 1 = 0 (o)-\u0026gt;marked \u0026amp; (~AGEBITS)) | a\n然后和a进行或运算,这个就等价于进行或运算的组合逻辑了 毕竟或运算逻辑\n0 | 0 = 0\n0 | 1 = 1\n1 | 0 = 1\n1 | 1 = 1\nchangeage(o,f,t) 改变年龄 宏公式check_exp(getage(o) == (f), (o)-\u0026gt;marked ^= ((f)^(t)))\n从f变到t 前提是o的年龄要等于f 举个例子changeage(curr, G_TOUCHED1, G_TOUCHED2) 如果getage(o) == (f) 那么marked的低3位是101 101^=(101^110) ,101^=011 o-\u0026gt;marked=110 也就等价与o-\u0026gt;marked从101变到了110\n这个公式是lua作者利用对同一个值进行两次异或等于本身原理来达到这样的效果\n0 ⊕ x = x\n1 ⊕ x = x'(x'表示取反)\nx ⊕ x = 0\n所以有 y ⊕ x ⊕ x = y\n增量GC 经过前面的叙述,我们能知道Lua 增量GC使用的是4色标记清除算法\n当前白:表示本轮GC不会被回收的对象,也是对象开始创建时候的初始状态 其他白:表示本轮GC要被回收的对象,这个白一般都是上轮GC留下来的旧白,也可以认为这个白已经没有引用任何对象了 灰色:表示本来GC对象引用的其他对象还没有被访问到,需要进行扫描标记 黑色:表示本来GC对象引用的其他对象都已经被访问过了 增量GC时候存放GCobject的链表 lua本身有一个global_State的全局状态机,这里存着需要被GC流程处理的数据,大概如下所示\ntypedef struct global_State { GCObject *allgc; GCObject **sweepgc; GCObject *finobj; GCObject *gray; GCObject *grayagain; GCObject *weak; GCObject *ephemeron; GCObject *allweak; GCObject *tobefnz; GCObject *fixedgc; struct lua_State *twups; } 链表 作用 allgc 存放待GC对象的链表,所有对象创建之后都会放入该链表中 sweepgc 由于回收阶段不是一次性全部回收这个链表的所有数据\n所以使用这个变量来保存当前回收的位置,下一次从这个位置开始继续回收操作 finobj 存放所有带有析构函数(__gc)的GC obj链表 gray 存放灰色节点的链表 grayagain 存放需要一次性扫描处理的灰色节点链表,也就是说,这个链表上所有数据的处理需要一步到位\n不能被打断 weak 存放弱值的链表 ephemeron 键值对(pair),键是弱引用,但键对值的 mark 有如下影响\n如果键可达(reachable),则 mark 其值\n如果键不可达,则不必 mark 其值\n主要用来解决弱表的循环引用问题 弱引用(weak reference):可以访问对象,但不会阻止对象被收集\n弱表(weak table):键或(和)值是弱引用 allweak 具有要清除的弱键或弱值 或者弱键弱值同时存在的表 tobefnz 所有准备终结的userdata对象 fixedgc 永远不回收的对象链表, 如保留关键字的字符串, 对象必须在创建之后马上\n从 allgc 链表移入该链表中, 用的是 lgc.c 中的 luaC_fix 函数 twups 所有带有open upvalue 的 thread 都会放到这个链表中\n这样提供了一个方便的遍历 thread 的途径\n并且排除掉了没有 open upvalue 的 thread 增量GC流程 上图是增量GC的简易流程图,每个步骤关键的函数,我也画在了上面,大家先初步了解,能有一个大概印象,接下来我将详细的讲解里面的弯弯绕绕,细节部分\n新建对象阶段 从上图我们可以看到\n在创建一个新的GC类型的对象的时候,它都会把当前GC的颜色标识设置成当前白 并且还会把用头插法的方法,将新创建的对象 放入全局状态机的allgc链表当中,这其实也透露出因为用了头插法,所以我们在GC扫描的时候能优先扫描新创建的对象,需要接下来被GC待扫描处理的对象都会存在这个里面 GC触发阶段 自动触发 自动触发:luaC_checkGC,checkGC\n我们可以看到自动触发函数luaC_condGC包装在了luaC_checkGC函数中\n而lua在每次增删查改lua对象,虚拟栈,引起内存变化的时候,就会自动触发GC流程\n还有一个就是lua虚拟机在执行\nOP_NEWTABLE:新建一个表 OP_CONCAT:拼接对象 OP_CLOSURE:根据函数原型新建一个闭包 这些指令导致内存发送变化时候也会自动触发GC流程\n手动触发 手动触发:luaC_step\nLUA_API int lua_gc (lua_State *L, int what, ...) { ....... case LUA_GCSTEP: { int data = va_arg(argp, int); l_mem debt = 1; /* =1 to signal that it did an actual step */ lu_byte oldstp = g-\u0026gt;gcstp; g-\u0026gt;gcstp = 0; /* allow GC to run (GCSTPGC must be zero here) */ if (data == 0) { luaE_setdebt(g, 0); /* do a basic step */ luaC_step(L); } else { /* add \u0026#39;data\u0026#39; to total debt */ debt = cast(l_mem, data) * 1024 + g-\u0026gt;GCdebt; luaE_setdebt(g, debt); luaC_checkGC(L);///这个地方触发 } g-\u0026gt;gcstp = oldstp; /* restore previous state */ if (debt \u0026gt; 0 \u0026amp;\u0026amp; g-\u0026gt;gcstate == GCSpause) /* end of cycle? */ res = 1; /* signal it */ break; } ....... } 比如lua层调用collectgarbage(\u0026quot;step\u0026quot;)语句的时候,就会调用到这里来,等价于手动单步运行垃圾回收\n不管是手动还是自动触发,只要是设置的增量GC方式都会进入singlestep函数\nsinglestep函数就是增量GC的主力函数,因为前面参数的设置调控和singlestep函数内部的逻辑处理,就可以实现增量处理,可以被中断再恢复并继续进行,不会在像双色GC程序必须暂停下来,不能进行其他操作导致卡顿\n开始阶段:GCSpause 从上面可以看出这个阶段主要靠restartcollection函数处理相关逻辑\n进入函数中,我们可以看到这个函数主要是处理了这些事情\n将g-\u0026gt;gray灰色节点链 g-\u0026gt;grayagain原子操作灰色节点链表初始化\n将3个和弱表相关的链表初始化\n将mainthread:主执行栈,l_registry:全局注册表,markmt(g):全局元表,markbeingfnz(g):上次GC循环中剩余的finalize中的userdata对象在此进行标记\n而对对象进行标记是由reallymarkobject函数进行的\nreallymarkobject 主要逻辑是直接将 userdata, string, closed upvalue 涂黑, 其它类型对象涂灰等待进一步处理\n当这些都处理完以后就进入了传播阶段:GCSpropagate\n传播阶段:GCSpropagate 从上图中我们可以看到,如果g-\u0026gt;gray不等于空,那么就会一直调用propagatemark函数从灰色列表中取出一个灰色对象进行涂黑,并对他的引用进行标记,还有注意这里并不是一个循环一直在循环调用propagatemark函数进行循环取灰色对象,进行标记,而只有g-\u0026gt;gray==NULL的时候才会进入下一次GC阶段,由此我们可以看出这个是可以被中断的,毕竟propagatemark函数中有g-\u0026gt;gray指针一直记录这执行到了那一个灰色对象,在下次进来的时候从这个地方在开始执行就行了,这样做能有效的减少阻塞时间,更快的响应Lua虚拟机,毕竟谁也不想一直把性能处理长时间丢到这快地方,当gray链表当中的灰色节点处理完以后,就会进入GCSatomic的过渡状态:GCSenteratomic\n从上面其实我们还可以分析出,如果一直在创建对象,创建对象的速度一直大于GCSpropagate的处理速度,那么就会导致一直卡在这里\n解决这个办法,可以有如下方法\n一个是减少gray链表的数量,也就是减少灰色节点的创建,比如少弄一层又一层的引用,举个例子比如你创建了一个table,然后table的value又没有设置week,那么就会变量table中table所有可达的value,如果value是GC对象并且是白色的,那么就会有push到灰色链表当中,这样就子子孙孙无穷尽也,很有可能一直卡在这一块 第二中方法的话可以控制GC的各种阈值变量 比如通过调用collectgarbage(\u0026quot;setstepmul\u0026quot;)调节gcstepmul阈值变量,让他变小一点,这样就缩小了一步处理GC的工作量,从而减少处理时间 还可以调用collectgarbage(\u0026quot;setpause\u0026quot;)调节gcpause阈值变量,让他变小点,加快第二次GC开始到来的时间 上面介绍完,我们在来好好的讲解下propagatemark函数里面到底做了啥\n标记table:traversetable 从上图中我们可以分析出主要是通过扫描table类型,key,value的类型,是不是weak方式,决定放入那个全局虚拟机GC链表\nstrong key, weak value\n若 gc 处在 GCSpropagate 阶段, 并且g-\u0026gt;gray不为空将 weak table 加入到 g-\u0026gt;grayagain 链表中, 在 atomic phase 再次访问\n否则按下面的规则添加到对应链表\ntable数组部分 若table数组部分中有元素, 并且是atomic phase阶段加入到 g-\u0026gt;weak list\n若table数组部分中没有元素 并且不是atomic phase阶段加入到 g-\u0026gt;grayagain list\ntable hash部分 val is nil: 移除它\nval is not nil: 标记key,若value is白色 (且不为不可回收对象)\n是atomic phase阶段加入到 g-\u0026gt;weak list 不是atomic phase阶段加入到 g-\u0026gt;grayagain list weak key, strong value\ntable数组部分\n遍历数组如果有白色值就进行标记,并marked设置为true\ntable hash部分\n按倒序或者正序遍历进行标记,标记好以后进行如下操作\n若gc 处在GCSpropagate: 把h放入g-\u0026gt;grayagain中\n否则按如下规则处理\n​ val is nil: 移除它\n​ white key-white value: 把h放入g-\u0026gt;ephemeron\n​ white key-marked value: 把h放入g-\u0026gt;allweak\n​ marked key-white value: 标记value\n​ 其他:如果是touched1状态把黑色对象link进灰色链表,否则如果是touched2状态改变他的年龄到G_OLD\n3.weak key, weak value\n把table放入g-\u0026gt;allweak\nstrong key, strong value\ntable数组部分\n对value进行标记\ntable hash部分\nvalue is nil: 移除它\nvalue is not nil: 标记key, 标记value\n标记userdata:traverseudata 可以看到主要的事情是对userdata里面的元表和上值进行标记\n标记lua闭包:traverseLclosure 可以看到主要的事情是对lua闭包里面的引用对象函数原型和上值进行标记\n标记C闭包:traverseCclosure 主要是标记C闭包里面所有的上值\n标记函数原型:traverseproto 主要是标记函数原型里面引用的文件名,常量表,上值名,子函数表,局部变量\n标记线程:traversethread 如果现在GC是GCSpropagate阶段,线程也是旧对象,那么就丢到g-\u0026gt;grayagain列表放在后面atomic中进行处理,毕竟thread上关联的对象是Lua运行时的状态,变化很频繁,还不如丢到grayagin表中然后到atomic一次性进行标记处理\n如果现在GC是GCSatomic阶段\n清除已经不在使用的栈空间,并把它们置成nil\n如果线程的上值open链表有值\n标记上值open链表\n如果线程在twups链表中\n若 thread 不在twups链表中,但是 上面有openupval, 则将其重新加入到 g-\u0026gt;twups 链表\n其他类型 就是简单的调用nw2black(o)函数标记成黑色\n屏障操作 luaC_barrier\n向前走一步如果新建对象是白色,而它被一个黑色对象引用了那么将这个新建对象颜色从白色变为灰色\n这么做的主要是因为\n在赋值操作的时候有可能发生黑色对象,指向白色对象的可能性,出现这种情况是不合法的,毕竟如果你一个黑色对象指向了白色对象,比如 lua_load 函数当中的 luaC_barrier(L, f-\u0026gt;upvals[0], gt)执行语句如果不把gt从白色变成灰色,那么在lua GC状态机持续运转中到达回收状态中会把他当白色对象给回收了,那这样就会导致函数的上值表第一个位置存的元素消失,这样肯定是不合理的 也是为了让GC能够感知到你这个黑色对象重新赋值了一个白色对象,如果你不把这个黑色对象新引用的白色对象不改变颜色的话,很有可能在传播阶段和原子阶段因为这个白色对象不在gray链表中无法感知而无法标识这个白色节点引用的东西导致错误 luaC_barrierback\n标记向后一步此时将引用的它的黑色对象的颜色从黑色变为灰色,然后放入grayagain链表当中\n通过观察我们看到这个操作主要是给table使用的\n主要原因是\ntable关联的对象key,value是一对多的关系,如果调用的是向前操作,那么如果加入一个数据,那么就的放入gray链表中去等待扫描,如果引用的层级特别的多,可想而知,这样一直遍历gray链表,等待时间会非常长,增加不必要的开销,还不如向后一步,直接放入grayagain链表在原子阶段直接一次性标记扫描 接下来如果gray链表都标记清除处理完毕了,那么就进入了过渡阶段:GCSenteratomic\n过渡阶段:GCSenteratomic 这个阶段没太多可讲的主要是两个重要函数\natomic:进入原子收集标记阶段 entersweep: sweep过程中把非dead 对象标记为 currentwhite 上面两个函数也留到下一个阶段原子阶段:GCSatomic来讲解\n原子阶段:GCSatomic 从上面的函数这次集中处理的是运行中的协程栈 全局注册表 全局元表 open状态的上值 grayagain链表 弱表链表 所有准备终结的userdata对象 可以看出这次在遍历未处理的数据的时候,是一次性执行的,每一次遍历未处理的数据,都会再次调用propagateall函数以保证这次彻底的把gray链表访问到了\n然后将当前白色值切换到新一轮的白色值(在此之后,所有新建的对象虽然也为白色,但是在GC循环走完之前并不会被回收,而是等待下一轮GC回收)\n原子atomic处理完以后又会调用entersweep函数进入扫描复活模式,主要作用还是为了把这次GC中死亡的对象回收,未死亡的对象设置成当前白\n上述步骤终于做完了,我们就可以进行下一步来到回收阶段了\n清扫阶段 sweepstep函数最终会调用到sweeplist函数,而sweeplist函数上面也介绍过主要是为了把死对象回收,把非死对象标记为当前白\nGCSswpallgc 从上图函数中可以看出g-\u0026gt;sweepgc指针执行的是g-\u0026gt;allgc,所以这里的作用主要就是扫描g-\u0026gt;allgc,并把里面的死对象回收,非死亡对象标记为当前白\nGCSswpfinobj GCSswpfinobj同样也调用了sweeplist进行清除并且标记,主要是对global_State.finobj链表的处理,而前面我们也分析过finobj里面存的是什么东西\n从上面可以看出他除了清扫并标记,还做了对自定义__gc元方法调用\nGCSswptobefnz GCSswpfinobj同样也调用了sweeplist进行清除并且标记,,主要是对global_State.tobefnz链表的处理,tobefinz里面存的内容主要userdata对象相关\nGCSswpend GCSswpend最后回收结尾,主要是针对内存的回收,整理,字符串表的收缩,还有存活量的统计\n收尾阶段:GCScallfin 这是最后状态机的最后一步了,主要会对global_State.tobefnz链表进行遍历,然后调用userdata自己定义的__gc元方法,来进行自己的自定义回收,同时还会将tobefnz链表中的对象放到allgc链表中,参与下一次GC回收流程\n分代gc 时间关系,下周补全\nGC通过那些阈值进行调控 时间关系,下周补全\n更详细的注释请去我的GitHub地址 以下是我几乎每行都加了注释的GitHub地址\nlgc.c注释地址\nlgc.c注释\nlgc.h注释地址\nlgc.h注释\n","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.gc/","summary":"GC由来简介 c,c++的话基本都是手动管理内存,优点是效率很高,毕竟不需要去找出那些是垃圾,需要被清理这种逻辑处理,也不需要在gc清理的时候","title":"[Lua5.4.4源码].GC"},{"content":"调用栈,数据栈 数据栈数据结构 /// @brief 数据栈指针结构 typedef union StackValue { TValue val; struct { TValuefields; unsigned short delta;//相邻 tbc 变量在栈中的距离 } tbclist;//此堆栈中所有活动的将要关闭的变量的列表 } StackValue; //栈指针 typedef StackValue *StkId; struct lua_State { ... StkId top; /* first free slot in the stack *///指向栈的顶部,压入数据,都通过移动栈顶指针来实现 StkId stack_last; /* end of stack (last element + 1) *///最后可用的位置数据栈 正常的栈操作在[stack, stack_last]之间 StkId stack; /* stack base *///栈的起始地址 StkId tbclist; /* list of to-be-closed variables *///记录着最后一个tbc节点,栈缩容时会判断节点是否在缩容空间内,如果在那么就根据这个节点调用缩容空间内所有tbc变量的 __close() 元方法 }; //数据栈大小 #define stacksize(th)\tcast_int((th)-\u0026gt;stack_last - (th)-\u0026gt;stack) 调用栈数据结构 调用栈,数据栈初始化 这两个栈的初始化通过stack_init函数初始化\n大概示意图如下\n在64位机器上,64位lua exe 我们能得到sizeof(StackValue) =16 一开始线程创建一个大小为BASIC_STACK_SIZE + EXTRA_STACK 40个的StackValue的基础空间 数据栈stack_last指针,指向stack + BASIC_STACK_SIZE的位置,也就是40号位置的起始地址 数据栈 stack指针,tbclist指针,都指向首地址,也就是0号位置的起始地址 数据栈 top指针指向函数调用栈func + 1的位置,也就是栈顶位置或者说他是下一个free位置也行,因为0号位置给了func,所以top指针需要指向下一个free位置,也就是1号位置的起始地址 函数调用栈top指向函数调用栈的空间末尾,也就是20号位置的末尾,21号位置的起始地址 callInfo是当前函数A调用函数B的调用关系调用链,callInfo base_ci 指向调用链的起始,也就是函数帧第一层 callInfo ci指向当前执行的函数帧,这里图上只的是函数B 这里归纳总结起来有3个主要空间\n[数据栈stack指针,数据栈stack_last指针]表示数据栈空间\n[函数调用栈func指针,数据栈top指针]标识函数调用栈空间\nTBC变量空间\n我们可以看到当lua栈存了tbc变量的时候,他聪明的用了一个L-\u0026gt;tbclist指针指向了最后一个tbc变量,然后每一个tbc的变量内部都有一个delta字段,来表示相邻的两个tbc变量差多少偏移量,从而让每个tbc变量都能够串连起来,这个思路lua table里面插入值的时候有hash冲突时候利用next字段的偏移量串连上冲突值一个思路\ntbc变量的插入 从上面我们可以看出\n插入一个新的tbc变量的时候,只能插入到当前tbc变量的屁股后面, 检测完这些以后,那么它就会检测一下你是不是关联了__closed元方法 如果超过了unsigend short最大值,那么就会创建虚拟节点 当前面都过就到了两个关键点,一个是算相邻两个tbc的距离,一个是把tbclist指针指向最新的tbc变量位置 tbc变量的删除\n和下图类似\nLua调用C C层注册过程,并提供Lua接口过程 //能够被Lua调用的C函数必须是这种规则 函数的返回值int值表示C函数返回值的个数 typedef int (*lua_CFunction)(lua_State *L) 可能有人会问,为啥一定要这种样子的函数指针呢,让我们追溯源码了解一下\n我们以这个为例\n我们一步步分析\nluaopen_coroutine 这个函数有个前缀luaopen_ 这个是lua C库中开放函数的前缀,这样你就可以在lua文件中直接调用coroutine开头的函数了,比如上面的coroutine.create coroutine.resume 等等\n注意这里能直接调用luaopen_coroutine是因为这里已经注册到全局表了,而如果是自己自定义的那么就的通过require你的so文件,并从so文件中找到luaopen_开头的函数\n接下来我们调用 luaL_newlib(L, co_funcs)函数,并传递了一个funcs数组,执行完这个以后我们就创建了一个全局的table表,用来存funcs数组里面一一对应的函数,比如lua中调用coroutine.create 等价于就是调用C语言的luaB_cocreate函数\n从上图中我们可以看到还调用了luaL_setfuncs函数,这个是lua为啥能调用c代码的核心地方\n通过源码分析,我们可以看出这里其实就是把所有luaL_Reg数组中的函数注册到通过luaL_newlib创建的table中\n图上1号位置完美的解释了为什么funcs数组要以{NULL,NULL}结尾\n2号位置就是真正的把luaL_newlib创建的table和funcs数组一一关联起来,也就是形如t[l-\u0026gt;name] = func 形式通过这样的操作就能够实现lua中调用coroutine.create 然后跑到c语言的luaB_cocreate函数继续执行下面的逻辑了\n回到一下这个问题\n我们从这个箭头位置可以看到luaL_Reg其实指向的就是那个func数组第二列的c函数位置,比如下面话红线的位置就是func指向的地方\n调用过程 首先我们以如下代码作为例子\n//c层代码 #include \u0026lt;stdio.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; } int main(int ar) { lua_State* L = luaL_newstate();//创建主线程栈 luaL_openlibs(L);//打开常规的lua标准库 luaL_dofile(L, \u0026#34;helloworld.lua\u0026#34;);//加载并运行指定的文件 return 0; } local ff = function(a, b) local c = a +b print(\u0026#34;start yield\u0026#34;) local x,y, z= coroutine.yield(c) print(\u0026#34;restart co\u0026#34;, x,y,z) return x + y + z + c end local co = coroutine.create( ff ) 执行这段代码调用链如下\n通过以上的调用链流程我们就完美的调用到了对应的C函数\n更通俗的来讲就是如果想要Lua能调用C层那么我们就的在C层把对应的函数指针,注册到通过luaL_newlib函数new出来的table中,等待Lua通过luaL_dofile函数去加载lua文件并调用lua_pcallk去一步步找Lua函数对应的的C函数指针,从而达到Lua能调用C的要求\n这里在重点说一下luaL_loadfilex里面加载Lua文件的过程,当知道了这块过程以后,能初步的知道Lua解析文件后生成指令的大概过程,得到了指令以后,Lua就可以通过luaV_execute去找目标C函数指针调用C函数了\n来到f_parser这个地方的时候,我们可以看到如果是二进制文件,那么就是直接执行luaU_undump,如果是文本,那么就直接执行luaY_parser,因为我们是文本lua文件,所以我们进入的是luaY_parser\n从上图中我们可以看到当进行语法分析的时候,会创建一个LexState结构用于存储语法分析结果,FuncState结果用于存储函数状态,并创建了一个函数原型, 函数原型里面会保存当前函数的形参,局部变量,上值,等等一些信息, 便于后面变成指令执行,最后返回了一个LClosure结构出去\n接下来就会在执行body函数的时候把形参和OP_CLOSURE 等等相关指令创建出来,这样就便于后面luaV_execute函数去执行相关的指令了,从而在执行lua函数的时候通过找到对应的C函数指针而往下执行\n简介流程\nC调用Lua extern \u0026#34;C\u0026#34; { #include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; } lua_State* L; int luaadd(int x, int y) { int sum; /*函数名*/ lua_getglobal(L, \u0026#34;add\u0026#34;); /*参数入栈*/ lua_pushnumber(L, x); /*参数入栈*/ lua_pushnumber(L, y); /*开始调用函数，有2个参数，1个返回值*/ lua_call(L, 2, 1); /*取出返回值*/ sum = (int)lua_tonumber(L, -1); /*清除返回值的栈*/ lua_pop(L, 1); return sum; } int main(int argc, char* argv[]) { int sum; L = luaL_newstate(); /* 创建lua状态机 */ luaL_openlibs(L); /* 打开Lua状态机中所有Lua标准库 */ /*加载lua脚本*/ luaL_dofile(L, \u0026#34;helloworld.lua\u0026#34;); /*调用C函数，这个里面会调用lua函数*/ sum = luaadd(99, 10); printf(\u0026#34;The sum is %d \\n\u0026#34;, sum); /*清除Lua*/ lua_close(L); return 0; } function add(x,y) return x + y end 执行luaL_dofile(L, \u0026ldquo;helloworld.lua\u0026rdquo;) 效果会如下面流程图的一样\n把相应的指令,proto,局部变量,全局变量,上值等等其他都创建好,等待C语言的调用\n接下来我们一步步往下走\n执行sum = luaadd(99, 10); 执行lua_getglobal(L, \u0026ldquo;add\u0026rdquo;); 执行 lua_pushnumber(L, x);lua_pushnumber(L, y); 执行 lua_call(L, 2, 1); 执行 sum = (int)lua_tonumber(L, -1); 执行 lua_pop(L, 1); 这样就实现了C调用Lua的过程\n总结 从中可以看出不管是Lua调用C还是C调用Lua都离不开lua文件中需要去luaL_dofile解析Lua文件,生成相关的指令,函数原型,等等\n但是Lua调用C的时候还必须把luaL_Reg数组中的函数注册到lua虚拟机中,这样才能实现Lua调用C\n也有人说loadstring也能实现次功能,但是看完源码以后其实他类似于luaL_dofile的加载,没太大区别,只是一个是执行字符串块,一个是执行lua文件\n更详细的注释请去我的GitHub地址 以下是我几乎每行都加了注释的GitHub地址\nldo.c注释地址\nldo.c注释\nlparser.c注释地址\nlparser.c注释\n","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.stack/","summary":"调用栈,数据栈 数据栈数据结构 /// @brief 数据栈指针结构 typedef union StackValue { TValue val; struct { TValuefields; unsigned short delta;//相邻 tbc 变量在栈中的距离 } tbclist;//此堆栈中所有","title":"[Lua5.4.4源码].栈"},{"content":"thread即为线程,但是在lua中是没有线程的概念的,这个线程并不是真正意义上操作系统的线程,而更多的是一个能储存运行状态的数据结构,这个结构更多的是给协程coroutine使用的\n线程和协程的区别 线程消耗操作系统资源,协程可以靠编译语言实现,因此称为用户态线程量级更轻 线程并行,协程并发 线程同步,协程异步 线程抢占式,协程非抢占式,需要手动切换 线程上千,协程上万 线程切换需要上下文切换,协程切换不需要上下文切换,只在用户态进行切换 文字太枯燥,我们下面用几张图示来区别下进程,线程,协程的区别\n内存布局 从上面3张图,我们可以分析出\n进程拥有自己单独的虚拟内存,堆区,栈区,相互不影响,是资源分配的最小单位 线程可以拥有不同栈区,相互独立,堆区共享,是CPU分配的最小单位 而因为线程CPU上下文的切换,耗费的时间很多,所以牛B的工程师又在此基础上创造了协程,所以我们可以看出协程是用户态的,不需要进行CPU的切换,只是在CPU上模拟了线程的操作逻辑,大大的提高了效率 存储协程数据的数据结构 协程的四种状态 协程库对外接口 下面我们通过一个例子来解释这些接口的含义 创建协程 相同点\ncoroutine.create(f)和coroutine.wrap(f)都是用来创建协同程序的 不同点\n不同的是coroutine.create(f)返回的是一个线程号(一个协同程序就是一个线程),并且创建的协同程序处于suspend状态,必须用resume唤醒协同程序执行,执行完之后协同程序也就处于dead状态.\n而coroutine.wrap(f)则是返回一个函数,一但调用这个函数就进入coroutine状态.不需要resume唤醒,直接调用返回的函数就行\ncoroutine.create(f) 首先我们创建一个lua代码来进行讲解\nlocal co = coroutine.create( function(a, b) print(\u0026#34;a + b =\u0026#34;, a + b) end ) print(co); print(coroutine.status(co)) 运行结果如下:\n我们从print(co)能看出来在使用 coroutine.create的时候其实返回的是一个线程id,这个id就是协程栈的id 从print(coroutine.status(co))上能看出刚create出来的协程状态是suspended状态的 接下来我们来追踪源码,一共四步,现在我把每步的栈空间情况画出来分析\n执行1号位置代码的时候堆栈情况\n执行2号位置代码的时候堆栈情况,全局栈顶部会push一个新创建出来的协程,新的协程栈这个时候什么都没有\n执行3号位置代码的时候堆栈情况,这个时候会把L-\u0026gt;ci-\u0026gt;func +1指向的位置放到全局栈栈顶\n执行4号位置代码的时候堆栈情况,这个时候全局栈的栈顶元素ff会移动到协程栈的顶部\n至此一个协程就创建出来了\ncoroutine.wrap(f) lua测试代码\nlocal ff = function(a, b) print(\u0026#34;a + b =\u0026#34;, a + b) return a + b; end func = coroutine.wrap(ff) print(func) local ret = func(10 ,20)--不需要调用 coroutine.resume接口直接就可以运行 print(ret) 从上图中我们可以看出\n返回的是一个函数 不需要resume唤醒,直接调用返回的函数就行 我们在看一下源码解释\n从中我们可以看到,原来wrap只是包装了一层,然后把新创建的协程当做luaB_auxwrap的一个upvalue,进行返回,其他的操作和coroutine.create(f)类似\n启动协程 coroutine.resume(co, \u0026hellip;) 没有yield的协程的resume local co = coroutine.create( function(a, b) return a,b end ) local ret, a ,b = coroutine.resume(co,3) print(ret, a ,b) 可以看到首先没有yield的协程的resume,返回的就是create里面的函数return的a,b值 来源是resume后面的不定参数,传啥就对应啥,如果不传就默认是nil\n有yield的协程的resume local co = coroutine.create( function(a, b) local c = a +b print(\u0026#34;start yield\u0026#34;) local x,y, z= coroutine.yield(c) print(\u0026#34;restart co\u0026#34;, x,y,z) return x + y + z + c end ) local ret, a = coroutine.resume(co,3,4) print(ret, a) local ret, a = coroutine.resume(co,30,40,50) print(ret, a) local ret, a = coroutine.resume(co,300,400,500) print(ret, a) 首先我们利用了coroutine.resume创建了一个协程,但是这个协程因为返回的是协程id所以不可能想coroutine.wrap一样直接调用就行,只能通过coroutine.resume来启动\n根据上图我们可以分析出\n首先在1号位置第一次调用了coroutine.resume把3和4传给了函数的a,b,然后再函数里面遇到了coroutine.yield(c)挂起了函数,并把结果c通过yield形参传给了resume,然后直接下面就print出了true,7\n接着来到了2号位置第二次调用了coroutine.resume把30和40,50通过yield的返回值返回给了x,y,z,通过打印print(\u0026quot;restart co\u0026quot;, x,y,z)也能看出的确是这样的结果\n接着来到3号位置,第三次调用了coroutine.resume,这个时候发现print直接输出了false和cannot resume dead coroutine,传递啥参数也不起作用,主要原因是因为当协程完成的时候,或者有错误的时候就会报这个cannot resume dead coroutine错误提示\n具体参数传递,大家可以顺着下图线的颜色捋\n说了这么多,我们从头开始撸,为了方便讲解清楚,方便画流程图,我把create里面的函数用ff进行了保存\n当我们调用\nlocal ff = function(a, b) local c = a +b print(\u0026#34;start yield\u0026#34;) local x,y, z= coroutine.yield(c) print(\u0026#34;restart co\u0026#34;, x,y,z) return x + y + z + c end local co = coroutine.create( ff ) 的时候这个时候堆栈情况是\n当我们继续调用的时候\nlocal ret, a = coroutine.resume(co,3,4) 我们追踪源码这个时候主要起作用的核心是luaB_coresume函数里面调用的auxresume函数\n进入auxresume函数以后我们看到主要起作用的是这3个位置\n当我们在调用1号位置lua_xmove函数之前我们堆栈情况是这样的\n调用lua_xmove函数之后堆栈情况\n当做完这些准备的时候,我们来到了2号代码位置,尝试用lua_resume来真正唤醒启动一根协程来处理逻辑\n可以看到这有3个关键点,\n1号位置代表当函数执行完成以后,或者发送错误的时候,你这个时候在去调用coroutine.resume,这个时候发现直接输出了false和cannot resume dead coroutine\n2号位置也很重要这是执行回调函数的关键,里面会利用lua_longjmp和setjmp来进行当前环境变量的执行,还有异常抛出\nluaD_rawrunprotected执行逻辑整体流程如下\n函数最开始定义一个lua_longjmp结构体,用于保存当前执行环境,状态值设置为LUA_OK\n然后调用LUAI_TRY函数,该函数实际是一个宏定义,将当前执行环境setjmp,并执行回调函数\n如果回调函数执行内部,发生异常情况,则通过luaD_throw将异常抛出\n异常抛出函数,会执行 LUAI_THROW函数,该函数是longjmp的宏定义,并且将返回值设置为1\n由于执行了longjmp,则C语言内部方法会回到跳转点setjmp\nLUAI_TRY函数判断setjmp的返回值,之前是0,现在由于longjmp设置了值为1,所以不会继续执行回调函数,回调函数被中断\n当luaD_rawrunprotected函数的执行真的抛出异常的时候,这个时候就会调用precover函数进行恢复,这样我们不需要担心调用一个协程后会因为协程内部的错误导致外部的主程序崩溃\n第3号位置,我们可以看到函数的返回值的情况,其实就是对应了这张图的逻辑处理\n最后我们得到了从lua_resume的到的status状态和nres返回值个数的信息以后通过如下代码送到了原始协程\n​\t具体堆栈图示情况如下,到此我们的 resume流程就结束了\n​\t挂起协程 coroutine.yield(\u0026hellip;) 挂起协程源码如下\n从中我们可以看出主要是lua_yieldk函数在起作用\n从1号位置我们可以看出\n主栈不能yield\ncoroutine.resume \u0026ndash;\u0026gt; cfunc \u0026ndash;\u0026gt; luafunction\u0026ndash;\u0026gt; coroutine.yield \u0026mdash;\u0026ndash;\u0026gt; 报错\n从2号位置我们可以看出当yield的时候状态会被置成LUA_YIELD\n从3号位置我们可以看出这里报错了延续函数的上下文,和延续函数,主要是为了解决2号位置发生的报错信息\n延续函数 为什么我们需要延续函数呢,主要原因还是因为如下流程\ncoroutine.resume --\u0026gt; cfunc --\u0026gt; luafunction--\u0026gt; coroutine.yield -----\u0026gt; 报错 当我们从cfunc调用luafunction,然后luafunction调用yield的时候,和协程相关的状态信息都会被保存lua_state中,但是c函数不会因为调用了coroutine.yield而挂起,而是会继续执行下去,c函数执行完成以后也就全部销毁了,也无法保存恢复现场,这样就会导致c层的调用和lua层的调用不一致,lua层挂起,c层执行,这样逻辑代码也会发生错误\n比如下面的报错版本\n//c层代码 替换main函数的那个文件就行 #include \u0026lt;stdio.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; #include\u0026lt;lstate.h\u0026gt; } static void traceback(lua_State* L, int n) { lua_Debug ar; if (lua_getstack(L, n, \u0026amp;ar)) { lua_getinfo(L, \u0026#34;Sln\u0026#34;, \u0026amp;ar); if (ar.name) { printf(\u0026#34;\\tstack[%d] -\u0026gt; line %d : %s()[%s]\\n\u0026#34;, n, ar.currentline, ar.name, ar.short_src); } else { printf(\u0026#34;\\tstack[%d] -\u0026gt; line %d : unknown[%s]\\n\u0026#34;, n, ar.currentline, ar.short_src); } traceback(L, n + 1); } } static int TraceBack(lua_State* L) { printf(\u0026#34;STACK TRACEBACK: %s\\n\u0026#34;, lua_tostring(L, -1)); traceback(L, 0); return 0; } static int Cfunction(lua_State* L) { printf(\u0026#34;Cfunction enter!\\n\u0026#34;); lua_pushcfunction(L, TraceBack); lua_getglobal(L, \u0026#34;Luafunction\u0026#34;); lua_pcall(L, 0, 0, -2); printf(\u0026#34;Cfunction leave!\\n\u0026#34;);//报错版本这里直接往下执行了,并未和lua层一起挂起,导致了和lua层行为不一致 return 0; } int main() { lua_State* L; int status; L = luaL_newstate(); luaL_openlibs(L); lua_pushcfunction(L, Cfunction); lua_setglobal(L, \u0026#34;Cfunction\u0026#34;); status = luaL_loadfile(L, \u0026#34;helloworld.lua\u0026#34;); if (status) { printf(\u0026#34;loadfile error!(%s)\\n\u0026#34;, lua_tostring(L, -1)); lua_settop(L, 0); return 0; } status = lua_pcall(L, 0, 0, -2); if (status) { lua_settop(L, 0); return 0; } return 1; } --lua文件 function Luafunction() print(\u0026#34;Luafunction yield enter!\u0026#34;) coroutine.yield() print(\u0026#34;Luafunction yield leave!\u0026#34;) end local co = coroutine.create( function() print(\u0026#34;Luafunction coroutine resume!\u0026#34;) Cfunction() end ) coroutine.resume(co) 运行结果\n在现在这个版本,通过lua_callk, lua_pcallk, lua_yieldk这些API函数传递了延续函数,然后再调用coroutine.resume的时候能够保证和lua一起保持同步调用,这样就不会报错了\n下面我们来看看加了延续函数版本\n//c层代码 替换main函数的那个文件就行 #include \u0026lt;stdio.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026lt;lua.h\u0026gt; #include \u0026lt;lualib.h\u0026gt; #include \u0026lt;lauxlib.h\u0026gt; #include\u0026lt;lstate.h\u0026gt; } static void traceback(lua_State* L, int n) { lua_Debug ar; if (lua_getstack(L, n, \u0026amp;ar)) { lua_getinfo(L, \u0026#34;Sln\u0026#34;, \u0026amp;ar); if (ar.name) { printf(\u0026#34;\\tstack[%d] -\u0026gt; line %d : %s()[%s]\\n\u0026#34;, n, ar.currentline, ar.name, ar.short_src); } else { printf(\u0026#34;\\tstack[%d] -\u0026gt; line %d : unknown[%s]\\n\u0026#34;, n, ar.currentline, ar.short_src); } traceback(L, n + 1); } } static int TraceBack(lua_State* L) { printf(\u0026#34;STACK TRACEBACK: %s\\n\u0026#34;, lua_tostring(L, -1)); traceback(L, 0); return 0; } //延续函数 static int cfunctionContinuation(lua_State* L, int status, lua_KContext ctx) { printf(\u0026#34;Cfunction leave!\\n\u0026#34;); return 0; } static int Cfunction(lua_State* L) { printf(\u0026#34;Cfunction enter!\\n\u0026#34;); lua_pushcfunction(L, TraceBack); lua_getglobal(L, \u0026#34;Luafunction\u0026#34;); //lua_pcall(L, 0, 0, -2); lua_pcallk(L, 0, 0, -2, 0, cfunctionContinuation);//这里加了延续函数 return 0; } int main() { lua_State* L; int status; L = luaL_newstate(); luaL_openlibs(L); lua_pushcfunction(L, Cfunction); lua_setglobal(L, \u0026#34;Cfunction\u0026#34;); status = luaL_loadfile(L, \u0026#34;helloworld.lua\u0026#34;); if (status) { printf(\u0026#34;loadfile error!(%s)\\n\u0026#34;, lua_tostring(L, -1)); lua_settop(L, 0); return 0; } status = lua_pcall(L, 0, 0, -2); if (status) { lua_settop(L, 0); return 0; } return 1; } 没有第二次调用coroutine.resume唤醒挂起协程的情况\nfunction Luafunction() print(\u0026#34;Luafunction yield enter!\u0026#34;) coroutine.yield() print(\u0026#34;Luafunction yield leave!\u0026#34;) end local co = coroutine.create( function() print(\u0026#34;Luafunction coroutine resume!\u0026#34;) Cfunction() end ) coroutine.resume(co) 第二次调用coroutine.resume唤醒挂起协程的情况\nfunction Luafunction() print(\u0026#34;Luafunction yield enter!\u0026#34;) coroutine.yield() print(\u0026#34;Luafunction yield leave!\u0026#34;) end local co = coroutine.create( function() print(\u0026#34;Luafunction coroutine resume!\u0026#34;) Cfunction() end ) coroutine.resume(co) coroutine.resume(co)--第二次调coroutine.resume 具体源码核心代码主要是这几个地方\n关闭协程 coroutine.close(co) 关闭协程 co,并关闭它所有等待 to-be-closed 的变量,并将协程状态设为 dead\n具体源码如下\n返回协程 coroutine.running() 返回当前正在运行的协程加一个布尔量. 如果当前运行的协程是主线程,其为真.\n获取协程状态 coroutine.status(co) 以字符串形式返回协程 co 的状态.\n具体情况4中\n状态 解释 running 运行 dead 死亡 suspended 挂起 normal 正常 协程是否可以让出 coroutine.isyieldable(co) 如果协程 co 可以让出，则返回真。co 默认为正在运行的协程。\n主要是靠这个宏来判断\n更详细的注释请去我的GitHub地址 以下是我几乎每行都加了注释的GitHub地址\nlcorolib.c注释地址\nlcorolib.c注释\n","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.coroutine/","summary":"thread即为线程,但是在lua中是没有线程的概念的,这个线程并不是真正意义上操作系统的线程,而更多的是一个能储存运行状态的数据结构,这个","title":"[Lua5.4.4源码].协程"},{"content":"函数原型 上面proto的大部分参数来源是lcode.c ,ldump.c,llex.c,lparser.c,lundumpc这几个文件赋予的\nlocvars在这里并不指实际的局部变量,实际的局部变量存在数据栈中,存的只是也写解析lua文件以后的一些数据\nupvalues 也不是指upvalues变量,而实际存储他们的位置在CClosure-\u0026gt;upvalue和LClosure-\u0026gt;upvals中\nnumparams表示函数有几个参数,is_vararg表示参数是否为可变参数列表,例如这个函数声明\nfunction f1(a1, a2, ...) ...... end 三个点…表示这是一个可变参数的函数.f1()在这里的numparams为2,并且is_vararg的值为1.\nmaxstacksize字段 编译过程计算得到代表本proto需用到的局部变量数量的最大值,从第一个型参开始计算(不包含不定参数...因为哪个没法知道确切的数量 实际调用时传给不定参数...的实参在L-\u0026gt;func----\u0026gt;L-\u0026gt;base之间,数量在OP_VARARG指令中已给出计算公式\n变量的查找 局部变量,全局变量,上值其实在编译期就知道结果了主要是通过下面singlevar和singlevaraux两个函数确定 我们可以通过这两个函数的分析,可以看出,在查找变量的方式如下\n总结\n局部变量存在数据栈中\n上值存在CClosure-\u0026gt;upvalue和LClosure-\u0026gt;upvals中\n全局变量存在_ENV中\n在Lua中,函数参数也是局部变量\n这里面还有一个lua5.4新增的新特性变量一个是TBC局部变量,还有一个是const局部变量\nconst局部变量\n从上面我们可以看到如果const类型的是只读数据,也就是赋值以后就确定下来了,不能在重新赋值\nlocal b \u0026lt;const\u0026gt; = 1 b = 2 我们从源码中可以看到有这样的函数check_readonly用来判断入股是const类型的变量,而且要进行赋值,那么我们就报\nattempt to assign to const variable这样的报错提示\n我们运行下上面的代码\n发现的确如我们预想的那样\n如果上述的代码,因为const类型变量是在编译时常量,不是指令类型的,所以我们也可以发现如果是下面这种类型的写法\nlocal b \u0026lt;const\u0026gt; = 1 c = b + 2 可以发现在lua在编译时就会直接把b替换成1,然后直接把表达式计算出来得到3直接付给c,这样做因为不是指令级别的,所以可以很大程度上的减少对寄存器的访问,所以如果发现自己的需求有大量的数值常量,比如游戏的配置表,就可以定义为const局部变量类型\n反编译看下字节码\n从上面我们可以看出并没有b变量的任何操作,然后再1号位置直接把结果3付给了_ENV.c 等价于_ENV.c=3\nclose变量\nclose变量To-be-closed Variables需要和close元方法结合使用，在变量超出作用域时，会调用变量的close元方法__close,close变量一般用于需要及时释放的资源的情况,多用这个其实也能减轻gc的负担\n举个栗子\nlocal t = {} setmetatable(t, {__close=function() print(\u0026#39;To-be-closed Variables is closed\u0026#39;) --接下来我们就可以在这个里面是否自己想要释放的资源 end}) local function func() local a \u0026lt;close\u0026gt; = t; end func() 通过如上图的源码的话,我们就可以调用__closed来释放对应资源了,当然如果你不写__closed元方法,lua也会给你相应的错误提示的\n尾调用 function f() … return g() end 因为调用g()后,f()中不再执行任何代码,所以不需要保留f()的调用栈信息,Lua做了这样的优化,称为尾调用消除,g()返回后,控制点直接返回到调用f()的地方,有点类似c语言的goto语句,这样做也能减少栈的空间\nlua函数种类 从lua的源码中我们可以看出lua一共分为3种\n宏 类型 注解 LUA_VLCL Lua闭包 用lua脚本写的函数.有上值,运行时需要闭包LClosure,函数原型Proto LUA_VLCF 轻量C函数 用C写,没有上值.运行时不须要闭包,函数原型lua_CFunction LUA_VCCL C语言闭包 用C写,有上值.运行时需要闭包CClosure,函数原型lua_CFunction 闭包 C闭包 Lua在执行到fucntion ... end表达式或者c层调用lua_pushcclosure\n会创建一个函数对象,内存布局如下\nlua闭包 lua闭包和C闭包不太一样它的动态内容里面不是Tvalue类型而是UpVal类型,为啥要这样类型呢,主要还是因为Lua层的代码需要更多的信息处理,比如不同函数层次的调用,函数return之后上值的处理,UpVal还提供还原函数和子函数之间共享数据的方法\n内存布局如下\nupvalue 提供一种闭包之间共享数据的方法\nUpVal有两种状态open状态 和close状态\nopen状态:还在lua函数的block中,所以是open状态,并且放入L-\u0026gt;openupval链表当中,同时TValue *v指针指向数据栈数据的位置 close状态:退出lua函数的block后,变成了close状态,并且放入L-\u0026gt;openupval链表当中,同时TValue *v指针指向TValue value成员,也就是存放close值得地方 闭包的创建 从上我们可以看出当虚拟机执行OP_CLOSURE指令的时候,就进入luaF_newLclosure函数创建一个lua闭包,并根据proto-\u0026gt;sizeupvalues数量对上值进行填充,这里有个注意点,就是上值的填充会根据instack标识来判断是直接从上值列表进行赋值,还是需要通过luaF_findupval来从L-\u0026gt;openupval列表中查找上值,找不到创建一个新的upval挂载入虚拟机openupval\ninstack指明这个upvalue会存在哪里,有两种情况要考虑：\nuv如果是上一层函数的局部变量,且这个上层函数还在活动中,那么该局部变量一定还在上层函数的栈中.此时,instack为1,表明它在栈中,idx指定在栈中的索引相对于上层函数的栈基址.\nuv如果是上一层函数之外的局部变量,就像下面代码这样：\nlocal x = 1 local function func() local function innerfunc() return x + 1 end end x在上两层函数之外声明,Lua是这样解决这个问题的：首先func会把x当成upvalue记录下来,然后innerfunc再从func的upvalue数组寻找.所以这种情况下,instack为0,则idx表示上层函数uv列表的索引.\n闭包的关闭 当函数执行完毕会调用luaF_close\n其实这里可以发现函数没有关闭时,引用的内存还是openupval上,关闭后就重新赋值了一份,这个时候upval就不是共享的了,每个闭包一份了\n因为有upval的存在这个也是因为lua比较难正确性热更新的其中一个原因\nupvalue的3中情况 upvalue不共享情况 function　f1(n) --　函数参数也是局部变量 local　function　f2() print(n)　--　引用外包函数的局部变量 end return　f2 end g1　=　f1(1979) g1()　--　打印出1979 g2　=　f1(500) g2()　--　打印出500 这种情况其实就是因为f1在退出自己的block的时候重新赋值了一份,这个时候upval就不是共享的了,而是单独存在了一份,这也说明了一个问题,当你在次调用f1的时候,它因为不是共享所以不会在利用前一次调用f1时候生成的upval\n一个函数创建的闭包共享一份upvalue function　Create(n) local　function　foo1() print(n) end local　function　foo2() n　=　n　+　10 end return　foo1,foo2 end f1,f2　=　Create(1979)--创建闭包 f1()　--　打印1979 f2() f1()　--　打印1989 f2() f1()　--　打印1999 f1,f2闭包共享create函数的局部变量n\n同一闭包创建的其他的闭包共享一份upvalue function　Test(n) local　function　foo() local　function　inner1() print(n) end local　function　inner2() n　=　n　+　10 end return　inner1,inner2 end return　foo end t　=　Test(1979)--创建闭包（共享一份upvalue） f1,f2　=　t()--创建闭包 f1()　--　打印1979 f2() f1()　--　打印1989 g1,g2　=　t() g1()　--　打印1989 g2() g1()　--　打印1999 f1()　--　打印1999 g1和g2与f1和f2共享同一个upvalue.因为g1和g2与f1和f2都是同一个闭包t 创建的,所以它们引用的upvalue (变量n)实际也是同一个变量,而它们的upvalue引用都会指向同一个地方\n更详细的注释请去我的GitHub地址 以下是我几乎每行都加了注释的GitHub地址\nlfunc.h注释地址\nlfunch注释\nlfunc.c注释地址\nlfunc.c注释\n","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.function/","summary":"函数原型 上面proto的大部分参数来源是lcode.c ,ldump.c,llex.c,lparser.c,lundumpc这几个文件赋予的 l","title":"[Lua5.4.4源码].函数"},{"content":"Table的结构 首先上一张示意图\n从上图中我们可以了解到Table是由数组和hash混合而成\nTable的数组部分的key和hash部分的key都不能为nil\nTable的下标是从1开始\n数组部分实际按2的指数增长\n不同key类型放数组段,还是hash段\n数字key一般放数组段 没有初始化的key都为nil,所以哪个段都放不了 在重新分配空间大小的时候,只有利用率超过50%的数组元素进入数组,否则进去hash 0和负数放在hash段 注意在使用长度操作符#对数组其长度时，数组不应该包含nil值，否则很容易出错。\nprint(#{1,nil}) --1 print(#{1,nil,1}) --3 print(#{1,nil,1,nil}) --1 尽量可以提前分配大小,明确知道table的内容或者知道大小的，可以先预先初始化. 例如 不建议:local tb = {}; tb[1] = 1; tb[2] = 2; tb[3] = 3因为这样会多次触发rehash 建议:local tb = {nil, nil, nil}或者local tb = {1, 2, 3}后面再作赋值操作 对应的源码数据结构表如下\n哈希表部分 hash表中式通过Node结构来组成闭散列的数组\n用lsizenode字段来进行hash表的扩容\n用 1 \u0026lt;\u0026lt; lsizenode来求实际的size,比如现在是2^3这样的情况,那么3就是现在lsizenode的大小\n用 int next字段来把冲突的节点连起来,这样哈希表就会非常的紧凑,只需要一块连续的内存就可以了,如下图一样\n源码定义如下\n假设lua代码是这样定义的\nlocal t = {} t[\u0026#34;xxx\u0026#34;] = 2222; 那么 上面例子中\nNodeKey的部分为\u0026quot;xxx\u0026quot;\nlu_byte key_tt是短字符串类型\nValue key_val是\u0026quot;xxx\u0026quot;\nTValuefields-\u0026gt; tt_是整型\nTValuefields-\u0026gt; value_是2222\nTValue i_va里面的tt_为整型\nTValue i_val里面的value_为2222\nTValue i_val指向了NodeKey里面的TValuefields,这么做只是为了方便后面进行读取\nhash解决冲突时候的两种方法 闭散列 (即开放地址法):当发生哈希冲突时，如果该哈希表还没有被填满，那么就把该元素放到哈希表的下一个空闲的位置\n优点:简单 易懂,当hash表已经没有空格的时候，lua就会resize这个hash表。这样做的好处主要是不用动态申请内存空间，hash表初始化的时候有多少内存空间就用多少，不够就resize这个hash表。\n缺点:一旦发生了哈希冲突，所有的冲突连接在一起，很容易产生数据堆积。即不同的数据占用可以利用的位置，就使得寻找其余数据的位置需要进行多次比较，就会导致查找的效率降低。\n通过前面的知识点学习,其实可以看出lua中Table的hash部分中用的就是这种闭散列的方式来解决冲突的\n开散列 开散列法(哈希桶):又名链地址法，先用哈希函数计算每个数据的散列地址，把具有相同地址的元素归于同一个集合之中，把该集合处理为一个链表，链表的头节点存储于哈希表之中。\n优点:解决了数据溢出的问题\n缺点:需要增加链接的指针，增加存储开销\n通过前面的知识点学习,其实可以看出lua的短字符串中用的就是这种开散列的方式来解决冲突的\n找free节点 主要是通过getfreepos来从后往前找第一个free的节点\n创建hash表 主要是通过下面的setnodevector函数生成\nsetnodevector(L, t, 0)会创建空表 hash表利用指向一个虚拟节点dummynode,并将lastfree指向NULL来代表这个Table的hash是个空表，图示如下\n2.setnodevector(L, t, 3)会创建一个 size为3, lsizenode为2,hash表的大小为1 \u0026lt;\u0026lt;lsizenode为2^2=4\nlsizenode 在setnodevector函数示意图上的1号位置通过luaO_ceillog2函数求出来等于2\nhash表的size由2号位置求出也就是1 \u0026lt;\u0026lt;lsizenode为2^2=4 lastfree指向hash表最大size位置(这不是一个合法位置)最后图示如下\nhash表的插入 hash表的插入主要通过luaH_newkey 实现,源码如下\n从上面源码中我们可以看出将一个key插入哈希表有3中情况\n首先通过key计算出主位置,也就是这次通过hashmod我应该放入hash表的那个位置\n主位置位空节点的情况 假设初始情况如上图,这个时候要插入个key:1 通过以下2个宏求余也就是求得hash位置值为1%4 = 1\n因为为空,这个时候只需要直接把key:1放入hash表就可以了\n如果主位置不是空,那么就有两种情况 这个时候就应该当前主位置上面的key是不是其他位置经过hash碰撞放到这里来的,我们通过\n计算得到othern位置\n比如说上图的key:9 按取余 9%4=1应该是1号位置,而不是现在3号下标位置,所以这个时候othern就是1\n如果该othern结点就是主位置结点 假设初始情况是这样\n要插入新的节点key:9 通过计算得到下面数据\nmp:9%4=1 表示现在key:9应该放到1号位置\nothern:因为现在1号位置上放的是key:1所以1%4=1 表示othern结点还是主位置结点\n所以会执行如下源码\n把key:9插入1号位置以后,会和key:1产生冲突,造成如下图所示的情况\n做完这步以后在把key:1下标Node里面的next指向key:9的下标位置\n,最后把前面找到free位置,设置成key:9如下图所示\n如果该othern结点不是主位置结点 比如如图上面的情况\n首先通过getfreepos找到了free位置\nfree位置:2号下标位置\n假如这个时候插入key:11,计算key:11的mp位置,通过求余11%4得到3号位置,也就是key:9的位置,产生冲突\nmp:11%4=3\n计算key:9的othern位置\nothern:9%4=1\n通过上面的结果判断othern!=mp也就是该othern结点不是主位置结点,所以我们需要如下操作\n执行的源码如下\n顺着key:9的othern的一路找到mp的前置节点\n本来前置节点指向的是mp的位置,现在改为指向新找的空位free\n将mp存到free\n处理mp的后继节点\n将mp位置腾出来的,原本属于我的位置的value域填入nil值(擦除残留的值)\n把key的值复制给mp节点,并返回节点的指针\n数组部分 计算出大于且最接近alimit的2的n次方长度 所以数组部分实际按2的指数增长\nTable的扩容 当我们在一直插入值到hash表的时候,如果通过getfreepos函数找不到free节点了,那么这个时候我们就需要调用rehash函数进行扩容了\n首先我们来看看rehash的源码实现\n具体过程如下:\n计算数组部分key的数量\n具体是通过numusearray函数进行统计的,数组部分实际按2的指数增长，新增部分为一个切片，按照2^(i-1) \u0026lt; k \u0026lt;= 2^i 规则进行切片,例如1，2，4，8增长，切片分为1~2,3~4,5~8四片\n遍历每一个切片,统计每个不为nil的下标，直到统计次数大于array的长度(2的n次方)，同时记录每一个切片的不为空的数量,并把结果存到nums中,然后把数组部分的数量进行返回\n计算hash部分key的数量 具体统计通过numusehash函数,这个函数具体通过两部实现统计\n统计hash部分非nil的Key值总数 在遍历hash部分的时候,如果发现key的类型为整型,那么就把这个key值统计到nums中,做数组部分切片统计 根据数组利用率需要达到50%以上才能放到数组部分规则,从新划分数组和hash部分大小 这一部分是通过函数computesizes做到的.通过源码可以看到这里是通过遍历nums的没一个切片,统计下这个切片里面的数量是不是超过了50%,如果超过了,那么就认为可以放到数组部分,反之就应该放hash部分\n调用luaH_resize函数进行Table内存分布调整 这部分很简单,主要做的事情就是根据第3步得到的数组大小和hash大小,进行扩容和伸缩,以及重新分配内存\nTable的迭代访问 迭代访问是通过luaH_next实现的\n从源码中可以看到如果Table里面有很多value的值为nil它并不会停下来直到找到下一个不为nil的元素位置 可以看到luaH_next遍历的顺序是先遍历数组部分,在遍历hash部分 从上面的特征可以看出如果一个Table前面有很多的nil值,而非nil的值在Table的最后几位,就会造成遍历效果非常慢,毕竟他是先先遍历数组部分,在遍历hash部分 #求长度 lua中的#求长度其实就是用luaH_getn求得\n取长度操作符写作一元操作 #。 字符串的长度是它的字节数（就是以一个字符一个字节计算的字符串长度）\ntable的长度被定义成一个整数下标 n 。 它满足 t[n] 不是 nil 而 t[n+1] 为 nil, 此外，如果 t[1] 为 nil ，n 就可能是零。 对于常规的数组，里面从 1 到 n 放着一些非空的值的时候， 它的长度就精确的为 n，即最后一个值的下标。 如果数组有一个空洞（就是说，nil 值被夹在非空值之间）， 那么 #t 可能是指向任何一个是 nil值的前一个位置的下标 (就是说，任何一个nil值都有可能被当成数组的结束)\n为了提高查找效率，lua源码并没有进行遍历查找，而是通过二分查找\n如果table数组部分的最后一个元素为nil，那么将在数组部分进行二分查找\n针对table的数组部分的，但若哈希部分的key为整数且刚好连着数组部分，则也会一并参与计算\n最后一种情况是数组部分中没有元素 或如果table数组部分的最后一个元素为nil，那么将在hash部分进行二分查找\n所以注意在使用长度操作符#对数组其长度时，数组不应该包含nil值，否则很容易出错,这是个不确定的因素,不要有侥幸,如果一个元素要删除，直接remove，不要用nil去代替\nprint(#{1,nil}) --1 print(#{1,nil,1}) --3 print(#{1,nil,1,nil}) --1 luaH_get函数流程 luaH_set函数流程 更详细的注释请去我的GitHub地址 以下是我几乎每行都加了注释的GitHub地址\nltable.h注释地址\nltable.h注释\nltable.c注释地址\nltable.c注释\n","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.table/","summary":"Table的结构 首先上一张示意图 从上图中我们可以了解到Table是由数组和hash混合而成 Table的数组部分的key和hash部分的key","title":"[Lua5.4.4源码].表"},{"content":"LUA_TNIL nil表示的意思就是无效值 如果赋值为nil,等价于就是删除,到时候GC判断没有任何关联,就会把这个值回收 LUA_TNIL 除了定义对外的LUA_VNIL nil类型,还会分为{LUA_VEMPTY:,LUA_VABSTKEY}这两个东西不对外,用于C层逻辑的判断 LUA_VEMPTY: 空槽位, C层用来占位和清除逻辑 LUA_VABSTKEY:C层用来查找Key时候找不到的时候返回类型 LUA_TBOOLEAN 在lua里面0也是真值,这点和其他语言比如C/C++等等语言不一样,要注意\n0:真\nnil:假\nfalse:假\n其他值:真\nLUA_TLIGHTUSERDATA 和 LUA_TUSERDATA 区别 LUA_TUSERDATA LUA_TLIGHTUSERDATA 作用 通常用来表示C中的结构体一小段固定的内存区域 通常用来表示C中的指针(void *) 内存管理 由Lua的垃圾回收器管理 使用者需要关心其内存 元表 有独立的元表 没有独立的元表 创建 void *lua_newuserdata(lua_State *L, size_t size) lua_pushlightuserdata(lua_State *L, void *p); 具体区别其实我们在lua源码中也能找到区别\n我们在源码中找到了这段代码可以看到这里根据类型返回了1和2两个不同的地址\n首先我们来说LUA_TUSERDATA\nLUA_TUSERDATA 1处我们返回的是一个宏,可以看到其实是返回的是一块实实在在的内存地址\n///计算用户数据的内存区域的偏移量 // offsetof是结构成员相对于结构开头的字节偏移量 #define udatamemoffset(nuv) \\ ((nuv) == 0 ? offsetof(Udata0, bindata) \\ : offsetof(Udata, uv) + (sizeof(UValue) * (nuv))) #define getudatamem(u)\t(cast_charp(u) + udatamemoffset((u)-\u0026gt;nuvalue)) //返回内存块的地址 从下图中我们也能看到LUA_TUSERDATA里面有 独立元表\nLUA_TUSERDATA实现例子 //c文件 //#include \u0026lt;string.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; } #include \u0026lt;iostream\u0026gt; using namespace std; static struct StudentTag { char *strName; // 学生姓名 char *strNum; // 学号 int iSex; // 学生性别 int iAge; // 学生年龄 }T; static int Student(lua_State *L) { size_t iBytes = sizeof(struct StudentTag); struct StudentTag *pStudent; pStudent = (struct StudentTag *)lua_newuserdata(L, iBytes); //设置元表 luaL_getmetatable(L, \u0026#34;Student\u0026#34;); lua_setmetatable(L, -2); //lua_pushnumber(L, 123); return 1; // 新的userdata已经在栈上了 } static int GetName(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); lua_pushstring(L, pStudent-\u0026gt;strName); return 1; } static int SetName(lua_State *L) { // 第一个参数是userdata struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); // 第二个参数是一个字符串 const char *pName = luaL_checkstring(L, 2); luaL_argcheck(L, pName != NULL \u0026amp;\u0026amp; pName != \u0026#34;\u0026#34;, 2, \u0026#34;Wrong Parameter\u0026#34;); pStudent-\u0026gt;strName =(char*) pName; return 0; } static int GetAge(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); lua_pushinteger(L, pStudent-\u0026gt;iAge); return 1; } static int SetAge(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); int iAge = luaL_checkinteger(L, 2); luaL_argcheck(L, iAge \u0026gt;= 6 \u0026amp;\u0026amp; iAge \u0026lt;= 100, 2, \u0026#34;Wrong Parameter\u0026#34;); pStudent-\u0026gt;iAge = iAge; return 0; } static int GetSex(lua_State *L) { // 这里由你来补充 return 1; } static int SetSex(lua_State *L) { // 这里由你来补充 return 0; } static int GetNum(lua_State *L) { // 这里由你来补充 return 1; } static int SetNum(lua_State *L) { // 这里由你来补充 return 0; } static luaL_Reg arrayFunc_meta[] = { { \u0026#34;getName\u0026#34;, GetName }, { \u0026#34;setName\u0026#34;, SetName }, { \u0026#34;getAge\u0026#34;, GetAge }, { \u0026#34;setAge\u0026#34;, SetAge }, { \u0026#34;getSex\u0026#34;, GetSex }, { \u0026#34;setSex\u0026#34;, SetSex }, { \u0026#34;getNum\u0026#34;, GetNum }, { \u0026#34;setNum\u0026#34;, SetNum }, { NULL, NULL } }; static luaL_Reg arrayFunc[] = { { \u0026#34;new\u0026#34;, Student}, { NULL, NULL } }; extern \u0026#34;C\u0026#34; _declspec(dllexport) int luaopen_mytestlib(lua_State *L) { // 创建一个新的元表 luaL_newmetatable(L, \u0026#34;Student\u0026#34;); // 元表.__index = 元表 lua_pushvalue(L, -1); lua_setfield(L, -2, \u0026#34;__index\u0026#34;); luaL_setfuncs(L, arrayFunc_meta, 0); luaL_newlib(L, arrayFunc); lua_pushvalue(L, -1); lua_setglobal(L, \u0026#34;Sdudent\u0026#34;); /* the module name */ return 1; } -- lua 文件 require \u0026#34;mytestlib\u0026#34; local objStudent = Sdudent.new() objStudent:setName(\u0026#34;果冻\u0026#34;) local strName = objStudent:getName() print(strName ) for k,v in pairs(getmetatable(objStudent)) do print(tostring(k),tostring(v)) end LUA_TLIGHTUSERDATA 2处我们返回的也是个宏\n#define pvalue(o)\tcheck_exp(ttislightuserdata(o), val_(o).p) //获取light userdata的指针 进一步追踪我们可以看到p指针指向的是这个结构体,里面并没有元表相关的实现,所以后面元表相关的处理都得我们自己处理\n体外话为什么有时候用CJSON去反序列化的时候能看到打印table里面的值居然是null 比如这样的结果\n{\u0026#34;key1\u0026#34;:\u0026#34;value\u0026#34;,\u0026#34;key\u0026#34;:null,\u0026#34;key2\u0026#34;:\u0026#34;value2\u0026#34;} 首先看看lua_pushlightuserdata实现\n在看看cjson.so的实现\nlua_newtable(L); lua_pushlightuserdata(L, NULL); lua_setfield(L, -2, \u0026#34;null\u0026#34;); 我们进入lua_pushlightuserdata(L, NULL); 然后看到了 setpvalue(L-\u0026gt;top, p)的调用\n这样在实际调用时, setpvalue(L-\u0026gt;top, p) 相当于 void *p = NULL 最后是被封装到table变量里返回的\n这个点需要注意很容易造成bug\nLUA_TLIGHTUSERDATA实现例子 //C文件 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; extern \u0026#34;C\u0026#34; { #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; } typedef struct { int x; int y; int z; }TData; static int getAttribute(lua_State* L) { TData *data = (TData*)lua_touserdata(L, 1); std::string attribute = luaL_checkstring(L, 2); int result = 0; if (attribute == \u0026#34;x\u0026#34;) { result = data-\u0026gt;x; } else if (attribute == \u0026#34;y\u0026#34;) { result = data-\u0026gt;y; } else { result = data-\u0026gt;z; } lua_pushnumber(L, result); return 1; } static luaL_Reg dataLib[] = { { \u0026#34;__index\u0026#34;, getAttribute }, { NULL, NULL } }; void getMetaTable(lua_State* L, luaL_Reg* methods) { lua_pushlightuserdata(L, methods); lua_gettable(L, LUA_REGISTRYINDEX); if (lua_isnil(L, -1)) { /* not found */ lua_pop(L, 1); lua_newtable(L); luaL_setfuncs(L, methods, 0); lua_pushlightuserdata(L, methods); lua_pushvalue(L, -2); lua_settable(L, LUA_REGISTRYINDEX); } } int main() { const char* filename = \u0026#34;test.lua\u0026#34;; lua_State *lua = luaL_newstate(); if (lua == NULL) { fprintf(stderr, \u0026#34;open lua failed\u0026#34;); return -1; } luaL_openlibs(lua); TData input = { 123, 231, 321 }; lua_pushlightuserdata(lua, \u0026amp;input); getMetaTable(lua, dataLib); lua_setmetatable(lua, -2); lua_setglobal(lua, \u0026#34;input\u0026#34;); if (luaL_dofile(lua, filename)) { //luaL_error(lua, \u0026#34;load file %s failed\u0026#34;, filename); } lua_getglobal(lua, \u0026#34;data\u0026#34;); int output = lua_tointeger(lua, -1); std::cout \u0026lt;\u0026lt; output \u0026lt;\u0026lt; std::endl; return 0; } --lua文件 data = input.x; print(data) LUA_TNUMBER lua5.3以后已经把这个数值类型分为了2中类型\nLUA_VNUMINT 整数类型 其实就是c中的longlong,占用8个字节 LUA_VNUMFLT 浮点类型 其实就是c中的double,占用8个字节 对应的源码如下\nLUA_TSTRING lua5.4将string分为了两种\nLUA_VSHRSTR:短字符串\n小于等于40字节的 hash值是在创建时就计算出来的 LUA_VLNGSTR 长字符串\n大于40字节的就是长字符串 真正需要它的hash值时，才会手动调用luaS_hashlongstr函数生成该值,lua内部现在只有在把长串作为table的key时，才会去计算它 字符串结构 存储位置 短字符串 相同hash字符串存储在 stringtable strt 链表结构上 一般短字符串会使用这种方式存储\n长字符串 因为长字符串是惰性生成的，只有在需要hash值得时候才会去创建,所以不会想短字符串一样存在global_State-\u0026gt;strt里面的,而是真正生成一片Tstring内存空间,所以相同的长字符串会有不同的内存空间副本存储,这点需要特别注意\n缓存 为了提高查找命中率,lua作者还使用hashMap这种方式来提高命中率\n下图中N是数组行，M是数组列\ni的下标值通过unsigned int i = point2uint(str) % STRCACHE_N求得\nj的最大值固定就是下面的宏函数 STRCACHE_M 2\n鉴于篇幅长度,后面会专门出一篇文章详细的讲解lua的string里里外外\nLUA_TTABLE 表 lua 的table是个很神奇的结构,他是hash,数组的混合体,通过table可以很方便的实现模块,元表,环境,面向对象,stl,等等功能\ntable的源码结构\n结构示意图\n详细解释,会在单独出一篇文章\nLUA_TTHREAD thread即为线程,但是在lua中是没有线程的概念的，这个线程并不是真正意义上操作系统的线程,而更多的是一个能储存运行状态的数据结构,这个结构更多的是给协程**coroutine**使用的\n线程和协程的区别 线程消耗操作系统资源，协程可以靠编译语言实现，因此称为用户态线程量级更轻 线程并行，协程并发 线程同步，协程异步 线程抢占式，协程非抢占式，需要手动切换 线程上千，协程上万 线程切换需要上下文切换，协程切换不需要上下文切换，只在用户态进行切换 源码结构\n/// @brief Lua 主线程栈 数据结构 ///作用：管理整个栈和当前函数使用的栈的情况，最主要的功能就是函数调用以及和c的通信 struct lua_State { CommonHeader; lu_byte status;//当前状态机的状态,LUA_YIELD和LUA_OK为lua_State状态机的状态,这两个状态和协程有这对应关系,详见auxstatus函数 lu_byte allowhook;//是否允许hook unsigned short nci; /* number of items in \u0026#39;ci\u0026#39; list *///ci列表中的条目数，存储一共多少个CallInfo StkId top; /* first free slot in the stack *///指向栈的顶部，压入数据，都通过移动栈顶指针来实现 global_State *l_G;//全局状态机，维护全局字符串表、内存管理函数、gc等信息 CallInfo *ci; /* call info for current function *///当前运行函数信息 StkId stack_last; /* end of stack (last element + 1) *///执行lua stack最后一个空闲的slot StkId stack; /* stack base *///stack基地址 UpVal *openupval; /* list of open upvalues in this stack */// upvalues open状态时候的的链表 StkId tbclist; /* list of to-be-closed variables *///此堆栈中所有活动的将要关闭的变量的列表 GCObject *gclist;//GC列表 struct lua_State *twups; /* list of threads with open upvalues *///twups 链表 所有带有 open upvalue 的 thread 都会放到这个链表中，这样提供了一个方便的遍历 thread 的途径，并且排除掉了没有 open upvalue 的 thread struct lua_longjmp *errorJmp; /* current error recover point *///发生错误的长跳转位置，用于记录当函数发生错误时跳转出去的位置 CallInfo base_ci; /* CallInfo for first level (C calling Lua) *///指向函数调用栈的栈底 volatile lua_Hook hook;//用户注册的hook回调函数 ptrdiff_t errfunc; /* current error handling function (stack index) *///发生错误的回调函数 l_uint32 nCcalls; /* number of nested (non-yieldable | C) calls */// 当前C函数的调用的深度 int oldpc; /* last pc traced *///最后一次执行的指令的位置 int basehookcount;//用户设置的执行指令数（在hookmask=LUA_MASK_COUNT生效） int hookcount;//运行时，跑了多少条指令 volatile l_signalT hookmask;//支持那些hook能力 }; 详细解释,会在单独出一篇文章\n值对象结构 /// @brief 实际存储的值 // GCObject和其他不需要进行进行GC的数据放在一个联合体里面构成了Value类型 // lua5.3以后 number类型就有了两个类型float和int 也就是下面的 lua_Number n和 lua_Integer i typedef union Value { struct GCObject *gc; /* collectable objects */// 可回收的对象 /*下面都是不可回收类型*/ void *p; /* light userdata *///轻量级userdata lua_CFunction f; /* light C functions *///函数指针 例如（typedef int (*lua_CFunction)(lua_State *L)） lua_Integer i; /* integer numbers *///整型 c中的longlong，占用8个字节 lua_Number n; /* float numbers *///浮点类型 c中的double，占用8个字节 } Value; 变量 说明 GCObject gc 用于垃圾回收 主要是为了连接垃圾回收对象的互相引用关系 void *p 为c中传入的指针，由c 分配和释放 light userdata lua_CFunction f 表示C导出给lua的函数指针，typedef int (*lua_CFunction) (lua_State *L) lua_Integer i 表示整数类型，typedef long long lua_Integer lua_Number n 表示双精度浮点类型，typedef double lua_Number 非GC对象 从上面可以看到非GC的对象有4中\nlight userdata C函数 整型 浮点型 int b(lua 5.4数字分为整数和浮点，而i正好也可以用作bool,所以把这个给**删除**,和 lua_Integer i 结合到一起了) GC对象 union GCUnion { GCObject gc; /* common header */ struct TString ts;//字符串 struct Udata u;//用户数据 union Closure cl;//闭包 struct Table h;//表 struct Proto p;//函数原型:存放函数字节码信息 struct lua_State th; /* thread *///线程 struct UpVal upv;//上值 }; 从上面的union结构体可以看到GC对象有6中\n字符串 userdata closure 闭包 table lua 函数原型 lua 线程 (其实就是协程) lua上值 CommonHeader类型 #define CommonHeader\tstruct GCObject *next; lu_byte tt; lu_byte marked next 指针 指向下一个GC对象 tt GC对象的实际类型(比如上面6中GC对象) marked 标识GC的状态 TValuefields 类型 #define TValuefields Value value_; int tt_ Value：存储具体数据的值 tt_：表示这个值的类型，即所有的基础数据类型 ","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.type/","summary":"LUA_TNIL nil表示的意思就是无效值 如果赋值为nil,等价于就是删除,到时候GC判断没有任何关联,就会把这个值回收 LUA_TNIL 除了定义对外的LUA_VNIL n","title":"[Lua5.4.4源码].数据类型"},{"content":"TString内存结构 TString 的内存结构分为公共头和内容,所以其实我们的字符串真正存储的地方是 contents 里面的，因为是C语言，所以其实还会在后面添一个'\\0'\n求大小 从TString的内存结构我们可以看出真正变化大小的因素是contents 里面的内容,所以我们可以这么求\noffsetof(TString, contents) 相对于TString开始到contents的字节偏移量,其实也就是公共头的字节大小 (l) 内容大小 + 1 是因为屁股后面要添加一个'\\0' 所以大小等于 (offsetof(TString, contents) + ((l) + 1) * sizeof(char))\n类型 从上图的宏定义来说,lua5.4通过40个字节的分界线将string分为了两种\nLUA_VSHRSTR 短字符串 小于等于40字节的 hash值是在创建时就计算出来的 LUA_VLNGSTR 长字符串 大于40字节的就是长字符串 真正需要它的hash值时，才会手动调用luaS_hashlongstr函数生成该值,lua内部现在只有在把长串作为table的key时，才会去计算它 缓存 为了提高查找命中率,lua作者还使用hashMap这种方式来提高命中率\n下图中N是数组行，M是数组列\ni的下标值通过unsigned int i = point2uint(str) % STRCACHE_N求得\nj的最大值固定就是下面的宏函数 STRCACHE_M 2\n创建 短字符串创建 短字符串的hash桶结构数据都会存储在这个地方\n让我们进入stringtable结构可以发现如下情况\nTString **hash:指向一个hash的数组，hash数组里面存着一堆hash*一维指针指向一个hash桶链表，当通过\n有冲突的时候,如果在hash桶链表中没找到短字符串数据,那么就通过\n创建一个短字符串插入到hash桶的后面\n总体图示方式\n通过这样的方式短字符串就能高效重复利用,而且相同的短字符串在内存中也只有一份,在查找,删除,比较的时候短字符串的时候只需要调用下面的宏比较指针地址相同不相同就行了\n长字符串创建 上面是TString的数据结构,也是长字符串在内存中的存储结构\n通过分析下面的luaS_createlngstrobj和createstrobj函数\n通过上面两张图上红线的分析\n我们可以得出结论在每一次创建长字符串的时候,并不会想短字符串一样有所谓的hash桶链表,来处理重复的使用的问题,也就是说如果是两个相同的长字符串,那么内存中就会有两份内存存在,这块地方需要注意. 长字符串的hash值也不是在创建的时候就生成了,只是随机的给了一个seed种子值,具体在哪里创建的可以看下面的章节 创建流程图 hash值 短字符hash值得计算 从这3部流程我们可以看到luaS_newlstr-\u0026gt;internshrstr-\u0026gt;createstrobj中间并没有阻拦,就在创建的时候就把hash值给创建出来了\n短字符串hash表的扩容和缩小 创建时候的扩容 从这里可以看出如果可以hash扩容,那么就原来2的倍数增长\n分代gc时候的收缩 短字符串的重新计算哈希 当短字符串hash表在进行收缩和扩容的时候会重新计算哈希\n长字符串hash处理 从上面代码1-\u0026gt;2的步骤可以看出长字符串的hash值是在lua内部现在只有在把长串作为table的key时，才会去计算它\n比较 短字符串的比较 短字符串会放入字符串常量池中，因此短串在内存中总是只有一份，直接比较地址即可\n长字符串的比较 可以看到比较步骤如下\n先比较是不是同类型 是不是指向同一个对象(指针地址相等的话,那么就说明指向了同一个地址) 如果还不行,就在比较长度是否相等，如果长度相等,那么就利用字符串长度, 用memcmp比较内存内容是否相等 TString-\u0026gt;extra作用 长字符串extra作用 从上图中我们看到长字符串在设置hash值得时候会把这个字段设置成1\n短字符串extra作用 可以看到这个llex.c文件中luaX_init()函数中在创建保留字的时候会吧这个字段设置成1,其实也从侧面来说保留字不可能会大于40个字节\n更详细的注释请去我的GitHub地址 以下是我几乎每行都加了注释的GitHub地址\nlstring.h注释地址\nlstring.h注释\nlstring.c注释地址\nlstring.c注释\n","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.string/","summary":"TString内存结构 TString 的内存结构分为公共头和内容,所以其实我们的字符串真正存储的地方是 contents 里面的，因为是C语言，所以其实还会在后面添一个'\\","title":"[Lua5.4.4源码].字符串"},{"content":"lua简介 lua 很小\n将lua添加到应用程序不会让代码膨胀,也不会有很多的第三方库,繁琐的配置,很容易就能键入到你的应用程序当中\nLua 5.4.4的压缩包含源代码和文档，压缩值为353K，未压缩值为1.3M。源代码包含大约30000行c语言。在64位Linux下，用所有标准Lua库构建的Lua解释器占用281K, Lua库占用468K\nlua是可移植性\nlua以一个小包的形式发布,可以在所有具有标准c编译器的平台上开箱即用\nlua速度很快\nlua在经过不断的版本迭代现在lua5.4.4上应用分代GC和增量GC GC这块已经不是什么卡壳点,还有TBC局部变量,元表提供的GC元方法,等等一些新特性能够让你更好的优化自己项目的性能\nlua已经经过很多应用和游戏的验证\n比如魔兽世界,愤怒的小鸟,巴西数字电视的ginga中间件,还有skynet的actor方式的微服务框架,c++ + lua的moon框架\nskynet\nmoon\nlua 嵌入\nlua可以很方便的和c,c++ 语言进行嵌入,还用于Java c# Smalltalk Fortran Ada Erlang，甚至其他脚本语言(如Perl和Ruby)编写的程序\n下载 本人已经在GitHub上对lua作者的源码进行大部分注解,后面还会逐步继续完善\nlua-5.4.4-每行都加注释版本\nlua 源码结构 虚拟机运转的核心功能 文件 作用 lapi.c Lua API。实现大量的Lua C API（lua_ *函数） ldebug.c 调试接口 ldo.c 函数调用以及栈管理 lfunc.c 函数原型及闭包管理 lgc.c 垃圾回收 lmem.c 内存管理接口[luaM_realloc / luaM_growaux_] lobject.c 对象操作的一些函数。包括数据类型\u0026lt;-\u0026gt;字符串转换 lstate.c 状态机 管理全局信息,和状态机相关的逻辑 lstring.c 字符串池 ltable.c 表类型的相关操作。Lua表（哈希） ltm.c 标记方法。实现从对象访问元方法。 lvm.c 虚拟机。执行字节码（luaV_execute）。还公开了lapi.c使用的一些功能（例如luaV_concat） lzio.c 通用的缓冲输入流接口 内嵌库 文件 作用 lauxlib.c c库编写用到的辅助函数库 lbaselib.c lua基础库 lcorolib.c 协程库 lctype.c 标准库中ctype相关实现 ldblib.c Debug库 linit.c 内嵌库的初始化 liolib.c IO库 lmathlib.c 数学库 loadlib.c 动态扩展库管理 loslib.c OS库 lstrlib.c 字符串库 ltablib.c 表处理库 源代码解析以及预编译字节码 文件 作用 lcode.c Lua的代码生成器。由lparser.c使用 ldump.c 序列化预编译的Lua字节码 llex.c 词法分析器。由lparser.c使用 lparser.c 解析器 lundump.c 还原预编译的字节码 可执行的解析器，字节码编译器 文件 作用 lua.c Lua独立解释器 luac.c Lua编译器（将字节码保存到文件中；还列出字节码） ","permalink":"https://frog-game.github.io/posts/read/lua5.4.4.introduction/","summary":"lua简介 lua 很小 将lua添加到应用程序不会让代码膨胀,也不会有很多的第三方库,繁琐的配置,很容易就能键入到你的应用程序当中 Lua 5.4.4的压缩","title":"[Lua5.4.4源码].结构分析"},{"content":"思维导图 点击下载《汇编》.xmind\n","permalink":"https://frog-game.github.io/posts/read/huibianzognjie/","summary":"思维导图 点击下载《汇编》.xmind","title":"汇编总结"},{"content":"使用的HybridCLR版本,unity版本 XAsset打包过程[这个过程每个公司,每个项目都不一样,但是原理差不多,下面是我这里的步骤] HybridCLR打包过程 Xcode上的要完成的一些前提 IOS XCode下记得编译libil2cpp.a[马赛克是自己的一些个人信息,进行了涂抹不用关心]\n执行后就生成\n然后按下面步骤进行替换\n然后就可以愉快的打IOS包了 如果XCode有其他报错,就自己根据项目解决吧。这个就不截图了\n热更新流程 这一步要注意去git查看是否真的生成了需要的内容只有打勾的地方才说明生成成功了\n然后后面就可以用你手机去进行下载热更新补丁操作了因为我用的是xAsset所以直接复用的xasset的整体补丁下载流程\n","permalink":"https://frog-game.github.io/posts/life/hybridclr-ios-dabao/","summary":"使用的HybridCLR版本,unity版本 XAsset打包过程[这个过程每个公司,每个项目都不一样,但是原理差不多,下面是我这里的步骤] H","title":"HybridCLR IOS打包热更新"},{"content":"一些前提知识点 代码术语区别 IL:微软平台上的一门中间语言，我们常写的C#代码在编译器中都会自动转换成IL,中间语言是编译使用高级 .NET 语言编写的代码后获得的结果。 对使用其中一种语言编写的代码进行编译后，即可获得 IL 所生成的二进制代码\n托管代码：托管代码就是执行过程交由运行时管理的代码。 在这种情况下，相关的运行时称为公共语言运行时 (CLR)，不管使用的是哪种实现（例如 Mono、.NET Framework 或 .NET Core/.NET 5+）。 CLR 负责提取托管代码、将其编译成机器代码，然后执行它。 除此之外，运行时还提供多个重要服务，例如自动内存管理、安全边界、类型安全，把托管代码理解成上面的IL中间语言也行\n非托管代码：非托管代码（Unmanaged Code）是指直接编译成目标计算机的机器码，这些代码只能运行在编译出这些代码的计算机上，或者是其他相同处理器或者几乎一样处理器的计算机上。非托管代码不能享受公共语言运行库所提供的一些服务，例如内存管理、安全管理等。非托管代码（Unmanaged Code）不由CLR公共语言运行库执行，而是由操作系统直接执行的代码,如果非托管代码需要进行内存管理等服务，就必须显式地调用操作系统的接口，通常非托管代码调用Windows SDK所提供的API来实现内存管理。\n原生代码:native code是本地cpu的目标执行代码, 不是IL, 所以速度很快, 它的执行不依赖某个虚拟机或者解释器，编译后可直接依附操作系统运行，不需要经过虚拟机之类的东西\n程序集:程序集（Assembly）的文件负责封装中间语言，程序集中包含了描述所创建的方法、类以及属性的所有元数据\n编译器 c#编译器: 将c#编译为IL [C#----\u0026gt;CIL] Mono Runtime编译器:将IL转换成原生码，然后让Mono运行时去执行,这样其实也达到了c#跨平台的效果 平台编译 build\n编译GCC的平台\nhost\n运行GCC的平台\ntarget\nGCC编译产生的应用程序的运行平台\nnative compiler:三者全部相同（build = host = target）就是原生编译 我们在PC上装的Ubuntu或者Fedora里面带的GCC，就是native compiler cross compile:如果build = host，但是target跟前两者不同就是 交叉编译开发手机应用程序的编译器，通常运行在PC或Mac上，但是编译出来的程序无法直接在PC或Mac上执行 编译方式 即时编译[Just in time, JIT]: 就是在程序运行的时候把CIL的byte code 转成目标平台的原生码,也就是Mono Runtime编译器干的活 提前编译[Ahead of time,AOT]:程序运行前将exe或者dll里面的CIL的byte code部分转成目标平台的原生码,并且存储起来，好加快速度,但是程序中还是会有部分的CIL的byte code需要JIT编译 完全静态编译[Full ahead of time,Full-AOT]:就是将所有源码编译成目标平台所需要的原生码 IOS不支持JIT编译的原因 模拟一下JIT的过程 JIT这么好，那它是如何实现既生成新代码，又能运行新代码的呢？\n首先我们要知道生成的所谓机器码到底是神马东西。一行看上去只是处理几个数字的代码，蕴含着的就是机器码。\nunsigned char[] macCode = {0x48, 0x8b, 0x07}; macCode对应的汇编指令就是：\nmov (%rdi),%rax 其实可以看出机器码就是比特流，所以将它加载进内存并不困难。而问题是应该如何执行。\n好啦。下面我们就模拟一下执行新生成的机器码的过程。假设JIT已经为我们编译出了新的机器码，是一个求和函数的机器码：\n//求和函数 long add(long num) { return num + 1; } //对应的机器码 0x48, 0x83, 0xc0, 0x01, 0xc3 首先，动态的在内存上创建函数之前，我们需要在内存上分配空间。具体到模拟动态创建函数，其实就是将对应的机器码映射到内存空间中。这里我们使用c语言做实验，利用 mmap函数 来实现这一点。\n头文件： #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; 定义函数： void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offsize) 函数说明： mmap()用来将某个文件内容映射到内存中，对该内存区域的存取即是直接对该文件内容的读写。\n因为我们想要把已经是 比特流的“求和函数”在内存中创建出来，同时还要运行它。所以mmap有几个参数需要注意一下。\n代表映射区域的保护方式，有下列组合：\nPROT_EXEC 映射区域可被执行； PROT_READ 映射区域可被读取； PROT_WRITE 映射区域可被写入； #include\u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; //分配内存 void* create_space(size_t size) { void* ptr = mmap(0, size, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANON, -1, 0); return ptr; } 这样我们就获得了一块分配给我们存放代码的空间。下一步就是实现一个方法将机器码，也就是比特流拷贝到分配给我们的那块空间上去。使用 memcpy 即可。\n//在内存中创建函数 void copy_code_2_space(unsigned char* m) { unsigned char macCode[] = { 0x48, 0x83, 0xc0, 0x01, c3 }; memcpy(m, macCode, sizeof(macCode)); } 然后我们在写一个main函数来处理整个逻辑：\n#include\u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/mman.h\u0026gt; //分配内存 void* create_space(size_t size) { void* ptr = mmap(0, size, PROT_READ | PROT_WRITE | PROT_EXEC, MAP_PRIVATE | MAP_ANON, -1, 0); return ptr; } //在内存中创建函数 void copy_code_2_space(unsigned char* addr) { unsigned char macCode[] = { 0x48, 0x83, 0xc0, 0x01, 0xc3 }; memcpy(addr, macCode, sizeof(macCode)); } //main 声明一个函数指针TestFun用来指向我们的求和函数在内存中的地址 int main(int argc, char** argv) { const size_t SIZE = 1024; typedef long (*TestFun)(long); void* addr = create_space(SIZE); copy_code_2_space(addr); TestFun test = addr; int result = test(1); printf(\u0026#34;result = %d\\n\u0026#34;, result); return 0; } 编译运行一下看下结果：\n//编译 gcc testFun.c //运行 ./a.out 1 为什么iOS不能使用JIT？\nOK，到此为止。这个例子模拟了动态代码在内存上的生成，和之后的运行。似乎没有什么问题呀？可不知道各位是否忽略了一个前提？那就是我们为这块区域设置的保护模式可是：可读，可写，可执行的啊！如果没有内存可读写可执行的权限，我们的实验还能成功吗？\n让我们把create_space函数中的“可执行”PROT_EXEC权限去掉，看看结果会是怎样的一番景象。\n修改代码，同时将刚才生成的可执行文件a.out删除重新生成运行。\nrm a.out vim testFun.c gcc testFun.c ./a.out 1 结果。。。报错了！\n所以IOS并非把JIT禁止了，主要还是IOS封了内存（或者堆的[可执行权限]，变相的封锁了JIT编译方式\n值类型和引用类型 C# 中的类型一共分为两类，一类是值类型(Value Type)，一类是引用类型(Reference Type)。\n值类型包括结构体(struct)和枚举(enum)。 引用类型包括类(class)、接口(interface)、委托(delegate)、数组(array)等。\n常见的简单类型如short、int、long、float、double、byte、char等其本质上都是结构体，对应struct System.Int16、System.Int32、System.Int64、System.Single、System.Double、Syetem.Byte、System.Char，因此它们都是值类型。但string和object例外，它们本质上是类，对应class System.String和System.Object，所以它们是引用类型。\n值类型 值类型变量本身保存了该类型的全部数据，当声明一个值类型的变量时，该变量会被分配到栈(Stack)上。\n引用类型 引用类型变量本身保存的是位于堆(Heap)上的该类型的实例的内存地址，并不包含数据。当声明一个引用类型变量时，该变量会被分配到栈上。如果仅仅只是声明这样一个变量，由于在堆上还没有创建该类型的实例，因此，变量值为null，意思是不指向任何类型实例(堆上的对象)。对于变量的类型声明，用于限制此变量可以保存的类型。\n值传递和引用传递 C#中方法的参数传递默认的是值传递，引用传递和输出传递需要在参数类型前面对应加上ref、out限制符，由于输出传递和引用传递类似，这里只讨论引用传递。\n值传递参数是原变量的拷贝，值传递参数和原变量的内存地址不同，因此方法中对值传递参数的修改不会改变原变量。\n引用传递参数是原变量的指针，引用传递参数和原变量的内存地址相同，相应的方法中对引用传递参数的修改会改变原变量。\nHybridCLR菜单 IL2CPP 就是上面的2.1编译方式中的AOT提前编译\n分为下面两部分 AOT编译器 ​\t把IL中间语言转成CPP文件的作用\n运行时库 ​\t主要是做垃圾回收,线程文件的获取，还有对托管数据的原生代码进行修改\n为啥要转换成CPP 运行速度快,这个毋庸置疑 mono 为了跨平台，他是通过VM来实现的，也就是说有几个平台，就需要实现几个VM,这种方法耗时耗力,而且为了实现各个平台的支持和移植，势必要把代码进行修改，然后出现bug在进行修复，来来回回时间和精力花费不少，所以为啥不利用现成各个平台的C++编译器执行了,这也是IL2CPP的核心思想 虽然最后代码都变成的静态的C++但是内存管理这块还是需要遵循c#的标准和方式,这也是为什么最后还需要一个 IL2CPP VM的原因 这个时候VM做得主要还是GC的管理,线程的创建等等一些辅助服务性的工作 工作原理就直接上官网的图了 为什么IL2CPP不支持热更新 因为IL2CPP是一个纯静态的AOT运行时，然后不支持运行时加载DLL，所以是不支持热更新\n然后hybridclr扩充了IL2CPP的代码,使他从AOT运行方式变成了AOT+Interpreter的混合方式从而可以动态的加载dll实现热更新\n区别 原始IL指令集是基于栈的指令集\nHybridclr是基于寄存器指令\n两种方式各有优缺点，基于栈的指令集很明显可移植高，但是工作效率较低。而基于寄存器指令集寄存器由硬件直接提供，工作效率高，程序受硬件约束。\n基于栈的指令集和基于寄存器指令集区别 如对数字2-1的操作，基于栈和基于寄存器的区别\n基于栈的指令\niconst_1 //将减数1压入栈顶 iconst_2 //将被减数2压入栈顶 isub //将栈中最上面的两个元素（2和1）弹出来，执行2-1的操作，将2-1的结果1压入栈顶 istore_0 //将1放入局部变量表的第0个位置上。 基于寄存器\nmov eax,2 //将2放入寄存器， sub eax,1//后面跟一个参数1，在现有的寄存器上减去1，在把结果放回寄存器。 Hybridclr的原理 dll不过是元数据和代码的集合,aot与 热更新dll的区别只不过一个函数以aot代码方式执行，一个以解释方式执行,最后都会直接在虚拟机层面将aot和热更新dll统一对待\n为什么Hybridclr能做到如此统一和彻底，因为元数据不过是数据，不管aot还是热更新是没有本质区别的\n而托管代码执行，依赖的不过是代码和数据\nHybridclr分两个工程\nHybridclr工程进行了源码的编译解析，在这里可以理解成这个工程做得主要事情是解释器的工作,此解释器是在IL2CPP VM扩充的，不解的可以看下图\n第二个工程是il2cpp_plus,这个工程会把泛型方法、泛型数据类型、以及其他的一些支持添加到IL2CPP里面,也可以简单的理解成为主要是为了给IL2CPP扩展功能用的，从而能让他动态的加载DLL\n源码解析 Hybridclr工程 这个是代码工程结构\n阅读前提 ARM64:CPU的ARM架构 主流的手机/平板品牌，绝大数是采用ARM架构\nBoehmGC算法，unity底层托管堆使用的是BoehmGC算法是用的mark-sweep（标记-清扫）算法,具体和Java的gc算法类型,这块由于篇幅问题就不详细写了,太多内容一句话说不清楚,以后有时间整理一篇详细文章出来\nModule 是 .dll 或 .exe 类型的可移植可执行文件，这些文件由一个或多个类和接口组成\nAssembly 是程序集\nAssembly有main程序函数。module只能附属于程序集，程序集可以拥有多个。\nMetaData就是用System.reflection得到的方法，属性，参数等等，这些都是元数据\nMethodBody 方法主体，就是调用方法时执行的代码块，方法的主体语句必须放在花括号（即大括号 {}）中。\nIl2CppImage 这个结构体是程序集镜像,可以通过它来获取命名空间,class,方法,函数指针地址等等\ntypedef struct Il2CppImage { const char* name;//名字 const char *nameNoExt;//扩展名字 Il2CppAssembly* assembly;//程序集指针 TypeDefinitionIndex typeStart;//方法类型偏移位置开始 uint32_t typeCount;//方法总数 TypeDefinitionIndex exportedTypeStart;//导出类型偏移位置开始 uint32_t exportedTypeCount;//导出类型总数 CustomAttributeIndex customAttributeStart;//自定义属性偏移位置开始 uint32_t customAttributeCount;//自定义属性总数 MethodIndex entryPointIndex;//方法入口点索引 #ifdef __cplusplus mutable #endif Il2CppNameToTypeDefinitionIndexHashTable * nameToClassHashTable;//name对应的class的hashTable const Il2CppCodeGenModule* codeGenModule;//Module指针 uint32_t token;//通过他可以得到函数指针地址 uint8_t dynamic;//没看到使用,估计是用来验证是不是动态lib使用的 } Il2CppImage; 所有的metadata 解析都是遵循的下面规范ECMA-335 - Ecma International (ecma-international.org)\nCLI中大多数metadata被为几十种类型，每个类型的数据组织成一个table如下图,如果有缺失类型,请去ECMA-335查看\nPortable PDB tables .NET引入了一种新的符号文件（PDB）格式，主要用于跨平台\n早期PDB格式是为了C和C++设计的，发展了多年以来现在已经支持.NET了。不幸的是，这种格式一直以来都被认为是专有的，这就意味着它没有很好文档记录，而且只能使用Windows库读取，所以有了.NET Core，而且为了跨平台，于是开发了这个新的跨平台PDB库\n原始 MethodInfo\ntypedef struct MethodInfo { Il2CppMethodPointer methodPointer;//指向普通执行函数 InvokerMethod invoker_method;//指向反射执行函数 const char* name;//名字 Il2CppClass *klass;//函数所属类指针 const Il2CppType *return_type;//返回值类型 const ParameterInfo* parameters;//参数信息 union//generic instance method { const Il2CppRGCTXData* rgctx_data; /* is_inflated is true and is_generic is false, i.e. a generic instance method */ const Il2CppMethodDefinition* methodDefinition;//方法定义 }; union//uninflated generic method { const Il2CppGenericMethod* genericMethod; /* is_inflated is true */ const Il2CppGenericContainer* genericContainer; /* is_inflated is false and is_generic is true */ }; uint32_t token; uint16_t flags; uint16_t iflags; uint16_t slot; uint8_t parameters_count; uint8_t is_generic : 1; /* true if method is a generic method definition */ uint8_t is_inflated : 1; /* true if declaring_type is a generic instance or if method is a generic instance*/ uint8_t wrapper_type : 1; /* always zero (MONO_WRAPPER_NONE) needed for the debugger */ uint8_t is_marshaled_from_native : 1; /* a fake MethodInfo wrapping a native function pointer */ } MethodInfo; 改写后的MethodInfo\ntypedef struct MethodInfo { Il2CppMethodPointer methodPointer; InvokerMethod invoker_method; const char* name; Il2CppClass *klass; const Il2CppType *return_type; const ParameterInfo* parameters; union { const Il2CppRGCTXData* rgctx_data; /* is_inflated is true and is_generic is false, i.e. a generic instance method */ const Il2CppMethodDefinition* methodDefinition; const Il2CppMethodDefinition* methodMetadataHandle; }; /* note, when is_generic == true and is_inflated == true the method represents an uninflated generic method on an inflated type. */ union { const Il2CppGenericMethod* genericMethod; /* is_inflated is true */ const Il2CppGenericContainer* genericContainer; /* is_inflated is false and is_generic is true */ Il2CppMetadataGenericContainerHandle genericContainerHandle; /* is_inflated is false and is_generic is true */ Il2CppMethodPointer nativeFunction; /* if is_marshaled_from_native is true */ }; uint32_t token; uint16_t flags; uint16_t iflags; uint16_t slot; uint8_t parameters_count; uint8_t is_generic : 1; /* true if method is a generic method definition */ uint8_t is_inflated : 1; /* true if declaring_type is a generic instance or if method is a generic instance*/ uint8_t wrapper_type : 1; /* always zero (MONO_WRAPPER_NONE) needed for the debugger */ uint8_t is_marshaled_from_native : 1; /* a fake MethodInfo wrapping a native function pointer */ void* interpData; Il2CppMethodPointer methodPointerCallByInterp; Il2CppMethodPointer virtualMethodPointerCallByInterp; bool initInterpCallMethodPointer; bool isInterpterImpl; } MethodInfo; 实例方法（instance method）和 静态方法（static method）\n被static修饰的方法为静态方法，之外的方法为实例方法\nvoid staticMethodTest(){ //直接调用静态方法 Boss.work(); //创建实例 Boss boss = new Boss(); //调用实例方法 boss.programming(); } class Boss { String name; public void programming(){ System.out.println(\u0026#34;I am programming.\u0026#34;); } public static void work(){ System.out.println(\u0026#34;I am working.\u0026#34;); } } AOT和interpreter桥接过程 AOT加载补充元数据原理 为什么需要AOT补充元数据,简单的来讲主要是下面几点\nl2cpp是AOT运行时，它运行时使用的几乎所有（为什么不是全部？）类型都是编译期已经静态确定的。你在AOT中只实例化过List\u0026lt;int\u0026gt; 和 List\u0026lt;string\u0026gt;，在热更新代码中是不能使用类似 new List\u0026lt;float\u0026gt;() 这样的代码的。\n尽管il2cpp可以在内存中创建出List\u0026lt;float\u0026gt;类型的大多数元数据，但它无法创建出它的各个成员函数实现。 你可以通过反射获得typeof(List\u0026lt;float\u0026gt;)，却无法调用它的任何成员函数，包括构造函数。\n无法创建出AOT泛型类型的成员函数实现的本质原因是il2cpp在完成IL到c++代码的转换后，丢失了原始IL函数体信息， 导致无法根据泛型基类List\u0026lt;\u0026gt;的元数据实例化出List\u0026lt;float\u0026gt;的各个成员函数实现。\n泛型类，尤其是泛型容器List、Dictionary之类在代码中使用如此广泛，如果因为AOT限制，导致List之类的都不能运行，那游戏热更新的代码限制也太大了。幸运的是，HybridCLR使用两类技术彻底解决了这个问题：\n基于il2cpp的泛型共享技术[这个技术有局限性和缺陷] [官方用这个技术其实主要还是想用共享机制来减少包体的大小] [优点是节约代码大小，缺点是极大地伤害了泛型函数的性能]\n由于值类型不能泛型共享，泛型实例（类或函数）的泛型参数中如果出现值类型，这个泛型实例必须提前在AOT提前实例化。如果 你的泛型参数类型是热更新代码中定义的值类型，由于热更新类型显然不可能提前在AOT中泛型实例化，导致你在热更新代码 中无法使用 List\u0026lt;热更新值类型\u0026gt; 这样的代码，给开发带来极多的不便。\n基于补充元数据技术，这也是HybridCLR的专利技术[具体源码,原理如下图]\n下载 Hybridclr 工程 下面是我正在阅读的Hybridclr作者初始源码版本 git clone https://gitee.com/focus-creative-games/hybridclr.git -b main git reset --hard 0540b31aa739fd275d8cfcd861cb41568d4a982c 执行上面的命令就能下载到我正在阅读的指定的分支,指定的commit版本\n下面是我加上的对应的注释版本 git clone https://github.com/frog-game/hybridclr-0540b31aa739fd275d8cfcd861cb41568d4a982c.git 执行上面的命令就能下载到我加上的对应的注释版本\nil2cpp_plus工程 下面是我正在阅读的il2cpp_plus作者初始源码版本 git clone -b v2019-1.0.0-rc --depth=1 https://github.com/focus-creative-games/il2cpp_plus.git 执行上面的命令就能下载到我正在阅读的指定的tag版本\nIOS热更演示 ","permalink":"https://frog-game.github.io/posts/read/hybridclr-yuanmayuedu/","summary":"一些前提知识点 代码术语区别 IL:微软平台上的一门中间语言，我们常写的C#代码在编译器中都会自动转换成IL,中间语言是编译使用高级 .NET 语言编写的","title":"HybridCLR源码赏析"},{"content":"NTP授时原理 C1 客户端发送请求的时间 S2 服务器接收请求的时间 S3 包离开场景时候的时间 C4 客户端接到返回包时间 m_nNetDelay 网络延时 d = (S2 - C1) + (C4 - S3) m_nDiftime 服务器与客户端的时差 T = [(S2 - C1) + (S3 - C4)] / 2 m_nNetDelay 其实就是RTT 也就是往返时间 也可以这么求 C4 - C1 - (S3 - S2) protobuff包定义 message SceneClocksyncRequest { int64\toriginate_timestamp = 1;客户端发送请求的时间C1 } message SceneClocksyncRet { int64 originate_timestamp = 1;客户端发送请求的时间 C1 int64 receive_timestamp = 2;服务器接收请求的时间 S2 int64 scene_timestamp = 3;场景同步时间戳【不参与NPT计算】 int64 transmit_timestamp = 4;包离开场景时候的时间 S3 } 具体代码实现 -- 同步请求 local function SendClockSyncReqMsg() local sceneClocksyncRequest = { originate_timestamp = serviceCore.getClockRealtime() } serviceCore.send(m_channelID,\u0026#34;SceneClocksyncRequest\u0026#34;,sceneClocksyncRequest) end -- 同步反馈 function robotStateMachine.SceneClocksyncRet(proto) --proto.originate_timestamp C1 客户端发送请求的时间 --proto.receive_timestamp S2 服务器接收请求的时间 --proto.transmit_timestamp S3 包离开场景时候的时间 --destination_timestamp C4 客户端接到返回包时间 --m_nNetDelay 网络延时 d = (S2 - C1) + (C4 - S3) --m_nDiftime 服务器与客户端的时差 T = [(S2 - C1) + (S3 - C4)] / 2 --m_nNetDelay 其实就是RTT也就是往返时间 也可以这么求 C4 - C1 - (S3 - S2) local destination_timestamp = serviceCore.getClockRealtime() m_nNetDelay = (proto.receive_timestamp - proto.originate_timestamp) + ((destination_timestamp - proto.transmit_timestamp)) m_nDiftime = ((proto.receive_timestamp - proto.originate_timestamp) + (proto.transmit_timestamp - destination_timestamp) / 2) RTT = destination_timestamp - proto.originate_timestamp - (proto.transmit_timestamp - proto.receive_timestamp); end -- 真正算出来的同步时间 function GetServerTime() return serviceCore.getClockRealtime() + m_nNetDelay + m_nDiftime end ","permalink":"https://frog-game.github.io/posts/tech/ntp-shijian-tongbu/","summary":"NTP授时原理 C1 客户端发送请求的时间 S2 服务器接收请求的时间 S3 包离开场景时候的时间 C4 客户端接到返回包时间 m_nNetDelay 网络延时 d = (S2 - C1) + (C4 - S3) m_nDiftime 服务器与","title":"NTP时间同步"},{"content":"一些字段的解释 观察者：我可以观察到那些人。 被观察者：那些人能观察到自己。 #define WATCHER_MODE 0x01 观察者模式 #define MARKER_MODE 0x02 被观察者模式 灯塔相关[结构体] 1：灯塔区域结构\nstruct towerSpace_s { void (*callback)(void*pUserData,bool bAddTo,uint64_t watcher, uint64_t marker); -- 回调函数 void*\tpUserData; //用户信息 float\tfMin[2]; //最小位置 float\tfGridLength[3];//网格x y,z方向长度 float\tfMovefRange;//移动范围 int32_t\tiSplitThreshold;//拆分阈值 int32_t iMaxWidth; //最大宽度 int32_t iMaxHeight;//最大高度 int32_t* pGrids;//网格数据 tower_tt*\tpTowers;//灯塔数据 int32_t\tiTowerNext;//下一个灯塔id int32_t\tiTowerCapacity;//灯塔容量 aoiObj_tt* pSlotObj;//格子里面对象 int32_t\tiSlotIndex;//格子索引 int32_t iSlotCapacity;//格子容量 }; 2：灯塔信息结构\ntypedef struct tower_s { aoi_tree_tt watcher; //灯塔观察者[用来存储观察到的对象] aoi_tree_tt\tmarker;//灯塔被观察者 int32_t iMarkerCount;//被观察者数量 int32_t iFirstChildId;//第一个儿子节点索引 } tower_tt; 3：灯塔划分后的节点结构【四个儿子节点】\ntypedef struct aoiNode_s { RB_ENTRY(aoiNode_s) entry; //实体 int32_t\tiId; //id } aoiNode_tt; 4：灯塔里面对象结构\ntypedef struct aoiObj_s { int32_t\tiId; // id int32_t iMode; // 模式(MARKER_MODE:被观察者模式 WATCHER_MODE:观察模式) uint64_t uiMask;//掩码 uint64_t uiUserData; //用户数据 float\tfViewRadius; // 视野半径 float last[3]; //上一个xyz位置 float pos[3];//当前xyz位置 } aoiObj_tt; 灯塔AOI相关的一些操作函数 int32_t luaopen_laoi(lua_State *L) { #ifdef luaL_checkversion luaL_checkversion(L); #endif registerTowerSpaceL(L); luaL_Reg lualib_funcs[] = { {\u0026#34;createAoiSpace\u0026#34;,\tlcreateAoiSpace},//创建aoi区域 {NULL, NULL} }; luaL_newlib(L, lualib_funcs); return 1; } int32_t registerTowerSpaceL(struct lua_State *L) { luaL_newmetatable(L, \u0026#34;towerSpace\u0026#34;); lua_pushvalue(L, -1); lua_setfield(L, -2, \u0026#34;__index\u0026#34;); struct luaL_Reg lua_towerSpaceFuncs[] = { {\u0026#34;setCallback\u0026#34;,\tlaoi_setCallback}, //设置回调函数 {\u0026#34;addObj\u0026#34;,\tlaoi_addObj},//增加一个实体对象 {\u0026#34;removeObj\u0026#34;,\tlaoi_removeObj},//移除一个实体对象 {\u0026#34;updateObjMask\u0026#34;,\tlaoi_updateObjMask},//更新对象的mask[0x01:观察者 0x02:被观察者] {\u0026#34;updateObjPos\u0026#34;,\tlaoi_updateObjPos},//更新对象的pos {\u0026#34;addObjWatcher\u0026#34;,\tlaoi_addObjWatcher},//增加对象到相应的观察容器 {\u0026#34;removeObjWatcher\u0026#34;,laoi_removeObjWatcher},//从相应的观察容器移除对象 {\u0026#34;addObjMarker\u0026#34;,\tlaoi_addObjMarker},//增加对象到被观察者 {\u0026#34;removeObjMarker\u0026#34;,\tlaoi_removeObjMarker},//移除对象到被观察者 {\u0026#34;__gc\u0026#34;, laoi_towerSpace_gc},//此区域进行GC回收 {NULL, NULL} }; luaL_setfuncs(L, lua_towerSpaceFuncs, 0); return 1; } [四叉树]lod示意图 黑色大框是AOI的区域大小 每个正方形块上面都有一个灯塔 暂时定的最多分裂3层 黑色的原点是场景内的实体 灯塔AOI一些关键函数[具体代码在frog-game-server框架] 1. 更新观察者集合\ninline static void changeAoiObjWatcher(towerSpace_tt* pTowerSpace,aoiObj_tt* pObj) { float bmin[3]; float bmax[3]; bmin[0] = pObj-\u0026gt;last[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;last[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;last[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;last[2] + pObj-\u0026gt;fViewRadius; int32_t minxLast = 0; int32_t minyLast = 0; int32_t maxxLast = 0; int32_t maxyLast = 0; calcGridLodLoc(pTowerSpace, 2,bmin, \u0026amp;minxLast, \u0026amp;minyLast); calcGridLodLoc(pTowerSpace, 2,bmax, \u0026amp;maxxLast, \u0026amp;maxyLast); minxLast = minxLast \u0026gt; 0 ? minxLast : 0; minyLast = minyLast \u0026gt; 0 ? minyLast : 0; maxxLast = maxxLast \u0026lt; pTowerSpace-\u0026gt;iMaxWidth * 4 ? maxxLast : pTowerSpace-\u0026gt;iMaxWidth*4 - 1; maxyLast = maxyLast \u0026lt; pTowerSpace-\u0026gt;iMaxHeight * 4 ? maxyLast : pTowerSpace-\u0026gt;iMaxHeight*4 - 1; bmin[0] = pObj-\u0026gt;pos[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;pos[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;pos[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;pos[2] + pObj-\u0026gt;fViewRadius; int32_t minx = 0; int32_t miny = 0; int32_t maxx = 0; int32_t maxy = 0; calcGridLodLoc(pTowerSpace, 2,bmin, \u0026amp;minx, \u0026amp;miny); calcGridLodLoc(pTowerSpace, 2,bmax, \u0026amp;maxx, \u0026amp;maxy); minx = minx \u0026gt; 0 ? minx : 0; miny = miny \u0026gt; 0 ? miny : 0; maxx = maxx \u0026lt; pTowerSpace-\u0026gt;iMaxWidth*4 ? maxx : pTowerSpace-\u0026gt;iMaxWidth*4 - 1; maxy = maxy \u0026lt; pTowerSpace-\u0026gt;iMaxHeight*4 ? maxy : pTowerSpace-\u0026gt;iMaxHeight*4 - 1; //是否重合 if(isOverlap(minx,miny,maxx,maxy,minxLast,minyLast,maxxLast,maxyLast)) { int32_t iMinX = minx \u0026lt; minxLast ? minx : minxLast; int32_t iMinY = miny \u0026lt; minyLast ? miny : minyLast; int32_t iMaxX = maxx \u0026gt;= maxxLast ? maxx : maxxLast; int32_t iMaxY = maxy \u0026gt;= maxyLast ? maxy : maxyLast; int32_t iChanged = 0; //往上找到最大的网格块 //为什么是iMinY/4 是因为除以4就像四叉树一样找最上面的父节点的索引值一样 for (int32_t iY = iMinY/4; iY \u0026lt; (iMaxY+3)/4; ++iY) { for (int32_t iX = iMinX/4; iX \u0026lt; (iMaxX+3)/4; ++iX) { iChanged = 0; if(isInInside(iX*4,iY*4,iX*4+3,iY*4+3,minxLast,minyLast,maxxLast,maxyLast)) { iChanged = 0x1; } if(isInInside(iX*4,iY*4,iX*4+3,iY*4+3,minx,miny,maxx,maxy)) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { removeGridWatcher(pTowerSpace,pObj,iX,iY); } break; case 0x2: { insertGridWatcher(pTowerSpace,pObj,iX,iY,pObj-\u0026gt;pos); } break; case 0x3: { int32_t iTowerId = pTowerSpace-\u0026gt;pGrids[iX + iY * pTowerSpace-\u0026gt;iMaxWidth]; assert(iTowerId != -1); tower_tt* pTower = pTowerSpace-\u0026gt;pTowers + iTowerId; if (pTower-\u0026gt;iFirstChildId == -1) { continue; } for (int32_t ly = 0; ly \u0026lt; 2; ly++) { for (int32_t lx = 0; lx \u0026lt; 2; lx++) { iChanged = 0; if (isInInside(iX * 4 + lx * 2, iY * 4 + ly * 2, iX * 4 + lx * 2 + 1, iY * 4 + ly * 2 + 1, minxLast, minyLast, maxxLast, maxyLast)) { iChanged = 0x1; } if (isInInside(iX * 4 + lx * 2, iY * 4 + ly * 2, iX * 4 + lx * 2 + 1, iY * 4 + ly * 2 + 1, minx, miny, maxx, maxy)) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { removeLodWatcher(pTowerSpace, iTowerId, pObj, iX, iY, iX * 4 + lx * 2, iY * 4 + ly * 2); } break; case 0x2: { insertLodWatcher(pTowerSpace, iTowerId, pObj, iX, iY, iX * 4 + lx * 2, iY * 4 + ly * 2); } break; case 0x3: { tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + pTower-\u0026gt;iFirstChildId + ly * 2 + lx; if (pLodTower-\u0026gt;iFirstChildId == -1) { continue; } for (int32_t l2y = 0; l2y \u0026lt; 2; l2y++) { for (int32_t l2x = 0; l2x \u0026lt; 2; l2x++) { iChanged = 0; if (isInRect(iX * 4 + lx * 2+l2x, iY * 4 + ly * 2+l2y, minxLast, minyLast, maxxLast, maxyLast)) { iChanged = 0x1; } if (isInRect(iX * 4 + lx * 2+l2x, iY * 4 + ly * 2+l2y, minx, miny, maxx, maxy)) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId + l2y * 2 + l2x; aoiNode_tt findNode; findNode.iId = pObj-\u0026gt;iId; aoiNode_tt* pT = RB_FIND(aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;watcher, \u0026amp;findNode); assert(pT); RB_REMOVE(aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;watcher, pT); mem_free(pT); aoiNode_tt* pI; RB_FOREACH(pI, aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;marker) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if ((pI-\u0026gt;iId != pObj-\u0026gt;iId) \u0026amp;\u0026amp; (pObj-\u0026gt;uiMask \u0026amp; pMarkerObj-\u0026gt;uiMask)) { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData, false, pObj-\u0026gt;uiUserData, pMarkerObj-\u0026gt;uiUserData); } } } break; case 0x2: { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId + l2y * 2 + l2x; aoiNode_tt* pNode = mem_malloc(sizeof(aoiNode_tt)); pNode-\u0026gt;iId = pObj-\u0026gt;iId; RB_INSERT(aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;watcher, pNode); aoiNode_tt* pI; RB_FOREACH(pI, aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;marker) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if ((pI-\u0026gt;iId != pObj-\u0026gt;iId) \u0026amp;\u0026amp; (pObj-\u0026gt;uiMask \u0026amp; pMarkerObj-\u0026gt;uiMask)) { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData, true, pObj-\u0026gt;uiUserData, pMarkerObj-\u0026gt;uiUserData); } } } break; } } } } break; } } } } break; } } } } else { for (int32_t iY = minyLast / 4; iY \u0026lt;= (maxyLast + 3) / 4; ++iY) { for (int32_t iX = minxLast / 4; iX \u0026lt;= (maxxLast + 3) / 4; ++iX) { removeGridWatcher(pTowerSpace, pObj, iX, iY); } } for (int32_t iY = miny/4; iY \u0026lt;= (maxy+3)/4; ++iY) { for (int32_t iX = minx/4; iX \u0026lt;= (maxx+3)/4; ++iX) { insertGridWatcher(pTowerSpace,pObj,iX,iY,pObj-\u0026gt;pos); } } }\t} 2. 把被观察者转入观察者容器\ninline static void changeAoiObjMaskToWatcher(towerSpace_tt* pTowerSpace,aoiObj_tt* pObj,int32_t iX,int32_t iY,uint64_t uiMask) { int32_t iTowerId = pTowerSpace-\u0026gt;pGrids[iX+iY*pTowerSpace-\u0026gt;iMaxWidth]; assert(iTowerId != -1); tower_tt* pTower = pTowerSpace-\u0026gt;pTowers + iTowerId; if (pTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { iChanged = 0; aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } return; } int32_t minGridX =iX*4; int32_t minGridY =iY*4; int32_t maxGridX =iX*4+3; int32_t maxGridY =iY*4+3; float bmin[3]; float bmax[3]; int32_t minx = 0; int32_t miny = 0; int32_t maxx = 0; int32_t maxy = 0; bmin[0] = pObj-\u0026gt;last[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;last[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;last[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;last[2] + pObj-\u0026gt;fViewRadius; calcGridLodLoc(pTowerSpace, 2,bmin, \u0026amp;minx, \u0026amp;miny); calcGridLodLoc(pTowerSpace, 2,bmax, \u0026amp;maxx, \u0026amp;maxy); if(!isInInside(minGridX,minGridY,maxGridX,maxGridY,minx,miny,maxx,maxy)) { for (int32_t y = 0; y \u0026lt; 2; y++) { for (int32_t x = 0; x \u0026lt; 2; x++) { tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + pTower-\u0026gt;iFirstChildId + y*2+x; if(pLodTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { iChanged = 0; aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } else { if(!isInInside(minGridX+x*2,minGridY+y*2,minGridX+x*2+1,minGridY+y*2+1,minx,miny,maxx,maxy)) { for (int32_t ly = 0; ly \u0026lt; 2; ly++) { for (int32_t lx = 0; lx \u0026lt; 2; lx++) { if(isInRect(minGridX+x*2+lx,minGridY+y*2+ly,minx,miny,maxx,maxy)) { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId + ly*2+lx; int32_t iChanged; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { iChanged = 0; aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } } } } else { int32_t iChanged; aoiNode_tt* pI; for (int32_t i = 0; i \u0026lt; 4; i++) { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId+i; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } } } } } } else { int32_t iChanged; aoiNode_tt* pI; for (int32_t i = 0; i \u0026lt; 4; i++) { tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + pTower-\u0026gt;iFirstChildId+i; if (pLodTower-\u0026gt;iFirstChildId == -1) { RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } else { for (int32_t j = 0; j \u0026lt; 4; j++) { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId+j; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } } } } } 3. 更新AOI的被观察者\nvoid towerSpace_updateAoiObjMask(towerSpace_tt* pTowerSpace,int32_t iObjId,uint64_t uiMask) { aoiObj_tt* pObj = pTowerSpace-\u0026gt;pSlotObj + iObjId; assert(pObj-\u0026gt;iId == iObjId); if(pObj-\u0026gt;uiMask == uiMask) { return; } if(pObj-\u0026gt;iMode\u0026amp;MARKER_MODE) { int32_t iX; int32_t iY; calcGridLoc(pTowerSpace,pObj-\u0026gt;last,\u0026amp;iX,\u0026amp;iY); int32_t iTowerId = pTowerSpace-\u0026gt;pGrids[iX+iY*pTowerSpace-\u0026gt;iMaxWidth]; assert(iTowerId != -1); tower_tt* pTower = pTowerSpace-\u0026gt;pTowers + iTowerId; if(pTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged = 0; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } } else { int32_t iLodX; int32_t iLodY; calcGridLodLoc(pTowerSpace,1,pObj-\u0026gt;last,\u0026amp;iLodX,\u0026amp;iLodY); int32_t iTowerLodId = pTower-\u0026gt;iFirstChildId + (iLodX -iX*2)+(iLodY - iY*2)*2; tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + iTowerLodId; if(pLodTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged = 0; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } } else { int32_t iLod2X; int32_t iLod2Y; calcGridLodLoc(pTowerSpace,2,pObj-\u0026gt;last,\u0026amp;iLod2X,\u0026amp;iLod2Y); int32_t iTowerLod2Id = pLodTower-\u0026gt;iFirstChildId + (iLod2X -iLodX*2)+(iLod2Y - iLodY*2)*2; tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + iTowerLod2Id; int32_t iChanged = 0; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } } } } if(pObj-\u0026gt;iMode\u0026amp;WATCHER_MODE) { float bmin[3]; float bmax[3]; bmin[0] = pObj-\u0026gt;last[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;last[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;last[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;last[2] + pObj-\u0026gt;fViewRadius; int32_t minx = 0; int32_t miny = 0; int32_t maxx = 0; int32_t maxy = 0; calcGridLoc(pTowerSpace, bmin, \u0026amp;minx, \u0026amp;miny); calcGridLoc(pTowerSpace, bmax, \u0026amp;maxx, \u0026amp;maxy); minx = minx \u0026gt; 0 ? minx : 0; miny = miny \u0026gt; 0 ? miny : 0; maxx = maxx \u0026lt; pTowerSpace-\u0026gt;iMaxWidth ? maxx : pTowerSpace-\u0026gt;iMaxWidth - 1; maxy = maxy \u0026lt; pTowerSpace-\u0026gt;iMaxHeight ? maxy : pTowerSpace-\u0026gt;iMaxHeight - 1; for (int32_t iY = miny; iY \u0026lt;= maxy; ++iY) { for (int32_t iX = minx; iX \u0026lt;= maxx; ++iX) { changeAoiObjMaskToWatcher(pTowerSpace,pObj,iX,iY,uiMask); } } } pObj-\u0026gt;uiMask = uiMask; } 在此AOI模式下微服务器大世界地图分割方法和传统进程分割方法的不同 传统大世界地图分割方法 此方法为垂直分割方法，将一个一二十公里的大地图分割成很多小地图放到各自的进程当中去处理数据，这种需要处理大世界地图边缝问题，需要做镜像数据管理，还有如果角色在一个进程中也就是某个小地图上面堆积，那么这个进程的压力会很大，别的进程却很休闲，这个也需要处理，总之很多麻烦。所以我们改成了微服务器水平分割加灯塔AOI方式\n微服务大世界地图处理方法\n此结构基于微服务水平分割，每个相同微服务可以并行再开很多来并行处理减少压力，比如灯塔AOI开了5个微服务我发现算力还是不够， 那么我可以在增加新的灯塔AOI微服务来并行处理数据，所以理论上一个20公里的地图撑个10多万的人不成问题。而且这种模式在服务器不需要处理无缝问题\n一些疑问的总结 为什么有了观察者集合，还需要被观察者集合 因为有时候想主动检查对象的状态，从怪物AI会定时检查被观察者集合的距离，决定是否发动攻击；又比如释放技能需要遍历被观察者集合，判断它们是否命中。如果没有被观察者集合，就必须遍历整个场景的对象\n简单测试数据 ","permalink":"https://frog-game.github.io/posts/tech/aoi-tower/","summary":"一些字段的解释 观察者：我可以观察到那些人。 被观察者：那些人能观察到自己。 #define WATCHER_MODE 0x01 观察者模式 #define MARKER_MODE 0x02 被观察者模式 灯塔相关[结构体] 1：灯塔区域结构","title":"四叉树Lod灯塔AOI"},{"content":"lua删除table中的多个元素 很多时候，我们有这样的需求:删除table中若干符合条件的元素，最原始的想法就是用for遍历一边table，符合条件的用table.remove就可以了\nfunction test1(t) for i , v in ipairs(t) do if v.id%3 == 0 then table.remove(t ,i) end end end 结果证明这是不行的，因为table.remove删除第i元素后，i后面的元素会向前补齐，这样删除前处于i+1的元素就变成了i元素，然后for循环从t中取第i+1个元素，这样就漏掉了第i+1个元素，既然这样不行，很自然的就想到用while循环，可以自由控制“遍历的指针”是否前进，有删除操作，就不前进，否则才前进\n代码如下\nfunction test2(t) local int i =1 while(t[i]) do if t[i].id%3 == 0 then table.remove(t , i) else i = i + 1 end end end 跑一下，很正常！\n但是注意table.remove是删除队列中的一个元素，每一次操作都要移动大量元素，性能不会太好，因此可以考虑用临时的table，用来保存没有被删除的元素，最后再让t指向这个table，以空间来换时间，而实际使用中，t中的元素往往是table类型，这样临时的table中只会保存元素的引用，因此占用的空间几乎可以忽略不计。\n代码如下\nfunction test3(t) local newT = {} for i ,v in ipairs(t) do if v.id%3 ~= 0 then table.insert(newT , v) end end t= newT end 很好奇test3()到底比test2()快多少呢，我测试了一下\nt = {} local n = 10000 for i = 1,n do table.insert(t ,{id = i}) end n是10000的情况下：\ntest2耗时0.234s\ntest3耗时0.002s\n相差非常大。\n结论：\n删除table中的多个元素，在table较大，且删除操作较频繁时，切忌使用table.remove\nLUA-点号和冒号 由于LUA中是模拟类，没有class，\n所以这里是使用.号来访问实例的成员\nre.SetActive(re, re.activeSelf == false); 而冒号： 则是种语法糖，省略了上面代码中的第一个参数\nre:SetActive(re.activeSelf == false); 也就是说：lua中对象.方法，只能找到方法，对象只能是类型，即使传入的是对象，所以等效于确定了单纯的方法！\n所以冒号的方法，模拟了对象访问自己方法的思想，但本质不是！\n记住：lua没有面向对象！\n为什么JSON字符串当中会出现反斜杠? 对table或者对象进行了两次的序列化。说白了就是进行了两次的toJSONString\nlua 取余问题 lua 对数字字符串取余 lua 对字符串'0'取余， lua因为是弱语言所以会尝试把上面的字符串'0'转换成数字0，然后去进行取余，但是又不能对0进行取余所以会返回NaN\n为啥返回NaN 有可能是这个原因\n类型是int时做了判断，为double或者字符串会做转换跳过了前置判断，也就NaN了\nlua直接对数字0取余 会直接报语法错误\n","permalink":"https://frog-game.github.io/posts/blog/lua-kaifa-zhuyidian/","summary":"lua删除table中的多个元素 很多时候，我们有这样的需求:删除table中若干符合条件的元素，最原始的想法就是用for遍历一边table，","title":"lua开发经验总结"},{"content":"背景 每当我们接收一份新的版本，代码拿到手要做的第一件事就是查看 git log，看看这份代码的提交记录，最近代码做什么修改。如果我们看到 git log 杂乱无章，如果不知道每次提交的代码到底是做了什么，那么对于我们来说是比较痛苦的事情。所以说，规范的 CHANGELOG 不仅有助于他人帮忙 review 代码，也能高效的输出 Release Note，对版本管理也至关重要。\n所以我们可以考虑使用 [Gitlab]的服务端 hook 来针对git change log 进行校验，拦截不符合我们规范的提交到仓库。\n方案设计 服务端 git hook 分为三种，分别是：\npre-receive（推送前） update post-receive（推送后） 这三个步骤就是我们本地 push 完代码服务端要做的事情，如图所示：\n我们可以在 pre-receive（推送前）阶段来做提交信息的校验，如果不符合我们的要求，直接返回，则该推送便不会推送到 GitLab 仓库中去。\n实践落地-简单例子 环境说明 gitlab版本:14.3.3\nhook 配置 第一步，找到要配置仓库在 gitlab 中存储的路径，但因 gitlab 的仓库自某个版本开始采用 hash 存储，我们想要知道仓库对应的物理路径，可以如下操作\nGitlab默认的仓库存储路径在 /var/opt/gitlab/git-data目录下，仓库存储在子目录repositories里面，可以通过修改/etc/gitlab/gitlab.rb文件中git_data_dirs参数来自定义仓库存储路径。下图是我们服务器的仓库路径。 保存git代码路径时用的是hash来保存的，因为我要在代码库的hooks目录添加一些git hooks。但是gitlab保存的路径却是这样的如下。 gitlab是根据hash值来保存的路径，这个值是项目id,项目id在每个项目的设置页面可以找到。 我test项目的ID是7，在shell中执行下面命令（echo -n ID | sha256sum）生成一个hash值，按这个值去找这个git库的代码位置。test项目的hash值是7902699be42c8a8e46fbbb4501726517e86b22c56a189f7625a6da49081b2451. 查看gitlab /opt/git/git-data/repositories/@hashed/79/02/目录，有一个跟这个一模一样的hash值，ok。 第三步，hooks 中是 gitlab 示例的一些钩子，我们这里首先新建目录 custom_hooks，然后用再创建文件 pre-receive（推送前），pre-receive 文件内容如下（脚本语言为 shell），同时修改 pre-receive 文件的权限。\n修改文件权限：\nchmod +777 pre-receive #!/bin/bash echo \u0026#34;开始提交信息检查...\u0026#34; # 从标准输入获取本次提交的commit id及分支的信息 read normalInput ARR=($normalInput) parentCommitId=${ARR[0]} currentCommitId=${ARR[1]} branch=${ARR[2]} echo \u0026#34;您提交的分支为：$branch\u0026#34; # 获取coomit的信息，用户，邮箱，msg等 user=$(git log --pretty=format:\u0026#34;%an\u0026#34; $currentCommitId -1) echo \u0026#34;提交者为：$user\u0026#34; commitDate=$(git log --pretty=format:\u0026#34;%cd\u0026#34; $currentCommitId -1) echo \u0026#34;提交日期为：$commitDate\u0026#34; msg=$(git log --pretty=format:\u0026#34;%s\u0026#34; $currentCommitId -1) echo \u0026#34;提交的注释为：$msg\u0026#34; flag=$(echo $msg | grep -E \u0026#34;fix.*|add.*|del.*|update.*|temp.*|test.*|revert.*|Merge.*\u0026#34;) if [ -z \u0026#34;$flag\u0026#34; ]; then echo \u0026#34;[ERROR]提交信息校验未通过，需以 fix|add|del|update|temp|test|revert 开头\u0026#34; exit 1 fi 第四步，在本地尝试推送，推送显示如下，如果不符合规范则无法提交成功。\n第五步，我们再次查看目录如下： pre-receive.py[主要做了代码化风格检查+luacheck] #!/usr/bin/python # coding=utf-8 import re import shutil import tempfile import subprocess import os import sys import emoji from rich.panel import Panel from rich import box from rich.console import Console class Trigger(object): def __init__(self): \u0026#39;\u0026#39;\u0026#39; 初始化提交者，提交id， 提交者msg信息,当前操作的分支 \u0026#39;\u0026#39;\u0026#39; self.pushAuthor = \u0026#34;\u0026#34; self.pushCommit = [] self.pushMsg = [] self.pushCount = \u0026#34;\u0026#34; self.pushFile = [] self.console = Console() self.astyle_lint_dir = \u0026#39;/var/opt/gitlab/gitlab_cicd/format_check/linux\u0026#39; def __getGitInfo(self): \u0026#39;\u0026#39;\u0026#39; \u0026#39;\u0026#39;\u0026#39; self.oldObject, self.newObject, self.ref = sys.stdin.readline().strip().split(\u0026#39; \u0026#39;) def __getPushInfo(self): \u0026#39;\u0026#39;\u0026#39; git show命令获取push作者，时间，以及文件列表 文件的路径为相对于版本库根目录的一个相对路径 \u0026#39;\u0026#39;\u0026#39; rev = subprocess.Popen( \u0026#39;git rev-list \u0026#39; + self.newObject, shell=True, stdout=subprocess.PIPE) revList = rev.stdout.readlines() revList = [x.decode(\u0026#39;utf-8\u0026#39;).strip() for x in revList] # print(revList) # 查找从上次提交self.oldObject之后还有多少次提交 # 主要是为了获取提交的文件列表 if \u0026#34;0000000000000000000000000000000000000000\u0026#34; == self.oldObject: exit(0) indexOld = revList.index(self.oldObject) pushList = revList[:indexOld] pushList.reverse() getFlag = False # print(pushList) # temp file c_cpp_tempdir = tempfile.mkdtemp(\u0026#39;git_c_cpp_hook\u0026#39;) lua_tempdir = tempfile.mkdtemp(\u0026#39;git_lua_hook\u0026#39;) # print(lua_tempdir) c_cpp_temp_file_path = [] lua_temp_file_path = [] # 循环获取每次提交的文件列表 for pObject in pushList: p = subprocess.Popen(\u0026#39;git show \u0026#39; + pObject, shell=True, stdout=subprocess.PIPE) pipe = p.stdout.readlines() pipe = [x.decode(\u0026#39;utf-8\u0026#39;).strip() for x in pipe] self.pushMsg.append(pipe[4].strip() + \u0026#39;\\n\u0026#39;) self.pushCommit.append(pipe[0].strip(\u0026#34;commit\u0026#34;).strip()) if not getFlag: self.pushAuthor = pipe[1].strip( \u0026#34;Author\u0026#34;).replace(\u0026#39;:\u0026#39;, \u0026#39;\u0026#39;).strip() self.pushCount = len(pushList) getFlag = True # print(pipe) # 验证是否c,c++,lua文件 fileList = [x for x in pipe if x.startswith(\u0026#34;diff --git\u0026#34;)] # print(\u0026#34;===\u0026gt;\u0026#34;, fileList) indexList = [x for x in pipe if x.startswith( \u0026#34;index \u0026#34;) or x.startswith(\u0026#34;similarity index 100%\u0026#34;)] # print(\u0026#34;===\u0026gt;\u0026#34;, indexList) # fiList = dict(zip(fileList, indexList)) fiList = {fileList[i]: indexList[i] for i in range(len(fileList))} # print(\u0026#34;===\u0026gt;\u0026#34;, fiList) for file in fiList: if fiList[file].strip().startswith(\u0026#34;similarity index 100%\u0026#34;): continue if not (file.lower().endswith(\u0026#39;.cpp\u0026#39;) or file.lower().endswith(\u0026#39;.h\u0026#39;) or file.lower().endswith(\u0026#39;.c\u0026#39;) or file.lower().endswith(\u0026#39;.lua\u0026#39;)): continue filename = file.split(\u0026#39;/\u0026#39;)[-1] # print(filename) self.pushFile.append(filename) # git get Tree content_hash = fiList[file].strip()[15:22] # print(content_hash) content_p = subprocess.Popen( \u0026#39;git cat-file -p \u0026#39;+content_hash, shell=True, stdout=subprocess.PIPE) cpipe = content_p.stdout.readlines() cpipeList = [x.decode(\u0026#39;utf-8\u0026#39;) for x in cpipe] # print(cpipeList) if file.lower().endswith(\u0026#39;.cpp\u0026#39;) or file.lower().endswith(\u0026#39;.h\u0026#39;) or file.lower().endswith(\u0026#39;.c\u0026#39;): # print(filename) # print(content_hash) # print(file) # print(cpipeList) file_path = os.path.join(c_cpp_tempdir, filename) c_cpp_temp_file_path.append(file_path + \u0026#39;\\n\u0026#39;) with open(file_path, \u0026#39;w+\u0026#39;) as fp: fp.writelines(cpipeList) if file.lower().endswith(\u0026#39;.lua\u0026#39;): file_path = os.path.join(lua_tempdir, filename) lua_temp_file_path.append(file_path + \u0026#39;\\n\u0026#39;) with open(file_path, \u0026#39;w+\u0026#39;) as fp: fp.writelines(cpipeList) fc = open(self.astyle_lint_dir + \u0026#39;/.clang-format\u0026#39;) # print(fc.read()) with open(os.path.join(c_cpp_tempdir, \u0026#39;.clang-format\u0026#39;), \u0026#39;w+\u0026#39;) as fp: fp.writelines(fc.read()) fc.close() fe = open(self.astyle_lint_dir + \u0026#39;/.editorconfig\u0026#39;) # print(fe.read()) with open(os.path.join(lua_tempdir, \u0026#39;.editorconfig\u0026#39;), \u0026#39;w+\u0026#39;) as fp: fp.writelines(fe.read()) fe.close() # checkstyle exitflag = 0 exitflag |= self.check_commit_msg() exitflag |= self.c_cpp_handler_checkstyle( c_cpp_tempdir, c_cpp_temp_file_path) exitflag |= self.lua_handler_checkstyle( lua_tempdir, lua_temp_file_path) exitflag |= self.lua_handler_checkdiagnosis( lua_tempdir, lua_temp_file_path) if 1 == exitflag: exit(1) # 处理c,cpp文件 def c_cpp_handler_checkstyle(self, c_cpp_tempdir, c_cpp_temp_file_path): try: blag = 0 finalpipe = [] c_cpp_temp_name = [] for path in c_cpp_temp_file_path: cmd = r\u0026#39;python \u0026#39; + self.astyle_lint_dir + \u0026#34;/../run-clang-format.py\u0026#34; + \\ \u0026#39; --clang-format-executable clang-format -r \u0026#39; + path # print(cmd) result = subprocess.Popen( cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) rpipe = result.stdout.readlines() # print(rpipe) if len(rpipe) \u0026gt; 0: rpipeList = [ x.decode(\u0026#39;utf-8\u0026#39;).replace(c_cpp_tempdir + \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;) for x in rpipe] finalpipe.append(\u0026#34;\u0026#34;.join(rpipeList)) (filepath, tempfilename) = os.path.split(path) c_cpp_temp_name.append(tempfilename) blag = 1 # print(finalpipe) if len(finalpipe) \u0026gt; 0: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]处理c,cpp文件代码规范未通过\\n\u0026#34; + \u0026#34; 需要用vscode clang-format 插件进行代码格式化\\n\u0026#34; + \u0026#34; 或者去tools\\gitlab_cicd\\n\u0026#34; + \u0026#34; 下找到install.bat进行自动格式化\u0026#34; + \u0026#39;\\n\u0026#39; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;===\u0026gt;有问题的c,cpp文件\u0026lt;===:\\n\u0026#34; + \u0026#34;\u0026#34;.join(c_cpp_temp_name) + \u0026#34;\\n===\u0026gt;错误提示\u0026lt;===:\\n\u0026#34; + re.sub(\u0026#39;\\x1b.*?m\u0026#39;, \u0026#39;\u0026#39;, \u0026#34;\u0026#34;.join(finalpipe)) + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return blag finally: shutil.rmtree(c_cpp_tempdir) # pass # 处理lua文件风格 def lua_handler_checkstyle(self, lua_tempdir, lua_temp_file_path): try: blag = 0 finalpipe = [] lua_error_temp_name = [] for path in lua_temp_file_path: cmd = self.astyle_lint_dir + \u0026#39;/codeformat check -f \u0026#39; + path + \u0026#39; -DAE\u0026#39; # print(cmd) result = subprocess.Popen( cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) rpipe = result.stdout.readlines() # print(rpipe) if len(rpipe) \u0026gt; 0: rpipeList = [x.decode(\u0026#39;utf-8\u0026#39;).replace(lua_tempdir + \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;) for x in rpipe] rpipestr = \u0026#34;\u0026#34;.join(rpipeList) (filepath, tempfilename) = os.path.split(path) if(not re.search(r\u0026#39;^Check.*?OK$\u0026#39;, rpipestr)): finalpipe.append(rpipestr) lua_error_temp_name.append(tempfilename) blag = 1 # print(lua_error_temp_name) if 1 == blag: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]处理lua文件代码规范未通过\\n\u0026#34; + \u0026#34; 需要用vscode EmmyLuaCodeStyle 插件进行代码格式化\\n\u0026#34; + \u0026#34; 或者去tools\\gitlab_cicd\\n\u0026#34; + \u0026#34; 下找到install.bat进行自动格式化\u0026#34; + \u0026#39;\\n\u0026#39; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;===\u0026gt;有问题的lua文件\u0026lt;===:\\n\u0026#34; + \u0026#34;\u0026#34;.join(lua_error_temp_name) + \u0026#34;\\n===\u0026gt;错误提示\u0026lt;===:\\n\u0026#34; + re.sub(\u0026#39;\\x1b.*?m\u0026#39;, \u0026#39;\u0026#39;, \u0026#34;\u0026#34;.join(finalpipe)) + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return blag finally: # shutil.rmtree(lua_tempdir) pass def lua_handler_checkdiagnosis(self, lua_tempdir, lua_temp_file_path): try: blag = 0 finalpipe = [] lua_error_temp_name = [] for path in lua_temp_file_path: cmd = self.astyle_lint_dir + \u0026#39;/luacheck \u0026#39; + path + \\ \u0026#39; --no-config --no-default-config --codes -q --exclude-files **/config.lua --ignore 311\u0026#39; # print(cmd) result = subprocess.Popen( cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) rpipe = result.stdout.readlines() # print(rpipe) if len(rpipe) \u0026gt; 0: rpipeList = [ x.decode(\u0026#39;utf-8\u0026#39;).replace(lua_tempdir + \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;) for x in rpipe] rpipestr = \u0026#34;\u0026#34;.join(rpipeList) (filepath, tempfilename) = os.path.split(path) if(re.findall(r\u0026#39;^Check.*?error\u0026#39;, rpipestr)): finalpipe.append(rpipestr) lua_error_temp_name.append(tempfilename) blag = 1 # print(finalpipe) if 1 == blag: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]处理lua文件代码语法未通过\\n\u0026#34; + \u0026#34; 请手动修改并提交, 直到所有代码都符合规范为止...\u0026#34; + \u0026#39;\\n\u0026#39; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;===\u0026gt;有问题的lua文件\u0026lt;===:\\n\u0026#34; + \u0026#34;\u0026#34;.join(lua_error_temp_name) + \u0026#34; \\n===\u0026gt;错误提示\u0026lt;===:\\n\u0026#34; + re.sub(\u0026#39;\\x1b.*?m\u0026#39;, \u0026#39;\u0026#39;, \u0026#34;\u0026#34;.join(finalpipe)) + \u0026#39;[/]\u0026#39;, box=box.DOUBLE, expand=True)) return blag finally: shutil.rmtree(lua_tempdir) # pass def check_commit_msg(self): print(\u0026#34;开始提交信息检查...\u0026#34;) print(\u0026#34;提交者为:\u0026#34;, self.pushAuthor) print(\u0026#34;当前提交总次数:\u0026#34;, self.pushCount) print(\u0026#34;当前提交注释消息:\u0026#34;) for msg in self.pushMsg: print(msg, end=\u0026#34;\u0026#34;) for msg in self.pushMsg: if len(msg) \u0026lt; 10: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34;[ERROR]提交信息校验未通过\\n\u0026#34; \u0026#34;msg长度必须大于10\u0026#34; + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return 1 msgList = msg.split(\u0026#34; \u0026#34;, 1) if not (len(msgList) == 2 and emoji.is_emoji(msgList[0]) and re.search(r\u0026#39;^[init|feat|fix|docs|style|refactor|perf|test|build|ci|chore|revert](.*):[\\s]{1}[\\S]{1,20}\\n\u0026#39;, msgList[1]), re.S): self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]提交信息校验未通过,内容不符合规范\\n\u0026#34; + \u0026#34; 请去vscode下载git-commit-plugin进行规范提交\\n\u0026#34; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;e.g.:🎉 init(影响范围模块): 项目初始化\\n\u0026#34; + \u0026#34;e.g.:✨ feat(影响范围模块): 新增某某功能\\n\u0026#34; + \u0026#34;e.g.:🐞 fix(影响范围模块): 修复某某bug\\n\u0026#34; + \u0026#34;e.g.:📃 docs(影响范围模块): 新增某某说明文档\\n\u0026#34; + \u0026#34;e.g.:🌈 style(影响范围模块): 仅仅修改了空格,缩进,逗号等等\\n\u0026#34; + \u0026#34;e.g.:🦄 refactor(影响范围模块): 重构某某功能\\n\u0026#34; + \u0026#34;e.g.:🎈 perf(影响范围模块): 优化了提高某某模块性能\\n\u0026#34; + \u0026#34;e.g.:🧪 test(影响范围模块): 测试模块功能\\n\u0026#34; + \u0026#34;e.g.:🔧 build(影响范围模块): 构建了那个版本\\n\u0026#34; + \u0026#34;e.g.:🐎 ci(影响范围模块): 对某某ci文件的修改\\n\u0026#34; + \u0026#34;e.g.:🐳 chore(影响范围模块): 改变了某某构建流程\\n\u0026#34; + \u0026#34;e.g.:↩ revert(影响范围模块): 回退某个版本\\n\u0026#34; + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return 1 return 0 def getGitPushInfo(self): self.__getGitInfo() self.__getPushInfo() if __name__ == \u0026#34;__main__\u0026#34;: t = Trigger() t.getGitPushInfo() exit(0) ","permalink":"https://frog-game.github.io/posts/blog/gitlab-pre-receive-hook/","summary":"背景 每当我们接收一份新的版本，代码拿到手要做的第一件事就是查看 git log，看看这份代码的提交记录，最近代码做什么修改。如果我们看到 git log 杂乱无章","title":"gitlab服务器钩子"},{"content":"图解释 结构体 typedef struct byteQueue_s { char*\tpBuffer;//数据 size_t\tnCapacity;//容量 size_t\tnReadIndex;//读指针索引 size_t\tnWriteIndex;//写指针索引 } byteQueue_tt; 初始 结构体 假设要申请的空间 环形buff结构体大小为8\nnWriteIndex 写指针索引 nReadIndex 读指针索引 环形buff初始化\nvoid byteQueue_init(byteQueue_tt* pByteQueue,size_t nCapacity = /* = 8*/) { pByteQueue-\u0026gt;nReadIndex = nCapacity;//读指针索引位置设置为8,放到末尾 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置成0，放到开头 pByteQueue-\u0026gt;nCapacity = nCapacity;//容量 if( nCapacity != 0 ) { pByteQueue-\u0026gt;pBuffer = mem_malloc(nCapacity);//申请空间 } else { pByteQueue-\u0026gt;pBuffer = NULL;//置空 } } 清空结构体 void byteQueue_clear(byteQueue_tt* pByteQueue) { pByteQueue-\u0026gt;nReadIndex = 0;//读指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nCapacity = 0;//容量设置为0 if(pByteQueue-\u0026gt;pBuffer) { mem_free(pByteQueue-\u0026gt;pBuffer);//如果有数据进行释放 pByteQueue-\u0026gt;pBuffer = NULL;//并且置空 } } 获取剩余全部可写空间 static inline size_t byteQueue_getBytesWritable(byteQueue_tt* pByteQueue) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex )//写指针和读指针重合，或者在读指针前面 { return pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//直接读指针 - 写指针 就是 写入了多少内容 } else//写指针在读指针后面 { return pByteQueue-\u0026gt;nReadIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex); //读指针位置 + (容量 - 写指针位置) } } 写指针在读指针前面[求得是蓝色块数据] 写指针在读指针后面[求得是蓝色块数据] 获取剩余全部可读空间 static inline size_t byteQueue_getBytesReadable(byteQueue_tt* pByteQueue) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex) //读指针在写指针前面 { return pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//直接写指针 - 读指针 就是可以读多少数据 } else //读指针和写指针重合,或者读指针在写指针后面 { return pByteQueue-\u0026gt;nWriteIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex); //写指针 + (容量 - 读指针位置) } } 写指针在读指针后面[求的是红色块的数据] 写指针在读指针前面[求的是红色块的数据] 查看连续的可写空间 //查看连续的可写空间 //size_t* pWriteBytes 能连续写入的大小 static inline char* byteQueue_peekContiguousBytesWrite(byteQueue_tt* pByteQueue, size_t* pWriteBytes) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex)//读指针在写指针后面 { *pWriteBytes = pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } else//读指针在写指针前面 { *pWriteBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nWriteIndex;//开始连续写入指针的起始位置 } 写指针在读指针前面[求得连续可写的空间] 写指针在读指针后面[求得连续可写的空间] 查看连续可读空间 //查看连续的可读空间 //size_t* pWriteBytes 能连续读取的大小 static inline char* byteQueue_peekContiguousBytesRead(byteQueue_tt* pByteQueue, size_t* pReadBytes) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex)//写指针在读指针后面 { *pReadBytes = pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } else { *pReadBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nReadIndex;//开始连续读入指针的起始位置 } 写指针在读指针后面[求得连续可读的空间] 写指针在读指针前面[求得连续可读的空间] 写入一个字符[空间不足按256的倍数自动扩展] void byteQueue_writeChar(byteQueue_tt* pByteQueue, const char c) { if(pByteQueue-\u0026gt;nCapacity == 0) { //初始化容量,buffer大小，可读索引 pByteQueue-\u0026gt;nCapacity = 256;//初始化容量大小[256] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取获取剩余全部可写空间 if (1 \u0026gt; nBytesWritable) { //align_size 将size按align大小整数倍提升,用于内存对齐 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + 1,256); char* pBuffer = mem_malloc(nNewCapacity); if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//说明还有数据没有读走 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//获取剩余全部可读的空间 size_t nReadBytes = 0;//连续可读的空间的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取数据的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//如果连续可读的空间的大小!=剩余全部可读的空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//到了新空间需要重新移动读指针 pByteQueue-\u0026gt;nWriteIndex = nWritten;//到了新空间需要重新移动写指针 } else //没有数据需要读取直接初始化指针位置 { pByteQueue-\u0026gt;nReadIndex = nNewCapacity; pByteQueue-\u0026gt;nWriteIndex = 0; } pByteQueue-\u0026gt;nCapacity = nNewCapacity; mem_free(pByteQueue-\u0026gt;pBuffer); pByteQueue-\u0026gt;pBuffer = pBuffer; } } pByteQueue-\u0026gt;pBuffer[pByteQueue-\u0026gt;nWriteIndex] = c;//赋值 pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + 1) % pByteQueue-\u0026gt;nCapacity;//索引位移一位 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity)//如果读索引在尾部 { pByteQueue-\u0026gt;nReadIndex = 0;//把读索引放到头部 } } 写入指定大小空间的数据[空间不足按256的倍数自动扩展] void byteQueue_write(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = align_size(nLength,256);//初始化容量大小[256的倍数] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取剩余可写空间 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写空间 { //数据进行扩展 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + (nLength-nBytesWritable),256); char* pBuffer = mem_malloc(nNewCapacity);//申请空间大小 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity )//还有数据可读 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读空间 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始连续读入指针的起始位置 memcpy(pBuffer,pRead,nReadBytes);//把连续可读的空间写入新buffer空间 if( nReadBytes != nWritten )//如果连续可读的空间!=剩余全部可读空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;////重置容量大小 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧buff空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//重置指针到新buff空间 } } size_t nWriteBytes = 0;//连续可写的空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//开始写入的指针位置 if (nWriteBytes \u0026gt;= nLength)//如果连续写入的空间能够满足需要写入的空间大小 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入的空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//再把剩余要写入的大小空间写入 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置读索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置写索引 } } 写入指定大小空间的数据[空间不足按剩余需要空间大小申请] void byteQueue_writeBytes(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = nLength;//初始化容量大小[需要空间大小] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//剩余可写的全部空间大小 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写入的空间大小 { size_t nNewCapacity = pByteQueue-\u0026gt;nCapacity + (nLength - nBytesWritable);//开辟正好大小的空间 char* pBuffer = mem_malloc(nNewCapacity);//申请空间 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//还有空间可读需要把这段空间赋值到新空间 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余可读的全部空间 size_t nReadBytes = 0;//连续可读的空间 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取空间的起始位置 memcpy(pBuffer,pRead,nReadBytes);//拷贝到新空间 if( nReadBytes != nWritten )//连续可读的空间!=剩余可读的全部空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余数据到新空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;//重置容量 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间指针指向旧空间指针 } } size_t nWriteBytes = 0;//连续可写入空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//可写入开始指针 if (nWriteBytes \u0026gt;= nLength)//容量足够 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//剩余的在直接拷贝 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置写索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 } } 读取数据 bool byteQueue_readBytes(byteQueue_tt* pByteQueue, void* pOutBytes, size_t nMaxLengthToRead, bool bPeek /*= false*/ ) { size_t nBytesWritten = byteQueue_getBytesReadable(pByteQueue);//可读的空间大小 size_t nBytesToRead = nBytesWritten \u0026lt; nMaxLengthToRead ? nBytesWritten : nMaxLengthToRead;//得到可读取的大小 if (nBytesToRead == 0) { return false; } size_t nReadBytes = 0;//连续可读的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始索引 if( nReadBytes \u0026gt;= nBytesToRead )//满足可读大小需求 { memcpy(pOutBytes,pRead,nBytesToRead);//直接读取 } else { memcpy(pOutBytes,pRead,nReadBytes);//直接连续可读的空间大小 memcpy((char*)pOutBytes+nReadBytes,pByteQueue-\u0026gt;pBuffer,nBytesToRead-nReadBytes);//读取剩余需要读取的大小 } if (!bPeek)//不是探测 byteQueue_readOffset(pByteQueue,nBytesToRead);//直接移动指针 return true; } 重置容量 void byteQueue_reserve(byteQueue_tt* pByteQueue, size_t nCapacity) { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读大小 if(nWritten \u0026gt; nCapacity)//如果全部可读的大小大于要重置的容量大小 { return; } if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//有剩余需要读取的空间数据 { char* pBuffer = mem_malloc(nCapacity);//申请新的重置空间大小 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//还有剩余要拷贝的空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余要拷贝的数据 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间的指针指向旧空间指针 } else { pByteQueue-\u0026gt;pBuffer = mem_realloc(pByteQueue-\u0026gt;pBuffer,nCapacity);//直接指向申请空间的大小 pByteQueue-\u0026gt;nReadIndex = nCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nCapacity;//重置容量 } ","permalink":"https://frog-game.github.io/posts/tech/ringbuff/","summary":"图解释 结构体 typedef struct byteQueue_s { char* pBuffer;//数据 size_t nCapacity;//容量 size_t nReadIndex;//读指针索引 size_t nWriteIndex;","title":"环形buff"},{"content":"linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 网络流程图 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Socket在Skynet内部对应一个Lua虚拟机和一个客户特定的消息队列per client mq。当客户特定消息队列中有消息时，该队列会挂载到全局队列global message queue上供工作线程worker Threads进行调度处理。\n一个Socket线程socket thread会轮询所有的Socket，当收到客户端请求后将请求打包成一个消息，发送到该Socket对应的客户特定消息队列per client mq中，然后将该消息队列挂到全局队列队尾。\n多个Worker工作线程worker threads从全局队列头部获取客户特定消息队列，从客户特定消息队列中取出一个消息进行处理，处理完毕后再将消息队列重新挂到全局队列队尾。\nskynet中不同服务是利用系统的多线程完全并行的，当你从服务A向服务B和服务C分别各自发送一条消息时，并不能保证先发的消息先被处理。而当你从服务A向服务B依次发送两条消息时，先发的消息一定会被服务B先处理。\n使用Lua实现的服务只是一个内嵌了Lua虚拟机的服务，也遵守上面的规则。如果服务B是一个Lua服务，当服务A向服务B发送两条消息x和y时，Skynet一定保证x先被服务B中的Lua虚拟机接收到，并为消息x生成要给协程X，并运行这个协程。然后才会接收到消息y，并重新生成一个新的协程Y并运行。\n同步问题 同步也是skynet存在的问题，当一个服务call其他服务时，当前协程会挂起，但是这个服务还可以接受并处理其他消息。如果多个协程改到同一个数据，你不做同步处理就无法确定这个数据会是多少。\n这样的例子特别常见，比如，服务正当处理玩家login请求，刚好遇到call挂起，这时候又有新的请求到来，比如logout，服务就会转去处理logout消息。那玩家究竟是login，还是logout？\n当然，同步问题也容易解决，加多一个state的标识和一个协程列表，操作执行时，将state置doing，其他协程判断state=doing时就将自己加到协程列表，然后 skynet.wait。在操作执行完后，重置state，然后遍历协程列表依次 skynet.wakeup(co) ，最后将协程列表置空。\n解释此队列 红黑树上的节点是所有监听的socket 黄色底的是interesting 队列 蓝色底是黄色底的子队列 也就是就绪队列 epoll_ctrl() 执行增加操作时候就是往interesting队列塞socket 当有读写事件时候，就会往蓝色底队列放入socket也就是塞入就绪队列 通过epoll_wait()把就绪队列的东西返回出来\n线程类型 socket thread : 线程进程消息收发\nmonitor thread : 线程监控服务是不是陷入死循环，消息是否堵住\ntime thread : 线程主要用于实现skynet的定时器\nwork thread 线程 对消息队列进行调度\n消息流转 先从全局队列pop一个次级队列，然后从次级队列pop一个消息调用回调函数进行逻辑处理 用完以后如果次级队列不为空或者堵塞，继续把次级队列放入全局队列 启动流程 加载配置文件\n配置文件存入lua的全局变量env\n创建和启动c服务logger\n启动引导模块并启动第一个lua服务(bootstrap)\n然后在通过bootstrap配置去启动其他的微服务\ncluster 两条tcp通道总结 前提 两端是严格分为请求方和回应方。比如 A---\u0026gt; B ，那么只能是A向B提出请求，B 回应它；如果 B-----\u0026gt;\u0026gt;A 需要由 B 向 A 再建立一条通道。\nTCP特性使得每个TCP连接可以得到均等的带宽。在多用户环境下，一个用户拥有越多TCP连接，获得的带宽越大\n1条连接 优点：链接少，对于没有接触过skynet，传统服务器人很容易这种方式连接方式，因为大部分很多都是cs结构程序员过来的 **缺点：**如果断了，数据就无法传输，得重新建立新的连接，上层业务逻辑写起来也麻烦，需要清楚那边是发送方，那边是接受方\n2条连接 **优点：**在前面前提的基础上，有两条连接，上层业务逻辑程序员不需要关心我这个时候是client，还是server，只需要通过cluster.call，cluster.send，接口直接往里面塞数据就行了，多条连接也便于抢带宽 **缺点:**多了一条连接，对cs结构过来的程序员不太容易理解为什么这么弄有好处，或者是不知道有前面那个前提 为什么不在开辟更多的连接，因为开辟更多的链接意义不大，如果这台机器上弄了不少进程，连接数和机器的配置也是有关系的，多了，如果用不上也是一种浪费，同时对于业务程序员来说也逻辑混乱， 因为假如是4条，那么接受方还得区分是那条发过来的数据\nmaster / slave 组网过程 slave3发送sync给master，并启动自己的listen master收到信息给已经连接上的slave1，slave2发送slave3请求连接的情况 master给slave3发送当前已经连接上的slave数量，并把slave3加入节点组 slave1，slave3接收到master发送的信息后，调用connect去连接slave3 master /slave 断网过程 master检测到slave3失去连接，把slave3连接fd置成0 master把失去连接的slave3 id 广播给slave1，slave2 slave1，slave2得到slave3 id之后和slave3断开连接 harbor 服务 每个节点都有一个harborid，在发送消息的时候会把这个harborid放到消息id的\n高8位，所以通过高8位的对比就知道这个消息是远程消息，还是本地消息，如果是远程消息\n通过harbor和远程的harbor建立tcp连接发送数据过去，如果是本地直接放入本地节点处理逻辑\n消息处理方式 skeynet.send 非堵塞不需要应答 skynet.call 堵塞需要应答 skynet.ret 回应消息 skynet.response 请求和相应在不用协程处理 skynet.queue 串行化消息执行 锁 互斥锁 适用于得到锁以后处理时间\u0026gt;线程切换时间场景 得到锁的线程会被唤醒处理逻辑，没有抢占到锁的线程会进入休眠状态\n互斥锁加锁失败以后，会从用户态变成内核态，线程就会释放CPU 给其他线程,会有两次线程上下文的切换成本\n线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 上下文切换的时间，大概在几十纳秒到几微妙之间，所以如果你能确认你被锁住的代码时间很短，那么就不应该用互斥锁，而应该用自旋锁\n自旋锁 没有获取到权限的的线程不会进入休眠状态一直自旋检测是否能获取资源，适用于得到锁以后处理时间\u0026lt; 线程切换时间的场景，得到锁处理逻辑最好别有IO操作或者文件流操作\n自旋锁是通过cpu的CAS函数，在用户态就完成了加锁和解锁操作，所以不会有上下文的切换，相比互斥锁来说，会快一点\n一般加锁的过程有两步\n查看锁的状态，如果锁是空闲的，那么执行第二步 将锁设置为当前线程持有 自旋锁加锁失败以后线程会忙等待，直到它能拿到锁\n读写锁 实现在rwlock.h中\n读锁是共享锁概念，其他锁去读的时候读取的是共享的资源，\n写锁是独占概念，其他锁只能等待抢占到的锁释放资源，适用于读多写少场景\n所以更具场景可以分为读优先锁和写优先锁\n读优先锁 读优先锁对于读线程并发性更好，但是也不是没有问题，我们试想一下，如果一直有读线程获取锁，那么写线程就会被饿死\n写优先锁 写优先锁可以保证写线程不被饿死，但是如果一直有写线程获取，那么读线程也会被饿死\n所以不管是优先读锁还是写锁，对方都可能被饿死，所以我们不偏袒任何一方，搞个公平读写锁\n公平读写锁 用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的规则加锁，这样读线程一样能并发，也不会出现饥饿现象\n乐观锁和悲观锁区别 悲观锁做事比较悲观，他认为多线程同时修改共享资源的概率比较高，所以在访问资源之前都会先上一把锁。\n乐观锁正好相反，他认为多线程同时修改共享资源的概率比较低，所以会让先修改完资源，然后在判断是不是有冲突，有没有其他的线程在修改资源，如果有的话就直接放弃本次操作，\n互斥锁、自旋锁、读写锁，都是属于悲观锁\n重入锁 就是能一条线程上能重复获取的锁，而不导致死锁\ncluster 模式 在每个 skynet 节点（单个进程）内，启动一个叫 clusterd 的服务。所有需要跨进程的消息投递都先把消息投递到这个服务上，再由它来转发到网络。\n首选通过clustername.lua配置表配置好全部的cluster节点 在所有要发现的节点上执行require\u0026quot;skynet.cluster\u0026quot; 用cluster.open建立自己的监听好让别的节点和自己建立tcp通道连接 通过cluster.register注册create的service 远程节点利用cluster.query()来得到注册过的节点 通过cluster.call skynet.call cluster.send skynet.send来调用远程function1 function2函数 简易的mmo 架构 网关服务 main.lua 建立 watchdog watchdog 通过skynet.start() 创建gateService gateService并通过rpc调用 watchdogService socket.open 函数 watchdogService 通过 socket.open 创建 agenService agenService 把fd forward给gateService client 发送请求给gateService gateService 把请求重定向给agentService agentService 把处理结果返回给client 协程 coroutine 实现 详细代码见lcorolib.c\n派发消息 function skynet.dispatch_message(...) -- 当前消息处理 local succ, err = pcall(raw_dispatch_message,...) while true do -- 顺序执行skynet.fork 创建的协程 if fork_queue.h \u0026gt; fork_queue.t then -- queue is empty fork_queue.h = 1 fork_queue.t = 0 break end -- pop queue local h = fork_queue.h local co = fork_queue[h] fork_queue[h] = nil fork_queue.h = h + 1 local fork_succ, fork_err = pcall(suspend,co,coroutine_resume(co)) if not fork_succ then if succ then succ = false err = tostring(fork_err) else err = tostring(err) .. \u0026#34;\\n\u0026#34; .. tostring(fork_err) end end end assert(succ, tostring(err)) end 处理当前消息 local function raw_dispatch_message(prototype, msg, sz, session, source) -- skynet.PTYPE_RESPONSE = 1, read skynet.h if prototype == 1 then -- 对回应类型的包处理 local co = session_id_coroutine[session] if co == \u0026#34;BREAK\u0026#34; then session_id_coroutine[session] = nil elseif co == nil then unknown_response(session, source, msg, sz) else local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;resume\u0026#34;) end session_id_coroutine[session] = nil suspend(co, coroutine_resume(co, true, msg, sz, session)) end else local p = proto[prototype] -- 找到对应的解析协议 if p == nil then if prototype == skynet.PTYPE_TRACE then -- trace next request trace_source[source] = c.tostring(msg,sz) elseif session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, prototype) end return end local f = p.dispatch -- 获取处理的函数 if f then local co = co_create(f) -- 获取协程 session_coroutine_id[co] = session session_coroutine_address[co] = source local traceflag = p.trace if traceflag == false then -- force off trace_source[source] = nil session_coroutine_tracetag[co] = false else local tag = trace_source[source] if tag then trace_source[source] = nil c.trace(tag, \u0026#34;request\u0026#34;) session_coroutine_tracetag[co] = tag elseif traceflag then -- set running_thread for trace running_thread = co skynet.trace() end end suspend(co, coroutine_resume(co, session,source, p.unpack(msg,sz))) else trace_source[source] = nil if session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, proto[prototype].name) end end end end 创建协程 local function co_create(f) local co = tremove(coroutine_pool) -- 从协程池中获取协程 if co == nil then --如果没有了 co = coroutine_create(function(...) -- 创建新的 f(...) --执行回调函数，不会立马执行只会调用coroutine.resume时候才会执行 while true do -- 为了能够复用刚创建的协成，下面需要对协程进行初始化和回收 local session = session_coroutine_id[co] if session and session ~= 0 then local source = debug.getinfo(f,\u0026#34;S\u0026#34;) skynet.error(string.format(\u0026#34;Maybe forgot response session %s from %s : %s:%d\u0026#34;, session, skynet.address(session_coroutine_address[co]), source.source, source.linedefined)) end -- coroutine exit local tag = session_coroutine_tracetag[co] if tag ~= nil then if tag then c.trace(tag, \u0026#34;end\u0026#34;) end session_coroutine_tracetag[co] = nil end local address = session_coroutine_address[co] if address then session_coroutine_id[co] = nil session_coroutine_address[co] = nil end -- recycle co into pool f = nil coroutine_pool[#coroutine_pool+1] = co -- recv new main function f f = coroutine_yield \u0026#34;SUSPEND\u0026#34; f(coroutine_yield()) end end) else -- pass the main function f to coroutine, and restore running thread local running = running_thread coroutine_resume(co, f) running_thread = running end return co end 协程挂起 -- suspend is local function function suspend(co, result, command) if not result then -- 执行co失败以后的处理 local session = session_coroutine_id[co] if session then -- coroutine may fork by others (session is nil) local addr = session_coroutine_address[co] if session ~= 0 then -- only call response error local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;error\u0026#34;) end c.send(addr, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) end session_coroutine_id[co] = nil end session_coroutine_address[co] = nil session_coroutine_tracetag[co] = nil skynet.fork(function() end) -- trigger command \u0026#34;SUSPEND\u0026#34; local tb = traceback(co,tostring(command)) coroutine.close(co) error(tb) end if command == \u0026#34;SUSPEND\u0026#34; then -- 挂起操作 return dispatch_wakeup() -- 如果有能够被唤醒的协程，就wakeup elseif command == \u0026#34;QUIT\u0026#34; then coroutine.close(co) -- service exit return elseif command == \u0026#34;USER\u0026#34; then -- See skynet.coutine for detail error(\u0026#34;Call skynet.coroutine.yield out of skynet.coroutine.resume\\n\u0026#34; .. traceback(co)) elseif command == nil then -- debug trace return else error(\u0026#34;Unknown command : \u0026#34; .. command .. \u0026#34;\\n\u0026#34; .. traceback(co)) end end\t协程销毁 主要是因为这种基础类型LUA_TTHREAD来决定怎么销毁\nLUA_TTHREAD 介绍:\n除了主线程以外，其它线程和其它Lua对象一样都是垃圾回收的对象。等待GC回收，当新建一个线程时，线程会压入栈，这样能确保新线程不会成为垃圾\n每次调用lua_newstate的时候都会创建一个新的luastate,不同的luastate完全独立，之间不共享任何数据\n创建一个线程就拥有一个独立的执行栈了，但是它与其线程共用虚拟机的全局状态\n协程提供了新的api接口和 lua_resetthread, coroutine.close 会使协程进入死亡状态,并且关闭所有的close变量\nsend.call 流程 API 相关 cluster cluster.call(node, address, ...) --远程调用node中的addr cluster.send(node, address, ...) --send调用远程node的addr cluster.open(port) --本地打开(监听)一个cluster结点，使其能在cluster中的其他结点发现 cluster.reload(config) --重载远程结点配置表，表中的cluster结点都open过，则可以通讯 cluster.proxy(node, name) --设置远程结点的代理，使得可以像调用本地RPC一样调用远程结点 cluster.snax(node, name, address) --生成一个远程的snax服务对象 cluster.register(name, addr) --注册一个cluster结点 cluster.query(node, name) --查找远程结点中注册过的结点是否存在 harbor harbor.link(id) --用来监控一个 slave 是否断开。如果 harbor id 对应的 slave 正常，这个 api 将阻塞。当 slave 断开时，会立刻返回。 harbor.linkmaster() --用来在 slave 上监控和 master 的连接是否正常。这个 api 多用于异常时的安全退出（因为当 slave 和 master 断开后，没有手段可以恢复）。 harbor.connect(id) --和 harbor.link 相反。如果 harbor id 对应的 slave 没有连接，这个 api 将阻塞，一直到它连上来才返回。 harbor.queryname(name) --可以用来查询全局名字或本地名字对应的服务地址。它是一个阻塞调用。 harbor.globalname(name, handle) --注册一个全局名字。如果 handle 为空，则注册自己。skynet.name 和 skynet.register 是用其实现的。 构建服务的一些基础接口 skynet.getenv(varName) --conf配置信息已经写入到注册表中，通过该函数获取注册表的变量值 skynet.setenv(varName, varValue) --设置注册表信息，varValue一般是number或string，但是不能设置已经存在的varname skynet.error(...) --打印函数 skynet.start(func) --用 func 函数初始化服务，并将消息处理函数注册到 C 层，让该服务可以工作。 skynet.init(func) --若服务尚未初始化完成，则注册一个函数等服务初始化阶段再执行；若服务已经初始化完成，则立刻运行该函数。 skynet.exit() --结束当前服务 skynet.self() --获取当前服务的句柄handler skynet.address(handler) --将handle转换成字符串 skynet.abort() --退出skynet进程 skynet.kill(address) ----强制杀死其他服务。可以用来强制关闭别的服务。但强烈不推荐这样做。因为对象会在任意一条消息处理完毕后，毫无征兆的退出。所以推荐的做法是，发送一条消息，让对方自己善后以及调用 skynet.exit 。注：skynet.kill(skynet.self()) 不完全等价于 skynet.exit() ，后者更安全。\t普通服务 skynet.newservice(luaServerName, ...)\t全局唯一服务 skynet.uniqueservice(servicename, ...) --当前的skynet节点全局唯一 skynet.uniqueservice(true, servicename, ...) --所有的节点全局唯一 skynet.queryservice(servicename, ...) --当前的skynet节点中查找 skynet.queryservice(true, servicename, ...) --所有的节点中查找 别名 别名分两种：\n本地别名 代表只能在当前skynet节点使用，本地别名用 .开头\n全局别名 可以在所有的skynet中使用 全局别名不能以. 开头\nskynet.register(aliasname) --给当前服务定一个别名，可以是全局别名，也可以是本地别名 skynet.name(aliasname, servicehandler) --给指定servicehandler的服务定一个别名，可以是全局别名，也可以是本地别名 --[[ 查询别名为aliasname的服务,可以是全局别名也可以是本地别名， 1、当查询本地别名时，返回servicehandler，不存在就返回nil 2、当查询全局别名时，返回servicehandler，不存在就阻塞等待到该服务初始化完成 ]]-- skynet.harbor.queryname(aliasname) skynet.localname(aliasname) --查询本地别名为aliasname的服务，返回servicehandler，不存在就返回nil skynet.kill(handle) --杀死带别名服务 服务调度 skynet.sleep(time) --让当前的任务等待 time * 0.01s 。 skynet.fork(func, ...) --启动一个新的任务去执行函数 func , 其实就是开了一个协程，函数调用完成将返回线程句柄 虽然你也可以使用原生的coroutine.create来创建协程，但是会打乱skynet的工作流程 skynet.yield() --让出当前的任务执行流程，使本服务内其它任务有机会执行，随后会继续运行。 skynet.wait() --让出当前的任务执行流程，直到用 wakeup 唤醒它。 skynet.wakeup(co) --唤醒用 wait 或 sleep 处于等待状态的任务。 skynet.timeout(time, func) --设定一个定时触发函数 func ，在 time * 0.01s 后触发。 skynet.starttime() --返回当前进程的启动 UTC 时间（秒）。 skynet.now() --返回当前进程启动后经过的时间 (0.01 秒) 。 skynet.time() --通过 starttime 和 now 计算出当前 UTC 时间（秒）。\t消息类型 #define PTYPE_TEXT 0 --文本 #define PTYPE_RESPONSE 1 --表示一个回应包 #define PTYPE_MULTICAST 2 --广播消息 #define PTYPE_CLIENT 3 --用来处理网络客户端的请求消息 #define PTYPE_SYSTEM 4 --系统消息 #define PTYPE_HARBOR 5 --集群内其他的 skynet 节点发来的消息 #define PTYPE_SOCKET 6 --套接字消息 #define PTYPE_ERROR 7 --错误消息，一般服务退出的时候会发送error消息给关联的服务 #define PTYPE_QUEUE 8 --队列方式 #define PTYPE_DEBUG 9 --调试 #define PTYPE_LUA 10 --lua类型的消息，最常用 #define PTYPE_SNAX 11 --snax服务消息 #define PTYPE_TAG_DONTCOPY 0x10000 --禁止拷贝 #define PTYPE_TAG_ALLOCSESSION 0x20000 --分配新的 session 打包解包 skynet.pack(...) --打包 skynet.unpack(msg, sz) --解包\t发送消息 -- 发送无需响应的消息 skynet.send(addr, type, ...) --用 type 类型向 addr 发送未打包的消息。该函数会自动把...参数列表进行打包，默认情况下lua消息使用skynet.pack打包。addr可以是服务句柄也可以是别名。自动打包与解包。） skynet.rawsend(addr, type, msg, sz) --用 type 类型向 addr 发送一个打包好的消息。addr可以是服务句柄也可以是别名。（需要自己打包与解包） -- 发送必须响应的消息 skynet.call(addr, type, ...) --用默认函数打包消息，向addr发送type类型的消息并等待返回响应，并对回应信息进行解包。（自动打包与解包。） skynet.rawcall(addr, type, msg, sz) --直接向addr发送type类型的msg,sz并等待返回响应，不对回应信息解包。（需要自己打包与解包） 响应消息 -- 同一个协成处理 skynet.ret() --目标服务消息处理后需要通过该函数将结果返回 skynet.retpack(...) --将消息用skynet.pack 打包，并调用 ret 回应。 --不在一个协成处理 local response = skynet.response(pack)--参数pack指定应答打包函数，不填默认使用skynet.pack, 必须根据接收到消息的打包函数一致 返回值是一个闭包函数 response(ok, ...) --参数ok的值可以是 \u0026#34;test\u0026#34;、true、false，为\u0026#34;test\u0026#34;时表示检查接收响应的服务是否存在，为true时表示发送应答PTYPE_RESPONSE，为false时表示发送PTYPE_ERROR错误消息。 消息冲入时序问题 skynet.queue() --帮助你回避这些服务重入或者伪并发引起的复杂性,但是明显降低了服务的并发处理能力，所以使用执行队列的时候尽量缩小临界区的颗粒度大小 协议转换 skynet.forward_type() --需要提供一张消息转换映射表forward_map, 其他的方法与skynet.start一样 伪造消息 skynet.redirect(dest,source,typename, session, msg, sz) --使用source服务地址，发送typename类型的消息给dest服务，不需要接收响应，（source，dest只能是服务ID）msg sz一般使用skynet.pack打包生成 组播 skynet.multicast -- 当组播的数据量较大时候可以节省内部的带宽 socket --建立一个 TCP 连接。返回一个数字 id 。 socket.open(address, port) --关闭一个连接，这个 API 有可能阻塞住执行流。因为如果有其它 coroutine --正在阻塞读这个 id 对应的连接，会先驱使读操作结束，close 操作才返回。 socket.close(id) --在极其罕见的情况下，需要粗暴的直接关闭某个连接，而避免 socket.close 的阻塞等待流程，可以使用它。 socket.close_fd(id) --强行关闭一个连接。和 close 不同的是，它不会等待可能存在的其它 coroutine 的读操作。 --一般不建议使用这个 API ，但如果你需要在 __gc 元方法中关闭连接的话， --shutdown 是一个比 close 更好的选择（因为在 gc 过程中无法切换 coroutine）。与close_fd类似 socket.shutdown(id) --[[ 从一个 socket 上读 sz 指定的字节数。 如果读到了指定长度的字符串，它把这个字符串返回。 如果连接断开导致字节数不够，将返回一个 false 加上读到的字符串。 如果 sz 为 nil ，则返回尽可能多的字节数，但至少读一个字节（若无新数据，会阻塞）。 --]] socket.read(id, sz) --从一个 socket 上读所有的数据，直到 socket 主动断开，或在其它 coroutine 用 socket.close 关闭它。 socket.readall(id) --从一个 socket 上读一行数据。sep 指行分割符。默认的 sep 为 \u0026#34;\\n\u0026#34;。读到的字符串是不包含这个分割符的。 --如果另外一端就关闭了，那么这个时候会返回一个nil，如果buffer中有未读数据则作为第二个返回值返回。 socket.readline(id, sep) --等待一个 socket 可读。 socket.block(id) --把一个字符串置入正常的写队列，skynet 框架会在 socket 可写时发送它。 socket.write(id, str) --把字符串写入低优先级队列。如果正常的写队列还有写操作未完成时，低优先级队列上的数据永远不会被发出。 --只有在正常写队列为空时，才会处理低优先级队列。但是，每次写的字符串都可以看成原子操作。 --不会只发送一半，然后转去发送正常写队列的数据。 socket.lwrite(id, str) --监听一个端口，返回一个 id ，供 start 使用。 socket.listen(address, port) --[[ accept 是一个函数。每当一个监听的 id 对应的 socket 上有连接接入的时候，都会调用 accept 函数。 这个函数会得到接入连接的 id 以及 ip 地址。你可以做后续操作。 每当 accept 函数获得一个新的 socket id 后，并不会立即收到这个 socket 上的数据。 这是因为，我们有时会希望把这个 socket 的操作权转让给别的服务去处理。accept(id, addr) ]]-- socket.start(id , accept) --[[ 任何一个服务只有在调用 socket.start(id) 之后，才可以读到这个 socket 上的数据。 向一个 socket id 写数据也需要先调用 start 。 socket 的 id 对于整个 skynet 节点都是公开的。也就是说，你可以把 id 这个数字 通过消息发送给其它服务，其他服务也可以去操作它。skynet 框架是根据调用 start 这个 api 的位置来决定把对应 socket 上的数据转发到哪里去的。 --]] socket.start(id) --清除 socket id 在本服务内的数据结构，但并不关闭这个 socket 。 --这可以用于你把 id 发送给其它服务，以转交 socket 的控制权。 socket.abandon(id) --[[ 当 id 对应的 socket 上待发的数据超过 1M 字节后，系统将回调 callback 以示警告。 function callback(id, size) 回调函数接收两个参数 id 和 size ，size 的单位是 K 。 如果你不设回调，那么将每增加 64K 利用 skynet.error 写一行错误信息。 --]] socket.warning(id, callback) socketChannel 用来支持双向传输，异步非堵塞处理数据 dns skynet.dns --调用了系统 api getaddrinfo ，有可能阻塞住整个 socket 线程 所以skynet封装了这个接口来解决dns查询时候造成的线程堵塞问题 skynet 的通信调试pack 客户端按大小端打包成二进制\nlocal result = string.pack(\u0026#34;\u0026gt;s2\u0026#34;,\u0026#34;string2pack\u0026#34;) pack \u0026gt; 表示按大端顺序。s2 表示按照2个字节打包。 我们知道string由char组成。1个char 是 0-255 之间的数，2^8 ,1char=8byte 需要注意的是，他除了被打包的部分之外，还会在前面加2个字节，表示长度。 如果要打包一个数字则需要转换。由2种办法 string.pack(\u0026#34;I2\u0026#34;,number)，会在前面二进制加2位表示长度的东西。 socket发送\nsocket.send 服务端接收\ngateserver已经有接收的代码了。 注意的是，socket会自动按pack的数据分段接收。也就是会根据pack的前面2位得到size。根据size去接收后面的数据。然后向上传递一份message。 接收到的message已经是去掉了前面2位的数据。 客户端接收\n户端接收到的数据目前我是用skynet提供的“client.socket”.没有netpack可用。 接收到的数据需要自行去除前面的2个字节的数据（string.pack产生的）。 skynet clientsocket 导致 io.read 无法正确工作的问题 https://blog.csdn.net/gneveek/article/details/78940693 ","permalink":"https://frog-game.github.io/posts/read/skynet/","summary":"linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 网络流程图 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Socket","title":"skynet赏析"},{"content":"luadebug 实现多虚拟机原理 先从luahook原理说起\n在lua.h 当中我们有 lua_sethook函数来给们设置钩子\nLUA_API void (lua_sethook) (lua_State *L, lua_Hook func, int mask, int count); lua_State *L :虚拟机的地址\nlua_Hook func:我们设定的钩子回调函数\nmask: 状态掩码可以组合操作\nLUA_MASKCALL : 调用函数时回调 LUA_MASKRET :函数返回时回调 LUA_MASKLINE :执行一行代码时候回调 LUA_MASKCOUNT :每执行count条指令时候回调 count：只有掩码包含LUA_MASKCOUNT 这个状态时候才有效果，代表执行count次才会回调一次钩子函数\nLUA_MASKCALL 会在调用函数时回调 我们在追踪lua源码，可以发现在每次调用函数之前都回ldo.c 去调用luaD_precall 函数并检测是否设置了掩码标识，如果设置了 LUA_MASKCALL掩码状态，就会调用 luaD_hook 这个回调函数\nLUA_MASKRET :会在函数返回时回调 我们在追踪lua源码，可以发现在每次函数返回时候都会去ldo.c 里面调用luaD_poscall 里面的rethook函数 如果设置了就会调用LUA_MASKRET 掩码状态 ， 就会调用 luaD_hook这个回调函数\nLUA_MASKLINE:执行一行代码时候回调 我们在追踪lua源码，可以发现在每次执行一行指令都会去ldebug.c 去调用 luaG_traceexec 函数 如果设置了LUA_MASKLINE 掩码状态 那么久会调用luaD_hook 函数\nLUA_MASKCOUNT :执行count条指令时候回调 我们在追踪lua源码，可以发现每次执行一行指令都会去ldebug.c 去调用 luaG_traceexec 函数 这个函数需要和count参数配合才能发挥效果，可以看到如果 L-\u0026gt;hookcount 在一次次递减之后等于 0 了就会调用 luaD_hook 函数\n综合上述我们看到最终都会调用到luaD_hook 函数，仔细看源码观察可以看到在经过一系列判断以后会回调我们设置好的 L-\u0026gt;hook 函数\n回到我们第**2 **个参数\n/* Functions to be called by the debugger in specific events */ typedef void(*lua_Hook) (lua_State *L, lua_Debug *ar); 可以看到返回了一个lua_Debug 结构体 我们进入这个结构体\n这里为了兼容每个不同的lua版本，弄了个**union **联合体 写在了lua_api_loder.h里面\n我们进入 lua_Debug_54 结构体里面\n可以发现这里有许多的信息\n结构变量 解释 event Event codes 事件类型标识如下几种 [LUA_HOOKCALL,LUA_HOOKRET,LUA_HOOKLINE,LUA_HOOKCOUNT,LUA_HOOKTAILCALL] name 函数名字 namewhat 作用域的含义，比如是global，local，method，field 或者\u0026quot;\u0026quot; \u0026ldquo;\u0026ldquo;代表没有找到这个函数 what \u0026lt;span style=\u0026quot;display:inline-block;width: 600px\u0026quot;\u0026gt;函数的类型 一般为\u0026quot;lua\u0026rdquo; source 函数定义的位置，如果是loadstring载入的，source是string 如果是在一个文件中source标识带有前缀的@文件名字 srclen source的长度 currentline 当前函数所在的行 linedefined 函数定义的首行地址 \u0026lt;span style=\u0026quot;display:inline-block;width: 120px\u0026quot;\u0026gt; lastlinedefined 函数定义的最后一行的行号 nups 上值的个数 nparams 参数数量 isvararg 是不是可变参数 istailcall 是不是最后一个函数是一个函数调用 形如**function f(x) return g(x) end ** ftransfer 与第一个转移值的偏移量 主要用call/return方式 ntransfer 传输的值 主要用call/return方式 short_src source 的简短表示 i_ci 记录一个函数调用涉及到的栈引用，lua在调用函数的时候会把每个callinfo用双向链表串起来 综合上述原理我们可以看到每一个lua_sethook 被调用时候通过hook返回的信息有这么多，而且每一个lua_state 都是沙盒隔离，所以我们可以利用沙盒原理，通过在进程中创建一个debuggerManager的管理器把所有生成的lua_state的指针保存在这个管理器里面，这样在每次lua调用pcall执行脚本的时候都会去触发自己相对应的lua_sethook设置的hook函数，在里面获取当时触发的时候的上表返回的信息，然后给客服端显示\nluadebug 实现修改变量值 首先需要创建一个protobuf的cmd命令\n**MessageCMD::SetVariableReq ** //修改变量\n客服端设置变量逻辑\n服务器接收到请求逻辑核心逻辑如下\n第一步: 将此lua定义check 用luaL_dostring 进行load执行\nconst char* loadstr = \u0026#34;function dlua_setvarvalue (name, frame, val, level)\\n\u0026#34; \u0026#34; local found\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; -- try local variables\\n\u0026#34; \u0026#34; local i = 1\\n\u0026#34; \u0026#34; while true do\\n\u0026#34; \u0026#34; local n, v = debug.getlocal(frame + level, i)\\n\u0026#34; \u0026#34; if not n then\\n\u0026#34; \u0026#34; break\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if n == name then\\n\u0026#34; \u0026#34; debug.setlocal(frame + level, i, val)\\n\u0026#34; \u0026#34; found = true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; i = i + 1\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if found then\\n\u0026#34; \u0026#34; return true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; -- try upvalues\\n\u0026#34; \u0026#34; local func = debug.getinfo(frame + level).func\\n\u0026#34; \u0026#34; i = 1\\n\u0026#34; \u0026#34; while true do\\n\u0026#34; \u0026#34; local n, v = debug.getupvalue(func, i)\\n\u0026#34; \u0026#34; if not n then\\n\u0026#34; \u0026#34; break\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if n == name then\\n\u0026#34; \u0026#34; debug.setupvalue(func, i, val)\\n\u0026#34; \u0026#34; return true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; i = i + 1\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; return false\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; luaL_dostring(L, loadstr); 如果是set a=1类型\nstd::string loadstr = \u0026#34;if not dlua_setvarvalue(\\\u0026#34;\u0026#34; + val + \u0026#34;\\\u0026#34;,\u0026#34; + std::to_string(currentFrameId) + \u0026#34;,\u0026#34; + input + \u0026#34;, 3\u0026#34; + \u0026#34;) then\\n\u0026#34;; loadstr += val + \u0026#34;=\u0026#34; + input + \u0026#34;\\n\u0026#34;; loadstr += \u0026#34;end\\n\u0026#34;; int status = luaL_dostring(L, loadstr.c_str()); if (status != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } 如果是set [t1] t1.a=1 类型\nstd::string loadstr = \u0026#34;function dlua_set_val(\u0026#34;; for (auto it = inputval.begin(); it != inputval.end();) { loadstr = loadstr + it-\u0026gt;first; it++; if (it != inputval.end()) { loadstr = loadstr + \u0026#34;,\u0026#34;; } } loadstr = loadstr + \u0026#34;)\\n\u0026#34; + val + \u0026#34;=\u0026#34; + input + \u0026#34;\\n\u0026#34;; loadstr = loadstr + \u0026#34;return \u0026#34;; for (auto it = inputval.begin(); it != inputval.end();) { loadstr = loadstr + it-\u0026gt;first; it++; if (it != inputval.end()) { loadstr = loadstr + \u0026#34;,\u0026#34;; } } loadstr = loadstr + \u0026#34;\\n end\\n\u0026#34;; int status = luaL_dostring(L, loadstr.c_str()); if (status != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } lua_settop(L, oldn); lua_getglobal(L, \u0026#34;dlua_set_val\u0026#34;); if (!lua_isfunction(L, -1)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, \u0026#34;get dlua_set_val fail\u0026#34;); return -1; } for (auto it = inputval.begin(); it != inputval.end(); it++) { if (!FindAndPushVal(L, it-\u0026gt;first, currentFrameId)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, (std::string(\u0026#34;can not find val \u0026#34;) + it-\u0026gt;first).c_str()); return -1; } } int ret = lua_pcall(L, inputval.size(), inputval.size(), 0); if (ret != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } int index = -inputval.size(); for (auto it = inputval.begin(); it != inputval.end(); it++) { std::string name = it-\u0026gt;first; int curoldn = lua_gettop(L); lua_getglobal(L, \u0026#34;dlua_setvarvalue\u0026#34;); if (!lua_isfunction(L, -1)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, \u0026#34;get dlua_setvarvalue fail\u0026#34;); return -1; } lua_pushstring(L, name.c_str()); lua_pushinteger(L,currentFrameId); lua_pushnil(L); lua_pushinteger(L, 2); lua_copy(L, index - 5, -2); ret = lua_pcall(L, 4, 1, 0); if (ret != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } bool suc = lua_toboolean(L, -1); if (!suc) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, (std::string(\u0026#34;dlua_setvarvalue set \u0026#34;) + name + \u0026#34; fail\u0026#34;).c_str()); return -1; } lua_settop(L, curoldn); index++; } 图片效果 真机调试 adb forward 原理 要想知道怎么真机调试我们首先应该知道adb调试的原理\n比如我现在调试安卓时候的使用的命令: adb forward tcp:8888 tcp:9966\n通过此端口转发我们就可以做到吧电脑tcp端口的消息转发到真机里面tcp9966端口上\n条件断点 条件断点分为\n1：表达式 2：命中次数\n3：日志断点\n首先需要在此结构中定义3个变量用于处理3中类型，然后通过vscode设置条件端点类型\n部分核心代码\nbool Debugger::ProcessBreakPoint(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { if (!bp-\u0026gt;condition.empty()) { auto ctx = std::make_shared\u0026lt;EvalContext\u0026gt;(); ctx-\u0026gt;expr = bp-\u0026gt;condition; ctx-\u0026gt;depth = 1; bool suc = DoEval(ctx); return suc \u0026amp;\u0026amp; ctx-\u0026gt;result-\u0026gt;valueType == LUA_TBOOLEAN \u0026amp;\u0026amp; ctx-\u0026gt;result-\u0026gt;value == \u0026#34;true\u0026#34;; } if (!bp-\u0026gt;logMessage.empty()) { DoLogMessage(bp); return false; } if (!bp-\u0026gt;hitCondition.empty()) { bp-\u0026gt;hitCount++; return DoHitCondition(bp); } return true; } bool Debugger::DoEval(std::shared_ptr\u0026lt;EvalContext\u0026gt; evalContext) { if (!currentL || !evalContext) { return false; } auto L = currentL; //auto* const L = L; // From \u0026#34;cacheId\u0026#34; if (evalContext-\u0026gt;cacheId \u0026gt; 0) { lua_getfield(L, LUA_REGISTRYINDEX, CACHE_TABLE_NAME); // 1: cacheTable|nil if (lua_type(L, -1) == LUA_TTABLE) { lua_getfield(L, -1, std::to_string(evalContext-\u0026gt;cacheId).c_str()); // 1: cacheTable, 2: value GetVariable(evalContext-\u0026gt;result, -1, evalContext-\u0026gt;depth); lua_pop(L, 2); return true; } lua_pop(L, 1); } // LOAD AS \u0026#34;return expr\u0026#34; std::string statement = \u0026#34;return \u0026#34;; statement.append(evalContext-\u0026gt;expr); int r = luaL_loadstring(L, statement.c_str()); if (r == LUA_ERRSYNTAX) { evalContext-\u0026gt;error = \u0026#34;syntax err: \u0026#34;; evalContext-\u0026gt;error.append(evalContext-\u0026gt;expr); return false; } // call const int fIdx = lua_gettop(L); // create env if (!CreateEnv(evalContext-\u0026gt;stackLevel)) return false; // setup env #ifndef EMMY_USE_LUA_SOURCE lua_setfenv(L, fIdx); #elif defined(EMMY_LUA_51) || defined(EMMY_LUA_JIT) lua_setfenv(L, fIdx); #else //52 \u0026amp; 53 lua_setupvalue(L, fIdx, 1); #endif assert(lua_gettop(L) == fIdx); // call function() return expr end r = lua_pcall(L, 0, 1, 0); if (r == LUA_OK) { evalContext-\u0026gt;result-\u0026gt;name = evalContext-\u0026gt;expr; GetVariable(evalContext-\u0026gt;result, -1, evalContext-\u0026gt;depth); lua_pop(L, 1); return true; } if (r == LUA_ERRRUN) { evalContext-\u0026gt;error = lua_tostring(L, -1); } return false; } void Debugger::DoLogMessage(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { std::string\u0026amp; logMessage = bp-\u0026gt;logMessage; // 为什么不用regex? // 因为gcc 4.8 regex还是空实现 // 而且后续版本的gcc中正则表达式行为似乎也不太正常 enum class ParseState { Normal, LeftBrace, RightBrace } state = ParseState::Normal; std::vector\u0026lt;LogMessageReplaceExpress\u0026gt; replaceExpresses; std::size_t leftBraceBegin = 0; std::size_t rightBraceBegin = 0; // 如果在表达式中出现左大括号 std::size_t exprLeftCount = 0; for (std::size_t index = 0; index != logMessage.size(); index++) { char ch = logMessage[index]; switch (state) { case ParseState::Normal: { if (ch == \u0026#39;{\u0026#39;) { state = ParseState::LeftBrace; leftBraceBegin = index; exprLeftCount = 0; } else if (ch == \u0026#39;}\u0026#39;) { state = ParseState::RightBrace; rightBraceBegin = index; } break; } case ParseState::LeftBrace: { if (ch == \u0026#39;{\u0026#39;) { // 认为是左双大括号转义为可见的\u0026#39;{\u0026#39; if (index == leftBraceBegin + 1) { replaceExpresses.emplace_back(\u0026#34;{\u0026#34;, leftBraceBegin, index, false); state = ParseState::Normal; } else { exprLeftCount++; } } else if (ch == \u0026#39;}\u0026#39;) { // 认为是表达式内的大括号 if (exprLeftCount \u0026gt; 0) { exprLeftCount--; continue; } replaceExpresses.emplace_back(logMessage.substr(leftBraceBegin + 1, index - leftBraceBegin - 1), leftBraceBegin, index, true); state = ParseState::Normal; } break; } case ParseState::RightBrace: { if (ch == \u0026#39;}\u0026#39; \u0026amp;\u0026amp; (index == rightBraceBegin + 1)) { replaceExpresses.emplace_back(\u0026#34;}\u0026#34;, rightBraceBegin, index, false); } else { //认为左右大括号失配，之前的不做处理，退格一位回去重新判断 index--; } state = ParseState::Normal; break; } } } std::stringstream message; if (replaceExpresses.empty()) { message \u0026lt;\u0026lt; logMessage; } else { // 拼接字符串 // 怎么replace 函数都没有啊 std::size_t start = 0; for (std::size_t index = 0; index != replaceExpresses.size(); index++) { auto\u0026amp; replaceExpress = replaceExpresses[index]; if (start \u0026lt; replaceExpress.StartIndex) { auto fragment = logMessage.substr(start, replaceExpress.StartIndex - start); message \u0026lt;\u0026lt; fragment; start = replaceExpress.StartIndex; } if (replaceExpress.NeedEval) { auto ctx = std::make_shared\u0026lt;EvalContext\u0026gt;(); ctx-\u0026gt;expr = std::move(replaceExpress.Expr); ctx-\u0026gt;depth = 1; bool succeed = DoEval(ctx); if (succeed) { message \u0026lt;\u0026lt; ctx-\u0026gt;result-\u0026gt;value; } else { message \u0026lt;\u0026lt; ctx-\u0026gt;error; } } else { message \u0026lt;\u0026lt; replaceExpress.Expr; } start = replaceExpress.EndIndex + 1; } if (start \u0026lt; logMessage.size()) { auto fragment = logMessage.substr(start, logMessage.size() - start); message \u0026lt;\u0026lt; fragment; } } std::string baseName = BaseName(bp-\u0026gt;file); EmmyFacade::Get().SendLog(LogType::Info, \u0026#34;[%s:%d] %s\u0026#34;, baseName.c_str(), bp-\u0026gt;line, message.str().c_str()); } bool Debugger::DoHitCondition(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { auto\u0026amp; hitCondition = bp-\u0026gt;hitCondition; enum class ParseState { ExpectedOperator, // 大于 Gt, // 小于 Le, // 单等号 Eq, ExpectedHitTimes, ParseDigit, ParseFinish } state = ParseState::ExpectedOperator; enum class Operator { // 大于 Gt, // 小于 Le, // 小于等于 LeEq, // 大于等于 GtEq, // 双等号 EqEq, } evalOperator = Operator::EqEq; unsigned long long hitTimes = 0; for (std::size_t index = 0; index != hitCondition.size(); index++) { char ch = hitCondition[index]; switch (state) { case ParseState::ExpectedOperator: { if (ch == \u0026#39; \u0026#39;) { continue; } if (ch == \u0026#39;=\u0026#39;) { state = ParseState::Eq; } else if (ch == \u0026#39;\u0026lt;\u0026#39;) { state = ParseState::Le; } else if (ch == \u0026#39;\u0026gt;\u0026#39;) { state = ParseState::Gt; } else { return false; } break; } case ParseState::Eq: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::EqEq; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::Gt: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::GtEq; state = ParseState::ExpectedHitTimes; } else if (isdigit(ch)) { evalOperator = Operator::Gt; hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else if (ch == \u0026#39; \u0026#39;) { evalOperator = Operator::Gt; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::Le: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::LeEq; state = ParseState::ExpectedHitTimes; } else if (isdigit(ch)) { evalOperator = Operator::Le; hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else if (ch == \u0026#39; \u0026#39;) { evalOperator = Operator::Gt; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::ExpectedHitTimes: { if (ch == \u0026#39; \u0026#39;) { continue; } else if (isdigit(ch)) { hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else { return false; } break; } case ParseState::ParseDigit: { if (isdigit(ch)) { hitTimes = hitTimes * 10 + (ch - \u0026#39;0\u0026#39;); } else if (ch == \u0026#39; \u0026#39;) { state = ParseState::ParseFinish; } else { return false; } break; } case ParseState::ParseFinish: { if (ch == \u0026#39; \u0026#39;) { break; } else { return false; } break; } } } switch (evalOperator) { case Operator::EqEq: { return bp-\u0026gt;hitCount == hitTimes; } case Operator::Gt: { return bp-\u0026gt;hitCount \u0026gt; hitTimes; } case Operator::GtEq: { return bp-\u0026gt;hitCount \u0026gt;= hitTimes; } case Operator::Le: { return bp-\u0026gt;hitCount \u0026lt; hitTimes; } case Operator::LeEq: { return bp-\u0026gt;hitCount \u0026lt;= hitTimes; } } return false; } 视频效果展示 多虚拟机测试 linux测试 真机测试 插件下载地址 针对skynet这种微服器框架和自己从 0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店进行\n下载使用，有任何问题可以加QQ私聊\n","permalink":"https://frog-game.github.io/posts/blog/vscode-lua-chajian/","summary":"luadebug 实现多虚拟机原理 先从luahook原理说起 在lua.h 当中我们有 lua_sethook函数来给们设置钩子 LUA_API void (lua_sethook) (lua_State *L, lua_Hook func, int mask, int count); lua_State *L :虚拟机","title":"微服务lua调试器"},{"content":"在service_snlua.c 中增加此函数 void addLuaState(struct snlua *l,const char *debug_ip,const char * debug_port) { if (NULL == debug_ip) { return; } if (NULL == debug_port) { return; } int port = strtol(debug_port, NULL, 10); const char *lua_dofunction = \u0026#34;function snlua_addLuaState()\\n\u0026#34; \u0026#34;local dbg = require(\u0026#39;frog_debug\u0026#39;)\\n\u0026#34; \u0026#34;dbg.startDebugServer(\u0026#39;%s\u0026#39;, %d)\\n\u0026#34; \u0026#34;dbg.addLuaState()\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; char loadstr[200]; sprintf(loadstr, lua_dofunction, debug_ip, port); int oldn = lua_gettop(l-\u0026gt;L); int status = luaL_dostring(l-\u0026gt;L, loadstr); if (status != 0) { const char *ret = lua_tostring(l-\u0026gt;L, -1); lua_settop(l-\u0026gt;L, oldn); skynet_error(l-\u0026gt;ctx, \u0026#34;[ERROR] addLuaState lua_tostring error!! err:%s\u0026#34;, ret); return; } lua_getglobal(l-\u0026gt;L, \u0026#34;snlua_addLuaState\u0026#34;); if (!lua_isfunction(l-\u0026gt;L, -1)) { const char *ret = lua_tostring(l-\u0026gt;L, -1); lua_settop(l-\u0026gt;L, oldn); skynet_error( l-\u0026gt;ctx, \u0026#34;[ERROR] addLuaState lua_getglobal addLuaState error!! err:%s\u0026#34;, ret); return; } status = lua_pcall(l-\u0026gt;L, 0, 0, 0); if (status != 0) { const char *ret = lua_tostring(l-\u0026gt;L, -1); lua_settop(l-\u0026gt;L, oldn); skynet_error(l-\u0026gt;ctx, \u0026#34;[ERROR] addLuaState lua_pcall addLuaState error!! err:%s\u0026#34;, ret); return; } } 将addLuaState函数插入到service_snlua.c对应位置 static int init_cb(struct snlua *l, struct skynet_context *ctx, const char * args, size_t sz) { lua_State *L = l-\u0026gt;L; l-\u0026gt;ctx = ctx; lua_gc(L, LUA_GCSTOP, 0); lua_pushboolean(L, 1); /* signal for libraries to ignore env. vars. */ lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;LUA_NOENV\u0026#34;); luaL_openlibs(L); luaL_requiref(L, \u0026#34;skynet.profile\u0026#34;, init_profile, 0); int profile_lib = lua_gettop(L); // replace coroutine.resume / coroutine.wrap lua_getglobal(L, \u0026#34;coroutine\u0026#34;); lua_getfield(L, profile_lib, \u0026#34;resume\u0026#34;); lua_setfield(L, -2, \u0026#34;resume\u0026#34;); lua_getfield(L, profile_lib, \u0026#34;wrap\u0026#34;); lua_setfield(L, -2, \u0026#34;wrap\u0026#34;); lua_settop(L, profile_lib-1); lua_pushlightuserdata(L, ctx); lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;skynet_context\u0026#34;); luaL_requiref(L, \u0026#34;skynet.codecache\u0026#34;, codecache , 0); lua_pop(L,1); lua_gc(L, LUA_GCGEN, 0, 0); const char *path = optstring(ctx, \u0026#34;lua_path\u0026#34;,\u0026#34;./lualib/?.lua;./lualib/?/init.lua\u0026#34;); lua_pushstring(L, path); lua_setglobal(L, \u0026#34;LUA_PATH\u0026#34;); const char *cpath = optstring(ctx, \u0026#34;lua_cpath\u0026#34;,\u0026#34;./luaclib/?.so\u0026#34;); lua_pushstring(L, cpath); lua_setglobal(L, \u0026#34;LUA_CPATH\u0026#34;); const char *service = optstring(ctx, \u0026#34;luaservice\u0026#34;, \u0026#34;./service/?.lua\u0026#34;); lua_pushstring(L, service); lua_setglobal(L, \u0026#34;LUA_SERVICE\u0026#34;); const char *preload = skynet_command(ctx, \u0026#34;GETENV\u0026#34;, \u0026#34;preload\u0026#34;); lua_pushstring(L, preload); lua_setglobal(L, \u0026#34;LUA_PRELOAD\u0026#34;); lua_pushcfunction(L, traceback); assert(lua_gettop(L) == 1); const char * loader = optstring(ctx, \u0026#34;lualoader\u0026#34;, \u0026#34;./lualib/loader.lua\u0026#34;); int r = luaL_loadfile(L,loader); if (r != LUA_OK) { skynet_error(ctx, \u0026#34;Can\u0026#39;t load %s : %s\u0026#34;, loader, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; } lua_pushlstring(L, args, sz); r = lua_pcall(L,1,0,1); if (r != LUA_OK) { skynet_error(ctx, \u0026#34;lua loader error : %s\u0026#34;, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; } lua_settop(L,0); if (lua_getfield(L, LUA_REGISTRYINDEX, \u0026#34;memlimit\u0026#34;) == LUA_TNUMBER) { size_t limit = lua_tointeger(L, -1); l-\u0026gt;mem_limit = limit; skynet_error(ctx, \u0026#34;Set memory limit to %.2f M\u0026#34;, (float)limit / (1024 * 1024)); lua_pushnil(L); lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;memlimit\u0026#34;); } lua_pop(L, 1); addLuaState(l, optstring(ctx, \u0026#34;debug_ip\u0026#34;, NULL), optstring(ctx, \u0026#34;debug_port\u0026#34;, NULL));//调用函数放到这里 lua_gc(L, LUA_GCRESTART, 0); return 0; } 去vscode插件商场下载此插件并安装 远程调试 用everthing 找到 frog_debug.so 然后放到luaclib目录下上传到服务器 在config里面加上两个字段 debug_ip = \u0026#34;127.0.0.1\u0026#34; debug_port = \u0026#34;9966\u0026#34; 重编skynet代码 cd skynet make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 在vscode上按如下填写 创建launch.json文件 { // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;lua_remote\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;远程调试\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 9966, \u0026#34;ext\u0026#34;: [ \u0026#34;.lua\u0026#34;, \u0026#34;.lua.txt\u0026#34;, \u0026#34;.lua.bytes\u0026#34; ], \u0026#34;ideConnectDebugger\u0026#34;: true } ] } 我用的是wsl2,直接到你的skynet目录下启动 如果嫌弃麻烦,可以在github直接下载example example地址:https://github.com/frog-game/skynet-blueprint-debug.git\n然后按 6到8步骤执行就可以进行调试了\n利用nc命令调试skynet debug_console演示 调试展示 启动进程调试方法 ","permalink":"https://frog-game.github.io/posts/tech/vscode-chajian-zhidao/","summary":"在service_snlua.c 中增加此函数 void addLuaState(struct snlua *l,const char *debug_ip,const char * debug_port) { if (NULL == debug_ip) { return; } if (NULL == debug_port) { return; } int port = strtol(debug_port, NULL, 10); const char *lua_dofunction = \u0026#34;function snlua_addLuaState()\\n\u0026#34; \u0026#34;local dbg = require(\u0026#39;frog_debug\u0026#39;)\\n\u0026#34; \u0026#34;dbg.startDebugServer(\u0026#39;%s\u0026#39;, %d)\\n\u0026#34; \u0026#34;dbg.addLuaState()\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; char loadstr[200]; sprintf(loadstr,","title":"skynet-blueprint-debug lua多虚拟机调试"},{"content":" 演示\n安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana\nzabbix 6.0 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-sql-scripts zabbix-agent 创建初始数据库 mysql -uroot -p123456 mysql\u0026gt; create database zabbix character set utf8mb4 collate utf8mb4_bin; mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@`%`; mysql\u0026gt; quit; 导入初始架构和数据，系统将提示您输入新创建的密码[默认密码现在设置为 123456 zcat /usr/share/doc/zabbix-sql-scripts/mysql/server.sql.gz | mysql -uzabbix -p -h10.40.38.67 zabbix # 指定本地的IP地址，不默认就会指向本地localhost 如果报ERROR 2003 (HY000): Can't connect to MySQL server on '10.40.38.67:3306' (111) 看第5章mysql操作指导，多半是因为权限和密码问题\n为Zabbix server配置数据库 sudo vim /etc/zabbix/zabbix_server.conf 修改 DBPassword=123456 启动Zabbix server和agent进程 sudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server sudo systemctl enable zabbix-server zabbix-agent apache2 grafana-server 连接web前端[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http://10.40.38.67/zabbix 默认的用户名是Admin(A是大写)，Password：zabbix 修改时区 sudo vi /etc/apache2/conf-enabled/zabbix.conf 修改标准时区为 Asia/Shanghai 中文显示 sudo apt install language-pack-zh-hans #安装中文语言包 sudo vim /etc/locale.gen #找到zh_CN.UTF-8 UTF-8 并取消#号注释，然后保存并退出 sudo locale-gen #编译语言包 sudo vim /etc/default/locale #修改默认语言为中文，将原来的内容改为 LANG=zh_CN.UTF-8 安装出现的问题 Minimum required size of PHP post is 16M (configuration option \u0026ldquo;post_max_size\u0026rdquo;). 解决步骤：\nsudo vi /etc/php/8.1/apache2/php.ini post_max_size8M 16M\nmax_execution_time30 300\nmax_input_time60 300\ndate.timezone = Asia/Shanghai\nsudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server ERROR 1396 (HY000): Operation CREATE USER failed for 'zabbix'@'%' mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; ERROR 1396 (HY000): Operation CREATE USER failed for \u0026#39;zabbix\u0026#39;@\u0026#39;%\u0026#39; 原因分析：\n已经存在了zabbix用户 在执行删除zabbix用户的时候没有删除干净 解决方法：\n重新进行删除。\ndrop user zabbix@\u0026#39;%\u0026#39;; flush privileges; 卸载 zabbix 删除软件\nsudo apt-get --purge remove zabbix-server-mysql -y sudo apt-get autoremove zabbix-server-mysql -y sudo apt-get --purge remove zabbix-frontend-php -y sudo apt-get autoremove zabbix-frontend-php -y sudo apt-get --purge remove abbix-apache-conf -y sudo apt-get autoremove abbix-apache-conf -y sudo apt-get --purge remove zabbix-agent -y #删除软件其配置 sudo apt-get autoremove zabbix-agent -y #删除软件依赖包 清理数据\nsudo dpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 删除以上apt-get下载的软件包\nsudo apt-get autoclean 删除缓存的所有软件包\nsudo apt-get clean 删除其他软件依赖的但现在已不用的软件包（保留配置文件）\nsudo apt-get autoremove 查询出冗余文件并删除\nsudo find / -name zabbix 执行rm-rf 删除冗余文件\nsudo rm -rf /run/zabbix sudo rm -rf /etc/zabbix sudo rm -rf /usr/share/zabbix sudo rm -rf /var/log/zabbix sudo rm -rf /var/lib/mysql/zabbix 删除包含zabbix关键字的文件或者文件夹\nsudo find / -name \u0026#34;zabbix*\u0026#34; | sudo xargs rm -rf grafana 下载grafana deb安装包 sudo apt-get install -y adduser libfontconfig1 sudo wget https://dl.grafana.com/enterprise/release/grafana-enterprise_8.5.4_amd64.deb sudo dpkg -i grafana-enterprise_8.5.4_amd64.deb 启动grafana-server sudo systemctl restart grafana-server sudo systemctl enable grafana-server 安装zabbix插件 grafana-cli plugins list-remote sudo grafana-cli plugins install alexanderzobnin-zabbix-app #重启grafana-server sudo systemctl restart grafana-server 也可以在grafana-\u0026gt;plugins这里安装\n登录grafana服务器[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http:/10.40.38.67:3000/ #默认用户名和密码为admin、admin grafana 配置zabbix数据源 grafana 配置zabbix监控面板 在点击完new dashboard 按钮以后 按ctrl + s 保存一个自己定义的仪表盘\ngrafana增加主题 安装插件：grafana-cli plugins install yesoreyeram-boomtheme-panel grafana主题地址：https://github.com/charles1503/grafana-theme/tree/master/CSS/themes/grafanas grafana更改主题教程：https://www.bilibili.com/read/cv7004400 视频教程：https://cloud.tencent.com/developer/video/11330 http://10.40.38.67:3000/public/themes/aquamarine.css 具体操作步骤：\n创建一个目录，用于存放下载对应主题的css文件\nsudo mkdir /usr/share/grafana/public/themes/ cd /usr/share/grafana/public/themes/ 使用一个for 循环下载对应的所有主题css文件\nfor f in grafana-base.css aquamarine.css hotline.css dark.css plex.css space-gray.css organizr-dashboard.css;do wget https://raw.githubusercontent.com/505384662/grafana-theme/master/CSS/themes/grafana/$f;done 为Grafana安装社区插件Boom Theme\nsudo grafana-cli plugins install yesoreyeram-boomtheme-panel sudo systemctl restart grafana-server 在Dashboard中添加Boom Theme\ngrafana 主题修改地址 cd /usr/share/grafana/public/themes grafana 加时钟 grafana-cli plugins install grafana-clock-panel systemctl restart grafana-server grafana flowcharting安装 sudo grafana-cli plugins install agenty-flowcharting-panel sudo systemctl restart grafana-server grafana 修改模板地址 https://grafana.com/grafana/dashboards zabbix 修改配置地址：http://192.168.70.130/zabbix/setup.php zabbix 展示地址：http://192.168.70.130/zabbix/zabbix.php?action=dashboard.view grafana 展示地址: http://192.168.70.130:3000/d/tYxzFya7z/test_zabbix?orgId=1 Grafana 匿名访问（免登录） 修改Grafana配置文件\n在Grafana的配置文件 /etc/grafana/grafana.ini 中，找到 [auth.anonymous] 配置块，将其下的匿名访问控制 enabled 设置为 true，组织权限设置为 Viewer\nViewer:**只读**模式\nEditor:**可编辑**模式\nAdmin:**管理员**模式\n#################################### Anonymous Auth ###################### # Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false disable_login_form = true [auth.anonymous] # enable anonymous access enabled = true # specify organization name that should be used for unauthenticated users org_name = Main Org. # specify role for unauthenticated users org_role = Viewer 重启Grafana服务\n修改完配置文件，重启Grafana服务，命令如下：\nsudo systemctl restart grafana-server 卸载 grafana 查找到安装软件名\nsudo dpkg -l | grep grafana 删除软件\nsudo dpkg -r grafana-enterprise 查询出冗余文件并删除\nfind / -name grafana 用rm-rf 命令删除\nrm -rf /etc/grafana rm -rf /usr/share/grafana rm -rf /usr/share/grafana/public/themes/grafana-theme/CSS/themes/grafana rm -rf /var/log/grafana rm -rf /var/lib/grafana apache2 apache2启动报错 大致意思没有导入apache 环境变量 解决办法:\nsource /etc/apache2/envvars 还是报错\n大致意思是80端口被占用了 我选择的方法是kill占用进程在重启\nroot@hls:/root# netstat -lnp|grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 950/nginx: master p tcp6 0 0 :::80 :::* LISTEN 950/nginx: master p unix 2 [ ACC ] STREAM LISTENING 41930 1228/zabbix-plugin_ /tmp/plugin835680808 root@hls:/root# kill -9 950 root@hls:/root# systemctl restart zabbix-server zabbix-agent apache2 卸载apache2 删除软件\n//1. 删除apache sudo apt-get --purge remove apache2 sudo apt-get --purge remove apache2.2-common //2.找到没有删除掉的配置文件，一并删除 sudo find /etc -name \u0026#34;*apache*\u0026#34; |xargs rm -rf sudo rm -rf /var/www sudo rm -rf /etc/libapache2-mod-jk //3.删除关联，这样就可以再次用apt-get install apache2 重装了 #dpkg -l |grep apache2|awk \u0026#39;{print $2}\u0026#39;|xargs dpkg -P//注意：这一步可能会报错，但也没关系 查询出冗余文件并删除\nsudo find / -name apache2 用rm -rf 命令删除\nNginx 官网下载地址 http://nginx.org/en/download.html 一些环境准备 安装编译工具\nsudo apt-get install build-essential 安装编译工具 安装gcc什么的好便于下面编译安装 安装pcre包\nsudo apt-get update sudo apt-get install libpcre3 libpcre3-dev sudo apt-get install openssl libssl-dev 安装 zlib 库\nsudo apt install zlib1g-dev 下载安装Nginx sudo wget http://nginx.org/download/nginx-1.21.6.tar.gz sudo tar -xzvf nginx-1.21.6.tar.gz cd nginx-1.21.6 sudo ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-stream --with-mail=dynamic #最好用 --prefix指定路径，便于后面删除[只需要删除prefix指定的文件夹就行了]，不指定的话后面删除比较麻烦 sudo make sudo make install 制作软连接 ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 配置环境变量 编辑/etc/profile并且追加Nginx的环境变量 # nginx export NGINX_HOME=/usr/local/nginx export PATH=$PATH:$NGINX_HOME/sbin 生效环境变量 source /etc/profile 测试是否安装成功 nginx -v 启动Nginx sudo nginx 强制停止Nginx sudo pkill -9 nginx 查看Nginx进程 ps aux|grep nginx 配置防火墙 sudo ufw allow \u0026#39;Nginx Full\u0026#39; 验证防火墙是否允许 出现下面两种情况都认为可以 Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere Nginx Full ALLOW Anywhere 22/tcp (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) sudo ufw status 状态：不活动 测试访问 http://192.168.70.132:7000 Nginx 相关文件位置 nginx path prefix: \u0026#34;/usr/local/nginx\u0026#34; nginx binary file: \u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; nginx modules path: \u0026#34;/usr/local/nginx/modules\u0026#34; nginx configuration prefix: \u0026#34;/usr/local/nginx/conf\u0026#34; nginx configuration file: \u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; nginx pid file: \u0026#34;/usr/local/nginx/logs/nginx.pid\u0026#34; nginx error log file: \u0026#34;/usr/local/nginx/logs/error.log\u0026#34; nginx http access log file: \u0026#34;/usr/local/nginx/logs/access.log\u0026#34; nginx http client request body temporary files: \u0026#34;client_body_temp\u0026#34; nginx http proxy temporary files: \u0026#34;proxy_temp\u0026#34; nginx http fastcgi temporary files: \u0026#34;fastcgi_temp\u0026#34; nginx http uwsgi temporary files: \u0026#34;uwsgi_temp\u0026#34; nginx http scgi temporary files: \u0026#34;scgi_temp\u0026#34; 卸载 Nginx sudo rm -rf /usr/local/nginx sudo rm -rf /usr/local/nginx/sbin/nginx #软连接也记得删除 如果想完全干净，/etc/profile 配置文件中指定的环境变量也可以删除 mysql 安装mysql sudo apt update sudo apt install mysql-server 安装完成后，MySQL服务将自动启动。要验证MySQL服务器正在运行，请输入：\nsudo systemctl status mysql 彻底卸载mysql方法 查看依赖包\ndpkg --list | grep mysql 先依次执行以下命令\nsudo apt-get remove mysql-common sudo apt-get autoremove --purge mysql-server-5.0 # 卸载 MySQL 5.x 使用, 非5.x版本可跳过该步骤 sudo apt-get autoremove --purge mysql-server 然后再用\ndpkg --list | grep mysql 查看一下依赖包最后用下面命令清除残留数据\ndpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 查看从MySQL APT安装的软件列表, 执行后没有显示列表, 证明MySQL服务已完全卸载\ndpkg -l | grep mysql | grep i 博客地址\nhttps://blog.csdn.net/PY0312/article/details/89481421 MySQL在Ubuntu上启动出错Could not open ‘abstractions/mysql‘ rm -rf /etc/apparmor.d/abstractions/mysql rm -rf /etc/apparmor.d/cache/usr.sbin.mysqld find / -name \u0026#39;mysql*\u0026#39; -exec rm -rf {} \\; 连接MySql报错“can\u0026rsquo;t connect to local mysql server through socket \u0026lsquo;/var/run/mysqld/mysqld.sock\u0026rsquo; cd /etc/init.d sudo service mysql stop sudo service mysql start mysql Ubuntu 20.04 Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost 首先输入以下指令 获取密码：\nsudo cat /etc/mysql/debian.cnf 再输入以下指令进入mysql\n查询user关键字段\nselect user, authentication_string,plugin,Host from mysql.user; 修改密码格式\nuse mysql; update user set plugin=\u0026#39;mysql_native_password\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 修改密码\nuse mysql; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; flush privileges; 输入\nmysql -uroot -p123456; 查看效果\n让别的ip能连上wsl数据库\nuse mysql; update user set Host=\u0026#39;%\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 输入\nselect user, authentication_string,plugin,Host from mysql.user; 查看效果\n开启远程访问\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf # 注释 bind-address = 127.0.0.1 重启mysql\nsudo service mysql restart 效果\nELK 一些准备 官网地址 https://www.elastic.co/guide/en/elasticsearch/reference/8.0/deb.html#deb-repo 虚拟机 想要多开最好是克隆一份出来 比如2就是克隆的1的镜像\n修改 克隆的虚拟机网卡地址\nsudo vim /etc/netplan/00-installer-config.yaml 修改内容:\nnetwork: ethernets: ens33: #配置的网卡的名称 addresses: [192.168.70.130/24] #配置的静态ip地址和掩码 dhcp4: no #关闭DHCP，如果需要打开DHCP则写yes optional: true gateway4: 192.168.70.2 #网关地址 nameservers: addresses: [192.168.70.2,114.114.114.114] #DNS服务器地址，多个DNS服务器地址需要用英文逗号分隔开 version: 2 renderer: networkd #指定后端采用systemd-networkd或者Network Manager，可不填写则默认使用systemd-workd 使配置生效\nsudo netplan apply 注意事项\n1、ip地址和DNS服务器地址需要用[]括起来，但是网关地址不需要 2、注意每个冒号后边都要先加一个空格 3、注意每一层前边的缩进，至少比上一层多两个空格 安装java环境 安装java\nsudo apt install openjdk-8-jdk 查看java 版本\nsudo java -version 查看 java 路径\nsudo which java ls -l /usr/bin/java 看看这是否是个软连接，找出这个软连接指向的路径\nls -l /usr/bin/java 的确为软连接，继续往下找指向的路径\n至此，java 的安装路径即为 /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n配置 java 环境\nsudo vim /etc/profile 在弹出的 vim 编辑器中输入\n# JAVA JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH esc 退出编辑模式，输入 :x后，单击回车退出。\n在终端输入\nsource /etc/profile 使之前的配置生效。\n验证\njava -version\n$JAVA_HOME/bin/java -version\npython3 [不是必须装主要是想使用 json.tool 格式化输出]\n安装python3.8\nsudo apt-get install python3.8 建立软连接\nsudo ln -s /usr/bin/python3.8 /usr/bin/python 如果想要删除软连接\nsudo rm -rf /usr/bin/python 格式化输出\ncurl -XGET http://192.168.70.131:9200/_mapping | python -m json.tool Elasticsearch 基础知识 和关系型数据库的比较 DBMS Elasticsearch database Index table type(在7.0之后type为固定值_doc) Row Document Column Field Schema Mapping SQL DSL(Descriptor Structure Language) 安装Elasticsearch deb包安装方式\nsudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb sudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb.sha512 shasum -a 512 -c elasticsearch-8.2.2-amd64.deb.sha512 sudo dpkg -i elasticsearch-8.2.2-amd64.deb 执行**sudo dpkg -i elasticsearch-8.2.2-amd64.deb** 回生成超级用户密码 0NgzdrlHquc1YdXrQout\n--------------------------- Security autoconfiguration information ------------------------------ Authentication and authorization are enabled. TLS for the transport and HTTP layers is enabled and configured. The generated password for the elastic built-in superuser is : 0NgzdrlHquc1YdXrQout If this node should join an existing cluster, you can reconfigure this with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token \u0026lt;token-here\u0026gt;\u0026#39; after creating an enrollment token on your existing cluster. You can complete the following actions at any time: Reset the password of the elastic built-in superuser with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\u0026#39;. Generate an enrollment token for Kibana instances with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\u0026#39;. Generate an enrollment token for Elasticsearch nodes with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\u0026#39;. ------------------------------------------------------------------------------------------------- 生成 ca 、生成 证书\n# 生成 ca # 根据提示： # 输入 ca 的密码（密码不要忘记，后面生成证书需要） # 输入生成 ca 的文件名（默认会让你输入 elastic-stack-ca.p12，这里就按照默认的来） sudo /usr/share/elasticsearch/bin/elasticsearch-certutil ca # 生成证书 # 根据提示： # 输入之前 ca 的密码 # 输入生成证书的文件名（默认让你输入 elastic-certificates.p12，这里就按照默认的来） # 输入生成证书的密码（密码不要忘记，这个密码在配置 ES keystore 的时候需要） # --ca 后面的文件是上面步骤生成的 elastic-stack-ca.p12 文件，如果修改了的话，这里也需要修改 sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 ​\t为了方便管理，一般将 ca 与证书放到 ~/.config/certs 目录下\n# 创建目录并移动 ca 与证书 sudo mkdir -p ~/.config/certs \u0026amp;\u0026amp; sudo mv /usr/share/elasticsearch/elastic-stack-ca.p12 /usr/share/elasticsearch/elastic-certificates.p12 ~/.config/certs 启动 Elasticsearch ​\t[为了安全考虑Elasticsearch不允许使用root用户来启动]\n打开 elasticsearch 配置文件\nsudo vim /etc/elasticsearch/elasticsearch.yml #打开配置文件 修改 netWork.host, http.port 字段\nnetwork.host: 10.40.38.66 #注意 network.host:和10.40.38.66 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 http.port: 9200 #注意 http.port:和9200 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 因为是内网测试暂时关闭 xpack 安全验证方面选项,以后需要再去开启\n启动Elasticsearch\nsudo systemctl start elasticsearch.service 开机启动elasticsearch\nsudo systemctl enable elasticsearch.service 连接grafana Elasticsearch 操作命令 用jps命令关闭Elasticsearch\n$ jps | grep Elasticsearch 14542 Elasticsearch kill -9 14542 查看 Elasticsearch 端口\nsudo netstat -tnlp |grep java 检测是否启动成功\ncurl -XGET \u0026#39;http://192.168.70.131:9200/\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; 用journal 查看系统日志\nsudo journalctl -f 用 journal 查看elasticsearch 服务日志\nsudo journalctl --unit elasticsearch 用journal 查看elasticsearch 指定时间范围的日志\nsudo journalctl --unit elasticsearch --since \u0026#34;2022-02-01 18:17:16\u0026#34; 查看 elasticsearch.log\nsudo vim /var/log/elasticsearch/elasticsearch.log Elasticsearch 卸载 # 查看安装的软件 sudo dpkg -l | grep elasticsearch #查看安装关联 sudo dpkg -L elasticsearch #移除安装软件 sudo dpkg -P elasticsearch #继续查看未卸载的目录和文件 sudo find / -name elasticsearch #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/elasticsearch.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/log/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /usr/share/elasticsearch #在此查看是否有关联的目录和文件 sudo find / -name elasticsearch Logstash 安装 Logstash 下载安装公共签名\nsudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Elasticsearch了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install logstash 插件地址 https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html 配置表字段解释 https://blog.csdn.net/weixin_42073629/article/details/110154037?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-110154037.pc_agg_new_rank\u0026amp;utm_term=logstash%E5%8F%82%E6%95%B0convert\u0026amp;spm=1000.2123.3001.4430 查看安装的插件 sudo /usr/share/logstash/bin/logstash-plugin list 启动Lostash 修改 logstash.yml 配置\nsudo vim /etc/logstash/logstash.yml 导入数据[利用logstash 直接分析movies.csv 传送给elasticsearch方式] ​\t收集流程: movies.csv-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n下载ml-latest.zip 数据\nsudo wget https://files.grouplens.org/datasets/movielens/ml-latest.zip 解压 ml-latest.zip\nsudo unzip ml-latest.zip 在/etc/logstash 目录下创建logstash.conf 文件\nsudo vim /etc/logstash/logstash.conf 把以下内容写入logstash.conf\ninput { file { #监听文件的路径 path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/movies.csv\u0026#34; #监听文件的起始位置，默认是end start_position =\u0026gt; \u0026#34;beginning\u0026#34; #监听文件读取信息记录的位置 sincedb_path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/db_path.log\u0026#34; } } filter { csv { separator =\u0026gt; \u0026#34;,\u0026#34; columns =\u0026gt; [\u0026#34;id\u0026#34;,\u0026#34;content\u0026#34;,\u0026#34;genre\u0026#34;,\u0026#34;@timestamp\u0026#34;] } mutate { # split =\u0026gt; { \u0026#34;genre\u0026#34; =\u0026gt; \u0026#34;|\u0026#34; } # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;] #删除无用字段 } mutate { split =\u0026gt; [\u0026#34;content\u0026#34;, \u0026#34;(\u0026#34;] #左括号分割 add_field =\u0026gt; { \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;%{[content][0]}\u0026#34;} #增加字段 add_field =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;%{[content][1]}\u0026#34;} #增加字段 } mutate { convert =\u0026gt; { #year 转换成整型 \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;integer\u0026#34; } strip =\u0026gt; [\u0026#34;title\u0026#34;] #去掉字段首尾的空格 # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;,\u0026#34;content\u0026#34;] #删除无用字段 } } output { elasticsearch { # 双引号中的内容为ES的地址，视实际情况而定 hosts =\u0026gt; \u0026#34;http://192.168.70.131:9200\u0026#34; index =\u0026gt; \u0026#34;movies\u0026#34; document_id =\u0026gt; \u0026#34;%{id}\u0026#34; #docId 等价于_id 字段 } stdout {} } 如果需要重新导入，先删除db_path.log 文件\nsudo rm -rf /var/lib/logstash/.lock sudo rm -rf /home/hls/downs/ml-latest/db_path.log sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf 报错\n执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults 那么就创建软连接\ncd /usr/share/logstash sudo ln -s /etc/logstash ./config 执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nLogstash could not be started because there is already another instance using the configured data directory. If you wish to run multiple instances, you must change the \u0026#34;path.data\u0026#34; setting. 那么就去 logstash.yml 中path.data 指定的路径上去删除.lock文件\ncd /var/lib/logstash sudo ls -a sudo rm -rf .lock 或者直接一句话\nsudo rm -rf /var/lib/logstash/.lock 强制查看输出 logstash.conf 修改成你自己的文件 sudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --verbose --debug 查看数据 用Kibana的命令行工具执行 GET _cat/indices 命令，就能看见导入到Elasticsearch的索引\n用kibana的命令行工具执行**GET /lua_cpu_monitor-2022.06.03/_search**命令,就能看见导入到Elasticsearch的数据\n自动重新加载配置命令 logstash.conf 修改成你自己的文件\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.automatic 默认检测时间是**3**秒 可以通过下列命令修改 把\u0026lt;\u0026gt;号里面的2换成你想要的时间\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.interval \u0026lt;2\u0026gt; 卸载Logstash # 查看安装的软件 sudo dpkg -l | grep logstash #查看安装关联 sudo dpkg -L logstash #移除安装软件 sudo dpkg -P logstash #继续查看未卸载的目录和文件 sudo find / -name logstash #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/logstash \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/logstash.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/logstash \u0026amp;\u0026amp; sudo rm -rf /var/log/logstash \u0026amp;\u0026amp; sudo rm -rf /usr/share/logstash #在此查看是否有关联的目录和文件 sudo find / -name logstash Kibana 安装Kibana 下载安装公共签名\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Kibana了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install kibana 启动Kibana 打开kibana.yml 文档\nsudo vim /etc/kibana/kibana.yml 修改 server.port,server.host 字段\n启动\nsudo systemctl start kibana.service 自启动\nsudo systemctl enable kibana.service 查看 kibana日志\nsudo vim /var/log/kibana 用谷歌或者微软自带浏览器打开地址\nhttp://10.40.38.66:5601 卸载Kibana # 查看安装的软件 sudo dpkg -l | grep kibana #查看安装关联 sudo dpkg -L kibana #移除安装软件 sudo dpkg -P kibana #继续查看未卸载的目录和文件 sudo find / -name kibana #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/kibana \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/kibana.* \u0026amp;\u0026amp; sudo rm -rf /etc/kibana #在此查看是否有关联的目录和文件 sudo find / -name kibana Filebeat 搭配filebeat主要使用收集nginx数据, 和上面的利用logstash解析movies.csv，然后收集数据给elasticsearch的方式不一样\n收集流程: nginx-\u0026gt;filebeat-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n安装Filebeat sudo curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.2.2-amd64.deb sudo dpkg -i filebeat-8.2.2-amd64.deb 修改 filebat.yml 配置文件 sudo vim /etc/filebeat/filebeat.yml 修改下列几项\n# ============================== Filebeat inputs =============================== filebeat.inputs: - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_cpu_monitor.log tags: [\u0026#34;lua_cpu_monitor_log\u0026#34;] - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_mem_monitor.log tags: [\u0026#34;lua_mem_monitor_log\u0026#34;] # ============================== Filebeat modules ============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 1 # ------------------------------ Logstash Output ------------------------------- output.logstash: # The Logstash hosts hosts: [\u0026#34;10.40.38.66:5555\u0026#34;] # ================================= Processors ================================= processors: - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 测试filebeat启动后，查看相关输出信息 sudo filebeat -e -c /etc/filebeat/filebeat.yml -d \u0026#34;publish\u0026#34; 后台方式启动filebeat nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; #将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出 nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt; filebeat.log \u0026amp; 停止filebeat ps -ef | grep filebeat kill -9 进程号 启动出现的问题 执行命令systemctl start filebeat.service就能够启动了。而后执行ps -ef|grep filebeat查看一下\n能够看到已经启动胜利了，如果你发现没有启动成功，那么就执行 cd /usr/bin，在这个目录下执行./filebeat -c /etc/filebeat/filebeat.yml -e，这样会提醒具体的错误信息。而用systemctl start filebeat.service启动的时候没有任何提醒，连在 /var/log/filebeat/ 和 /var/lib/filebeat/registry/filebeat/ 都没找到错误信息，这里属实有点坑。\n重新启动命令systemctl restart filebeat.service\n去安装logstash的机器启动logstash 增加 logstash_filebeat.conf 文档\nsudo vim /etc/logstash/conf.d/logstash_filebeat.conf 把以下内容粘贴上保存\ninput { beats { port =\u0026gt; 5555 #这个地址不能和logstash.yml 里面的api.http.host: 9600 一样，要不会出现地址已经被绑定的错误 } } output { if \u0026#34;lua_cpu_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_cpu_monitor-%{+YYYY.MM.dd}\u0026#34; } } if \u0026#34;lua_men_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_men_monitor-%{+YYYY.MM.dd}\u0026#34; } } } 重新加载新的配置并启动logstash\n先启动logstash，然后在启动filebeat，不然的话filebeat会找不到beats插件的:5555端口\nsudo rm -rf /var/lib/logstash/.lock sudo /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash_filebeat.conf --verbose --debug 用filebeat 监控 nginx 修改 nginx conf 配置表\nsudo vim /usr/local/nginx/conf/nginx.conf 加入如下日志格式\nlog_format main \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;@source\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;hostname\u0026#34;:\u0026#34;$hostname\u0026#34;,\u0026#39; \u0026#39;\u0026#34;ip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_method\u0026#34;:\u0026#34;$request_method\u0026#34;,\u0026#39; \u0026#39;\u0026#34;scheme\u0026#34;:\u0026#34;$scheme\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$server_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request_uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;args\u0026#34;:\u0026#34;$args\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamaddr\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;https\u0026#34;:\u0026#34;$https\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; 对比修改下图对应的3个红框地方\n重启 nginx\nsudo pkill -9 nginx \u0026amp;\u0026amp; sudo nginx 用 http:192.168.70.132:7000 登录nginx 网站生成登录日志，然后打开 access.log 日志\nsudo vim /usr/local/nginx/logs/access.log sudo tail -f /usr/local/nginx/logs/access.log 卸载Filebeat # 查看安装的软件 sudo dpkg -l | grep filebeat #查看安装关联 sudo dpkg -L filebeat #移除安装软件 sudo dpkg -P filebeat #继续查看未卸载的目录和文件 sudo find / -name filebeat #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat \u0026amp;\u0026amp; sudo rm -rf /usr/share/filebeat #在此查看是否有关联的目录和文件 sudo find / -name filebeat ","permalink":"https://frog-game.github.io/posts/blog/zabbix-mysql8.0/","summary":"演示 安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana zabbix 6.0 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf","title":"zabbix游戏日志监控"},{"content":"为啥选择帧同步 和写单机游戏类似，客服端收集自己的指令操作发送到服务器，服务器进行收集广播给所有的玩家，客服端本地通过收到的包来推进游戏进度\n服务器：每隔一段时间收集客服端的操作，发给客服端，然后继续采集下一次的操作，在发给客服端\n客服端：收到服务器的广播下来的操作\u0026mdash;-\u0026gt;计算逻辑\u0026mdash;\u0026gt;采集自己操作上报服务器\n帧同步适用于实时性要求高，人数较少的情况\n帧同步服务器每隔多久同步一次比较合适呢\n上限： 网络传输时间，比如我们的ping百度网站你得到的时间是10ms 那么 1000/10 100 帧\n下限：下发给玩家的速度，也就是玩家的体验，科学数据玩家在50 ms-100ms 之间人不会感觉到卡顿认为比较流畅\n那么就是[1000/50,1000/100]\u0026mdash;\u0026gt;[20,10] 所以王者荣耀一般取中间值15fps 也就是1秒15帧 一帧 1000/15 66ms\n算下带宽是多少，承受的了吗\n假设5000个人，按一个房间10人，那么就得500个房间\n假设**1秒的数据， 一帧我们每人16个字节的指令数据，那么16 * 10 * 15 * 500** \u0026mdash;\u0026gt;1,200,000Byte \u0026ndash;\u0026gt; 1172KB \u0026mdash;\u0026gt; **1MB**带宽，对于现在的服务器完全是可以承受的\n选用udp还是tcp tcp ：准确 丢包重传\n通常tcp也能做到做帧同步，但是很难因对网络波动，因为假如tcp有条链路发送了一个1号包过去，这个时候因为网络波动这个链路网速下降，这个时候可能会触发重传，在发送2号包过来的时候，就可能会卡主2号包，从而导致客服端收不到包数据\nudp：高效，可能丢包，乱序 假设1号包卡主了，那么udp不会去等待1号包是否发完，在下一次需要发送的时候就会再次通过新的链接发送2号包过去\n基于可靠传输的UDP，是指在UDP上加一层封装，自己去实现丢包处理，消息序列，重传等类似TCP的消息处理方式，保证上层逻辑在处理数据包的时候，不需要考虑包的顺序，丢包等。类似的实现有Enet，KCP等。\n冗余信息的UDP，是指需要上层逻辑自己处理丢包，乱序，重传等问题，底层直接用原始的UDP，或者用类似Enet的Unsequenced模式。常见的处理方式，就是两端的消息里面，带有确认帧信息，比如客户端（C）通知服务器（S）第100帧的数据，S收到后通知C，已收到C的第100帧，如果C一直没收到S的通知（丢包，乱序等原因），就会继续发送第100帧的数据给S，直到收到S的确认信息。\n一旦客户端没收到服务端已确认其发送的数据，就会一直重传直到服务端确认为止\n发送者维持一个发送队列，对每一次发送进行编号。每一次发送时，会将待发送的数据写入队列。然后将队列里的数据+编号发送给接收者。\n接收者收到数据后，会将该编号回送给发送者以确认。发送者收到确认编号后，会将该编号对应的数据包从队列中删除，否则该数据仍保存在发送队列中。\n下次发送时，会有新的数据进入队列。然后将队列中的数据+最新的编号发送给接收者。以此循环反复\n上图解析：\n第1次发送，在发送队列里只有Data1，于是将Data1和编号1（Seq=1）发送给接收者。收到确认编号1（Ack=1）后，将Data1从队列中删除。 第4到7次发送，由于从第4次发送开始就没有收到确认编号，于是队列中包含了Data4到Data7。第7次发送后，收到确认编号6，于是将Data4至Data6从队列中删除。 第8次发送，队列中包含Data7和Data8。发送后收到确认编号8，从而将Data7和Data8从队列中删除。 以上的关键点是，发送者未收到确认编号，并不一直等待，而是会继续下一次发送。结合图1：\n如果发送者是服务器，则会每隔66MS会将一个Frame数据写入发送队列，然后将该队列里的所有Frame数据一起发送给客户端 。 如果发送者是客户端，则会在玩家有操作时，将玩家的每一个OperateCmd数据写入发送队列，然后将该队列里的所有OperateCmd数据一起发送给服务器 。如果发送队列不为空，则每隔99MS重复发送。如果发送队列为空，则不再发送。直到玩家下一次操作。 由于服务器和客户端即是发送者，又是接收者。则服务器和客户端的每一次发送，除了会带上该次发送的编号，还会带上对对方发送编号的确认。 区别\n但是这两种方式，区别是巨大的。可靠传输的UDP，在帧同步中，个人认为是不合适的，因为他为了保证包的顺序和处理丢包重传等，在网络不佳的情况下，delay很大，将导致收发包处理都会变成类似tcp的效果，只是比TCP会好一些。必须要用冗余信息的UDP的方式，才能获得好的效果。并且实现并不复杂，只要和服务器商议好确认帧和如何重传即可，自己实现，有很大的优化空间\n帧同步运行前提 输入一致性\n确定性的碰撞，寻路结果 玩家操作顺序唯一 计算要一致性\n服务器针对每个单局游戏开局时间生成随机数种子，逻辑帧计算均为伪随机\n浮点数采用多个定点数保存和运算，确保浮点数计算结果一致\n每个网络包都包含自增序号，具体算法可根据项目自行定义\n严格控制静态变量（全局变量）的使用\n禁止使用不稳定的排序算法\n禁止使用顺序不确定的数据结构\n尽量不使用非开源的第三方库（无法确定第三方库中是否有上述的结果不一致算法）\n多线程问题\n主要是每个客服端多线程算出结果可能会不一致，比如A客服端用了3个线程来算你\t这个数据，b客服端用1个线程来算你这个数据导致最后A和B的结果不一致，除非你\t能保证最后结果一致，要不最好别用\n协程 (Coroutine)内写逻辑带来的不确定性也要注意\n开始演示代码前，要保证运行的多个客服端代码版本要一致，如果因为版本不一致导致运行结果不一样，然后查了很久bug那就太2了，如果当前线上存在多个版本，则只有同版本玩家可匹配到单局游戏中\nc#的dictionary遍历的时候是无序的，这个要注意,很容翻车\n如果同批发送的包比较多，尽量合并，减少包头信息的冗余\n业务层上面尽量减少数据结构包的大小\n逻辑帧的规则\n收到第N帧，只有当我收到第N+1帧的时候，第N这一帧我才可以执行。 服务器会按照一定的频率，不同的给大家同步帧编号，包括这一帧的输入带给客户端，如果带一帧给你的数据你拿到之后就执行，下一帧数据没来就不能执行，它的结果就是卡顿。\n战斗流畅保证方法 逻辑帧保证在15-18帧上下\n数据包冗余发送，发送数据量较少的当前帧时，可以把前几帧数据合并发送\n渲染帧保证在30帧以上\n常见的客户端预测，客户端插值，服务器延迟补偿方法保证客户端画面流畅\n帧同步流程 服务器:\n服务器的每个比赛对象，都有一个成员frameid 保持了当前的比赛，下一帧要进入的id，frameid =1\n我们在服务器上定义了一个数据结构 match_frames 用来保存我们所有玩家每帧的操作\n保存match_frames这个结构的作用:\n录像回放\n断线重连\n在不同步的情况下，看看有没有作弊\nudp丢包时序问题，丢包的时候需要补发给客服端\nnext_frame_opt 每帧服务器采集到的客服端操作\nnext_frame_opt = {frameid ,{1号操作玩家指令,2号操作玩家指令,3号操作玩家指令,4号操作玩家指令, ..}}\n服务器启动定时器 每隔66ms触发一次 on_logic_frame\n保存我们当前的操作到match_frames\n遍历每个玩家，给每个玩家发送我们的帧操作\n服务器进入下一帧 frameid = frameid + 1\n服务器进入采集下一帧的操作，清空上一帧采集到的客服端操作:也就是把next_frame_opt清空\nnext_frame_opt = {frameid ,{}}\n发送服务器认为这个玩家还没有同步的帧，每个玩家对象记录了一个变量 sync_frameid 用来记录这个客服端已经同步了多少帧\n同步的帧： sync_frameid + 1 TO 最新的帧 \u0026mdash;\u0026gt;主要是用来解决udp丢包和时序问题\n采用udp 将我们需要补发的帧同步给客服端[sync_frameid + 1,最新帧]\n客服端:\n通过网络受到网络受到帧同步的数据包以后,\n每个客服端也会有一个sync_frameid,用来记录一下你这个客服端真正已经同步到那个帧了\n如果收到的帧id小于客服端的帧id，那么直接丢弃这个帧\n为什么会出现需要丢弃这个帧的情况\n因为udp 时序问题 ：有先发后到，后发先到的可能\n为什么我们没有收到99帧，可以开始处理100帧，还能同步吗\n99帧没有处理，服务器发100帧的时候回补发99帧\n如果上一帧的操作不为空，那么这个时候，我们在处理下一帧之前，一定要先同步下上一帧的结果\n客服端A:|\u0026hellip;.|..66.3.|\u0026hellip;.|\n客服端B:|\u0026hellip;.|\u0026hellip;66.2.|\u0026hellip;.|\n在播放动画的帧与帧之间，我们会出现时间的差异，会导致位置不同步，\nlogic_pos 66ms \u0026ndash;\u0026gt;统一用66ms来计算新的位置和结果\n客服端A:|\u0026hellip;.|\u0026hellip;66.|\u0026hellip;.|\n客服端B:|\u0026hellip;.|\u0026hellip;66.|\u0026hellip;.|\n每帧都同步，处理下一帧之前，每帧都要同步，同样的输入\u0026mdash;\u0026gt;同样的输出\n跳帧 快速的同步完过时的帧，直到最新的帧\n控制我们的客服端，来根据操作，来播放动画，更新我们的逻辑推进，创建怪物，防御塔，等等逻辑\n采集你自己的操作，上报给客服端\n服务器:\n收到玩家的操作，更新服务器上认为玩家已经处理的帧id\n98处理完\u0026ndash;\u0026gt;99, 服务器发99帧-\u0026gt;客服端\u0026mdash;\u0026gt; 处理完99帧，客服端收集100帧操作，服务器收到100帧操作 100 - 1已经同步完了，这个时候就吧98变成99帧也就是 变成98\u0026ndash;\u0026gt;99\n如果收到玩家操作的帧id，next_frame_opts.frameid 等于马上要触发的帧id，说明收到了玩家过时的操作\n假设服务器已经处理完99帧，马上要下发100帧了，这个时候客服端还上传99帧，那么可以认为玩家因为网络或者特殊原因发送了过时的操作，所以直接丢弃\n这样丢弃会影响玩家的手感吗\n丢帧肯定会影响玩家的手感，但是基本不影响玩家操作，15fps，按一个按钮基本4次，中间丢一帧，不太会影响玩家整体，基本玩家感受不出来。\n保存玩家的操作，等待下一帧的触发，goto到逻辑4\n如何克服udp的时序和丢包问题 客服端: 丢包, 晚到，服务器会补发丢掉的帧\n服务器: 丢包, 没有太多的影响， 下一帧马上就可以处理\n防外挂 视野外挂\n划分地图区域 玩家信息分层 属性外挂 多客户端状态校验，客户端执行完每个逻辑帧后，根据游戏的状态计算出一个Hash值，用其标定一个具体的游戏状态。不同客户端通过对比这个值，即可判断客户端之间是否保持同步\n数据的加密处理\n输入的合理性检测\n服务器运行一个精简的可信赖的客户端环境，得到可信赖的数据\n反外挂是一个很大的议题。帧同步结构中，所有数据都在玩家本地，理论上玩家可以任意修改这些数据。这里不讨论传统的加壳及反调试技术。这里讨论在实际开发中，帧同步框架能够通过什么方法来解决该问题。框架能提供至少3种保护: a. 关键数据保护，b. 虚拟化, c. 服务器后验证。关键数据保护可以有很多技术，框架对核心数据，可以做内存加密，内存多拷贝冗余保护等。框架提供虚拟化技术，也是一个不错的选择，部分代码可以在虚拟机(lua)中直接执行，破解难度会增加(前提是资源保护足够)。服务器后验证是杀手锏，验证服务器能运行游戏录像，并直接得出游戏战斗结果，任何作弊都无所遁形。\n因此对于帧同步，反外挂相对是一件比较容易的事情。游戏过程中，玩家作弊只会影响到自己，不会影响到他人。游戏结算时，当服务器检测到玩家之间游戏结果不一致时，通过验证服务器，对游戏录像进行验证计算，很容易就能发现是哪个玩家发生了作弊。\n怎么优化卡顿的问题 buffer缓存\n本地插值平滑加逻辑与表现分离\n使用UDP（在手机环境下，弱网的情况下，TCP很难恢复重连）\n服务端Sleep(1)，并不是代表休息1ms，具体精度看操作系统。（windows约15ms，linux约1ms）\n要在windows上测试需要将全局设置高精度计时器 timeBeginPeriod(1)，有些别的软件开启时会设置全局的精度。\n当调用Sleep（1）时，CPU会进入睡眠状态，以节省电量，因此，如果CPU处于睡眠状态，操作系统（OS）如何唤醒你的线程？答案是硬件中断。操作系统对计时器芯片进行编程，然后该计时器芯片触发中断以唤醒CPU，然后操作系统可以调度线程\n计时器中断之间的间隔取决于Windows版本和你的硬件，但在我最近使用的每台计算机上，默认间隔为15.625毫秒（1,000毫秒除以64）。这意味着，如果你在某个随机时间调用Sleep（1），那么将来每当下一个中断触发时（或者如果下一个中断过早，则在此之后触发），你可能会在1.0毫秒至16.625毫秒之间的某个时间被唤醒。\n最近用ET框架遇到的问题 NLOG没有开启异步日志模式导致的周期性卡顿\n逻辑帧率是否越高越好 并非如此，建议15帧/秒。\n逻辑帧率增加带来的影响如下：\n逻辑层计算次数增多，cpu消耗越大。 网络流量消耗越多 对服务器CPU和带宽压力增大 利用预测回滚,客服端插值，对抗高延迟 预测 预测就是将玩家的输入立即应用到本地状态，而无需等待服务端返回。\n如果玩家的每一次操作如果都要等到服务端确认后才能生效，那么延迟将是不可避免的。解决方案就是：玩家做出任何操作后，立刻将输入应用到本地状态，并刷新表现层显示。例如按下了 “右”，那么就立即向右移动，而无需等待服务端返回，效果如图。\n现在，操作的延迟消失了。你按下 “左” 或者 “右” 都可以得到立刻的反馈。\n但问题似乎并没有完全解决，在移动过程中，你总是能感到来回的 “拉扯” 或者位置抖动。这是因为你在执行本地预测的时候，也在接收来自服务端的同步，而服务端发来的状态总是滞后的。\n例如：\n你的坐标是 (0,0) 你发出了 2 个 右移 指令（每次向右移动 1 个单位），服务器尚未返回，执行本地预测后，坐标变为 (2,0) 你又发出了 2 个 右移 指令，服务器尚未返回，执行本地预测后，坐标变为 (4,0) 服务端发回了你的前 2 个右移指令：从 (0,0) 执行 2 次右移，坐标变为 (2,0)，被拉回之前的位置 由于延迟的存在，服务端的同步总是滞后的，所以你总是被拉回之前的位置。如此往复，就是你在图中看到的抖动和拉扯。\n归根到底，是服务端同步过来的状态与本地预测的状态不一致，所以我们需要 “和解” 它们。\n和解 和解就是一个公式：预测状态 =权威状态 + 预测输入\n重要\n和解的概念最难理解，但也是实现无延迟感体验最重要的一步。你可以先简单记住上面的公式，应用到项目中试试看。\n权威和预测 一般我们认为服务器总是权威的，从服务端接收到的输入称为 权威输入，经权威输入计算出来的状态称为 权威状态。同样的，当我们发出一个输入，但尚未得到服务端的返回确认时，这个输入称为非权威输入，也叫 预测输入。\n在网络畅通的情况下，预测输入迟早会按发送顺序变成权威输入。我们需要知道发出去的输入，哪些已经变成了权威输入，哪些还是预测输入。在可靠的传输协议下（例如 WebSocket）你无需关注丢包和包序问题，所以只需简单地对比消息序号即可做到。\n和解过程 在前述预测的基础上，和解就是我们处理服务端同步的状态的方式。如果使用的是状态同步，那么这个过程是：\n收到服务端同步来的 权威状态 将本地状态立即设为此权威状态 在权威状态的基础上，应用当前所有 预测输入 如果使用的是帧同步，那么这个过程是：\n收到服务端同步来的权威输入 将本地状态立即 回滚 至 上一次的权威状态 将权威输入应用到当前状态，得到此次的 权威状态 在权威状态的基础上，应用当前所有 预测输入 由此可见，状态同步和帧同步只是网络传输的内容不同，但它们是完全可以相互替代的 —— 最终目的都是为了同步权威状态。\n例子 这有用吗？我们回看一下上面预测的例子，有了和解之后，会变成怎样：\n你的坐标是 (0,0)\n你发出了 2 个 右移 指令（每次向右移动 1 个单位），服务器尚未返回\n权威状态：(0,0) 预测输入：右移#1 右移#2 预测状态：(2,0) （权威状态 + 预测输入） 你又发出了 2 个 右移 指令，服务器尚未返回\n权威状态：(0,0) （未收到服务端同步，不变） 预测输入：右移#1 右移#2 右移#3 右移#4 预测状态：(4,0) （权威状态 + 预测输入） 服务端发回了你的前 2 个右移指令 （帧同步）\n上一次的权威状态：(0,0) 权威输入：右移#1 右移#2 权威状态：(2,0) （上一次的权威状态 + 权威输入） 预测输入：右移#3 右移#4 （#1、#2 变成了权威输入） 预测状态：(4,0) （权威状态 + 预测输入，之前的拉扯不见了） 看！虽然服务端同步来的权威状态是 “过去” 的，但有了和解之后，拉扯问题解决了，效果如图：\n预测 + 和解处理本地输入是非常通用的方式。你会发现，在没有冲突时，网络延迟可以完全不影响操作延迟，就跟单机游戏一样！例如上面移动的例子，如果不发生冲突（例如与它人碰撞），即便网络延迟有 10 秒，你也可以毫无延迟并且平滑的移动。这就是在有延迟的情况下，还能实现无延迟体验的魔术。\n冲突 那么冲突的情况会怎样呢？比如上面的例子，你发送了 4 次移动指令，但在服务端，第 2 次移动指令之后，服务端插入了一个新输入 —— “你被人一板砖拍晕了”。这意味着，你的后两次右移指令将不会生效（因为你晕了）。那么该过程会变成这样：\n你的坐标是 (0,0)\n你发出了 2 个 右移 指令（每次向右移动 1 个单位），服务器尚未返回\n权威状态：(0,0) 预测输入：右移#1 右移#2 预测状态：(2,0) 你又发出了 2 个 右移 指令，服务器尚未返回\n权威状态：(0,0) 预测输入：右移#1 右移#2 右移#3 右移#4 预测状态：(4,0) 服务端发回了你的前 2 个右移指令\n权威状态：(2,0) 预测输入：右移#3 右移#4 （#1、#2 变成了权威输入） 预测状态：(4,0) 服务端发回了与预期冲突的新输入\n上一次的权威状态：(2,0) 权威输入：你被拍晕了 右移#3 右移#4 权威状态：(2,0) （因为先被拍晕了，所以后两个右移指令无效） 预测输入：无 （所有预测输入都已变为权威输入） 预测状态：(2,0) 此时，之前的预测状态 (4,0) 与最新的预测状态 (2,0) 发生了冲突，客户端当然是以最新状态为主，所以你的位置被拉回了 (2,0) 并表现为晕眩。这就是网络延迟的代价 —— 冲突概率。\n插值 插值指在表现层更新 “其它人” 的状态变化时使用插值动画去平滑过渡。\n到目前为止，我们已经获得了自己在本地无延迟的丝滑体验。但在其它玩家的眼中，我们依旧是卡顿的。这是由于同步帧率和显示帧率不一致导致的，所以我们在更新其它人的状态时，并非一步到位的更新，而是通过插值动画来平滑过渡。\n预测+和解是解决 自己 的问题，发生在 逻辑层；插值是解决 其它人 的问题，发生在 表现层 。\n例如上面的例子，显示帧率是 30fps，服务端的同步帧率是 3 fps。收到服务端同步的其它玩家的状态后，不是立即设置 node.position，而是通过 Tween 使其在一个短暂的时间内从当前位置平滑移动到新位置。如此，在其它玩家眼中，我们看起来也是平滑的了：\n解决快节奏有冲突的同步，就是 预测、和解、插值 这 3 个核心思想，掌握了它们你应该就能举一反三，轻松应对各种场景。\n延迟不影响操作 从上面的几个例子中，我们可以得出几个重要的结论：\n在无冲突时，网络延迟并 不会 影响操作延迟，预测+和解能实现本地 零延迟 的操作体验 发生冲突时，本地状态立即重设到最新状态，画面跳变，只有此时玩家能明显感受到 “卡了” 网络延迟影响的是冲突概率：网络延迟越大，发生冲突的可能性越大 当使用了预测 + 和解之后，我们之前认为的 “网络延迟越大操作延迟越大”，就变成了一个 误解 。\n即便是一个 MOBA 游戏，你在打野，另外一名玩家在刷兵线 —— 你们之间不存在 “冲突” 的可能性。此时即便网络有很大延迟，你们各自的游戏体验也应该都是单机游戏般 零延迟 的！只有当你们在打团战时，才可能出现因为网络延迟导致技能判定等冲突；也只有当冲突出现时，你们才能直观感受到延迟的存在。\n延迟越小越好吗 服务端可以在收到客户端输入后立即广播出去，也可以通过 LockStep 的方式固定同步频率。除了网络之外，同步频率也会影响延迟。比如服务端逻辑帧率每秒同步 10 次，那么意味着即便局域网内也可能出现 100ms 的延迟。\n但网络延迟真的越低越好吗？其实，延迟小也有一个副作用：插值不平滑。\n假设你用 1 秒时间从 A 点匀速移动到 B 点，如果同步频率恰好是每秒 1 次，那么通过插值，其它玩家看到的应该是一个完全匀速的移动过程。但如果同步频率是每秒 60 次呢？理论上每 16ms 你就会收到一个新状态，然后每 16ms 就要更新一次插值动画。但就跟延迟一样，网络抖动也是客观存在的 。你大概率不是均匀的每 16ms 收到一次消息，而是很可能时而 200ms 才收到一条消息，时而 20ms 内就收到 N 条消息。如此，其它玩家看到的移动过程将是忽快忽慢的，这种不平滑的动画会带来直观的卡顿感。\n所以，延迟并非越小越好，这也是一个权衡利弊的过程：\n延迟大 ：插值更平滑，冲突概率更大 延迟小 ：插值不平滑，冲突概率更小 延迟和同步频率在多少是最好的呢？这个没有标准答案，应该根据实际玩法需要权衡利弊后决定。\n有延迟下的判定 在有延迟的情况下，技能命中的判定，该听谁的呢？来看一个简单的例子。\n场景举例\n在一片空地上，你拿起狙击枪瞄准一个正在移动的敌人头部。点下鼠标，一发弹道闪过 —— 你很确定，命中了！然而，由于网络延迟的存在，你看到的敌人，实际上是 200ms 以前的位置。在服务端的视角看来，你开枪的时刻敌人已经走远 —— 你打空了。那么此时，应当如何判定呢？我们分别来看看。\n假设我们选择以 服务端 的判定为准，那么你会很不爽。因为在你看来，明明打中了，敌人却没掉血，那对面肯定是开挂了。理论上，对面会很爽，因为服务端保护了他免于受伤。但事实上他没什么可开心的，因为他完全不知道服务端为他做了什么，他只会觉得 “对面真菜” 。\n那如果我们选择以 客户端 的判定为准呢？当然你会很爽，因为判定结果和你的预期一致，你觉得这个游戏丝滑流畅没延迟，爽爆了。理论上对面会不爽，因为从服务端视角来看，其实你没打中他。但事实上他并不知道实际上发生了什么，他只会觉得是你枪法不错，打中了他。虽然被打中了，但对于他而言，游戏体验是流畅和符合预期的，没什么不爽。\n所以看起来听客户端的大家都开心，那么是不是这样就万无一失了呢？也存在例外。\n假如对面不是在空地上跑，而是躲进了一堵墙后面。此时他认为自己是安全的，但由于网络延迟，你这边依旧判定打中了他。此时在墙后的他仍然受到了伤害，他肯定很不爽，要么是网卡了要么是你开了穿墙挂。所以并没有 100% 完美的解决方案，权衡利弊后，如果你觉得出现这种情况的概率比较小可以接受，那么可以选择以客户端判定为准从而带来更好的游戏体验。\n你也可以在客户端发送输入时带上游戏时间，由服务端根据实际延迟来决定由谁判定。比如延迟在 200ms 以内时由客户端判定，否则由服务端判定。\n断线重连 下面方法从低级到高级递增\n方法1:在玩家登录的时候把所有历史帧的数据发送给客户端，让客户去进行追帧\n方法2:客户端记录当前已经跑到了第几帧，把当前帧数据和状态值数据存入本地文档,并定时把文档数据MD5发送到服务器进行对比验证合法性,然后当断线重连的时候服务器把客户端的已经执行到的最新帧数发送到服务器进行请求,也就是只请求（客服端断线是最新帧,服务器现在跑到的帧数）发送给客户端进行追帧,极端情况下玩家在玩的途中，换新手机这个时候客户端已经没有本地存档了，那么我们就应该在服务器建立一个通过指令跑出断线客户端执行到了第几帧,如果能算出内存数据一下发给客户端最好,这也是方法3\n方法3: 服务器ECS进行数据分层,把客服端收集到的指令进行转换,存入C，当客户端断线重连的时候，可以把C里面的状态数据发给客户端,让客户端进行恢复,这样客户端也不需要在进行追帧操作，客户端也能很快的进入游戏，卡的关键点也只会是客户端的资源加载进度\n","permalink":"https://frog-game.github.io/posts/blog/zhentongbu/","summary":"为啥选择帧同步 和写单机游戏类似，客服端收集自己的指令操作发送到服务器，服务器进行收集广播给所有的玩家，客服端本地通过收到的包来推进游戏进度 服","title":"帧同步"},{"content":"前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑做不到，手机就更加不用说了 这类大地图，在客服端都是分区域进行加载，也就是会进行切割，比如像绝地求生这样的游戏，大概80公里左右大的地图，会被切割成100 *100 个格子，大概每个格子800米左右，每个格子会打上索引标记，当客服端在进行移动的时候就会根据视野，一般都是九宫格区域，然后根据视野新旧对地图块进行预加载和删除。 在绝地求生跳伞阶段，其实是整张地图进行加载的，但是这个时候不是加载的高精度地图块，而是一个经过简化的地图，而且这种地图块不会只有一份，一般会有多份，这种也叫多层LOD，也就是随着你跳伞以后，距离地面越来越近，程序会给你切换不同的地图块，这也就是为什么有时候你在跳伞的过程中有时候会看到闪烁情况，其实这个时候是程序在给你切换不同的地图块 构建大世界地图 利用bspTree原理对地图进行动态切割 分裂条件：\n人数达到上线 区域大小必须超过多大，比如必须达到50 *50 大小才能分裂 1.场景管理服务器启动以后会创建一个全局的space，假设大小是100 * 100，同时也创建一个同样大小的cell1\n假如按宽10进行分割，会形成 10 * 100,90 * 100 两个长方形\n假如按长90来对剩下的3进行分割\n一直往下切割的话，左边会越来越多，右儿子会越来越少，从而达到负载均衡的效果但是也有分割也有条件\n兄弟两都为叶子节点 左二子被分割后的大小不应该大于右儿子 利用bspTree原理对地图进行动态合并 合并条件:\nCell区域小于100(可配) 人数小于指定人数(可配) 待合并的2个结点必须是叶子结点 删除待合并的两个儿子结点，修改父亲结点的场景区域 合并前\n合并后\n当不管是分割还是合并发现他的实体已经不再当前cell了那么实体应该迁移到他合适的地方去\n边缝处理 假设我们现在有3个cellServer进程管理着各自的ABC3个cell块\n当上面的a角色到达边界的时候，我们这个时候就需要进行real和ghost的数据同步，开始在重叠区域进行转换，进行转换的区域一般要比自己的视野范围要大，比如现在的重叠转换区域就是那个红色圈，大于自己的视野黑色圈\n在entity aoi范围内，又不在同一cell的，在这个cell上创建同坐标的一个ghost 镜像，也就是上面的暗红色和绿色星星就是BC cell上面的ghost镜像 ghost 只能是只读的，每次去修改只能先修改real实体然后在去同步ghost属性 新的边缝处理方法 比如现在有A B两个cell 这个时候黄色的角色从A走向了B 现在过了边界，但是我们现在不用创建镜像和实体的方法来实现无缝地图，而是用传送的方式，传送触发的实际就是那根绿色线和边界的距离，比如5米，当玩家走到了这个触发范围我们就开始直接把人传送到B，这样也不用处理ghost和real之间定时同步，还有异步技能带来的各种异常情况，bug查找\n技能处理 攻击方一定要是real实体，被攻击方可以是real实体，也可以是ghost实体\n下方的数据同步可以写到核心框架，也就是定时同步real实体的信息到ghost实体上\n寻路 因为世界地图很大，所以我们可以用**路点+ 小段距离A星或者jps算法**来实现寻路\n先求路点，比如如下的地铁图，我们可以根据权重值或者时间的组合，通过**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法求出最短路径，这些路径可以离线先求出来，等使用的时候直接使用 还是以上面这图为例子现在你在红色小人那个位置也就是关庄下面小人的位置，这个时候如果障碍物多，你可以骑单车过来也就是用**A星算法寻路到惠新西街南口，如果障碍物少，那么你可以打车，或者坐大巴也就是jps算法到彗新西街南口，到了起始点之后，你就可以坐地铁也就是前面用Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算出的离线路径直接到达下面的地跌目的地南锣鼓巷\n到了南锣鼓巷以后，同样你也可以按2步骤，选择是**a星还是jps算法**到达公司\n如果地图超大，其实在用**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算地铁图的时候我们可以分几块区域算出各自地铁路线图，然后连接起来，举个栗子，比如可以划分，彗星西街南口到北土城是一个区域，北土城到鼓楼大街是个区域，鼓楼大街到南锣鼓巷是个区域，这3个区域各自算好，各自存储好，到时拼接起来就是惠新西街南口到南锣鼓巷的整条离线路线，如下图红，黑，黄三个框，代表3个区域\n","permalink":"https://frog-game.github.io/posts/blog/wufengdashijie/","summary":"前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑","title":"无缝大世界"},{"content":"网络层 通过多reactor +多线程 + 协程池方式，实现win,linux,mac 3方跨平台的底层通讯,能轻松万级别QPS起步，应对高并发请求量大，IO密集型和CPU密集型业务都能处理\n进程 win\nlinux\nmac\nlua调试 插件能对微服务lua代码进行调试\n视频效果展示 多虚拟机测试 linux测试 真机测试 日志监控 利用Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafan 搭建的游戏日志监控系统 能快速的收集 查询 追踪 定位 报警问题\ngit hook 利用git_pre_commit git_pre_reveive 对提交的消息进行代码规范化检查,commit msg提交检查,lua语法检查,Excel检查\n自动化check,格式化,编译,部署,通知 利用gitlab cicd 能对上传以后的代码进行 check,格式化,编译,部署,通知\n自动化 check,格式化,编译,部署\n群通知\n个人通知\n在线exel协同开发 属性自动更新 lua的工程化强化 Teal Teal 和 Lua 的关系就类似 TypeScript 和 JavaScript 的关系，支持给已有的库进行类型标记，最终是翻译为 Lua 去实际使用的。\n类型标记可以写在 xx.d.tl 文件中，比如\nlocal record os exit: function(number) end return os 在 Teal 中主要新增了 record、array 和 map 类型，更多的语言特性可以见文档 https://github.com/teal-language/tl/blob/master/docs/tutorial.md\n代码样例\n-- record 类似其他语言中的结构体 local record arg_t github地址在下边\nteal-language/tl: The compiler for Teal, a typed dialect of Lua (github.com)\n叫青语言，\n安装颇费了一番功夫,主要是我对环境不熟悉\n需要luarocks，\n需要mingw（安装gcc），注意是mingw不是mingw-w64,这tm是完全不同的两个项目\n然后有什么用呢\n来看一段正常的lua代码\n//正常lua代码 local function add(a, b) return a + b end local s = add(1, 2) print(s) 这代码执行肯定返回3\n//bug lua代码 local function add(a, b) return a + b end local s = add(\u0026#34;ni\u0026#34;, 2) print(s) 然后来一段bug代码，这个bug代码 你用luac 肯定是没问题，等到执行期才会出问题，因为lua设计为一门动态语言，而且这从vm层次就决定了，这个情况有点像js，因为动态化，错误检查时机被拖到了运行时，不运行，无法发现问题（人眼除外）\n软件工程的实践中，代码静态检查能发现太多的问题（静态类型编程语言），js因为微软的typescript得到了极大的工程化加强。\n青语言就是对lua的类型化加强，和ts之于js是一样的概念。\n//青语言bug代码 local function add(a: number, b: number): number return a + b end local s = add(\u0026#34;a1\u0026#34;,2) print(s) 然后使用青语言，加上类型标注，标注的形式也像极了typescript\n然后就可以 tl check来检查这个青语言代码的问题了\n不用执行就可以提前知道第五行有个bug，这就是静态类型的功能所在。\n通过tl gen 指令 可以将青语言代码编译为lua，这个思路也是和ts=\u0026gt;js一致的。\n他的工程化优势参考ts带来的js革命性生态进化就可以想象一二。\n热更新 在代码复用和组织数据方面，面向对象可能是大家第一反应。面向对象三大特性继承，封装，多态，在一定程度上能解决不少代码复用，数据复用的问题。不过面向对象不是万能的，它也有极大的缺陷：\n数据结构耦合性极强 一旦父类中增加或删除某个字段，可能要影响到所有子类，影响到所有子类相关的逻辑。这显得非常不灵活，在一套复杂的继承体系中，往父类中改变字段会变得越来越麻烦，比方说ABC是D的子类，某天发现需要增加一个AB都有的数据，但是C没有，那么这个数据肯定不好放到父类中，只能将AB抽象出来一个父类E，E继承于D，AB共有的字段加到E中，一旦继承结构发生了变化，可能接口也要改变，比方说之前有个接口传入参数类型是E，当AB不再需要共用的那个字段，那么需要调整继承关系，让AB重新继承D，那么这个接口的传入参数类型需要改成D，其中的逻辑代码很可能也要发生调整。更可怕的是游戏逻辑变化非常复杂，非常频繁，可能今天加了个字段，明天又删掉了，假如每次都要去调整继承结构，这简直就是噩梦。继承结构面对频繁的数据结构调整感觉很无力\n难以热插拔 继承结构无法运行时增加删除字段，比如玩家Player平常是走路，使用坐骑后就骑马。问题是坐骑的相关信息就需要一直挂在Player对象上面。这就显得很不灵活，我不骑马的时候内存中为啥要有马的数据？接口也有同样的问题，一个类实现了一个接口，那么这个接口就永远粘在了这个类身上，你想甩掉她都不行，还是以骑马为例，玩家Player可以进行骑行，那么可能继承一个骑行的接口，问题是，当我这个Player从坐骑上下来时，玩家Player身上还是有骑行的接口，根本没法动态删掉这个接口！可能例子举得不是很对，但是道理表述的应该很清楚了\n使用面向对象可能导致灾难性后果，游戏开发中有新人有老人，有技术好的，有技术差的。人都是喜欢偷懒的，当你发现调整继承关系麻烦的时候，有可能AB中增加一个字段为了省事直接就放到父类D中去了。导致C莫名奇妙的多了一个无用的字段。关键还没法发现，最后导致父类D越来越大，到最后有可能干脆就不用ABC了，直接让所有对象都变成D，方便嘛！是的，很多游戏就是这么干的，开发到最后根本就不管继承关系了，因为想管也管不了了。\n面向对象在面对复杂的游戏逻辑时很无力，所以很多游戏开发者又倒退了回去，使用面向过程进行开发游戏，面向过程，简单粗暴，不考虑复杂的继承，不考虑抽象，不考虑多态，是开发届的freestyle，挽起袖子就开撸，但同时，代码逻辑的复用性，数据的复用性也大大降低。面向过程也不是一种好的游戏开发模式。\n组件模式很好的解决了面向对象以及面向过程的种种缺陷，在游戏客户端中使用非常广泛，Unity3d，虚幻4，等等都使用了组件模式。组件模式的特点： 1.高度模块化，一个组件就是一份数据加一段逻辑 2.组件可热插拔，需要就加上，不需要就删除 3.类型之间依赖极少，任何类型增加或删除组件不会影响到其它类型。\n但是目前只有极少有服务端使用了组件的设计，守望先锋服务端应该是使用了组件的设计，守望先锋的开发人员称之为ECS架构，其实就是组件模式的一个变种，E就是Entity，C就是Component，S是System，其实就是将组件Component的逻辑与数据剥离，逻辑部分叫System\n","permalink":"https://frog-game.github.io/posts/tech/kuangjia-work/","summary":"网络层 通过多reactor +多线程 + 协程池方式，实现win,linux,mac 3方跨平台的底层通讯,能轻松万级别QPS起步，应对高并发请求量","title":"服务器简介"},{"content":"网络编程流程 堵塞IO 非堵塞IO 信号驱动IO 异步io模型 多路复用 单reactor 代表作：redis 内存数据库\n注意：redis 6.0 以后是多线程\n单reactor 多进程模型 代表：nginx\n单reactor模型 + 任务队列 + 线程池 代表作:skynet\n主从 reactor 代表作：netty\n多reactor + 多线程 代表作：memcache\n多reactor + 多线程 +协程池 ","permalink":"https://frog-game.github.io/posts/read/wangluo_io_zhongjie/","summary":"网络编程流程 堵塞IO 非堵塞IO 信号驱动IO 异步io模型 多路复用 单reactor 代表作：redis 内存数据库 注意：redis 6.0 以后是多线程 单r","title":"网络IO模型总结"},{"content":"tcp 握手挥手 序列号: 在建立连接的时候有计算机生成的随机数并作为初始值，通过syn包传给接收端主机，每发一次数据，就累加一次该数据字节数的大小，主要是用来解决网络包乱序问题\n确认应答号:指下一次期望收到的数据的序列号，发送端收到这个确认应答以后可以认为这个序号之前的数据都被正常接收了，主要用来解决不丢包的问题\n控制位:\nACK: 该位为1的时候，确认应答字段变得有效，该字段规定除了最初开始建立连接时候syn包之外，改为必须设置为1\nRST:该位为1的时候，标识TCP连接中出现异常必须强制断开连接\nSYN:该为位1时候，表示希望建立连接，并在序列号的字段进行序列号初始值的设定\nFIN:该位为1的时候，表示今后不会再有数据发送，希望断开连接，当通讯结束希望端口连接时,通讯双方的主机之间可以相互交互FIN 位为1的TCP段\n为什么需要tcp协议，tcp工作在那一层 IP层是不可靠的，他不保证网络包的交互，不保证网络报的按序交互，也不保证网络包中的数据的完整性，如果需要保证数据的完整性那么就需要TCP层来负责 TCP有哪些特性 面向连接的，可靠的，基于字节流的\n建立一个tcp连接需要达成哪些共识 socket：由ip地址和端口号组成\n序列号：主要用来解决乱序问题\n窗口大小：主要用来做流量控制\nTCP四元组 有一个ip的服务器监听了一个端口，他的TCP的最大连接数是多少 对于IP4来说，客服端ip最多为2的32次方(4 294 967 296) 客服端的端口最多为2的16次方(65536) 也就是服务器单机最大的TCP链接数，约为2的48次方 最大tcp链接数 = 客服端ip数 * 客服端的端口数\n如果服务器不能达到理想数，一般是因为什么原因 首先是文件描述符的限制，Socket都是文件，所以首先要通过 ulimit 配置文件描述符的数目\n另一个就是内存限制，每个tcp链接都要占用一定的内存，操作系统的内存是有限的\nudp和tcp的区别 目标和源端口号：主要是告诉udp协议应该吧报文发给那个进程\n包长度：保存了UDP首部的长度跟数据的长度之和\n校验和：主要是位了提供可靠的udp首部和数据而设计的\n区别\n连接\nTCP是面向连接的传输层,传输数据前先要建立链接\nUDP是不需要连接的，即可传输数据\n服务对象\nTCP是一对一的两点服务器，即一条连接只有两个端点\nUDP是支持一对一，一对多，多对多的交互通信\n可靠性\nTCP是可交互数据的，可以无差错，不丢失，不重复，按需到达\nUDP是尽自己最大的努力交互，不保证可靠交互数据\n拥塞控制，流量控制\nTCP有拥塞控制和流量控制机制，保证数据传输的安全性\nUDP则没有，即使网络非常堵塞，也不会影响UDP的发送速率\n首部开销\nTCP首部长度较长，会有一定的开销，首部在没有使用选项的时候都能达到20字节，如果使用了选项则会变长 UDP首部只有8个字节，并且是固定不变的，开销较小\n传输方式\nTCP是流失传输，没有边界，但是保证顺序和可靠\nUDP是一个包一个包发送，是有边界的，但是可能会丢包和乱序\n分片不同\nMSS就是TCP报文段所允许传送的最大数据部分的长度，主机一般默认MSS为536字节(576IP最大字节数-20字节TCP协议头-20字节IP协议头=536字节)\nMTU 最大传输单元,一般1500\nTCP数据大小如果大于MSS大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装TCP数据包，如果中途丢失了一个分片，只需传输丢失的这个分片\nUDP的数据大小如果大于MTU大小，则会在IP层进行分片，目标主机在收到后，在IP进行组装数据，接着在传给传输层，但是如果中途丢了一个分片，在实现可靠传输的UDP时则需要重传所有的数据包，这样传输效率非常差，所以通常UDP的报文，应该小于MTU\n为什么UDP头部没有首部字段，而TCP头部有\n原因TCP有可变长的选项字段，而UDP头部长度则不会变化，无需多一个字节去记录UDP的首部长度\n为什么UDP头部有包长度，而tcp没有\nTCP数据的长度 = IP总长度 - IP首部长度 - TCP首部长度\n其中 IP 总⻓度 和 IP ⾸部⻓度，在 IP ⾸部格式是已知的。TCP ⾸部⻓度，则是在 TCP ⾸部格式已知的，所以就 可以求得 TCP 数据的⻓度。 ⼤家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据⻓度也可以通过这个公式计算呀？ 为何还要有 「包⻓度」呢？” 这么⼀问，确实感觉 UDP 「包⻓度」是冗余的。 因为为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 44 字节的整数倍。 如果去掉 UDP 「包⻓度」字段，那 UDP ⾸部⻓度就不是 4 字节的整数倍了，所以觉得这可能是为了补全 UDP ⾸部⻓度是 4 字节的整数倍，才补充了「包⻓度」字段\n为什么MTU是1500\n其实一个标准的以太网数据帧大小是：1518，头信息有14字节，尾部校验和FCS占了4字节，所以真正留给上层协议传输数据的大小就是：1518 - 14 - 4 = 1500，那么，1518这个值又是从哪里来的呢？\n最根本原因\n问题就出在路由器拨号，如果是PC拨号，那么PC会进行PPPoE的封装，会按照MTU:1492来进行以太网帧的封装，即使通过路由器，路由器这时候也只是转发而已，不会进行拆包。\n而当用路由器拨号时，PC并不知道路由器的通信方式，会以网卡的设置，默认1500的MTU来进行以太网帧的封装，到达路由器时，由于路由器需要进行PPPoE协议的封装，加上8字节的头信息，这样一来，就必须进行拆包，路由器把这一帧的内容拆成两帧发送，一帧是1492，一帧是8，然后分别加上PPPoE的头进行发送。\n平时玩游戏不卡，是因为数据量路由器还处理得过来，而当进行群怪AOE的时候，由于短时间数据量过大，路由器处理不过来，就会发生丢包卡顿的情况，也就掉线了。\n帖子里面提到的1480，猜测可能是尽量设小一点，避免二次拨号带来的又一次PPPoE的封装，因为时间久远，没办法回到当时的场景再去抓包了。\nTCP 连接建立(3次握手) 一开始客户端和服务器都处于close状态\n服务开始监听端口，这个时候服务器处于listen状态\n客户端会随机初始化序列号 client_isn，然后把这个初始值付给tcp首部的序列号字段，并把标识位syn设置成1，代表这是一个syn包，此包不包含应用层数据，发送出去以后，客服端处于sys_sent状态\n三次握手第一个报文 SYN 报文\n服务器收到客户端报文，首先服务器会随机初始化自己的server_isn ,将server _isn号存入序列号中，并把客服端的client_isn +1 存入确认应答号中，同时吧SYN和ACK标志位置为1，此包不会包含应用层数据，发送出去以后服务器进入syc_rcvd状态\n三次握手第二个报文 SYN + ACK报文\n客服端收到服务器发送的syn + ack 报文以后，最后还会向服务器发送一个ACK确认报文，并把server_isn 序列号 + 1 存入确认应答号，然后把ACK标志位设置成1，此包这个时候可以带应用层数据发过去，这个时候客户端进入进入established状态，服务器收到ACK确认应答包以后也进入established状态\n从这一步可以看出前两步是不带数据的，第三步可以带数据发送\n为什么握手是3次，不是2次,4次 主要是3个方面\n可以防止重复历史链接数\n同步双方初始序列号 四次握手其实也能够可靠的同步双方的初始化序号，但是由于第二步和第一步可以优化成一步，所以就成了3次握手，\n而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方序列号都能被确认接收\n避免资源浪费\n如果只有两次握手，当客服端的syn请求连接在网络中堵塞，客服端没有接收到ACK报文，就会重新发送syn，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送链接的ack确认信号，所以只能自己创建链接，\n如果多次堵塞，多次发送syn，那么服务器就会多次创建，造成冗余的链接。\n总结：为什么不使用两次握手或者四次握手\n两次握手：无法防止历史链接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号\n四次握手：三次握手就已经理论上最少可靠链接建立，所以不需要使用更多的通信次数\n为什么客服端和服务器的isn号不相同 如果一个已经失效的历史报文残留在网络中，那么如果isn号码相同那么无法分辨到底是不是历史报文，如果历史报文被接受了那么就有可能产生数据错乱，所以每次建立连接前都会初始化一个序列号，好让分辨出来是不是历史报文，好丢弃掉 还有一个方面是为了安全，防止黑客伪造相同的tcp报文被对方接收 syn攻击 我们知道tcp链接需要3次握手，假设攻击者短时间内，伪造不同的ip地址syn报文，服务器每接收一个就进入syn_rcvd 状态，但服务器发送出去的ack + syn报文，无法得知位置ip主机的ack应答，久而久之就会占满服务器syn接收队列（未连接队列）使得服务器不能为正常用户服务\n解决办法一\n控制接收队列大小\nnet.core.netdev_max_backlog SYN_RCVD 状态连接的最大个数\nnet.ipv4.tcp_max_syn_backlog 超出处理能力时候对于新的syn 直接发送RST 丢弃链接\nnet.ipv4.tcp_max_syn_backlog 解决方法二\n首先是正常的3次握手流程\nTCP 连接断开 客服端，打算关闭连接，此时会发送一个tcp首部FIN标志为1的报文，之后客户端进入fin_wait1状态 服务器收到fin报文之后然后发送ack确认码给客服端，开始进入close_wait状态， 客服端收到ack确认码以后进入fin_wait2状态 服务器处理完数据发送fin报文给客服以后进入last_ack阶段 客服端收到fin报文以后发送ack确认码给服务器开始进入time_wait状态 服务器接到ack应答报文开始进入close状态 客服端经过2msl时间自动进入close状态 你可以看到每个方向都有fin报文和ack应答码，所以简称四次挥手\n只有主动关闭的一方才会进入time_wait 状态\n为什么挥手需要四次 客服端发送fin链接的时候，仅仅表示客户端不在发送数据，但是还能接收数据\n服务器收到fin报文以后，先回一个ack码，而服务器还有数据需要处理和发送，等服务器不在发送数据\n的时候才发送fin报文给客服端\n从上可知，因为要等待服务器处理完数据，所以服务器的ack和fin码会分开发\n为什么time_wait是2ML MSL是报文生存最大时间，他在任何报文在网络中存在的最大时间，超过这个时间，报文会被丢弃，因为tcp是基于\nIP协议的，在IP协议中有一个TTL字段，是IP层经过的最大路由器数，每经过一个处理，就会减1，一直到0，就把这\n个数据包进行丢弃，同时发送icmp报文通知主机\nMSL和TTL区别\nMSL单位是时间 TTL是路由跳数，所以MSL应该大于TTL消耗为0的时间，以保证报文是自然消亡\nTIME_WAIT等于2倍，是因为网络中可能存在发送方发过来的数据包，当这些发送方的数据包被接收方处理后，又会向对方发送响应，所以一来一回需要等待2倍的时间\n比如被动关闭方没有收到断开连接的最后的ACK报文，就会触发重发fin报文，另一方收到fin报文后，会重发ack应答码\n一来一回正好2ML\n2ML是客服端接受到FIN包以后发送ACK码开始计时的，如果在2ML时间内，服务器没有收到ACK确认码，重发了fin报文，那么这个时候客服端会重发ACK码并重新进入2ML计时\n2ML一般多长 linux 中一般设置为60s 也就是一个msl是30秒\n#define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT state, about 60 seconds */ time_wait 相关 time_wait 过多原因 大量高并发的短连接 程序错误，没有调用close关闭连接 ack码丢失，导致服务器重新发送fin报文，让time_wait重新进入计时，不会进入close 为什么需要time_wait状态 防止旧链接的数据包\n如上图的sql =301的包被网络延迟了，这个时候time_wait设置的时间很短，或者没有，上次的链接的被关闭\n这个时候如果重新建立相同端口号的连接被重用，而网络中还有seq =301的消息包这个时候抵达，那么这个\n时候客服端收到了旧的数据包，这个时候数据就会错乱，造成问题\n如果这个时候有2ML的time_wait时间，那么足够保证在建立新的相同端口连接时候，网络中旧的数据包消亡\n保证连接正确关闭\n如果最后的ack丢失了，服务器就会一直处于last_ack状态，如果这个时候客服端发起新的连接，那么这个时候服务器因为处于last_ack状态，所以会发送rst报文给客服端，让客服端直接终止链接\ntime_wait过多会怎么样 如果服务器有处于time_wait状态的tcp 那么说明是服务器主动发起的端开请求\n内存资源的占用 端口资源的占用，端口资源也是有限的 所以如果发起连接的一方time_wait状态过多，占满了所有资源端口，则会导致无法创建新的连接\n客户端 time_wait多的话，因为端口资源的限制，就会导致端口资源被占用，被占满就会导致无法创建新的链接\n服务器time_wait过多的话，因为系统资源的限制，由于一个四元组表示一个tcp连接，理论上服务器可以创建很多连接，服务器确实也可以监听一个端口，但是这些连接会扔给处理线程，理论上监听的端口可以被继续监听，但是线程池处理不了那么多的一直不断的连接，所以当出现大量time_wait的时候，系统资源就会被占满，导致处理不了新的连接\n怎么优化time_wait 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项\ntcp_tw_reuse 功能只能⽤客户端（连接发起⽅），因为开启了该功能，在调⽤ connect() 函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复⽤\nnet.ipv4.tcp_max_tw_buckets\n这个值默认为 18000，当系统中处于 TIME_WAIT 的连接⼀旦超过这个值时，系统就会将后⾯的 TIME_WAIT 连接 状态重置\n程序中使⽤ SO_LINGER ，应⽤强制使⽤ RST 关闭。\nclose_wait 相关 close_wait 多的原因 一般都是程序逻辑造成，在client发送fin过来的时候，这边进入了close_wait状态，但是因为程序逻辑问题，迟迟没有调用close()，或者shutdown函数进行关闭，导致close_wait超多\n如果已经建⽴了连接，但是客户端突然出现故障了怎么办 net.ipv4.tcp_keepalive_time=7200 #表示保活时间是 7200 秒（2⼩时），也就 2 ⼩时内如果没有任何连接相关的活 动，则会启动保活机制 net.ipv4.tcp_keepalive_intvl=75 #表示每次检测间隔 75 秒 net.ipv4.tcp_keepalive_probes=9 #表示检测 9 次⽆响应，认为对⽅是不可达的，从⽽中断本次的连接 主要是tcp的保活机制，如果在一段时间内，没有任何的连接相关的活动，tcp就会启动保活机制，每隔一段时间发送一个探测包，这个探测包数据量很小，如果连续几个探测包发过去都没有反应，那么就可以认为tcp连接已经死亡了\n开启了tcp保活机制以后，需要考虑一下几种情况\n对端程序正常工作，当tcp保活的探测包到达对方以后，对方正常响应，这个时候保活机制就会被重置 对端程序奔溃并重启，当tcp保活的探测包到达以后，由于对方没有相关的tcp连接信息，这个时候会发送rst报文给对方，这样很快就可以发现tcp连接已经重置了 如果对方一直奔溃，当tcp报文一直发送，发送几次后没有反馈，那么这个时候就可以认为tcp连接已经死亡 服务器主动关闭 服务器调用close(),不管什么数据一缕发送rst报文进行强制关闭 服务器调用shutdown() ，如果是正常数据还是走正常数据接收流程，一直到数据发送完毕，然后发送fin报文正常关闭\ntcp重传 超时重传 指的是我们在发送数据的时候，会设定一个定时器，当超过定时器设定的时间，我们在没有收到对方的ack确认码之后就会触发重传机制\n触发超时重传条件 数据包丢失，因为数据包丢失，所以B无法发送ack确认码下去，A无法收到ACK确认码，无法知道服务器是否收到数据就会在特定时间间隔内，触发重传\n确认应答丢失\n超时重传时间设置多少最好 RTT 包的往返时间\n时间设置的过长过短发生的情况\n当RTO较大时候，重发就满，丢了老半天才重发，没有效率，性能差\n当RTO较小时候，可能是因为波动大，然后设置RTO又短，这个时候触发了重传，但是旧包却很快恢复了传输\n所有综合上述，所以我们应该 RTO应该略大于RTT\n快速重传 这个不是以时间为驱动，而是以数据为驱动\n如上发了1，2，3，4，5 共5份数据\n1号数据发过去了，这个时候ACK变成了2\n2号数据这个时候丢失了，\n3号数据这个时候进行了发送，但是接收端回复ACK的时候不会是3而会还是原来丢包的那个ACK2\n4号数据这个时候进行了发送，还是发送ACK2\n5号数据这个时候进行了发送，还是发送ACK2\n这个时候发送端发现有3次相同的ack码就会触发重传，这个是seq2会在定时器过期之前重传过去了，这个时候接收端\n发现了seq2，3，4，5都收到了，那么就会把ACK设置成6\nSACK 解决快速重传应该重传所有还是重传丢失者问题\nSACK方法[如果能支持SACK，那么必须双方都打开]\nLeft Edge:代表已收到的第一个不连续的第一个序号\nRight Edge:表示已收到的不连续块的最后一个序号+1 即左闭右开区间，通过ACK和sack发送方就能很快的确定接收方有哪些数据没有被收到 如果上面触发了重传会这样处理\n直接重传300 -499丢失的块，然后把ack变成700再次触发快速重传把700 -899补上\nDACK 主要是告诉发送方，主要通过SACK告诉发送方有哪些数据被重复接受了\nACK 丢包\n接收方发送给发送方的2个ack都丢失了，所以发送方超时后，重传了第一个数据包3000 - 3499\n接收方发现数据是收到的是重复数据，于是回了一个sack= 3000 - 3500 告诉发送方3000 - 3500的\n数据早就被接受了，因为现在ack已经到了4000 所以意味着这个sack代表的是dack\n这样发送方就知道了数据其实没有丢，只是接收方的ack确认报文丢失了\n网络延迟\n数据包 1000- 1499 被网络延迟了，导致发送方没有收到ack1500的确认报文\n而后面收到了3个相同的ack报文，触发了快速重传，但是在重传以后，网络延迟的1000 -1499也抵达了接收方\n所以接收方回了一个ack3000 和sack 1000 -1500 所以这个时候sack代表的就是dack，代表这是一个重复的报文\n这样发送方就知道快速重传的原因不是发数据丢了，也不是ack丢了，只是网络延迟了\n可见dack有这么几个好处\n可以让发送方知道是包丢了 还是接收方的ack丢了 还是发送方的数据包被网络延迟了 可以知道网络中是不是把发送方的数据包给复制了 滑动窗口 我们知道TCP每发送一个数据，就会进行一次确认应答，当上一个数据包收到了应答，在发送下一个，这个模式有点像\n两个人聊天，你发一句，然后我给你个ack报文，我发一句，然后你给我一个ack报文，这样其实效率很低的。\n如果你说完一句话，我在处理别的事情，没有及时给你回复ack报文，那么你就只能干等着，一直等到我处理完事情，\t然后给你回复ack码，这样处理的话效率太低了，如果是这个逻辑，那么tcp协议也就不用在完了\n所以这样的传输方式很大的弊端：就是包的往返时间越长，网络的吞吐就越大\n为了解决这样的问题，TCP发明了一个牛逼的概念：****滑动窗口\n如果有了滑动窗口，那么就可以指定窗口的大小，窗口的大小无需等待对方的确认应答，就可以继续发送数据的最大值\n上面ack300 即使丢了，但是因为我们收到了ack400 那么我们就可以认为400之前的数据都收到了，这种方式我们称为累计确认\n窗口大小由哪一方决定 tcp头里面有个字段叫window 也就是窗口大小\n这个字段是接收方告诉发送方自己还有多少缓冲区可以接受数据，于是发送方就靠这个字段来知道接收方能接收多少数据，而不会导致接收方接收不过来\n所以窗口的大小，一般由接收方窗口的大小来决定\n发送方，发送的数据不能超过接收方窗口的大小，否则接收方就无法接受数据\n发送窗口 SND.WND : 表示发送窗口的大小,由接收窗口控制\nSND.UNA : 表示已发送但未确认ack报文的空间的第一个字节位置\nSND.NET : 表示未发送但是还在接收窗口可处理空间的第一个字节位置\n可用窗口大小 = SND.WND - (SND.NXT - SND.UNA)\n发送端窗口大小怎么控制的 取决于接收端的大小[rwnd]和拥塞窗口[cwnd]的大小\n发送窗口 = min{rwnd,cwnd}\n接收窗口 RCV.NXT : 希望从发送方发过来的下一个字节数据的序列号\nRCV.WND : 接收窗口的大小，会通过tcp头部报文里面的window字段，通知发送窗口大小\n接收窗口大小怎么控制的 接收窗口的大小系统，网速，未处理数据的大小都有关系\n发送窗口大小和接收窗口大小一样吗 不完全相等，一般接收窗口略等于发送窗口\n流量控制 发送方不是无脑的一直发送数据给接收方的，也要考虑接收方的接收能力。\n如果一直无脑的发数据给对方，但对方处理不过来，就会触发重传机制，从而导致网络流量的无端浪费\n为了解决这个问题，引入了流量控制\n固定窗口大小场景 假设接收端和发送端窗口相同，都为200 假设两个设备在传输过程中都保证窗口大小不变，不收外界影响 动态变化窗口大小场景 当发送方变成窗口变成0的时候其实发送方还会定时的发送探测报文，以便知道接收方改变了窗口\n丢包情况 当服务端系统资源⾮常紧张的时候，操⼼系统可能会直接减少了接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓 存数据，那么这时候就有严᯿的事情发⽣了，会出现数据包丢失的现象。\n为了避免这种情况 TCP规定不允许系统收缩缓存的时候同时减少窗口大小，而是采用先收缩窗口，过段时间在减少缓存的办法\n窗口关闭死锁问题 如果解决这种死锁问题 为了解决这种死锁问题，TCP为每个连接设有与一个持续定时器如果定时器超时就会发送窗口探测报文\n如果接收窗⼝仍然为 0，那么收到这个报⽂的⼀⽅就会᯿新启动持续计时器； 如果接收窗⼝不是 0，那么死锁的局⾯就可以被打破了。 窗⼝探测的次数⼀般为 3 次，每次⼤约 30-60 秒（不同的实现可能会不⼀样）。如果 3 次过后接收窗⼝还是 0 的 话，有的 TCP 实现就会发 RST 报⽂来中断连接。\n糊涂窗口综合症 于是，要解决糊涂窗⼝综合症，就解决上⾯两个问题就可以了\n让接收⽅不通告⼩窗⼝给发送⽅ 让发送⽅避免发送⼩数据 怎么让接收⽅不通告⼩窗⼝呢？\n接收⽅通常的策略\n当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 ) ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通 告窗⼝为 0 ，也就阻⽌了发送⽅再发数据过来。 等到接收⽅处理了⼀些数据后，窗⼝⼤⼩ \u0026gt;= MSS，或者接收⽅缓存空间有⼀半可以使⽤，就可以把窗⼝打开让发 送⽅发送数据过来。\n怎么让发送⽅避免发送⼩数据呢？\n发送方策略\n使⽤ Nagle 算法，该算法的思路是延时处理，它满⾜以下两个条件中的⼀条才可以发送数据：\n要等到窗⼝⼤⼩ \u0026gt;= MSS 或是 数据⼤⼩ \u0026gt;= MSS 收到之前发送数据的 ack 回包 拥塞控制 前面的流量控制主要是为了解决发送方到接收方的缓存，但是不知道网络中发生了什么\n一般来说，计算机网络是个共享的环境，因此也有可能会因为其他主机之间的通信，而是网络堵塞\n如果在网络堵塞的时候继续发送大量的数据包，那么就可能导致数据包的时延，丢失等，这个时候tcp就会重传数据，但是一重传，就会导致网络的负担更重，于是就会导致更大的延迟和丢包，甚至进入恶性循环\n于是现在就有了拥塞控制手段，这个手段主要控制的是控制发送方数据充满网络\n为了让发送方控制发送数据的量，于是就有了拥塞窗口的概念\n拥塞窗口和发送窗口的关系 拥塞窗口cwnd是发送方维护的一个状态变量，他会根据网络动态变化\n前面我们提到的swnd和rwnd是约等于的关系，那么假如cwnd概念以后，此时发送窗口的值是\nswnd = min(cwnd,rwnd)\n拥塞窗口的变化规则 只要网络中没有堵塞，那么就加大cwnd的数值 如果网络中出现了拥塞，cwnd就减少 怎么知道当前网络出现了拥塞 只要发送方在没有规定的时间内接受到ack确认码，也就是发生了超时重传，就认为网络中出现了拥塞\n拥塞控制有哪些算法 慢启动 拥塞避免 拥塞发生 快速恢复 慢启动 慢启动的算法就是，当发送方每收到一个ack，拥塞窗口cwnd的大小就加1\n那么慢启动什么时候是个头呢，\n有一个叫慢启动的门限ssthresh\n当 cwnd \u0026lt; ssthresh 时使用慢启动\n当 cwnd \u0026gt;= sssthresh 时启动拥塞避免\n拥塞避免 它的规则是：每当收到⼀个 ACK 时，cwnd 增加 1/cwnd\n拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓ 速度缓慢了⼀些。 就这么⼀直增⻓着后，⽹络就会慢慢进⼊了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进 ⾏᯿传。 当触发了᯿传机制，也就进⼊了拥塞发⽣算法\n拥塞发生 其实这个时候就是写的tcp重传机制主要是两种\n超时重传\n因为想途中的cwnd从12突然变到了1，然后开始慢启动，可以看到此种方法很容易马上回到解放前，方法也很激进，容易造成网络卡顿，那么发生这种情况我们还有没有更好的办法呢，其实有的也就是前面写的快速重传\n在收到3次相同的ack码的时候我们可以在超时重传还没发生之前就重传数据过去，而不必等到超时重传\n这个时候tcp认为这中情况也不是很严重那么我们可以这样设置参数\ncwnd = cwnd/2 ，也就是设置为原来的⼀半 ssthresh = cwnd 进⼊快速恢复算法 快速恢复 由于进入快速恢复之前 cwnd和ssthresh已经进行了更新\ncwnd = cwnd/2 ，也就是设置为原来的⼀半\nssthresh = cwnd\n快速恢复算法如下\n拥塞窗口 cwnd = ssthresh + 3 3的意思代表确认有3个数据包已经收到了 重传丢失的数据包 如果在收到重复的数据包那么cwnd + 1 如果收到新数据的ack 那么吧cwnd 设置成第一个不的ssthresh的值，原因是该ack已经确认了新的数据，说明从dack时候的数据已经都收到了，该恢复过程已经结束，那么就可以恢复到之前的状态了，也就是可以再次进入拥塞避免状态 粘包 粘包的问题是不知道消息的边界在哪里，如果知道边界在哪里就好办了。所以有如下3种方法解决\n固定长度 就是规定每一个包固定的长度，比如20KB，当收到了20KB的数据满了之后，就认为是一个包,但是这种方法灵活性不高，用的很少\n特殊字符做边界 比如像HTTP这种直接在尾部加回车，换行来作为数据的边界，但是这种方法有个问题，就是如果特殊字符是内容，那么就需要对这个数据做特殊处理\n自定义消息结构 我们可以自己定义消息结构，由包头 + 数据组成 在包头里面有一个字段是用来表示数据包的大小的，如下:\nstruct { int32 message_length; char message_data[]; } message; 这样当客服端可以先解析包头里面消息的长度，然后在读满这个长度大小的数据，就可以认为收到了一个完整的包\nRST 标识 收到RST应用层处理情况 如果应用层尝试去读，比如 recv 应用层就会收到 Connection reset by peer 意思是连接被重置 如果应用层尝试去写，比如 send 应用层就会收到 Broken pipe 意思是这个通道已经坏了 RST出现的场景 RST 一般出现在异常情况，一般为 对端的端口不可用和 socket 提前关闭\n端口不可用 端口未监听\n服务器 Listen方法会创建一个 sock放入全局的 哈希表中，当客服端来连接的时候，会根据 ip和 端口从这个 hash表中去获取 sock\n端口未监听一定会发送 RST吗 不一定因为在知道服务器没有 listen过，不会立马发送 RST报文，而是会进行 校验和检查,只有在校验和没有问题的时候才会发 RST给对端\n校验和可以验证数据从端到端是否出现了异常，由发送端计算，然后接收端效验，计算范围覆盖数据包的 tcp首部和 tcp数据\n为什么一定要先进行效验和，通过以后才发送RST 一般校验和出现了问题这个时候一般都是包被篡改了，或者是一个数据紊乱伪造的包\n在网络的5层协议中，如果出现这中问题，一般的做法都是丢弃，而不是傻乎乎的恢复一个包给对方\n如果是 TCP协议，因为是可靠的，所以丢了也没有事情，当没有接到对端的 ACK的时候，会重传\n如果是 UDP协议，因为是不可靠传输的，接收端已经接收了不可靠的这中情况，那么丢了就丢了\n程序启动了但是崩了 这个和端口未监听差不多，因为程序崩了，资源就会释放，那么就会进入 Close状态，重启了以后，客服端新的连接进来的时候去全局的 hash表根据 IP地址和 端口查找，却找不到 Sock这个时候如果校验和通过了，那么也会发送 RST报文过去\nsocket提前关闭 本端提前关闭 如果本端 socket接收缓冲区还有数据，此时提前 close() socket 那么本端会先把接 收缓冲区的数据清空，然后给远端一个 RST\n远端提前关闭 远端已经 close()这个时候本地还尝试给远端发送数据，这个时候远端会给本端回一个 RST\n大家知道，TCP是全双工通信，意思是发送数据的同时，还可以接收数据。\nClose()的含义是，此时要同时关闭发送和接收消息的功能。\n客户端执行 close()， 正常情况下，会发出第一次挥手FIN，然后服务端回第二次挥手 ACK。如果在第二次和第三次挥手之间，如果服务方还尝试传数据给客户端，那么客户端不仅不收这个消息，还会发一个 RST消息到服务端。直接结束掉这次连接。\nRST包丢了怎么办 RST丢了，问题不大，比如说上方的图，服务器发了 RST之后，就认为服务器连接不可用了\n如果发送 RST之前，客服端发送了数据，客服端没有等到 ACK确认码，这个时候就会重发，重发的时候，服务器也会返回 RST包\n如果在发送 RST之前，客服端没有发送数据，那么因为有 keepalive 机制，会定期发送探活包，这种数据到了服务器，可以触发一个 RST包\n收到RST一定会端开吗 不一定会端开，因为在收到 RST之后，会进行检查 seq是否合法，其实也是看这个 seq是不是在合法的接收范围内，如果不在就丢弃这个 RST包\n至于这个接收窗口是啥，如下图\n为什么一定要校验在范围内 因为如果不校验的话，不怀好意的第三方伪造了 seq的包，这个时候就会让客服端或者服务断开连接，如果效验的话毕竟因为窗口是在不断变化的，seq也在不断的变化，所以在范围内的 seq很难被伪造出来\nsocket recv和send 情况 如果接收缓冲区有数据，这个时候close 如果接收缓冲区还有数据未读，会先把接收缓冲区的数据清空，然后给对端发送一个 RST\n如果接收缓存区是空的，那么就会发送 FIN，开始正常的四次挥手过程\n如果发送缓冲区有数据，这个时候close socket 是个先进先出的队列，这个时候内核会把最后一块数据的标识置位 FIN，然后安静的等待内核把数据都发出去\nUDP udp有发送缓冲区吗 udp也是socket， 只要是socket就会有发和收两个缓冲区，和什么协议无关\nudp用发送缓冲区吗 一般情况下，会把数据拷贝到发送缓存区后直接发送\n一些网络异常回答 在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。 即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手\n如果有数据传输，那么就的分两种情况\n客户端宕机，然后立马重启。\n在客户宕机的时候，服务器一直接不到 ACK确认码，这个时候就会触发重传\n如果客户端没有进程监听这个 TCP报文的目标端口号，由于找不到目标端口号，那么客服端就会发送 RST包，重置改连接\n如果客户端有进程监听这个 TCP报文，这个时候重启，之前的 TCP连接的 socket结构体数据都会丢失，这个时候客户端找不到该 TCP相关的 socket数据，也会发送 RST包\n客户端宕机，一直没有重启\n服务器就会触发超时重传报文机制，一般 15次，不过 tcp超时重传不止基于 15次判断，还会基于最大超时时间来判定，也就是先达到最大超传次数或者最大超时时间，就会判定 TCP有问题，就会停止重传\n","permalink":"https://frog-game.github.io/posts/read/wangluozongjie/","summary":"tcp 握手挥手 序列号: 在建立连接的时候有计算机生成的随机数并作为初始值，通过syn包传给接收端主机，每发一次数据，就累加一次该数据字节数的大小，","title":"网络底层总结"},{"content":" frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 ","permalink":"https://frog-game.github.io/links/","summary":"frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客","title":"🤝友链"},{"content":"关于我\n英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山 ","permalink":"https://frog-game.github.io/about/","summary":"关于我 英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️关于"}]