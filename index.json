[{"content":"使用的HybridCLR版本,unity版本 XAsset打包过程[这个过程每个公司,每个项目都不一样,但是原理差不多,下面是我这里的步骤] HybridCLR打包过程 Xcode上的要完成的一些前提 IOS XCode下记得编译libil2cpp.a[马赛克是自己的一些个人信息,进行了涂抹不用关心]\n执行后就生成\n然后按下面步骤进行替换\n然后就可以愉快的打IOS包了 如果XCode有其他报错,就自己根据项目解决吧。这个就不截图了\n热更新流程 这一步要注意去git查看是否真的生成了需要的内容只有打勾的地方才说明生成成功了\n然后后面就可以用你手机去进行下载热更新补丁操作了因为我用的是xAsset所以直接复用的xasset的整体补丁下载流程\n","permalink":"https://frog-game.github.io/posts/life/hybridclr-ios-dabao/","summary":"使用的HybridCLR版本,unity版本 XAsset打包过程[这个过程每个公司,每个项目都不一样,但是原理差不多,下面是我这里的步骤] H","title":"HybridCLR IOS打包热更新"},{"content":"一些前提知识点 代码术语区别 IL:微软平台上的一门中间语言，我们常写的C#代码在编译器中都会自动转换成IL,中间语言是编译使用高级 .NET 语言编写的代码后获得的结果。 对使用其中一种语言编写的代码进行编译后，即可获得 IL 所生成的二进制代码\n托管代码：托管代码就是执行过程交由运行时管理的代码。 在这种情况下，相关的运行时称为公共语言运行时 (CLR)，不管使用的是哪种实现（例如 Mono、.NET Framework 或 .NET Core/.NET 5+）。 CLR 负责提取托管代码、将其编译成机器代码，然后执行它。 除此之外，运行时还提供多个重要服务，例如自动内存管理、安全边界、类型安全，把托管代码理解成上面的IL中间语言也行\n非托管代码：非托管代码（Unmanaged Code）是指直接编译成目标计算机的机器码，这些代码只能运行在编译出这些代码的计算机上，或者是其他相同处理器或者几乎一样处理器的计算机上。非托管代码不能享受公共语言运行库所提供的一些服务，例如内存管理、安全管理等。非托管代码（Unmanaged Code）不由CLR公共语言运行库执行，而是由操作系统直接执行的代码,如果非托管代码需要进行内存管理等服务，就必须显式地调用操作系统的接口，通常非托管代码调用Windows SDK所提供的API来实现内存管理。\n原生代码:native code是本地cpu的目标执行代码, 不是IL, 所以速度很快, 它的执行不依赖某个虚拟机或者解释器，编译后可直接依附操作系统运行，不需要经过虚拟机之类的东西\n程序集:程序集（Assembly）的文件负责封装中间语言，程序集中包含了描述所创建的方法、类以及属性的所有元数据\n编译器 c#编译器: 将c#编译为IL [C#----\u0026gt;CIL] Mono Runtime编译器:将IL转换成原生码，然后让Mono运行时去执行,这样其实也达到了c#跨平台的效果 平台编译 build\n编译GCC的平台\nhost\n运行GCC的平台\ntarget\nGCC编译产生的应用程序的运行平台\nnative compiler:三者全部相同（build = host = target）就是原生编译 我们在PC上装的Ubuntu或者Fedora里面带的GCC，就是native compiler cross compile:如果build = host，但是target跟前两者不同就是 交叉编译开发手机应用程序的编译器，通常运行在PC或Mac上，但是编译出来的程序无法直接在PC或Mac上执行 编译方式 即时编译[Just in time, JIT]: 就是在程序运行的时候把CIL的byte code 转成目标平台的原生码,也就是Mono Runtime编译器干的活 提前编译[Ahead of time,AOT]:程序运行前将exe或者dll里面的CIL的byte code部分转成目标平台的原生码,并且存储起来，好加快速度,但是程序中还是会有部分的CIL的byte code需要JIT编译 完全静态编译[Full ahead of time,Full-AOT]:就是将所有源码编译成目标平台所需要的原生码 IOS不支持JIT编译的原因 IOS并非把JIT禁止了，主要还是IOS封存了内存的[可执行权限]，变相的封锁了JIT编译方式 值类型和引用类型 C# 中的类型一共分为两类，一类是值类型(Value Type)，一类是引用类型(Reference Type)。\n值类型包括结构体(struct)和枚举(enum)。 引用类型包括类(class)、接口(interface)、委托(delegate)、数组(array)等。\n常见的简单类型如short、int、long、float、double、byte、char等其本质上都是结构体，对应struct System.Int16、System.Int32、System.Int64、System.Single、System.Double、Syetem.Byte、System.Char，因此它们都是值类型。但string和object例外，它们本质上是类，对应class System.String和System.Object，所以它们是引用类型。\n值类型 值类型变量本身保存了该类型的全部数据，当声明一个值类型的变量时，该变量会被分配到栈(Stack)上。\n引用类型 引用类型变量本身保存的是位于堆(Heap)上的该类型的实例的内存地址，并不包含数据。当声明一个引用类型变量时，该变量会被分配到栈上。如果仅仅只是声明这样一个变量，由于在堆上还没有创建该类型的实例，因此，变量值为null，意思是不指向任何类型实例(堆上的对象)。对于变量的类型声明，用于限制此变量可以保存的类型。\n值传递和引用传递 C#中方法的参数传递默认的是值传递，引用传递和输出传递需要在参数类型前面对应加上ref、out限制符，由于输出传递和引用传递类似，这里只讨论引用传递。\n值传递参数是原变量的拷贝，值传递参数和原变量的内存地址不同，因此方法中对值传递参数的修改不会改变原变量。\n引用传递参数是原变量的指针，引用传递参数和原变量的内存地址相同，相应的方法中对引用传递参数的修改会改变原变量。\nHybridCLR菜单 IL2CPP 就是上面的2.1编译方式中的AOT提前编译\n分为下面两部分 AOT编译器 ​\t把IL中间语言转成CPP文件的作用\n运行时库 ​\t主要是做垃圾回收,线程文件的获取，还有对托管数据的原生代码进行修改\n为啥要转换成CPP 运行速度快,这个毋庸置疑 mono 为了跨平台，他是通过VM来实现的，也就是说有几个平台，就需要实现几个VM,这种方法耗时耗力,而且为了实现各个平台的支持和移植，势必要把代码进行修改，然后出现bug在进行修复，来来回回时间和精力花费不少，所以为啥不利用现成各个平台的C++编译器执行了,这也是IL2CPP的核心思想 虽然最后代码都变成的静态的C++但是内存管理这块还是需要遵循c#的标准和方式,这也是为什么最后还需要一个 IL2CPP VM的原因 这个时候VM做得主要还是GC的管理,线程的创建等等一些辅助服务性的工作 工作原理就直接上官网的图了 为什么IL2CPP不支持热更新 因为IL2CPP是一个纯静态的AOT运行时，然后不支持运行时加载DLL，所以是不支持热更新\n然后hybridclr扩充了IL2CPP的代码,使他从AOT运行方式变成了AOT+Interpreter的混合方式从而可以动态的加载dll实现热更新\n区别 原始IL指令集是基于栈的指令集\nHybridclr是基于寄存器指令\n两种方式各有优缺点，基于栈的指令集很明显可移植高，但是工作效率较低。而基于寄存器指令集寄存器由硬件直接提供，工作效率高，程序受硬件约束。\nHybridclr的原理 dll不过是元数据和代码的集合,aot与 热更新dll的区别只不过一个函数以aot代码方式执行，一个以解释方式执行,最后都会直接在虚拟机层面将aot和热更新dll统一对待\n为什么Hybridclr能做到如此统一和彻底，因为元数据不过是数据，不管aot还是热更新是没有本质区别的\n而托管代码执行，依赖的不过是代码和数据\nHybridclr分两个工程\nHybridclr工程进行了源码的编译解析，在这里可以理解成这个工程做得主要事情是解释器的工作,此解释器是在IL2CPP VM扩充的，不解的可以看下图\n第二个工程是il2cpp_plus,这个工程会把泛型方法、泛型数据类型、以及其他的一些支持添加到IL2CPP里面,也可以简单的理解成为主要是为了给IL2CPP扩展功能用的，从而能让他动态的加载DLL\n源码解析 Hybridclr工程 这个是代码工程结构\n阅读前提 ARM64:CPU的ARM架构 主流的手机/平板品牌，绝大数是采用ARM架构\nBoehmGC算法，unity底层托管堆使用的是BoehmGC算法是用的mark-sweep（标记-清扫）算法,具体和Java的gc算法类型,这块由于篇幅问题就不详细写了,太多内容一句话说不清楚,以后有时间整理一篇详细文章出来\nModule 是 .dll 或 .exe 类型的可移植可执行文件，这些文件由一个或多个类和接口组成\nAssembly 是程序集\nAssembly有main程序函数。module只能附属于程序集，程序集可以拥有多个。\nMetaData就是用System.reflection得到的方法，属性，参数等等，这些都是元数据\nMethodBody 方法主体，就是调用方法时执行的代码块，方法的主体语句必须放在花括号（即大括号 {}）中。\nIl2CppImage 这个结构体是程序集镜像,可以通过它来获取命名空间,class,方法,函数指针地址等等\ntypedef struct Il2CppImage { const char* name;//名字 const char *nameNoExt;//扩展名字 Il2CppAssembly* assembly;//程序集指针 TypeDefinitionIndex typeStart;//方法类型偏移位置开始 uint32_t typeCount;//方法总数 TypeDefinitionIndex exportedTypeStart;//导出类型偏移位置开始 uint32_t exportedTypeCount;//导出类型总数 CustomAttributeIndex customAttributeStart;//自定义属性偏移位置开始 uint32_t customAttributeCount;//自定义属性总数 MethodIndex entryPointIndex;//方法入口点索引 #ifdef __cplusplus mutable #endif Il2CppNameToTypeDefinitionIndexHashTable * nameToClassHashTable;//name对应的class的hashTable const Il2CppCodeGenModule* codeGenModule;//Module指针 uint32_t token;//通过他可以得到函数指针地址 uint8_t dynamic;//没看到使用,估计是用来验证是不是动态lib使用的 } Il2CppImage; 所有的metadata 解析都是遵循的下面规范ECMA-335 - Ecma International (ecma-international.org)\nCLI中大多数metadata被为几十种类型，每个类型的数据组织成一个table如下图,如果有缺失类型,请去ECMA-335查看\nPortable PDB tables .NET引入了一种新的符号文件（PDB）格式，主要用于跨平台\n早期PDB格式是为了C和C++设计的，发展了多年以来现在已经支持.NET了。不幸的是，这种格式一直以来都被认为是专有的，这就意味着它没有很好文档记录，而且只能使用Windows库读取，所以有了.NET Core，而且为了跨平台，于是开发了这个新的跨平台PDB库\n原始 MethodInfo\ntypedef struct MethodInfo { Il2CppMethodPointer methodPointer;//指向普通执行函数 InvokerMethod invoker_method;//指向反射执行函数 const char* name;//名字 Il2CppClass *klass;//函数所属类指针 const Il2CppType *return_type;//返回值类型 const ParameterInfo* parameters;//参数信息 union//generic instance method { const Il2CppRGCTXData* rgctx_data; /* is_inflated is true and is_generic is false, i.e. a generic instance method */ const Il2CppMethodDefinition* methodDefinition;//方法定义 }; union//uninflated generic method { const Il2CppGenericMethod* genericMethod; /* is_inflated is true */ const Il2CppGenericContainer* genericContainer; /* is_inflated is false and is_generic is true */ }; uint32_t token; uint16_t flags; uint16_t iflags; uint16_t slot; uint8_t parameters_count; uint8_t is_generic : 1; /* true if method is a generic method definition */ uint8_t is_inflated : 1; /* true if declaring_type is a generic instance or if method is a generic instance*/ uint8_t wrapper_type : 1; /* always zero (MONO_WRAPPER_NONE) needed for the debugger */ uint8_t is_marshaled_from_native : 1; /* a fake MethodInfo wrapping a native function pointer */ } MethodInfo; 改写后的MethodInfo\ntypedef struct MethodInfo { Il2CppMethodPointer methodPointer; InvokerMethod invoker_method; const char* name; Il2CppClass *klass; const Il2CppType *return_type; const ParameterInfo* parameters; union { const Il2CppRGCTXData* rgctx_data; /* is_inflated is true and is_generic is false, i.e. a generic instance method */ const Il2CppMethodDefinition* methodDefinition; const Il2CppMethodDefinition* methodMetadataHandle; }; /* note, when is_generic == true and is_inflated == true the method represents an uninflated generic method on an inflated type. */ union { const Il2CppGenericMethod* genericMethod; /* is_inflated is true */ const Il2CppGenericContainer* genericContainer; /* is_inflated is false and is_generic is true */ Il2CppMetadataGenericContainerHandle genericContainerHandle; /* is_inflated is false and is_generic is true */ Il2CppMethodPointer nativeFunction; /* if is_marshaled_from_native is true */ }; uint32_t token; uint16_t flags; uint16_t iflags; uint16_t slot; uint8_t parameters_count; uint8_t is_generic : 1; /* true if method is a generic method definition */ uint8_t is_inflated : 1; /* true if declaring_type is a generic instance or if method is a generic instance*/ uint8_t wrapper_type : 1; /* always zero (MONO_WRAPPER_NONE) needed for the debugger */ uint8_t is_marshaled_from_native : 1; /* a fake MethodInfo wrapping a native function pointer */ void* interpData; Il2CppMethodPointer methodPointerCallByInterp; Il2CppMethodPointer virtualMethodPointerCallByInterp; bool initInterpCallMethodPointer; bool isInterpterImpl; } MethodInfo; 实例方法（instance method）和 静态方法（static method）\n被static修饰的方法为静态方法，之外的方法为实例方法\nvoid staticMethodTest(){ //直接调用静态方法 Boss.work(); //创建实例 Boss boss = new Boss(); //调用实例方法 boss.programming(); } class Boss { String name; public void programming(){ System.out.println(\u0026#34;I am programming.\u0026#34;); } public static void work(){ System.out.println(\u0026#34;I am working.\u0026#34;); } } AOT和interpreter桥接过程 AOT加载补充元数据原理 为什么需要AOT补充元数据,简单的来讲主要是下面几点\nl2cpp是AOT运行时，它运行时使用的几乎所有（为什么不是全部？）类型都是编译期已经静态确定的。你在AOT中只实例化过List\u0026lt;int\u0026gt; 和 List\u0026lt;string\u0026gt;，在热更新代码中是不能使用类似 new List\u0026lt;float\u0026gt;() 这样的代码的。\n尽管il2cpp可以在内存中创建出List\u0026lt;float\u0026gt;类型的大多数元数据，但它无法创建出它的各个成员函数实现。 你可以通过反射获得typeof(List\u0026lt;float\u0026gt;)，却无法调用它的任何成员函数，包括构造函数。\n无法创建出AOT泛型类型的成员函数实现的本质原因是il2cpp在完成IL到c++代码的转换后，丢失了原始IL函数体信息， 导致无法根据泛型基类List\u0026lt;\u0026gt;的元数据实例化出List\u0026lt;float\u0026gt;的各个成员函数实现。\n泛型类，尤其是泛型容器List、Dictionary之类在代码中使用如此广泛，如果因为AOT限制，导致List之类的都不能运行，那游戏热更新的代码限制也太大了。幸运的是，HybridCLR使用两类技术彻底解决了这个问题：\n基于il2cpp的泛型共享技术[这个技术有局限性和缺陷] [官方用这个技术其实主要还是想用共享机制来减少包体的大小] [优点是节约代码大小，缺点是极大地伤害了泛型函数的性能]\n由于值类型不能泛型共享，泛型实例（类或函数）的泛型参数中如果出现值类型，这个泛型实例必须提前在AOT提前实例化。如果 你的泛型参数类型是热更新代码中定义的值类型，由于热更新类型显然不可能提前在AOT中泛型实例化，导致你在热更新代码 中无法使用 List\u0026lt;热更新值类型\u0026gt; 这样的代码，给开发带来极多的不便。\n基于补充元数据技术，这也是HybridCLR的专利技术[具体源码,原理如下图]\n下载 Hybridclr 工程 下面是我正在阅读的Hybridclr作者初始源码版本 git clone https://gitee.com/focus-creative-games/hybridclr.git -b main git reset --hard 0540b31aa739fd275d8cfcd861cb41568d4a982c 执行上面的命令就能下载到我正在阅读的指定的分支,指定的commit版本\n下面是我加上的对应的注释版本 git clone https://github.com/frog-game/hybridclr-0540b31aa739fd275d8cfcd861cb41568d4a982c.git 执行上面的命令就能下载到我加上的对应的注释版本\nil2cpp_plus工程 下面是我正在阅读的il2cpp_plus作者初始源码版本 git clone -b v2019-1.0.0-rc --depth=1 https://github.com/focus-creative-games/il2cpp_plus.git 执行上面的命令就能下载到我正在阅读的指定的tag版本\nIOS热更演示 ","permalink":"https://frog-game.github.io/posts/read/hybridclr-yuanmayuedu/","summary":"一些前提知识点 代码术语区别 IL:微软平台上的一门中间语言，我们常写的C#代码在编译器中都会自动转换成IL,中间语言是编译使用高级 .NET 语言编写的","title":"HybridCLR源码赏析"},{"content":"NTP授时原理 C1 客户端发送请求的时间 S2 服务器接收请求的时间 S3 包离开场景时候的时间 C4 客户端接到返回包时间 m_nNetDelay 网络延时 d = (S2 - C1) + (C4 - S3) m_nDiftime 服务器与客户端的时差 T = [(S2 - C1) + (S3 - C4)] / 2 m_nNetDelay 其实就是RTT 也就是往返时间 也可以这么求 C4 - C1 - (S3 - S2) protobuff包定义 message SceneClocksyncRequest { int64\toriginate_timestamp = 1;客户端发送请求的时间C1 } message SceneClocksyncRet { int64 originate_timestamp = 1;客户端发送请求的时间 C1 int64 receive_timestamp = 2;服务器接收请求的时间 S2 int64 scene_timestamp = 3;场景同步时间戳【不参与NPT计算】 int64 transmit_timestamp = 4;包离开场景时候的时间 S3 } 具体代码实现 -- 同步请求 local function SendClockSyncReqMsg() local sceneClocksyncRequest = { originate_timestamp = serviceCore.getClockRealtime() } serviceCore.send(m_channelID,\u0026#34;SceneClocksyncRequest\u0026#34;,sceneClocksyncRequest) end -- 同步反馈 function robotStateMachine.SceneClocksyncRet(proto) --proto.originate_timestamp C1 客户端发送请求的时间 --proto.receive_timestamp S2 服务器接收请求的时间 --proto.transmit_timestamp S3 包离开场景时候的时间 --destination_timestamp C4 客户端接到返回包时间 --m_nNetDelay 网络延时 d = (S2 - C1) + (C4 - S3) --m_nDiftime 服务器与客户端的时差 T = [(S2 - C1) + (S3 - C4)] / 2 --m_nNetDelay 其实就是RTT也就是往返时间 也可以这么求 C4 - C1 - (S3 - S2) local destination_timestamp = serviceCore.getClockRealtime() m_nNetDelay = (proto.receive_timestamp - proto.originate_timestamp) + ((destination_timestamp - proto.transmit_timestamp)) m_nDiftime = ((proto.receive_timestamp - proto.originate_timestamp) + (proto.transmit_timestamp - destination_timestamp) / 2) RTT = destination_timestamp - proto.originate_timestamp - (proto.transmit_timestamp - proto.receive_timestamp); end -- 真正算出来的同步时间 function GetServerTime() return serviceCore.getClockRealtime() + m_nNetDelay + m_nDiftime end ","permalink":"https://frog-game.github.io/posts/tech/ntp-shijian-tongbu/","summary":"NTP授时原理 C1 客户端发送请求的时间 S2 服务器接收请求的时间 S3 包离开场景时候的时间 C4 客户端接到返回包时间 m_nNetDelay 网络延时 d = (S2 - C1) + (C4 - S3) m_nDiftime 服务器与","title":"NTP时间同步"},{"content":"一些字段的解释 观察者：我可以观察到那些人。 被观察者：那些人能观察到自己。 #define WATCHER_MODE 0x01 观察者模式 #define MARKER_MODE 0x02 被观察者模式 灯塔相关[结构体] 1：灯塔区域结构\nstruct towerSpace_s { void (*callback)(void*pUserData,bool bAddTo,uint64_t watcher, uint64_t marker); -- 回调函数 void*\tpUserData; //用户信息 float\tfMin[2]; //最小位置 float\tfGridLength[3];//网格x y,z方向长度 float\tfMovefRange;//移动范围 int32_t\tiSplitThreshold;//拆分阈值 int32_t iMaxWidth; //最大宽度 int32_t iMaxHeight;//最大高度 int32_t* pGrids;//网格数据 tower_tt*\tpTowers;//灯塔数据 int32_t\tiTowerNext;//下一个灯塔id int32_t\tiTowerCapacity;//灯塔容量 aoiObj_tt* pSlotObj;//格子里面对象 int32_t\tiSlotIndex;//格子索引 int32_t iSlotCapacity;//格子容量 }; 2：灯塔信息结构\ntypedef struct tower_s { aoi_tree_tt watcher; //灯塔观察者[用来存储观察到的对象] aoi_tree_tt\tmarker;//灯塔被观察者 int32_t iMarkerCount;//被观察者数量 int32_t iFirstChildId;//第一个儿子节点索引 } tower_tt; 3：灯塔划分后的节点结构【四个儿子节点】\ntypedef struct aoiNode_s { RB_ENTRY(aoiNode_s) entry; //实体 int32_t\tiId; //id } aoiNode_tt; 4：灯塔里面对象结构\ntypedef struct aoiObj_s { int32_t\tiId; // id int32_t iMode; // 模式(MARKER_MODE:被观察者模式 WATCHER_MODE:观察模式) uint64_t uiMask;//掩码 uint64_t uiUserData; //用户数据 float\tfViewRadius; // 视野半径 float last[3]; //上一个xyz位置 float pos[3];//当前xyz位置 } aoiObj_tt; 灯塔AOI相关的一些操作函数 int32_t luaopen_laoi(lua_State *L) { #ifdef luaL_checkversion luaL_checkversion(L); #endif registerTowerSpaceL(L); luaL_Reg lualib_funcs[] = { {\u0026#34;createAoiSpace\u0026#34;,\tlcreateAoiSpace},//创建aoi区域 {NULL, NULL} }; luaL_newlib(L, lualib_funcs); return 1; } int32_t registerTowerSpaceL(struct lua_State *L) { luaL_newmetatable(L, \u0026#34;towerSpace\u0026#34;); lua_pushvalue(L, -1); lua_setfield(L, -2, \u0026#34;__index\u0026#34;); struct luaL_Reg lua_towerSpaceFuncs[] = { {\u0026#34;setCallback\u0026#34;,\tlaoi_setCallback}, //设置回调函数 {\u0026#34;addObj\u0026#34;,\tlaoi_addObj},//增加一个实体对象 {\u0026#34;removeObj\u0026#34;,\tlaoi_removeObj},//移除一个实体对象 {\u0026#34;updateObjMask\u0026#34;,\tlaoi_updateObjMask},//更新对象的mask[0x01:观察者 0x02:被观察者] {\u0026#34;updateObjPos\u0026#34;,\tlaoi_updateObjPos},//更新对象的pos {\u0026#34;addObjWatcher\u0026#34;,\tlaoi_addObjWatcher},//增加对象到相应的观察容器 {\u0026#34;removeObjWatcher\u0026#34;,laoi_removeObjWatcher},//从相应的观察容器移除对象 {\u0026#34;addObjMarker\u0026#34;,\tlaoi_addObjMarker},//增加对象到被观察者 {\u0026#34;removeObjMarker\u0026#34;,\tlaoi_removeObjMarker},//移除对象到被观察者 {\u0026#34;__gc\u0026#34;, laoi_towerSpace_gc},//此区域进行GC回收 {NULL, NULL} }; luaL_setfuncs(L, lua_towerSpaceFuncs, 0); return 1; } [四叉树]lod示意图 黑色大框是AOI的区域大小 每个正方形块上面都有一个灯塔 暂时定的最多分裂3层 黑色的原点是场景内的实体 灯塔AOI一些关键函数[具体代码在frog-game-server框架] 1. 更新观察者集合\ninline static void changeAoiObjWatcher(towerSpace_tt* pTowerSpace,aoiObj_tt* pObj) { float bmin[3]; float bmax[3]; bmin[0] = pObj-\u0026gt;last[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;last[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;last[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;last[2] + pObj-\u0026gt;fViewRadius; int32_t minxLast = 0; int32_t minyLast = 0; int32_t maxxLast = 0; int32_t maxyLast = 0; calcGridLodLoc(pTowerSpace, 2,bmin, \u0026amp;minxLast, \u0026amp;minyLast); calcGridLodLoc(pTowerSpace, 2,bmax, \u0026amp;maxxLast, \u0026amp;maxyLast); minxLast = minxLast \u0026gt; 0 ? minxLast : 0; minyLast = minyLast \u0026gt; 0 ? minyLast : 0; maxxLast = maxxLast \u0026lt; pTowerSpace-\u0026gt;iMaxWidth * 4 ? maxxLast : pTowerSpace-\u0026gt;iMaxWidth*4 - 1; maxyLast = maxyLast \u0026lt; pTowerSpace-\u0026gt;iMaxHeight * 4 ? maxyLast : pTowerSpace-\u0026gt;iMaxHeight*4 - 1; bmin[0] = pObj-\u0026gt;pos[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;pos[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;pos[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;pos[2] + pObj-\u0026gt;fViewRadius; int32_t minx = 0; int32_t miny = 0; int32_t maxx = 0; int32_t maxy = 0; calcGridLodLoc(pTowerSpace, 2,bmin, \u0026amp;minx, \u0026amp;miny); calcGridLodLoc(pTowerSpace, 2,bmax, \u0026amp;maxx, \u0026amp;maxy); minx = minx \u0026gt; 0 ? minx : 0; miny = miny \u0026gt; 0 ? miny : 0; maxx = maxx \u0026lt; pTowerSpace-\u0026gt;iMaxWidth*4 ? maxx : pTowerSpace-\u0026gt;iMaxWidth*4 - 1; maxy = maxy \u0026lt; pTowerSpace-\u0026gt;iMaxHeight*4 ? maxy : pTowerSpace-\u0026gt;iMaxHeight*4 - 1; //是否重合 if(isOverlap(minx,miny,maxx,maxy,minxLast,minyLast,maxxLast,maxyLast)) { int32_t iMinX = minx \u0026lt; minxLast ? minx : minxLast; int32_t iMinY = miny \u0026lt; minyLast ? miny : minyLast; int32_t iMaxX = maxx \u0026gt;= maxxLast ? maxx : maxxLast; int32_t iMaxY = maxy \u0026gt;= maxyLast ? maxy : maxyLast; int32_t iChanged = 0; //往上找到最大的网格块 //为什么是iMinY/4 是因为除以4就像四叉树一样找最上面的父节点的索引值一样 for (int32_t iY = iMinY/4; iY \u0026lt; (iMaxY+3)/4; ++iY) { for (int32_t iX = iMinX/4; iX \u0026lt; (iMaxX+3)/4; ++iX) { iChanged = 0; if(isInInside(iX*4,iY*4,iX*4+3,iY*4+3,minxLast,minyLast,maxxLast,maxyLast)) { iChanged = 0x1; } if(isInInside(iX*4,iY*4,iX*4+3,iY*4+3,minx,miny,maxx,maxy)) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { removeGridWatcher(pTowerSpace,pObj,iX,iY); } break; case 0x2: { insertGridWatcher(pTowerSpace,pObj,iX,iY,pObj-\u0026gt;pos); } break; case 0x3: { int32_t iTowerId = pTowerSpace-\u0026gt;pGrids[iX + iY * pTowerSpace-\u0026gt;iMaxWidth]; assert(iTowerId != -1); tower_tt* pTower = pTowerSpace-\u0026gt;pTowers + iTowerId; if (pTower-\u0026gt;iFirstChildId == -1) { continue; } for (int32_t ly = 0; ly \u0026lt; 2; ly++) { for (int32_t lx = 0; lx \u0026lt; 2; lx++) { iChanged = 0; if (isInInside(iX * 4 + lx * 2, iY * 4 + ly * 2, iX * 4 + lx * 2 + 1, iY * 4 + ly * 2 + 1, minxLast, minyLast, maxxLast, maxyLast)) { iChanged = 0x1; } if (isInInside(iX * 4 + lx * 2, iY * 4 + ly * 2, iX * 4 + lx * 2 + 1, iY * 4 + ly * 2 + 1, minx, miny, maxx, maxy)) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { removeLodWatcher(pTowerSpace, iTowerId, pObj, iX, iY, iX * 4 + lx * 2, iY * 4 + ly * 2); } break; case 0x2: { insertLodWatcher(pTowerSpace, iTowerId, pObj, iX, iY, iX * 4 + lx * 2, iY * 4 + ly * 2); } break; case 0x3: { tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + pTower-\u0026gt;iFirstChildId + ly * 2 + lx; if (pLodTower-\u0026gt;iFirstChildId == -1) { continue; } for (int32_t l2y = 0; l2y \u0026lt; 2; l2y++) { for (int32_t l2x = 0; l2x \u0026lt; 2; l2x++) { iChanged = 0; if (isInRect(iX * 4 + lx * 2+l2x, iY * 4 + ly * 2+l2y, minxLast, minyLast, maxxLast, maxyLast)) { iChanged = 0x1; } if (isInRect(iX * 4 + lx * 2+l2x, iY * 4 + ly * 2+l2y, minx, miny, maxx, maxy)) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId + l2y * 2 + l2x; aoiNode_tt findNode; findNode.iId = pObj-\u0026gt;iId; aoiNode_tt* pT = RB_FIND(aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;watcher, \u0026amp;findNode); assert(pT); RB_REMOVE(aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;watcher, pT); mem_free(pT); aoiNode_tt* pI; RB_FOREACH(pI, aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;marker) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if ((pI-\u0026gt;iId != pObj-\u0026gt;iId) \u0026amp;\u0026amp; (pObj-\u0026gt;uiMask \u0026amp; pMarkerObj-\u0026gt;uiMask)) { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData, false, pObj-\u0026gt;uiUserData, pMarkerObj-\u0026gt;uiUserData); } } } break; case 0x2: { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId + l2y * 2 + l2x; aoiNode_tt* pNode = mem_malloc(sizeof(aoiNode_tt)); pNode-\u0026gt;iId = pObj-\u0026gt;iId; RB_INSERT(aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;watcher, pNode); aoiNode_tt* pI; RB_FOREACH(pI, aoi_tree_s, \u0026amp;pLod2Tower-\u0026gt;marker) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if ((pI-\u0026gt;iId != pObj-\u0026gt;iId) \u0026amp;\u0026amp; (pObj-\u0026gt;uiMask \u0026amp; pMarkerObj-\u0026gt;uiMask)) { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData, true, pObj-\u0026gt;uiUserData, pMarkerObj-\u0026gt;uiUserData); } } } break; } } } } break; } } } } break; } } } } else { for (int32_t iY = minyLast / 4; iY \u0026lt;= (maxyLast + 3) / 4; ++iY) { for (int32_t iX = minxLast / 4; iX \u0026lt;= (maxxLast + 3) / 4; ++iX) { removeGridWatcher(pTowerSpace, pObj, iX, iY); } } for (int32_t iY = miny/4; iY \u0026lt;= (maxy+3)/4; ++iY) { for (int32_t iX = minx/4; iX \u0026lt;= (maxx+3)/4; ++iX) { insertGridWatcher(pTowerSpace,pObj,iX,iY,pObj-\u0026gt;pos); } } }\t} 2. 把被观察者转入观察者容器\ninline static void changeAoiObjMaskToWatcher(towerSpace_tt* pTowerSpace,aoiObj_tt* pObj,int32_t iX,int32_t iY,uint64_t uiMask) { int32_t iTowerId = pTowerSpace-\u0026gt;pGrids[iX+iY*pTowerSpace-\u0026gt;iMaxWidth]; assert(iTowerId != -1); tower_tt* pTower = pTowerSpace-\u0026gt;pTowers + iTowerId; if (pTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { iChanged = 0; aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } return; } int32_t minGridX =iX*4; int32_t minGridY =iY*4; int32_t maxGridX =iX*4+3; int32_t maxGridY =iY*4+3; float bmin[3]; float bmax[3]; int32_t minx = 0; int32_t miny = 0; int32_t maxx = 0; int32_t maxy = 0; bmin[0] = pObj-\u0026gt;last[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;last[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;last[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;last[2] + pObj-\u0026gt;fViewRadius; calcGridLodLoc(pTowerSpace, 2,bmin, \u0026amp;minx, \u0026amp;miny); calcGridLodLoc(pTowerSpace, 2,bmax, \u0026amp;maxx, \u0026amp;maxy); if(!isInInside(minGridX,minGridY,maxGridX,maxGridY,minx,miny,maxx,maxy)) { for (int32_t y = 0; y \u0026lt; 2; y++) { for (int32_t x = 0; x \u0026lt; 2; x++) { tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + pTower-\u0026gt;iFirstChildId + y*2+x; if(pLodTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { iChanged = 0; aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } else { if(!isInInside(minGridX+x*2,minGridY+y*2,minGridX+x*2+1,minGridY+y*2+1,minx,miny,maxx,maxy)) { for (int32_t ly = 0; ly \u0026lt; 2; ly++) { for (int32_t lx = 0; lx \u0026lt; 2; lx++) { if(isInRect(minGridX+x*2+lx,minGridY+y*2+ly,minx,miny,maxx,maxy)) { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId + ly*2+lx; int32_t iChanged; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { iChanged = 0; aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } } } } else { int32_t iChanged; aoiNode_tt* pI; for (int32_t i = 0; i \u0026lt; 4; i++) { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId+i; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } } } } } } else { int32_t iChanged; aoiNode_tt* pI; for (int32_t i = 0; i \u0026lt; 4; i++) { tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + pTower-\u0026gt;iFirstChildId+i; if (pLodTower-\u0026gt;iFirstChildId == -1) { RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } else { for (int32_t j = 0; j \u0026lt; 4; j++) { tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + pLodTower-\u0026gt;iFirstChildId+j; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;marker) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pMarkerObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pMarkerObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pMarkerObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pObj-\u0026gt;uiUserData,pMarkerObj-\u0026gt;uiUserData); } break; } } } } } } } } 3. 更新AOI的被观察者\nvoid towerSpace_updateAoiObjMask(towerSpace_tt* pTowerSpace,int32_t iObjId,uint64_t uiMask) { aoiObj_tt* pObj = pTowerSpace-\u0026gt;pSlotObj + iObjId; assert(pObj-\u0026gt;iId == iObjId); if(pObj-\u0026gt;uiMask == uiMask) { return; } if(pObj-\u0026gt;iMode\u0026amp;MARKER_MODE) { int32_t iX; int32_t iY; calcGridLoc(pTowerSpace,pObj-\u0026gt;last,\u0026amp;iX,\u0026amp;iY); int32_t iTowerId = pTowerSpace-\u0026gt;pGrids[iX+iY*pTowerSpace-\u0026gt;iMaxWidth]; assert(iTowerId != -1); tower_tt* pTower = pTowerSpace-\u0026gt;pTowers + iTowerId; if(pTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged = 0; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } } else { int32_t iLodX; int32_t iLodY; calcGridLodLoc(pTowerSpace,1,pObj-\u0026gt;last,\u0026amp;iLodX,\u0026amp;iLodY); int32_t iTowerLodId = pTower-\u0026gt;iFirstChildId + (iLodX -iX*2)+(iLodY - iY*2)*2; tower_tt* pLodTower = pTowerSpace-\u0026gt;pTowers + iTowerLodId; if(pLodTower-\u0026gt;iFirstChildId == -1) { int32_t iChanged = 0; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } } else { int32_t iLod2X; int32_t iLod2Y; calcGridLodLoc(pTowerSpace,2,pObj-\u0026gt;last,\u0026amp;iLod2X,\u0026amp;iLod2Y); int32_t iTowerLod2Id = pLodTower-\u0026gt;iFirstChildId + (iLod2X -iLodX*2)+(iLod2Y - iLodY*2)*2; tower_tt* pLod2Tower = pTowerSpace-\u0026gt;pTowers + iTowerLod2Id; int32_t iChanged = 0; aoiNode_tt* pI; RB_FOREACH(pI,aoi_tree_s,\u0026amp;pTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLodTower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } RB_FOREACH(pI,aoi_tree_s,\u0026amp;pLod2Tower-\u0026gt;watcher) { if(pI-\u0026gt;iId != pObj-\u0026gt;iId) { aoiObj_tt* pWatcherObj = pTowerSpace-\u0026gt;pSlotObj + pI-\u0026gt;iId; iChanged = 0; if(pWatcherObj-\u0026gt;iMode\u0026amp;pObj-\u0026gt;uiMask) { iChanged = 0x1; } if(pWatcherObj-\u0026gt;iMode\u0026amp;uiMask) { iChanged |= 0x2; } switch (iChanged) { case 0x1: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,false,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; case 0x2: { pTowerSpace-\u0026gt;callback(pTowerSpace-\u0026gt;pUserData,true,pI-\u0026gt;iId,pObj-\u0026gt;iId); } break; } } } } } } if(pObj-\u0026gt;iMode\u0026amp;WATCHER_MODE) { float bmin[3]; float bmax[3]; bmin[0] = pObj-\u0026gt;last[0] - pObj-\u0026gt;fViewRadius; bmin[2] = pObj-\u0026gt;last[2] - pObj-\u0026gt;fViewRadius; bmax[0] = pObj-\u0026gt;last[0] + pObj-\u0026gt;fViewRadius; bmax[2] = pObj-\u0026gt;last[2] + pObj-\u0026gt;fViewRadius; int32_t minx = 0; int32_t miny = 0; int32_t maxx = 0; int32_t maxy = 0; calcGridLoc(pTowerSpace, bmin, \u0026amp;minx, \u0026amp;miny); calcGridLoc(pTowerSpace, bmax, \u0026amp;maxx, \u0026amp;maxy); minx = minx \u0026gt; 0 ? minx : 0; miny = miny \u0026gt; 0 ? miny : 0; maxx = maxx \u0026lt; pTowerSpace-\u0026gt;iMaxWidth ? maxx : pTowerSpace-\u0026gt;iMaxWidth - 1; maxy = maxy \u0026lt; pTowerSpace-\u0026gt;iMaxHeight ? maxy : pTowerSpace-\u0026gt;iMaxHeight - 1; for (int32_t iY = miny; iY \u0026lt;= maxy; ++iY) { for (int32_t iX = minx; iX \u0026lt;= maxx; ++iX) { changeAoiObjMaskToWatcher(pTowerSpace,pObj,iX,iY,uiMask); } } } pObj-\u0026gt;uiMask = uiMask; } 在此AOI模式下微服务器大世界地图分割方法和传统进程分割方法的不同 传统大世界地图分割方法 此方法为垂直分割方法，将一个一二十公里的大地图分割成很多小地图放到各自的进程当中去处理数据，这种需要处理大世界地图边缝问题，需要做镜像数据管理，还有如果角色在一个进程中也就是某个小地图上面堆积，那么这个进程的压力会很大，别的进程却很休闲，这个也需要处理，总之很多麻烦。所以我们改成了微服务器水平分割加灯塔AOI方式\n微服务大世界地图处理方法\n此结构基于微服务水平分割，每个相同微服务可以并行再开很多来并行处理减少压力，比如灯塔AOI开了5个微服务我发现算力还是不够， 那么我可以在增加新的灯塔AOI微服务来并行处理数据，所以理论上一个20公里的地图撑个10多万的人不成问题。而且这种模式在服务器不需要处理无缝问题\n一些疑问的总结 为什么有了观察者集合，还需要被观察者集合 因为有时候想主动检查对象的状态，从怪物AI会定时检查被观察者集合的距离，决定是否发动攻击；又比如释放技能需要遍历被观察者集合，判断它们是否命中。如果没有被观察者集合，就必须遍历整个场景的对象\n简单测试数据 ","permalink":"https://frog-game.github.io/posts/blog/aoi-tower/","summary":"一些字段的解释 观察者：我可以观察到那些人。 被观察者：那些人能观察到自己。 #define WATCHER_MODE 0x01 观察者模式 #define MARKER_MODE 0x02 被观察者模式 灯塔相关[结构体] 1：灯塔区域结构","title":"四叉树Lod灯塔AOI"},{"content":"lua删除table中的多个元素 很多时候，我们有这样的需求:删除table中若干符合条件的元素，最原始的想法就是用for遍历一边table，符合条件的用table.remove就可以了\nfunction test1(t) for i , v in ipairs(t) do if v.id%3 == 0 then table.remove(t ,i) end end end 结果证明这是不行的，因为table.remove删除第i元素后，i后面的元素会向前补齐，这样删除前处于i+1的元素就变成了i元素，然后for循环从t中取第i+1个元素，这样就漏掉了第i+1个元素，既然这样不行，很自然的就想到用while循环，可以自由控制“遍历的指针”是否前进，有删除操作，就不前进，否则才前进\n代码如下\nfunction test2(t) local int i =1 while(t[i]) do if t[i].id%3 == 0 then table.remove(t , i) else i = i + 1 end end end 跑一下，很正常！\n但是注意table.remove是删除队列中的一个元素，每一次操作都要移动大量元素，性能不会太好，因此可以考虑用临时的table，用来保存没有被删除的元素，最后再让t指向这个table，以空间来换时间，而实际使用中，t中的元素往往是table类型，这样临时的table中只会保存元素的引用，因此占用的空间几乎可以忽略不计。\n代码如下\nfunction test3(t) local newT = {} for i ,v in ipairs(t) do if v.id%3 ~= 0 then table.insert(newT , v) end end t= newT end 很好奇test3()到底比test2()快多少呢，我测试了一下\nt = {} local n = 10000 for i = 1,n do table.insert(t ,{id = i}) end n是10000的情况下：\ntest2耗时0.234s\ntest3耗时0.002s\n相差非常大。\n结论：\n删除table中的多个元素，在table较大，且删除操作较频繁时，切忌使用table.remove\nLUA-点号和冒号 由于LUA中是模拟类，没有class，\n所以这里是使用.号来访问实例的成员\nre.SetActive(re, re.activeSelf == false); 而冒号： 则是种语法糖，省略了上面代码中的第一个参数\nre:SetActive(re.activeSelf == false); 也就是说：lua中对象.方法，只能找到方法，对象只能是类型，即使传入的是对象，所以等效于确定了单纯的方法！\n所以冒号的方法，模拟了对象访问自己方法的思想，但本质不是！\n记住：lua没有面向对象！\n为什么JSON字符串当中会出现反斜杠? 对table或者对象进行了两次的序列化。说白了就是进行了两次的toJSONString\nlua 取余问题 lua 对数字字符串取余 lua 对字符串'0'取余， lua因为是弱语言所以会尝试把上面的字符串'0'转换成数字0，然后去进行取余，但是又不能对0进行取余所以会返回NaN\n为啥返回NaN 有可能是这个原因\n类型是int时做了判断，为double或者字符串会做转换跳过了前置判断，也就NaN了\nlua直接对数字0取余 会直接报语法错误\n","permalink":"https://frog-game.github.io/posts/blog/lua-kaifa-zhuyidian/","summary":"lua删除table中的多个元素 很多时候，我们有这样的需求:删除table中若干符合条件的元素，最原始的想法就是用for遍历一边table，","title":"lua开发经验总结"},{"content":"背景 每当我们接收一份新的版本，代码拿到手要做的第一件事就是查看 git log，看看这份代码的提交记录，最近代码做什么修改。如果我们看到 git log 杂乱无章，如果不知道每次提交的代码到底是做了什么，那么对于我们来说是比较痛苦的事情。所以说，规范的 CHANGELOG 不仅有助于他人帮忙 review 代码，也能高效的输出 Release Note，对版本管理也至关重要。\n所以我们可以考虑使用 [Gitlab]的服务端 hook 来针对git change log 进行校验，拦截不符合我们规范的提交到仓库。\n方案设计 服务端 git hook 分为三种，分别是：\npre-receive（推送前） update post-receive（推送后） 这三个步骤就是我们本地 push 完代码服务端要做的事情，如图所示：\n我们可以在 pre-receive（推送前）阶段来做提交信息的校验，如果不符合我们的要求，直接返回，则该推送便不会推送到 GitLab 仓库中去。\n实践落地-简单例子 环境说明 gitlab版本:14.3.3\nhook 配置 第一步，找到要配置仓库在 gitlab 中存储的路径，但因 gitlab 的仓库自某个版本开始采用 hash 存储，我们想要知道仓库对应的物理路径，可以如下操作\nGitlab默认的仓库存储路径在 /var/opt/gitlab/git-data目录下，仓库存储在子目录repositories里面，可以通过修改/etc/gitlab/gitlab.rb文件中git_data_dirs参数来自定义仓库存储路径。下图是我们服务器的仓库路径。 保存git代码路径时用的是hash来保存的，因为我要在代码库的hooks目录添加一些git hooks。但是gitlab保存的路径却是这样的如下。 gitlab是根据hash值来保存的路径，这个值是项目id,项目id在每个项目的设置页面可以找到。 我test项目的ID是7，在shell中执行下面命令（echo -n ID | sha256sum）生成一个hash值，按这个值去找这个git库的代码位置。test项目的hash值是7902699be42c8a8e46fbbb4501726517e86b22c56a189f7625a6da49081b2451. 查看gitlab /opt/git/git-data/repositories/@hashed/79/02/目录，有一个跟这个一模一样的hash值，ok。 第三步，hooks 中是 gitlab 示例的一些钩子，我们这里首先新建目录 custom_hooks，然后用再创建文件 pre-receive（推送前），pre-receive 文件内容如下（脚本语言为 shell），同时修改 pre-receive 文件的权限。\n修改文件权限：\nchmod +777 pre-receive #!/bin/bash echo \u0026#34;开始提交信息检查...\u0026#34; # 从标准输入获取本次提交的commit id及分支的信息 read normalInput ARR=($normalInput) parentCommitId=${ARR[0]} currentCommitId=${ARR[1]} branch=${ARR[2]} echo \u0026#34;您提交的分支为：$branch\u0026#34; # 获取coomit的信息，用户，邮箱，msg等 user=$(git log --pretty=format:\u0026#34;%an\u0026#34; $currentCommitId -1) echo \u0026#34;提交者为：$user\u0026#34; commitDate=$(git log --pretty=format:\u0026#34;%cd\u0026#34; $currentCommitId -1) echo \u0026#34;提交日期为：$commitDate\u0026#34; msg=$(git log --pretty=format:\u0026#34;%s\u0026#34; $currentCommitId -1) echo \u0026#34;提交的注释为：$msg\u0026#34; flag=$(echo $msg | grep -E \u0026#34;fix.*|add.*|del.*|update.*|temp.*|test.*|revert.*|Merge.*\u0026#34;) if [ -z \u0026#34;$flag\u0026#34; ]; then echo \u0026#34;[ERROR]提交信息校验未通过，需以 fix|add|del|update|temp|test|revert 开头\u0026#34; exit 1 fi 第四步，在本地尝试推送，推送显示如下，如果不符合规范则无法提交成功。\n第五步，我们再次查看目录如下： pre-receive.py[主要做了代码化风格检查+luacheck] #!/usr/bin/python # coding=utf-8 import re import shutil import tempfile import subprocess import os import sys import emoji from rich.panel import Panel from rich import box from rich.console import Console class Trigger(object): def __init__(self): \u0026#39;\u0026#39;\u0026#39; 初始化提交者，提交id， 提交者msg信息,当前操作的分支 \u0026#39;\u0026#39;\u0026#39; self.pushAuthor = \u0026#34;\u0026#34; self.pushCommit = [] self.pushMsg = [] self.pushCount = \u0026#34;\u0026#34; self.pushFile = [] self.console = Console() self.astyle_lint_dir = \u0026#39;/var/opt/gitlab/gitlab_cicd/format_check/linux\u0026#39; def __getGitInfo(self): \u0026#39;\u0026#39;\u0026#39; \u0026#39;\u0026#39;\u0026#39; self.oldObject, self.newObject, self.ref = sys.stdin.readline().strip().split(\u0026#39; \u0026#39;) def __getPushInfo(self): \u0026#39;\u0026#39;\u0026#39; git show命令获取push作者，时间，以及文件列表 文件的路径为相对于版本库根目录的一个相对路径 \u0026#39;\u0026#39;\u0026#39; rev = subprocess.Popen( \u0026#39;git rev-list \u0026#39; + self.newObject, shell=True, stdout=subprocess.PIPE) revList = rev.stdout.readlines() revList = [x.decode(\u0026#39;utf-8\u0026#39;).strip() for x in revList] # print(revList) # 查找从上次提交self.oldObject之后还有多少次提交 # 主要是为了获取提交的文件列表 if \u0026#34;0000000000000000000000000000000000000000\u0026#34; == self.oldObject: exit(0) indexOld = revList.index(self.oldObject) pushList = revList[:indexOld] pushList.reverse() getFlag = False # print(pushList) # temp file c_cpp_tempdir = tempfile.mkdtemp(\u0026#39;git_c_cpp_hook\u0026#39;) lua_tempdir = tempfile.mkdtemp(\u0026#39;git_lua_hook\u0026#39;) # print(lua_tempdir) c_cpp_temp_file_path = [] lua_temp_file_path = [] # 循环获取每次提交的文件列表 for pObject in pushList: p = subprocess.Popen(\u0026#39;git show \u0026#39; + pObject, shell=True, stdout=subprocess.PIPE) pipe = p.stdout.readlines() pipe = [x.decode(\u0026#39;utf-8\u0026#39;).strip() for x in pipe] self.pushMsg.append(pipe[4].strip() + \u0026#39;\\n\u0026#39;) self.pushCommit.append(pipe[0].strip(\u0026#34;commit\u0026#34;).strip()) if not getFlag: self.pushAuthor = pipe[1].strip( \u0026#34;Author\u0026#34;).replace(\u0026#39;:\u0026#39;, \u0026#39;\u0026#39;).strip() self.pushCount = len(pushList) getFlag = True # print(pipe) # 验证是否c,c++,lua文件 fileList = [x for x in pipe if x.startswith(\u0026#34;diff --git\u0026#34;)] # print(\u0026#34;===\u0026gt;\u0026#34;, fileList) indexList = [x for x in pipe if x.startswith( \u0026#34;index \u0026#34;) or x.startswith(\u0026#34;similarity index 100%\u0026#34;)] # print(\u0026#34;===\u0026gt;\u0026#34;, indexList) # fiList = dict(zip(fileList, indexList)) fiList = {fileList[i]: indexList[i] for i in range(len(fileList))} # print(\u0026#34;===\u0026gt;\u0026#34;, fiList) for file in fiList: if fiList[file].strip().startswith(\u0026#34;similarity index 100%\u0026#34;): continue if not (file.lower().endswith(\u0026#39;.cpp\u0026#39;) or file.lower().endswith(\u0026#39;.h\u0026#39;) or file.lower().endswith(\u0026#39;.c\u0026#39;) or file.lower().endswith(\u0026#39;.lua\u0026#39;)): continue filename = file.split(\u0026#39;/\u0026#39;)[-1] # print(filename) self.pushFile.append(filename) # git get Tree content_hash = fiList[file].strip()[15:22] # print(content_hash) content_p = subprocess.Popen( \u0026#39;git cat-file -p \u0026#39;+content_hash, shell=True, stdout=subprocess.PIPE) cpipe = content_p.stdout.readlines() cpipeList = [x.decode(\u0026#39;utf-8\u0026#39;) for x in cpipe] # print(cpipeList) if file.lower().endswith(\u0026#39;.cpp\u0026#39;) or file.lower().endswith(\u0026#39;.h\u0026#39;) or file.lower().endswith(\u0026#39;.c\u0026#39;): # print(filename) # print(content_hash) # print(file) # print(cpipeList) file_path = os.path.join(c_cpp_tempdir, filename) c_cpp_temp_file_path.append(file_path + \u0026#39;\\n\u0026#39;) with open(file_path, \u0026#39;w+\u0026#39;) as fp: fp.writelines(cpipeList) if file.lower().endswith(\u0026#39;.lua\u0026#39;): file_path = os.path.join(lua_tempdir, filename) lua_temp_file_path.append(file_path + \u0026#39;\\n\u0026#39;) with open(file_path, \u0026#39;w+\u0026#39;) as fp: fp.writelines(cpipeList) fc = open(self.astyle_lint_dir + \u0026#39;/.clang-format\u0026#39;) # print(fc.read()) with open(os.path.join(c_cpp_tempdir, \u0026#39;.clang-format\u0026#39;), \u0026#39;w+\u0026#39;) as fp: fp.writelines(fc.read()) fc.close() fe = open(self.astyle_lint_dir + \u0026#39;/.editorconfig\u0026#39;) # print(fe.read()) with open(os.path.join(lua_tempdir, \u0026#39;.editorconfig\u0026#39;), \u0026#39;w+\u0026#39;) as fp: fp.writelines(fe.read()) fe.close() # checkstyle exitflag = 0 exitflag |= self.check_commit_msg() exitflag |= self.c_cpp_handler_checkstyle( c_cpp_tempdir, c_cpp_temp_file_path) exitflag |= self.lua_handler_checkstyle( lua_tempdir, lua_temp_file_path) exitflag |= self.lua_handler_checkdiagnosis( lua_tempdir, lua_temp_file_path) if 1 == exitflag: exit(1) # 处理c,cpp文件 def c_cpp_handler_checkstyle(self, c_cpp_tempdir, c_cpp_temp_file_path): try: blag = 0 finalpipe = [] c_cpp_temp_name = [] for path in c_cpp_temp_file_path: cmd = r\u0026#39;python \u0026#39; + self.astyle_lint_dir + \u0026#34;/../run-clang-format.py\u0026#34; + \\ \u0026#39; --clang-format-executable clang-format -r \u0026#39; + path # print(cmd) result = subprocess.Popen( cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) rpipe = result.stdout.readlines() # print(rpipe) if len(rpipe) \u0026gt; 0: rpipeList = [ x.decode(\u0026#39;utf-8\u0026#39;).replace(c_cpp_tempdir + \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;) for x in rpipe] finalpipe.append(\u0026#34;\u0026#34;.join(rpipeList)) (filepath, tempfilename) = os.path.split(path) c_cpp_temp_name.append(tempfilename) blag = 1 # print(finalpipe) if len(finalpipe) \u0026gt; 0: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]处理c,cpp文件代码规范未通过\\n\u0026#34; + \u0026#34; 需要用vscode clang-format 插件进行代码格式化\\n\u0026#34; + \u0026#34; 或者去tools\\gitlab_cicd\\n\u0026#34; + \u0026#34; 下找到install.bat进行自动格式化\u0026#34; + \u0026#39;\\n\u0026#39; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;===\u0026gt;有问题的c,cpp文件\u0026lt;===:\\n\u0026#34; + \u0026#34;\u0026#34;.join(c_cpp_temp_name) + \u0026#34;\\n===\u0026gt;错误提示\u0026lt;===:\\n\u0026#34; + re.sub(\u0026#39;\\x1b.*?m\u0026#39;, \u0026#39;\u0026#39;, \u0026#34;\u0026#34;.join(finalpipe)) + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return blag finally: shutil.rmtree(c_cpp_tempdir) # pass # 处理lua文件风格 def lua_handler_checkstyle(self, lua_tempdir, lua_temp_file_path): try: blag = 0 finalpipe = [] lua_error_temp_name = [] for path in lua_temp_file_path: cmd = self.astyle_lint_dir + \u0026#39;/codeformat check -f \u0026#39; + path + \u0026#39; -DAE\u0026#39; # print(cmd) result = subprocess.Popen( cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) rpipe = result.stdout.readlines() # print(rpipe) if len(rpipe) \u0026gt; 0: rpipeList = [x.decode(\u0026#39;utf-8\u0026#39;).replace(lua_tempdir + \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;) for x in rpipe] rpipestr = \u0026#34;\u0026#34;.join(rpipeList) (filepath, tempfilename) = os.path.split(path) if(not re.search(r\u0026#39;^Check.*?OK$\u0026#39;, rpipestr)): finalpipe.append(rpipestr) lua_error_temp_name.append(tempfilename) blag = 1 # print(lua_error_temp_name) if 1 == blag: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]处理lua文件代码规范未通过\\n\u0026#34; + \u0026#34; 需要用vscode EmmyLuaCodeStyle 插件进行代码格式化\\n\u0026#34; + \u0026#34; 或者去tools\\gitlab_cicd\\n\u0026#34; + \u0026#34; 下找到install.bat进行自动格式化\u0026#34; + \u0026#39;\\n\u0026#39; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;===\u0026gt;有问题的lua文件\u0026lt;===:\\n\u0026#34; + \u0026#34;\u0026#34;.join(lua_error_temp_name) + \u0026#34;\\n===\u0026gt;错误提示\u0026lt;===:\\n\u0026#34; + re.sub(\u0026#39;\\x1b.*?m\u0026#39;, \u0026#39;\u0026#39;, \u0026#34;\u0026#34;.join(finalpipe)) + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return blag finally: # shutil.rmtree(lua_tempdir) pass def lua_handler_checkdiagnosis(self, lua_tempdir, lua_temp_file_path): try: blag = 0 finalpipe = [] lua_error_temp_name = [] for path in lua_temp_file_path: cmd = self.astyle_lint_dir + \u0026#39;/luacheck \u0026#39; + path + \\ \u0026#39; --no-config --no-default-config --codes -q --exclude-files **/config.lua --ignore 311\u0026#39; # print(cmd) result = subprocess.Popen( cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE) rpipe = result.stdout.readlines() # print(rpipe) if len(rpipe) \u0026gt; 0: rpipeList = [ x.decode(\u0026#39;utf-8\u0026#39;).replace(lua_tempdir + \u0026#39;/\u0026#39;, \u0026#39;\u0026#39;) for x in rpipe] rpipestr = \u0026#34;\u0026#34;.join(rpipeList) (filepath, tempfilename) = os.path.split(path) if(re.findall(r\u0026#39;^Check.*?error\u0026#39;, rpipestr)): finalpipe.append(rpipestr) lua_error_temp_name.append(tempfilename) blag = 1 # print(finalpipe) if 1 == blag: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]处理lua文件代码语法未通过\\n\u0026#34; + \u0026#34; 请手动修改并提交, 直到所有代码都符合规范为止...\u0026#34; + \u0026#39;\\n\u0026#39; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;===\u0026gt;有问题的lua文件\u0026lt;===:\\n\u0026#34; + \u0026#34;\u0026#34;.join(lua_error_temp_name) + \u0026#34; \\n===\u0026gt;错误提示\u0026lt;===:\\n\u0026#34; + re.sub(\u0026#39;\\x1b.*?m\u0026#39;, \u0026#39;\u0026#39;, \u0026#34;\u0026#34;.join(finalpipe)) + \u0026#39;[/]\u0026#39;, box=box.DOUBLE, expand=True)) return blag finally: shutil.rmtree(lua_tempdir) # pass def check_commit_msg(self): print(\u0026#34;开始提交信息检查...\u0026#34;) print(\u0026#34;提交者为:\u0026#34;, self.pushAuthor) print(\u0026#34;当前提交总次数:\u0026#34;, self.pushCount) print(\u0026#34;当前提交注释消息:\u0026#34;) for msg in self.pushMsg: print(msg, end=\u0026#34;\u0026#34;) for msg in self.pushMsg: if len(msg) \u0026lt; 10: self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34;[ERROR]提交信息校验未通过\\n\u0026#34; \u0026#34;msg长度必须大于10\u0026#34; + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return 1 msgList = msg.split(\u0026#34; \u0026#34;, 1) if not (len(msgList) == 2 and emoji.is_emoji(msgList[0]) and re.search(r\u0026#39;^[init|feat|fix|docs|style|refactor|perf|test|build|ci|chore|revert](.*):[\\s]{1}[\\S]{1,20}\\n\u0026#39;, msgList[1]), re.S): self.console.print( Panel(\u0026#39;[blue]\u0026#39; + \u0026#34; [ERROR]提交信息校验未通过,内容不符合规范\\n\u0026#34; + \u0026#34; 请去vscode下载git-commit-plugin进行规范提交\\n\u0026#34; + \u0026#34;════════════════════════════════════════════════════════════════════════════\\n\u0026#34; + \u0026#34;e.g.:🎉 init(影响范围模块): 项目初始化\\n\u0026#34; + \u0026#34;e.g.:✨ feat(影响范围模块): 新增某某功能\\n\u0026#34; + \u0026#34;e.g.:🐞 fix(影响范围模块): 修复某某bug\\n\u0026#34; + \u0026#34;e.g.:📃 docs(影响范围模块): 新增某某说明文档\\n\u0026#34; + \u0026#34;e.g.:🌈 style(影响范围模块): 仅仅修改了空格,缩进,逗号等等\\n\u0026#34; + \u0026#34;e.g.:🦄 refactor(影响范围模块): 重构某某功能\\n\u0026#34; + \u0026#34;e.g.:🎈 perf(影响范围模块): 优化了提高某某模块性能\\n\u0026#34; + \u0026#34;e.g.:🧪 test(影响范围模块): 测试模块功能\\n\u0026#34; + \u0026#34;e.g.:🔧 build(影响范围模块): 构建了那个版本\\n\u0026#34; + \u0026#34;e.g.:🐎 ci(影响范围模块): 对某某ci文件的修改\\n\u0026#34; + \u0026#34;e.g.:🐳 chore(影响范围模块): 改变了某某构建流程\\n\u0026#34; + \u0026#34;e.g.:↩ revert(影响范围模块): 回退某个版本\\n\u0026#34; + \u0026#39;[/]\u0026#39;, box=box.DOUBLE)) return 1 return 0 def getGitPushInfo(self): self.__getGitInfo() self.__getPushInfo() if __name__ == \u0026#34;__main__\u0026#34;: t = Trigger() t.getGitPushInfo() exit(0) ","permalink":"https://frog-game.github.io/posts/blog/gitlab-pre-receive-hook/","summary":"背景 每当我们接收一份新的版本，代码拿到手要做的第一件事就是查看 git log，看看这份代码的提交记录，最近代码做什么修改。如果我们看到 git log 杂乱无章","title":"gitlab服务器钩子"},{"content":"基础类型 定义 解释 LUA_TNONE 判断这个变量是否等于为空使用的，lua内部使用，注意不是和nil类型不等价 LUA_TNIL 全局变量没被复制就是nil类型，删除变量会被赋值成nil类型，nil类型就nil一个值，表示变量是否被赋值，变量赋值成nil也表示删除变量 LUA_TBOOLEAN false和nil为假 其他都为真(包括0) LUA_TLIGHTUSERDATA 见1.1 表 LUA_TNUMBER 所有数字，int float double 类型都为number类型 number类型可以和全是数字的字符串进行计算，字符串会进行类型转换 LUA_TSTRING 一但被赋值就不能被修改，可以通过方法string.gsub()来修改；分为长字符串和短字符串（小于等于40字符） LUA_TTABLE 数组容器 LUA_TFUNCTION 函数 LUA_TUSERDAT 见1.1 表 LUA_TTHREAD 协程，只是拷贝了一个栈空间 LUA_NUMTAGS tag 总数 LUA_TTHREAD 代表协程类型 除了主线程以外，其它线程和其它Lua对象一样都是垃圾回收的对象。当新建一个线程时，线程会压入栈，这样能确保新线程不会成为垃圾 每次调用lua_newstate的时候都会创建一个新的luastate,不同的luastate完全独立，之间不共享任何数据 协程提供了新的api接口和lua_resetthread,coroutine.close 会使协程进入死亡状态,并且关闭所有的close变量 full userdata和light userdata区别 区别 full userdata light userdata 作用 通常用来表示C中的结构体一小段固定的内存区域 通常用来表示C中的指针(void *) 内存管理 由Lua的垃圾回收器管理 使用者需要关心其内存 元表 有独立的元表 没有独立的元表 创建 void *lua_newuserdata(lua_State *L, size_t size) lua_pushlightuserdata(lua_State *L, void *p); full userdata //c文件 //#include \u0026lt;string.h\u0026gt; extern \u0026#34;C\u0026#34; { #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; } #include \u0026lt;iostream\u0026gt; using namespace std; static struct StudentTag { char *strName; // 学生姓名 char *strNum; // 学号 int iSex; // 学生性别 int iAge; // 学生年龄 }T; static int Student(lua_State *L) { size_t iBytes = sizeof(struct StudentTag); struct StudentTag *pStudent; pStudent = (struct StudentTag *)lua_newuserdata(L, iBytes); //设置元表 luaL_getmetatable(L, \u0026#34;Student\u0026#34;); lua_setmetatable(L, -2); //lua_pushnumber(L, 123); return 1; // 新的userdata已经在栈上了 } static int GetName(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); lua_pushstring(L, pStudent-\u0026gt;strName); return 1; } static int SetName(lua_State *L) { // 第一个参数是userdata struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); // 第二个参数是一个字符串 const char *pName = luaL_checkstring(L, 2); luaL_argcheck(L, pName != NULL \u0026amp;\u0026amp; pName != \u0026#34;\u0026#34;, 2, \u0026#34;Wrong Parameter\u0026#34;); pStudent-\u0026gt;strName =(char*) pName; return 0; } static int GetAge(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); lua_pushinteger(L, pStudent-\u0026gt;iAge); return 1; } static int SetAge(lua_State *L) { struct StudentTag *pStudent = (struct StudentTag *)luaL_checkudata(L, 1, \u0026#34;Student\u0026#34;); int iAge = luaL_checkinteger(L, 2); luaL_argcheck(L, iAge \u0026gt;= 6 \u0026amp;\u0026amp; iAge \u0026lt;= 100, 2, \u0026#34;Wrong Parameter\u0026#34;); pStudent-\u0026gt;iAge = iAge; return 0; } static int GetSex(lua_State *L) { // 这里由你来补充 return 1; } static int SetSex(lua_State *L) { // 这里由你来补充 return 0; } static int GetNum(lua_State *L) { // 这里由你来补充 return 1; } static int SetNum(lua_State *L) { // 这里由你来补充 return 0; } static luaL_Reg arrayFunc_meta[] = { { \u0026#34;getName\u0026#34;, GetName }, { \u0026#34;setName\u0026#34;, SetName }, { \u0026#34;getAge\u0026#34;, GetAge }, { \u0026#34;setAge\u0026#34;, SetAge }, { \u0026#34;getSex\u0026#34;, GetSex }, { \u0026#34;setSex\u0026#34;, SetSex }, { \u0026#34;getNum\u0026#34;, GetNum }, { \u0026#34;setNum\u0026#34;, SetNum }, { NULL, NULL } }; static luaL_Reg arrayFunc[] = { { \u0026#34;new\u0026#34;, Student}, { NULL, NULL } }; extern \u0026#34;C\u0026#34; _declspec(dllexport) int luaopen_mytestlib(lua_State *L) { // 创建一个新的元表 luaL_newmetatable(L, \u0026#34;Student\u0026#34;); // 元表.__index = 元表 lua_pushvalue(L, -1); lua_setfield(L, -2, \u0026#34;__index\u0026#34;); luaL_setfuncs(L, arrayFunc_meta, 0); luaL_newlib(L, arrayFunc); lua_pushvalue(L, -1); lua_setglobal(L, \u0026#34;Sdudent\u0026#34;); /* the module name */ return 1; } -- lua 文件 require \u0026#34;mytestlib\u0026#34; local objStudent = Sdudent.new() objStudent:setName(\u0026#34;果冻\u0026#34;) local strName = objStudent:getName() print(strName ) for k,v in pairs(getmetatable(objStudent)) do print(tostring(k),tostring(v)) end light userdata //C文件 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;iostream\u0026gt; using namespace std; extern \u0026#34;C\u0026#34; { #include \u0026#34;lua.h\u0026#34; #include \u0026#34;lualib.h\u0026#34; #include \u0026#34;lauxlib.h\u0026#34; } typedef struct { int x; int y; int z; }TData; static int getAttribute(lua_State* L) { TData *data = (TData*)lua_touserdata(L, 1); std::string attribute = luaL_checkstring(L, 2); int result = 0; if (attribute == \u0026#34;x\u0026#34;) { result = data-\u0026gt;x; } else if (attribute == \u0026#34;y\u0026#34;) { result = data-\u0026gt;y; } else { result = data-\u0026gt;z; } lua_pushnumber(L, result); return 1; } static luaL_Reg dataLib[] = { { \u0026#34;__index\u0026#34;, getAttribute }, { NULL, NULL } }; void getMetaTable(lua_State* L, luaL_Reg* methods) { lua_pushlightuserdata(L, methods); lua_gettable(L, LUA_REGISTRYINDEX); if (lua_isnil(L, -1)) { /* not found */ lua_pop(L, 1); lua_newtable(L); luaL_setfuncs(L, methods, 0); lua_pushlightuserdata(L, methods); lua_pushvalue(L, -2); lua_settable(L, LUA_REGISTRYINDEX); } } int main() { const char* filename = \u0026#34;test.lua\u0026#34;; lua_State *lua = luaL_newstate(); if (lua == NULL) { fprintf(stderr, \u0026#34;open lua failed\u0026#34;); return -1; } luaL_openlibs(lua); TData input = { 123, 231, 321 }; lua_pushlightuserdata(lua, \u0026amp;input); getMetaTable(lua, dataLib); lua_setmetatable(lua, -2); lua_setglobal(lua, \u0026#34;input\u0026#34;); if (luaL_dofile(lua, filename)) { //luaL_error(lua, \u0026#34;load file %s failed\u0026#34;, filename); } lua_getglobal(lua, \u0026#34;data\u0026#34;); int output = lua_tointeger(lua, -1); std::cout \u0026lt;\u0026lt; output \u0026lt;\u0026lt; std::endl; return 0; } --lua文件 data = input.x; print(data) 需要注意地方 序号 注意项 1 Lua中变量没有预定义类型，每个变量可以包含任意类型的值，要用就直接赋值一种数据类型的值 2 nil类型就nil一个值，表示变量是否被赋值，变量赋值成nil也表示删除变量 3 使用Type(xxx变量) 可以获取该变量的数据类型 4 number 所有数字，int float double 类型等都为number类型了 5 字符串一旦赋值不能被修改，可以通过方法string.gsub()来修改，可以写成’xxas’单引号，但是建议用双引号”” 6 number类型可以和全是数字的字符串进行计算，字符串会进行类型转换 7 .. 连接符号 ，可以连接字符串类型，也可以连接整形的变量，但是如果直接使用真实的数字要在后面加个空格，因为系统会把 数字.. 看出2个浮点 如 1..2 （错误写法） 1 ..2 (正确写法) 8 类型不同，比较判断也不会相等,如number类型的123不等于string类型的123 9 计算运算符中取余可以和浮点数计算，可以精确到小数级别 10 关系运算符中~= 表示不等于，类似其他语言如c的 != 11 逻辑运算符 and ，or ，not 对应 \u0026amp;\u0026amp; ，|| , ！ 12 表达式：a and b a为假则返回a 否则返回b， a or b a为真返回a否则返回b ,简单理解and就是先判断a a正确就继续判断b，如果b也正确返回btrue，则if(a and b) 为true ，这实际上也是\u0026amp;\u0026amp;的使用原理一样 ，如果a为假就是false直接返回a if(a and b) 就是false了 。 or 同理 13 赋值方式一：多个变量同时赋值，多的变量(变量个数多于值个数)默认为nil，少的变量(变量个数少于值个数)不做处理，可以类型混搭 14 局部变量 用local修饰声明 ，内存在栈上，在一个函数，代码块{ }内 函数，代码块结束，内存自动释放 15 全局变量在堆上，可以随时创建，程序结束，内存自动释放 16 控制语句上，有if for where 没有switch结构 17 控制语句上，不需要写 () {} {指代 ：then } 指代 ： end 18 循环结构 while do end ,里面不能写() 以及 ++ – += 类似的运算符 19 循环结构 for 也不需要写() 也不在赋值除了对第一个赋值，其他都可以省略写默认写为 \u0026lt;= +xx 或 \u0026gt;= -xx 20 函数的返回值和其他语言一样可以返回个值，变量。但是不同的是可以同时返回多个变量，进行多个赋值 21 table可以有数组的形式，字典的形式，数组字典同时混合的形式 22 print()打印会默认换行 23 #号数组是计算数组容器table的下标个数，lua的数组容器下标从1开始计算递增，字典不包括key元素 24 ipairs 仅仅遍历值，按照索引升序遍历，索引中断停止遍历。不能返回 nil,如果遇到 nil 则退出。它只能遍历到集合中出现的第一个不是整数的 key。 pairs 能遍历集合的所有元素。即 pairs 可以遍历集合中所有的 key，并且除了迭代器本身以及遍历表本身还可以返回 nil。 25 lua布尔类型只有两个取值false和true. 但要注意lua中所有的值都可以作为条件. 在控制结构的条件中除了false和nil为假, 其他值都为真。lua认为 0 和 空字符串都是真！！ pairs和ipairs 例子比较 test = {[\u0026#34;xxx\u0026#34;] = nil , tt = \u0026#34;tabao\u0026#34;} for k , v in pairs(test) do print(k,v) end 输出： tt tabao test = {nil = xxxx , tt = \u0026#34;tabao\u0026#34;} for k , v in pairs(test) do print(k,v) end 输出：stdin:1: bad argument #1 to \u0026#39;for iterator\u0026#39; (table expected, got nil) stack traceback: [C]: in function \u0026#39;next\u0026#39; stdin:1: in main chunk [C]: in ? local tab = { [1] = \u0026#34;a\u0026#34;, [3] = \u0026#34;b\u0026#34;, [4] = \u0026#34;c\u0026#34; } for k, v in ipairs(tab) do print(k, v) end 输出：1 a ,在key等于2处断开 local tab= { [2] = \u0026#34;a\u0026#34;, [3] = \u0026#34;b\u0026#34;, [4] = \u0026#34;c\u0026#34; } for k, v in ipairs(tab) do print(k, v) end 输出：什么都没输出，为什么？因为控制变量初始值是按升序来遍历的，当key为1时，value为nil，此时便停止了遍历， 所有什么结果都没输出。 for k, v in pairs(tab) do print(k, v) end 输出：2 a, 3 b, 4 c local tab = {\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, [3] = \u0026#34;c\u0026#34;, [\u0026#34;two\u0026#34;] = \u0026#34;d\u0026#34;} for i,v in ipairs(tab) do print( tab [i] ) end 输出：a，b，c for i,v in pairs(tab) do print( tab [i] ) 输出：a，b，c，d。 lua 模块 import 和 require 差异 载入一个模块 import() 与 require() 功能相同，但具有一定程度的自动化特性。\nimport支持相对路径的写法，一个点表示当前目录，两个点表示上一级目录，以此类推。\nrequire 最好写成绝对路径的形式如：require \u0026quot;src.ui.common.FightPointAdd\u0026quot; or require \u0026quot;src/common/FightPointAdd\u0026quot;\nimport还有一个优势是假设：A/B/下有两个文件 c.lua,d.lua，如果在 c中用到了 d话,require( \u0026quot;A/B/d\u0026quot;),import(\u0026quot;.d\u0026quot;) ，如果后面目录结构改了 ,c,d都到了 A目录下,那对应的要修改 require(\u0026quot;A/d) 而 import可以不用修改。\nlua 正则表达式 测试工具地址:https://wiki.luatos.com/pages/emulator.html\n下面的表列出了 Lua支持的所有字符类:\n. 任意字符 %a 字母 %c 控制字符 %d 数字 %l 小写字母 %p 标点字符 %s 空白符 %u 大写字母 %w 字母和数字 %x 十六进制数字 %z 代表0的字符 上面字符类的大写形式表示小写所代表的集合的补集。例如, %A非字母的字符:\nprint(string.gsub(\u0026#34;hello, up-down!\u0026#34;, \u0026#34;%A\u0026#34;, \u0026#34;.\u0026#34;)) --\u0026gt; hello..up.down. 4 数字 4不是字符串结果的一部分，他是 gsub返回的第二个结果，代表发生替换的次数.\nlua特殊字符\n( ) . % + - * ? [ ^ $ %用作特殊字符的转义字符，因此 %. 匹配点; %%匹配字符 % .转义字符 %不仅可以用来转义特殊字符，还可以用于所有的非字母的字符。当对一个字符有疑问的时候，为安全起见请使用转义字符转义他。\n\\ 是lua的转义字符\n[%w_]将匹配字母数字和下划线\n[01]匹配二进制数字，[%[%]]匹配一对方括号\n第一个字符和最后一个字符之间用连字符 -连接表示这两个字符之间范围内的字符集合\n%d表示 [0-9]\n%x表示 [0-9a-fA-F]\n查找八进制数:[0-7]\n匹配任何非换行符户的字符: [^\\n]\n模式修饰符\n+ 匹配前一字符1次或多次 * 匹配前一字符0次或多次 - 匹配前一字符0次或多次 ? 匹配前一字符0次或1次 +匹配一个或多个字符，她总是进行最长的匹配. 比如，模式串 %a+匹配一个或多个字母或者一个单词 :\nprint(string.gsub(\u0026#34;one, and two; and three\u0026#34;, \u0026#34;%a+\u0026#34;, \u0026#34;word\u0026#34;)) --\u0026gt; word, word word; word word %d+匹配一个或多个数字 (整数):\ni, j = string.find(\u0026#34;the number 1298 is even\u0026#34;, \u0026#34;%d+\u0026#34;) print(i,j) --\u0026gt; 12 15 * 与 +类似, 但是他匹配一个字符 0次或多次出现.一个典型的应用是匹配空白。比如，为了匹配一对圆括号 ()或者 ( )之间的空白，可以使用 %(%s*%) ( '%s*用来匹配 0个或多个空白,由于圆括号在模式中有特殊的含义，所以我们必须使用 %转义他 .) 再看一个例子，[_%a][_%w]*匹配 Lua程序中的标示符：字母或者下划线开头的字母下划线数字序列。\n-与 *一样，都匹配一个字符的0次或多次出现，但是他进行的是最短匹配。某些时候这两个用起来没有区别，但有些时候结果将截然不同。比如，如果你使用模式 [_%a][_%w]-来查找标示符，你将只能找到第一个字母，因为 [_%w]-永远匹配空。另一方面，假定你想查找C程序中的注释，很多人可能使用 /%*.*%*/ (也就是说 \u0026quot;/*\u0026quot; 后面跟着任意多个字符，然后跟着 \u0026quot;*/\u0026quot;) 然而，由于 .*进行的是最长匹配，这个模式将匹配程序中第一个 \u0026quot;/*\u0026quot; 和最后一个 \u0026quot;*/\u0026quot;之间所有部分:\ntest = \u0026#34;int x; /* x */ int y; /* y */\u0026#34; print(string.gsub(test, \u0026#34;/%*.*%*/\u0026#34;, \u0026#34;\u0026lt;COMMENT\u0026gt;\u0026#34;)) --\u0026gt; int x; \u0026lt;COMMENT\u0026gt; 然而模式 .-进行的是最短匹配，她会匹配 \u0026quot;/*\u0026quot;开始到第一个 \u0026quot;*/\u0026quot;之前的部分:\ntest = \u0026#34;int x; /* x */ int y; /* y */\u0026#34; print(string.gsub(test, \u0026#34;/%*.-%*/\u0026#34;, \u0026#34;\u0026lt;COMMENT\u0026gt;\u0026#34;)) --\u0026gt; int x; \u0026lt;COMMENT\u0026gt; int y; \u0026lt;COMMENT\u0026gt; ?匹配一个字符 0次或 1次.举个例子，假定我们想在一段文本内查找一个整数，整数可能带有正负号。 模式 [+-]?%d+符合我们的要求，她可以匹配 像 \u0026quot;-12\u0026quot;, \u0026quot;23\u0026quot; 和 \u0026quot;+1009\u0026quot;等数字. [+-] 是一个匹配 +或者 -的字符类；接下来的 ?意思是匹配前面的字符类 0次或者 1次.\n与其他系统的模式不同的是，Lua中的修饰符不能用字符类；不能将模式分组然后使用修饰符作用这个分组。比如，没有一个模式可以匹配一个可选的单词(除非这个单词只有一个字母)。下面我将看到，通常你可以使用一些高级技术绕开这个限制。\n以 ^开头的模式只匹配目标串的开始部分，相似的，以 $结尾的模式只匹配目标串的结尾部分。这不仅可以用来限制你要查找的模式，还可以定位(anchor)模式。比如：\nif string.find(s, \u0026#34;^%d\u0026#34;) then ... 符串s是否以数字开头，而 if string.find(s, \u0026#34;^[+-]?%d+$\u0026#34;) then ... 检查字符串 s是否是一个整数。\n%b用来匹配对称的字符.常写为 %bxy,x和 y是任意两个不同的字符；x作为匹配的开始,y作为匹配的结束。比如， %b()匹配以 (开始， 以 )结束的字符串:\nprint(string.gsub(\u0026#34;a (enclosed (in) parentheses) line\u0026#34;, \u0026#34;%b()\u0026#34;, \u0026#34;\u0026#34;)) --\u0026gt; a line 常用的这种模式有： %b(), %b[], %b%{%},和 %b\u0026lt;\u0026gt;。你也可以使用任何字符作为分隔符。\nlua字符串管理 typedef struct TString { CommonHeader; // 字符串的子类型有两种：长字符串和短字符串 // 短字符串：extra表示Lua保留字的索引，如果为0就不是保留字 // 长字符串：extra标记是否已经计算哈希值，0表示还未计算 lu_byte extra; lu_byte shrlen; // 短字符串长度 unsigned int hash; // 字符串的哈希值 // 下面联合分两种情况： // 如果是长字符串则是长度lnglen // 如果是短字符串则是hnext，指向下一个短字符串对象，短字符串会用哈希表缓存， union { size_t lnglen; struct TString *hnext; } u; char contents[1];//真正的字符串存储在这里 } TString; 字符串创建方式 全局字符串表 typedef struct stringtable { TString **hash;//hash散列桶 int nuse; /* number of elements *///实际的使用元素 int size;//当前桶的大小 } stringtable; 链表方式 相同 hash字符串存储在 stringtable strt 链表结构上 一般 短字符串会使用这种方式存储\nhashMap缓存方式 下图中N是数组行，M是数组列\ni的下标值通过 unsigned int i = point2uint(str) % STRCACHE_Nhash求得\nj的最大值固定就是下面的宏函数 STRCACHE_M 2\n下面两个函数 luaS_new luaS_newlstr是创建字符串的核心函数\n/* ** Create or reuse a zero-terminated string, first checking in the ** cache (using the string address as a key). The cache can contain ** only zero-terminated strings, so it is safe to use \u0026#39;strcmp\u0026#39; to ** check hits. 创建或重用一个以\u0026#39;0\u0026#39;结尾的字符串，首先查找 global_state 的 strcache 缓存是否已存在该字符串， 若存在则直接返回，否则创建一个新的，并加入到缓存中 */ TString *luaS_new (lua_State *L, const char *str) { //point2uint 指针转无符号整数 unsigned int i = point2uint(str) % STRCACHE_N; /* hash */ //求出strcache下标 STRCACHE_N等于53 int j; //在全局G中查找strcache里面查找是否有这个string TString **p = G(L)-\u0026gt;strcache[i]; for (j = 0; j \u0026lt; STRCACHE_M; j++) { if (strcmp(str, getstr(p[j])) == 0) /* hit? */ return p[j]; /* that is it */ } //如果没有找到创建新的Tstring,并放到第一个位置 //同时也意味着最后一个元素会被移除strcache /* normal route */ for (j = STRCACHE_M - 1; j \u0026gt; 0; j--) p[j] = p[j - 1]; /* move out last element */ /* new element is first in the list */ p[0] = luaS_newlstr(L, str, strlen(str));//创建新的Tstring return p[0]; } /* ** new string (with explicit length) 创建一个给定长度的字符串 */ TString *luaS_newlstr (lua_State *L, const char *str, size_t l) { if (l \u0026lt;= LUAI_MAXSHORTLEN) /* short string? */ //判断是不是短字符串 return internshrstr(L, str, l);//短字符串创建 else {//长字符串创建 TString *ts; if (l_unlikely(l \u0026gt;= (MAX_SIZE - sizeof(TString))/sizeof(char)))//如果字符串太长 创建失败 luaM_toobig(L); ts = luaS_createlngstrobj(L, l);//直接创建长字符串 memcpy(getstr(ts), str, l * sizeof(char));//拷贝字符串内容 return ts; } } /* ** Checks whether short string exists and reuses it or creates a new one. ** 检查短字符串是否已经存在，如果存在则复用，否则创建一个新的 */ static TString *internshrstr (lua_State *L, const char *str, size_t l) { TString *ts; global_State *g = G(L);//全局表 stringtable *tb = \u0026amp;g-\u0026gt;strt;//全局字符串表，lua所有的短字符串都存在这个里面 unsigned int h = luaS_hash(str, l, g-\u0026gt;seed);//求的hash值 TString **list = \u0026amp;tb-\u0026gt;hash[lmod(h, tb-\u0026gt;size)];//求得全局字符串表中对应hash位置的链表 lua_assert(str != NULL); /* otherwise \u0026#39;memcmp\u0026#39;/\u0026#39;memcpy\u0026#39; are undefined */ for (ts = *list; ts != NULL; ts = ts-\u0026gt;u.hnext) {//遍历链表查找是否有相同的字符串 if (l == ts-\u0026gt;shrlen \u0026amp;\u0026amp; (memcmp(str, getstr(ts), l * sizeof(char)) == 0)) { /* found! */ if (isdead(g, ts)) /* dead (but not collected yet)? *///如果找到，并且当前gc判断要被回收 changewhite(ts); /* resurrect it *///这个时候修改它为白色状态，表示不需要回收 return ts;//直接返回查找到的字符串 } } /* else must create a new string *///否则必须创建一个字符串 if (tb-\u0026gt;nuse \u0026gt;= tb-\u0026gt;size) { /* need to grow string table? *///容量不够需要扩容 growstrtab(L, tb);//扩容容量 list = \u0026amp;tb-\u0026gt;hash[lmod(h, tb-\u0026gt;size)]; /* rehash with new size *///重新计算全局字符串表中对应的hash位置的链表 } ts = createstrobj(L, l, LUA_VSHRSTR, h);//创建一个字符串对象 memcpy(getstr(ts), str, l * sizeof(char));//拷贝进去 ts-\u0026gt;shrlen = cast_byte(l);//赋值字符串大小，按无符号char大小求长度 ts-\u0026gt;u.hnext = *list;//添加到全局的字符串表中,此处是头插法插入数据 *list = ts; tb-\u0026gt;nuse++; return ts; } //创建一个长串 TString *luaS_createlngstrobj (lua_State *L, size_t l) { TString *ts = createstrobj(L, l, LUA_VLNGSTR, G(L)-\u0026gt;seed); ts-\u0026gt;u.lnglen = l; return ts; } /*创建一个长字符串或者短字符串 ** creates a new string object */ static TString *createstrobj (lua_State *L, size_t l, int tag, unsigned int h) { TString *ts; GCObject *o; size_t totalsize; /* total size of TString object */ totalsize = sizelstring(l);//得到真正字符串的大小 o = luaC_newobj(L, tag, totalsize);//创建一个GC对象 ts = gco2ts(o);//强制转换为Tsing结构 ts-\u0026gt;hash = h;//赋seed值也就是随机种子 ts-\u0026gt;extra = 0;//0表示还未计算真正的hash值 getstr(ts)[l] = \u0026#39;\\0\u0026#39;; /* ending 0 */ return ts; } 函数调用过程 字符串大小 字符串内容会在有效数据的结尾强制加上 \\0，所以字符串对象的总大小为:\n头的大小加上字符串的空间+加上最后的 \\0\n/* ** Size of a TString: Size of the header plus space for the string ** itself (including final \u0026#39;\\0\u0026#39;). */ #define sizelstring(l) (offsetof(TString, contents) + ((l) + 1) * sizeof(char)) //offsetof(TString, contents) contents成员相对于TString开头位置的偏移量，等价于头的大小 //((l) + 1) l是外部传进来长短字符串的大小 +1是最后\u0026#39;\\0\u0026#39;大小 长短字符串 /* ** Maximum length for short strings, that is, strings that are ** internalized. (Cannot be smaller than reserved words or tags for ** metamethods, as these strings must be internalized; ** #(\u0026#34;function\u0026#34;) = 8, #(\u0026#34;__newindex\u0026#34;) = 10.) */ #if !defined(LUAI_MAXSHORTLEN) #define LUAI_MAXSHORTLEN\t40 #endif 短字符串 定义:小于等于 40个字节的字符串\n比较大小 因为是重复利用的，所以直接比较指针地址就可以了\n/* ** equality for short strings, which are always internalized */ #define eqshrstr(a,b)\tcheck_exp((a)-\u0026gt;tt == LUA_VSHRSTR, (a) == (b)) 长字符串 计算hash值 长字符串不会马上计算哈希值，一般在调用 luaS_hashlongstr 时候才会去计算\nunsigned int luaS_hashlongstr (TString *ts) { lua_assert(ts-\u0026gt;tt == LUA_VLNGSTR); if (ts-\u0026gt;extra == 0) { /* no hash? *///extra为0的时候才去计算hash值 size_t len = ts-\u0026gt;u.lnglen; ts-\u0026gt;hash = luaS_hash(getstr(ts), len, ts-\u0026gt;hash);//通过luaS_hash创建hash值 ts-\u0026gt;extra = 1; /* now it has its hash */ } return ts-\u0026gt;hash; } unsigned int luaS_hash (const char *str, size_t l, unsigned int seed) { unsigned int h = seed ^ cast_uint(l); for (; l \u0026gt; 0; l--) h ^= ((h\u0026lt;\u0026lt;5) + (h\u0026gt;\u0026gt;2) + cast_byte(str[l - 1])); return h; } 比较大小 /* ** equality for long strings 长字符串的比较：先比较地址，再比较长度，最后比较内容 */ int luaS_eqlngstr (TString *a, TString *b) { size_t len = a-\u0026gt;u.lnglen; lua_assert(a-\u0026gt;tt == LUA_VLNGSTR \u0026amp;\u0026amp; b-\u0026gt;tt == LUA_VLNGSTR); return (a == b) || /* same instance or... */ ((len == b-\u0026gt;u.lnglen) \u0026amp;\u0026amp; /* equal length and ... */ (memcmp(getstr(a), getstr(b), len) == 0)); /* equal contents */ } lua设值取值重置hash和table过程 lua table 值对象结构 /* ** Union of all Lua values 还有几种数据类型是不需要进行垃圾回收的, //Lua 中将GCObject 和它们一起放在了联合体Value 中: */ typedef union Value { struct GCObject *gc; /* collectable objects */ void *p; /* light userdata */ lua_CFunction f; /* light C functions */ lua_Integer i; /* integer numbers */ lua_Number n; /* float numbers */ } Value; 变量 说明 GCObject gc 用于垃圾回收 主要是为了连接垃圾回收对象的互相引用关系 void *p 为c中传入的指针，由c 分配和释放 light userdata lua_CFunction f 表示C导出给lua的函数指针，typedef int (*lua_CFunction) (lua_State *L) lua_Integer i 表示整数类型，typedef long long lua_Integer lua_Number n 表示双精度浮点类型，typedef double lua_Number 非GC对象 从上面可以看到 非GC的对象有 4中\nlight userdata C函数 整型 浮点型 int b(lua 5.4 数字分为整数和浮点，而i正好也可以用作bool,所以把这个给删除,和 lua_Integer i 结合到一起了) GC对象 union GCUnion { GCObject gc; /* common header */ struct TString ts; struct Udata u; union Closure cl; struct Table h; struct Proto p;// Proto主要存放二进制指令集Opcode Lua在解析函数的过程中，会将一条条语句逐个‘编译’成指令集 struct lua_State th; /* thread */ struct UpVal upv; }; 从上面的 union结构体可以看到 GC对象有 6中\n字符串 userdata closure 闭包 table lua 函数原型(Proto主要存放二进制指令集Opcode) lua 线程 (其实就是协程) lua上值 CommonHeader类型 #define CommonHeader\tstruct GCObject *next; lu_byte tt; lu_byte marked next 指针 指向下一个GC对象 tt GC对象的实际类型(比如上面6中GC对象) marked 标识GC的状态(白1 白2 黑 final) TValuefields 类型 #define TValuefields Value value_; int tt_ Value：存储具体数据的值 tt_：表示这个值的类型，即所有的基础数据类型 table 结构 typedef struct Table { CommonHeader; lu_byte flags; /* 1\u0026lt;\u0026lt;p means tagmethod(p) is not present *///用于表示cache在该表中实现了哪些元方法 lu_byte lsizenode; /* log2 of size of \u0026#39;node\u0026#39; array *///哈希部分的长度对数：1 \u0026lt;\u0026lt; lsizenode 才能得到实际的size unsigned int alimit; /* \u0026#34;limit\u0026#34; of \u0026#39;array\u0026#39; array *///数组部分的长度 TValue *array; /* array part *///数组部分 Node *node;//hash部分 闭散列方法解决hash冲突 Node *lastfree; /* any free position is before this position *///空闲槽位 struct Table *metatable;//元表 GCObject *gclist;//gc链表 } Table; typedef union Node { struct NodeKey { TValuefields; /* fields for value *///值域 lu_byte key_tt; /* key type *///key类型 int next; /* for chaining *///链表下一个节点索引 Value key_val; /* key value *///key值 } u; TValue i_val; /* direct access to node\u0026#39;s value as a proper \u0026#39;TValue\u0026#39; */ } Node; hash解决冲突时候的两种方法 闭散列 （即开放地址法）：当发生哈希冲突时，如果该哈希表还没有被填满，那么就把该元素放到哈希表的下一个空闲的位置\n优点：简单 易懂,当hash表已经没有空格的时候，lua就会resize这个hash表。这样做的好处主要是不用动态申请内存空间，hash表初始化的时候有多少内存空间就用多少，不够就resize这个hash表。\n缺点：一旦发生了哈希冲突，所有的冲突连接在一起，很容易产生数据”堆积”。即不同的数据占用可以利用的位置，就使得寻找其余数据的位置需要进行多次比较，就会导致查找的效率降低。\n开散列 开散列法（哈希桶）：又名链地址法，先用哈希函数计算每个数据的散列地址，把具有相同地址的元素归于同一个集合之中，把该集合处理为一个链表，链表的头节点存储于哈希表之中。\n优点:解决了数据溢出的问题\n缺点:需要增加链接的指针，增加存储开销\n新建一个table Table *luaH_new (lua_State *L) { GCObject *o = luaC_newobj(L, LUA_VTABLE, sizeof(Table)); Table *t = gco2t(o); t-\u0026gt;metatable = NULL;//初始设置metatable为null t-\u0026gt;flags = cast_byte(maskflags); /* table has no metamethod fields */ t-\u0026gt;array = NULL;//初始化数组大小 t-\u0026gt;alimit = 0;//数组长度 setnodevector(L, t, 0);//初始化哈希部分 return t; } static void setnodevector (lua_State *L, Table *t, unsigned int size) { //如果size是0：就是说整个table为空，那么就是初始化这些东西为零 if (size == 0) { /* no elements to hash part? */ t-\u0026gt;node = cast(Node *, dummynode); /* use common \u0026#39;dummynode\u0026#39; */ t-\u0026gt;lsizenode = 0; t-\u0026gt;lastfree = NULL; /* signal that it is using dummy node */ } //如果size不为零： else { int i; int lsize = luaO_ceillog2(size); //拿到 新的 真实的 哈希部分长度log2之后的结果 //如果新的长度超出了最大的哈希长度: if (lsize \u0026gt; MAXHBITS || (1u \u0026lt;\u0026lt; lsize) \u0026gt; MAXHSIZE) luaG_runerror(L, \u0026#34;table overflow\u0026#34;);//报错 size = twoto(lsize); //要保证分配的是以2的指数增长来进行扩容的 //创建了个大小为 size*sizeof(Node) 的内存块，然后初始化这块内存 t-\u0026gt;node = luaM_newvector(L, size, Node); for (i = 0; i \u0026lt; (int)size; i++) { Node *n = gnode(t, i); //将这块内存给初始化 gnext(n) = 0; setnilkey(n); setempty(gval(n)); } t-\u0026gt;lsizenode = cast_byte(lsize); t-\u0026gt;lastfree = gnode(t, size); /* all positions are free */ } } 增加一个元素 /* 这个函数的主要功能将一个key插入哈希表，并返回key关联的value指针。 1. 首先通过key计算出主位置，如果主位置为空结点那最简单，将key设进该结点，然后返回结点的值指针。 2. 如果不是空结点就要分情况，看3和4两种情况 3.如果该结点就是主位置结点，那么要另找一个空闲位置，把Key放进去，和主结点链接起来， 然后返回新结点的值指针。 4.如果该结点不是主位置结点，把这个结点移到空闲位置去；然后我进驻这个位置，并返回结点的值指针。 */ TValue *luaH_newkey (lua_State *L, Table *t, const TValue *key) { Node *mp; TValue aux; if (unlikely(ttisnil(key))) //key是空值 报错 luaG_runerror(L, \u0026#34;table index is nil\u0026#34;); else if (ttisfloat(key)) { //key是float 转成int 不能就报错 lua_Number f = fltvalue(key);//得到float值 lua_Integer k; if (luaV_flttointeger(f, \u0026amp;k, F2Ieq)) { /* does key fit in an integer? *///如果能转成int setivalue(\u0026amp;aux, k); key = \u0026amp;aux; /* insert it as an integer *///插入一个int值 } else if (unlikely(luai_numisnan(f)))//如果是个nan数 luaG_runerror(L, \u0026#34;table index is NaN\u0026#34;); } mp = mainpositionTV(t, key);// mainposition函数通过key找到“主位置”的node桶 if (!isempty(gval(mp)) || isdummy(t)) { /* main position is taken? */// 主位置桶被占，或者哈希表部分为空 Node *othern; Node *f = getfreepos(t); /* get a free place */// 找空闲位置，这里还涉及到没空闲位置会重建哈希表的操作 if (f == NULL) { /* cannot find a free place? *///如果没空闲位置就重建table rehash(L, t, key); /* grow table */ //重建哈希表的操作 /* whatever called \u0026#39;newkey\u0026#39; takes care of TM cache */ return luaH_set(L, t, key); /* insert key into grown table */ } lua_assert(!isdummy(t)); othern = mainposition(t, keytt(mp), \u0026amp;keyval(mp));// 通过主位置这个结点的key，计算出本来的主位置结点 if (othern != mp) { /* is colliding node out of its main position? */ /* yes; move colliding node into free position */ while (othern + gnext(othern) != mp) /* find previous */// 这种就对应上面说的情况4的处理，把结点移到空闲位置去 othern += gnext(othern); gnext(othern) = cast_int(f - othern); /* rechain to point to \u0026#39;f\u0026#39; */// 移动之前，要先把链接结点的偏移调整一下 *f = *mp; /* copy colliding node into free pos. (mp-\u0026gt;next also goes) */// 把冲突结点移到空闲位置 if (gnext(mp) != 0) { // 如果冲突结点也有链接结点，也要调整过来 gnext(f) += cast_int(mp - f); /* correct \u0026#39;next\u0026#39; */ gnext(mp) = 0; /* now \u0026#39;mp\u0026#39; is free */ } setempty(gval(mp)); } else { /* colliding node is in its own main position */ /* new node will go into free position */ if (gnext(mp) != 0) gnext(f) = cast_int((mp + gnext(mp)) - f); /* chain new position */ else lua_assert(gnext(f) == 0); gnext(mp) = cast_int(f - mp); mp = f; } } setnodekey(L, mp, key); luaC_barrierback(L, obj2gco(t), key); lua_assert(isempty(gval(mp))); return gval(mp); } ","permalink":"https://frog-game.github.io/posts/read/luayuanmashagnxi/","summary":"基础类型 定义 解释 LUA_TNONE 判断这个变量是否等于为空使用的，lua内部使用，注意不是和nil类型不等价 LUA_TNIL 全局变量没被复制就是nil类型，删除变量会被赋","title":"lua源码赏析"},{"content":"图解释 结构体 typedef struct byteQueue_s { char*\tpBuffer;//数据 size_t\tnCapacity;//容量 size_t\tnReadIndex;//读指针索引 size_t\tnWriteIndex;//写指针索引 } byteQueue_tt; 初始 结构体 假设要申请的空间 环形buff结构体大小为8\nnWriteIndex 写指针索引 nReadIndex 读指针索引 环形buff初始化\nvoid byteQueue_init(byteQueue_tt* pByteQueue,size_t nCapacity = /* = 8*/) { pByteQueue-\u0026gt;nReadIndex = nCapacity;//读指针索引位置设置为8,放到末尾 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置成0，放到开头 pByteQueue-\u0026gt;nCapacity = nCapacity;//容量 if( nCapacity != 0 ) { pByteQueue-\u0026gt;pBuffer = mem_malloc(nCapacity);//申请空间 } else { pByteQueue-\u0026gt;pBuffer = NULL;//置空 } } 清空结构体 void byteQueue_clear(byteQueue_tt* pByteQueue) { pByteQueue-\u0026gt;nReadIndex = 0;//读指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nWriteIndex = 0;//写指针索引位置设置为0,放到开头 pByteQueue-\u0026gt;nCapacity = 0;//容量设置为0 if(pByteQueue-\u0026gt;pBuffer) { mem_free(pByteQueue-\u0026gt;pBuffer);//如果有数据进行释放 pByteQueue-\u0026gt;pBuffer = NULL;//并且置空 } } 获取剩余全部可写空间 static inline size_t byteQueue_getBytesWritable(byteQueue_tt* pByteQueue) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex )//写指针和读指针重合，或者在读指针前面 { return pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//直接读指针 - 写指针 就是 写入了多少内容 } else//写指针在读指针后面 { return pByteQueue-\u0026gt;nReadIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex); //读指针位置 + (容量 - 写指针位置) } } 写指针在读指针前面[求得是蓝色块数据] 写指针在读指针后面[求得是蓝色块数据] 获取剩余全部可读空间 static inline size_t byteQueue_getBytesReadable(byteQueue_tt* pByteQueue) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex) //读指针在写指针前面 { return pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//直接写指针 - 读指针 就是可以读多少数据 } else //读指针和写指针重合,或者读指针在写指针后面 { return pByteQueue-\u0026gt;nWriteIndex + (pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex); //写指针 + (容量 - 读指针位置) } } 写指针在读指针后面[求的是红色块的数据] 写指针在读指针前面[求的是红色块的数据] 查看连续的可写空间 //查看连续的可写空间 //size_t* pWriteBytes 能连续写入的大小 static inline char* byteQueue_peekContiguousBytesWrite(byteQueue_tt* pByteQueue, size_t* pWriteBytes) { if (pByteQueue-\u0026gt;nReadIndex \u0026gt;= pByteQueue-\u0026gt;nWriteIndex)//读指针在写指针后面 { *pWriteBytes = pByteQueue-\u0026gt;nReadIndex - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } else//读指针在写指针前面 { *pWriteBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nWriteIndex;//能连续写入的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nWriteIndex;//开始连续写入指针的起始位置 } 写指针在读指针前面[求得连续可写的空间] 写指针在读指针后面[求得连续可写的空间] 查看连续可读空间 //查看连续的可读空间 //size_t* pWriteBytes 能连续读取的大小 static inline char* byteQueue_peekContiguousBytesRead(byteQueue_tt* pByteQueue, size_t* pReadBytes) { if(pByteQueue-\u0026gt;nWriteIndex \u0026gt; pByteQueue-\u0026gt;nReadIndex)//写指针在读指针后面 { *pReadBytes = pByteQueue-\u0026gt;nWriteIndex - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } else { *pReadBytes = pByteQueue-\u0026gt;nCapacity - pByteQueue-\u0026gt;nReadIndex;//能连续读取的大小 } return pByteQueue-\u0026gt;pBuffer + pByteQueue-\u0026gt;nReadIndex;//开始连续读入指针的起始位置 } 写指针在读指针后面[求得连续可读的空间] 写指针在读指针前面[求得连续可读的空间] 写入一个字符[空间不足按256的倍数自动扩展] void byteQueue_writeChar(byteQueue_tt* pByteQueue, const char c) { if(pByteQueue-\u0026gt;nCapacity == 0) { //初始化容量,buffer大小，可读索引 pByteQueue-\u0026gt;nCapacity = 256;//初始化容量大小[256] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取获取剩余全部可写空间 if (1 \u0026gt; nBytesWritable) { //align_size 将size按align大小整数倍提升,用于内存对齐 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + 1,256); char* pBuffer = mem_malloc(nNewCapacity); if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//说明还有数据没有读走 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//获取剩余全部可读的空间 size_t nReadBytes = 0;//连续可读的空间的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取数据的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//如果连续可读的空间的大小!=剩余全部可读的空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//到了新空间需要重新移动读指针 pByteQueue-\u0026gt;nWriteIndex = nWritten;//到了新空间需要重新移动写指针 } else //没有数据需要读取直接初始化指针位置 { pByteQueue-\u0026gt;nReadIndex = nNewCapacity; pByteQueue-\u0026gt;nWriteIndex = 0; } pByteQueue-\u0026gt;nCapacity = nNewCapacity; mem_free(pByteQueue-\u0026gt;pBuffer); pByteQueue-\u0026gt;pBuffer = pBuffer; } } pByteQueue-\u0026gt;pBuffer[pByteQueue-\u0026gt;nWriteIndex] = c;//赋值 pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + 1) % pByteQueue-\u0026gt;nCapacity;//索引位移一位 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity)//如果读索引在尾部 { pByteQueue-\u0026gt;nReadIndex = 0;//把读索引放到头部 } } 写入指定大小空间的数据[空间不足按256的倍数自动扩展] void byteQueue_write(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = align_size(nLength,256);//初始化容量大小[256的倍数] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//获取剩余可写空间 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写空间 { //数据进行扩展 size_t nNewCapacity = align_size( (pByteQueue-\u0026gt;nCapacity \u0026lt;\u0026lt; 1) + (nLength-nBytesWritable),256); char* pBuffer = mem_malloc(nNewCapacity);//申请空间大小 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity )//还有数据可读 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读空间 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始连续读入指针的起始位置 memcpy(pBuffer,pRead,nReadBytes);//把连续可读的空间写入新buffer空间 if( nReadBytes != nWritten )//如果连续可读的空间!=剩余全部可读空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//把剩下的可读的空间写入新buffer空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;////重置容量大小 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧buff空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//重置指针到新buff空间 } } size_t nWriteBytes = 0;//连续可写的空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//开始写入的指针位置 if (nWriteBytes \u0026gt;= nLength)//如果连续写入的空间能够满足需要写入的空间大小 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入的空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//再把剩余要写入的大小空间写入 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置读索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置写索引 } } 写入指定大小空间的数据[空间不足按剩余需要空间大小申请] void byteQueue_writeBytes(byteQueue_tt* pByteQueue, const void* pInBytes, size_t nLength) { assert(nLength != 0); if(pByteQueue-\u0026gt;nCapacity == 0)//容量大小为0 { pByteQueue-\u0026gt;nCapacity = nLength;//初始化容量大小[需要空间大小] pByteQueue-\u0026gt;pBuffer = mem_malloc(pByteQueue-\u0026gt;nCapacity);//申请空间 pByteQueue-\u0026gt;nReadIndex = pByteQueue-\u0026gt;nCapacity;//初始化读索引位置 } else { size_t nBytesWritable = byteQueue_getBytesWritable(pByteQueue);//剩余可写的全部空间大小 if (nLength \u0026gt; nBytesWritable)//如果写入的大小大于剩余可写入的空间大小 { size_t nNewCapacity = pByteQueue-\u0026gt;nCapacity + (nLength - nBytesWritable);//开辟正好大小的空间 char* pBuffer = mem_malloc(nNewCapacity);//申请空间 if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//还有空间可读需要把这段空间赋值到新空间 { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余可读的全部空间 size_t nReadBytes = 0;//连续可读的空间 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//开始读取空间的起始位置 memcpy(pBuffer,pRead,nReadBytes);//拷贝到新空间 if( nReadBytes != nWritten )//连续可读的空间!=剩余可读的全部空间 { memcpy(pBuffer+ nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余数据到新空间 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 } else { pByteQueue-\u0026gt;nReadIndex = nNewCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nNewCapacity;//重置容量 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间指针指向旧空间指针 } } size_t nWriteBytes = 0;//连续可写入空间大小 char* pWrite = byteQueue_peekContiguousBytesWrite(pByteQueue,\u0026amp;nWriteBytes);//可写入开始指针 if (nWriteBytes \u0026gt;= nLength)//容量足够 { memcpy(pWrite, pInBytes, nLength);//直接拷贝 } else { memcpy(pWrite, pInBytes, nWriteBytes);//先拷贝连续可写入空间大小 memcpy(pByteQueue-\u0026gt;pBuffer, (const char*)pInBytes + nWriteBytes, nLength - nWriteBytes);//剩余的在直接拷贝 } pByteQueue-\u0026gt;nWriteIndex = (pByteQueue-\u0026gt;nWriteIndex + nLength) % pByteQueue-\u0026gt;nCapacity;//重置写索引 if (pByteQueue-\u0026gt;nReadIndex == pByteQueue-\u0026gt;nCapacity) { pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 } } 读取数据 bool byteQueue_readBytes(byteQueue_tt* pByteQueue, void* pOutBytes, size_t nMaxLengthToRead, bool bPeek /*= false*/ ) { size_t nBytesWritten = byteQueue_getBytesReadable(pByteQueue);//可读的空间大小 size_t nBytesToRead = nBytesWritten \u0026lt; nMaxLengthToRead ? nBytesWritten : nMaxLengthToRead;//得到可读取的大小 if (nBytesToRead == 0) { return false; } size_t nReadBytes = 0;//连续可读的大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始索引 if( nReadBytes \u0026gt;= nBytesToRead )//满足可读大小需求 { memcpy(pOutBytes,pRead,nBytesToRead);//直接读取 } else { memcpy(pOutBytes,pRead,nReadBytes);//直接连续可读的空间大小 memcpy((char*)pOutBytes+nReadBytes,pByteQueue-\u0026gt;pBuffer,nBytesToRead-nReadBytes);//读取剩余需要读取的大小 } if (!bPeek)//不是探测 byteQueue_readOffset(pByteQueue,nBytesToRead);//直接移动指针 return true; } 重置容量 void byteQueue_reserve(byteQueue_tt* pByteQueue, size_t nCapacity) { size_t nWritten = byteQueue_getBytesReadable(pByteQueue);//剩余全部可读大小 if(nWritten \u0026gt; nCapacity)//如果全部可读的大小大于要重置的容量大小 { return; } if(pByteQueue-\u0026gt;nReadIndex != pByteQueue-\u0026gt;nCapacity)//有剩余需要读取的空间数据 { char* pBuffer = mem_malloc(nCapacity);//申请新的重置空间大小 size_t nReadBytes = 0;//连续可读的空间大小 char* pRead = byteQueue_peekContiguousBytesRead(pByteQueue, \u0026amp;nReadBytes);//连续可读空间大小的起始位置 memcpy(pBuffer,pRead,nReadBytes);//直接拷贝 if( nReadBytes != nWritten )//还有剩余要拷贝的空间 { memcpy(pBuffer + nReadBytes,pByteQueue-\u0026gt;pBuffer,nWritten - nReadBytes);//拷贝剩余要拷贝的数据 } pByteQueue-\u0026gt;nReadIndex = 0;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = nWritten;//重置写索引 mem_free(pByteQueue-\u0026gt;pBuffer);//释放旧空间 pByteQueue-\u0026gt;pBuffer = pBuffer;//新空间的指针指向旧空间指针 } else { pByteQueue-\u0026gt;pBuffer = mem_realloc(pByteQueue-\u0026gt;pBuffer,nCapacity);//直接指向申请空间的大小 pByteQueue-\u0026gt;nReadIndex = nCapacity;//重置读索引 pByteQueue-\u0026gt;nWriteIndex = 0;//重置写索引 } pByteQueue-\u0026gt;nCapacity = nCapacity;//重置容量 } ","permalink":"https://frog-game.github.io/posts/blog/ringbuff/","summary":"图解释 结构体 typedef struct byteQueue_s { char* pBuffer;//数据 size_t nCapacity;//容量 size_t nReadIndex;//读指针索引 size_t nWriteIndex;","title":"环形buff"},{"content":"linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 网络流程图 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Socket在Skynet内部对应一个Lua虚拟机和一个客户特定的消息队列per client mq。当客户特定消息队列中有消息时，该队列会挂载到全局队列global message queue上供工作线程worker Threads进行调度处理。\n一个Socket线程socket thread会轮询所有的Socket，当收到客户端请求后将请求打包成一个消息，发送到该Socket对应的客户特定消息队列per client mq中，然后将该消息队列挂到全局队列队尾。\n多个Worker工作线程worker threads从全局队列头部获取客户特定消息队列，从客户特定消息队列中取出一个消息进行处理，处理完毕后再将消息队列重新挂到全局队列队尾。\nskynet中不同服务是利用系统的多线程完全并行的，当你从服务A向服务B和服务C分别各自发送一条消息时，并不能保证先发的消息先被处理。而当你从服务A向服务B依次发送两条消息时，先发的消息一定会被服务B先处理。\n使用Lua实现的服务只是一个内嵌了Lua虚拟机的服务，也遵守上面的规则。如果服务B是一个Lua服务，当服务A向服务B发送两条消息x和y时，Skynet一定保证x先被服务B中的Lua虚拟机接收到，并为消息x生成要给协程X，并运行这个协程。然后才会接收到消息y，并重新生成一个新的协程Y并运行。\n同步问题 同步也是skynet存在的问题，当一个服务call其他服务时，当前协程会挂起，但是这个服务还可以接受并处理其他消息。如果多个协程改到同一个数据，你不做同步处理就无法确定这个数据会是多少。\n这样的例子特别常见，比如，服务正当处理玩家login请求，刚好遇到call挂起，这时候又有新的请求到来，比如logout，服务就会转去处理logout消息。那玩家究竟是login，还是logout？\n当然，同步问题也容易解决，加多一个state的标识和一个协程列表，操作执行时，将state置doing，其他协程判断state=doing时就将自己加到协程列表，然后 skynet.wait。在操作执行完后，重置state，然后遍历协程列表依次 skynet.wakeup(co) ，最后将协程列表置空。\n解释此队列 红黑树上的节点是所有监听的socket 黄色底的是interesting 队列 蓝色底是黄色底的子队列 也就是就绪队列 epoll_ctrl() 执行增加操作时候就是往interesting队列塞socket 当有读写事件时候，就会往蓝色底队列放入socket也就是塞入就绪队列 通过epoll_wait()把就绪队列的东西返回出来\n线程类型 socket thread : 线程进程消息收发\nmonitor thread : 线程监控服务是不是陷入死循环，消息是否堵住\ntime thread : 线程主要用于实现skynet的定时器\nwork thread 线程 对消息队列进行调度\n消息流转 先从全局队列pop一个次级队列，然后从次级队列pop一个消息调用回调函数进行逻辑处理 用完以后如果次级队列不为空或者堵塞，继续把次级队列放入全局队列 启动流程 加载配置文件\n配置文件存入lua的全局变量env\n创建和启动c服务logger\n启动引导模块并启动第一个lua服务(bootstrap)\n然后在通过bootstrap配置去启动其他的微服务\ncluster 两条tcp通道总结 前提 两端是严格分为请求方和回应方。比如 A---\u0026gt; B ，那么只能是A向B提出请求，B 回应它；如果 B-----\u0026gt;\u0026gt;A 需要由 B 向 A 再建立一条通道。\nTCP特性使得每个TCP连接可以得到均等的带宽。在多用户环境下，一个用户拥有越多TCP连接，获得的带宽越大\n1条连接 优点：链接少，对于没有接触过skynet，传统服务器人很容易这种方式连接方式，因为大部分很多都是cs结构程序员过来的 **缺点：**如果断了，数据就无法传输，得重新建立新的连接，上层业务逻辑写起来也麻烦，需要清楚那边是发送方，那边是接受方\n2条连接 **优点：**在前面前提的基础上，有两条连接，上层业务逻辑程序员不需要关心我这个时候是client，还是server，只需要通过cluster.call，cluster.send，接口直接往里面塞数据就行了，多条连接也便于抢带宽 **缺点:**多了一条连接，对cs结构过来的程序员不太容易理解为什么这么弄有好处，或者是不知道有前面那个前提 为什么不在开辟更多的连接，因为开辟更多的链接意义不大，如果这台机器上弄了不少进程，连接数和机器的配置也是有关系的，多了，如果用不上也是一种浪费，同时对于业务程序员来说也逻辑混乱， 因为假如是4条，那么接受方还得区分是那条发过来的数据\nmaster / slave 组网过程 slave3发送sync给master，并启动自己的listen master收到信息给已经连接上的slave1，slave2发送slave3请求连接的情况 master给slave3发送当前已经连接上的slave数量，并把slave3加入节点组 slave1，slave3接收到master发送的信息后，调用connect去连接slave3 master /slave 断网过程 master检测到slave3失去连接，把slave3连接fd置成0 master把失去连接的slave3 id 广播给slave1，slave2 slave1，slave2得到slave3 id之后和slave3断开连接 harbor 服务 每个节点都有一个harborid，在发送消息的时候会把这个harborid放到消息id的\n高8位，所以通过高8位的对比就知道这个消息是远程消息，还是本地消息，如果是远程消息\n通过harbor和远程的harbor建立tcp连接发送数据过去，如果是本地直接放入本地节点处理逻辑\n消息处理方式 skeynet.send 非堵塞不需要应答 skynet.call 堵塞需要应答 skynet.ret 回应消息 skynet.response 请求和相应在不用协程处理 skynet.queue 串行化消息执行 锁 互斥锁 适用于得到锁以后处理时间\u0026gt;线程切换时间场景 得到锁的线程会被唤醒处理逻辑，没有抢占到锁的线程会进入休眠状态\n互斥锁加锁失败以后，会从用户态变成内核态，线程就会释放CPU 给其他线程,会有两次线程上下文的切换成本\n线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行 接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。 上下文切换的时间，大概在几十纳秒到几微妙之间，所以如果你能确认你被锁住的代码时间很短，那么就不应该用互斥锁，而应该用自旋锁\n自旋锁 没有获取到权限的的线程不会进入休眠状态一直自旋检测是否能获取资源，适用于得到锁以后处理时间\u0026lt; 线程切换时间的场景，得到锁处理逻辑最好别有IO操作或者文件流操作\n自旋锁是通过cpu的CAS函数，在用户态就完成了加锁和解锁操作，所以不会有上下文的切换，相比互斥锁来说，会快一点\n一般加锁的过程有两步\n查看锁的状态，如果锁是空闲的，那么执行第二步 将锁设置为当前线程持有 自旋锁加锁失败以后线程会忙等待，直到它能拿到锁\n读写锁 实现在rwlock.h中\n读锁是共享锁概念，其他锁去读的时候读取的是共享的资源，\n写锁是独占概念，其他锁只能等待抢占到的锁释放资源，适用于读多写少场景\n所以更具场景可以分为读优先锁和写优先锁\n读优先锁 读优先锁对于读线程并发性更好，但是也不是没有问题，我们试想一下，如果一直有读线程获取锁，那么写线程就会被饿死\n写优先锁 写优先锁可以保证写线程不被饿死，但是如果一直有写线程获取，那么读线程也会被饿死\n所以不管是优先读锁还是写锁，对方都可能被饿死，所以我们不偏袒任何一方，搞个公平读写锁\n公平读写锁 用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的规则加锁，这样读线程一样能并发，也不会出现饥饿现象\n乐观锁和悲观锁区别 悲观锁做事比较悲观，他认为多线程同时修改共享资源的概率比较高，所以在访问资源之前都会先上一把锁。\n乐观锁正好相反，他认为多线程同时修改共享资源的概率比较低，所以会让先修改完资源，然后在判断是不是有冲突，有没有其他的线程在修改资源，如果有的话就直接放弃本次操作，\n互斥锁、自旋锁、读写锁，都是属于悲观锁\n重入锁 就是能一条线程上能重复获取的锁，而不导致死锁\ncluster 模式 在每个 skynet 节点（单个进程）内，启动一个叫 clusterd 的服务。所有需要跨进程的消息投递都先把消息投递到这个服务上，再由它来转发到网络。\n首选通过clustername.lua配置表配置好全部的cluster节点 在所有要发现的节点上执行require\u0026quot;skynet.cluster\u0026quot; 用cluster.open建立自己的监听好让别的节点和自己建立tcp通道连接 通过cluster.register注册create的service 远程节点利用cluster.query()来得到注册过的节点 通过cluster.call skynet.call cluster.send skynet.send来调用远程function1 function2函数 简易的mmo 架构 网关服务 main.lua 建立 watchdog watchdog 通过skynet.start() 创建gateService gateService并通过rpc调用 watchdogService socket.open 函数 watchdogService 通过 socket.open 创建 agenService agenService 把fd forward给gateService client 发送请求给gateService gateService 把请求重定向给agentService agentService 把处理结果返回给client 协程 coroutine 实现 详细代码见lcorolib.c\n派发消息 function skynet.dispatch_message(...) -- 当前消息处理 local succ, err = pcall(raw_dispatch_message,...) while true do -- 顺序执行skynet.fork 创建的协程 if fork_queue.h \u0026gt; fork_queue.t then -- queue is empty fork_queue.h = 1 fork_queue.t = 0 break end -- pop queue local h = fork_queue.h local co = fork_queue[h] fork_queue[h] = nil fork_queue.h = h + 1 local fork_succ, fork_err = pcall(suspend,co,coroutine_resume(co)) if not fork_succ then if succ then succ = false err = tostring(fork_err) else err = tostring(err) .. \u0026#34;\\n\u0026#34; .. tostring(fork_err) end end end assert(succ, tostring(err)) end 处理当前消息 local function raw_dispatch_message(prototype, msg, sz, session, source) -- skynet.PTYPE_RESPONSE = 1, read skynet.h if prototype == 1 then -- 对回应类型的包处理 local co = session_id_coroutine[session] if co == \u0026#34;BREAK\u0026#34; then session_id_coroutine[session] = nil elseif co == nil then unknown_response(session, source, msg, sz) else local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;resume\u0026#34;) end session_id_coroutine[session] = nil suspend(co, coroutine_resume(co, true, msg, sz, session)) end else local p = proto[prototype] -- 找到对应的解析协议 if p == nil then if prototype == skynet.PTYPE_TRACE then -- trace next request trace_source[source] = c.tostring(msg,sz) elseif session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, prototype) end return end local f = p.dispatch -- 获取处理的函数 if f then local co = co_create(f) -- 获取协程 session_coroutine_id[co] = session session_coroutine_address[co] = source local traceflag = p.trace if traceflag == false then -- force off trace_source[source] = nil session_coroutine_tracetag[co] = false else local tag = trace_source[source] if tag then trace_source[source] = nil c.trace(tag, \u0026#34;request\u0026#34;) session_coroutine_tracetag[co] = tag elseif traceflag then -- set running_thread for trace running_thread = co skynet.trace() end end suspend(co, coroutine_resume(co, session,source, p.unpack(msg,sz))) else trace_source[source] = nil if session ~= 0 then c.send(source, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) else unknown_request(session, source, msg, sz, proto[prototype].name) end end end end 创建协程 local function co_create(f) local co = tremove(coroutine_pool) -- 从协程池中获取协程 if co == nil then --如果没有了 co = coroutine_create(function(...) -- 创建新的 f(...) --执行回调函数，不会立马执行只会调用coroutine.resume时候才会执行 while true do -- 为了能够复用刚创建的协成，下面需要对协程进行初始化和回收 local session = session_coroutine_id[co] if session and session ~= 0 then local source = debug.getinfo(f,\u0026#34;S\u0026#34;) skynet.error(string.format(\u0026#34;Maybe forgot response session %s from %s : %s:%d\u0026#34;, session, skynet.address(session_coroutine_address[co]), source.source, source.linedefined)) end -- coroutine exit local tag = session_coroutine_tracetag[co] if tag ~= nil then if tag then c.trace(tag, \u0026#34;end\u0026#34;) end session_coroutine_tracetag[co] = nil end local address = session_coroutine_address[co] if address then session_coroutine_id[co] = nil session_coroutine_address[co] = nil end -- recycle co into pool f = nil coroutine_pool[#coroutine_pool+1] = co -- recv new main function f f = coroutine_yield \u0026#34;SUSPEND\u0026#34; f(coroutine_yield()) end end) else -- pass the main function f to coroutine, and restore running thread local running = running_thread coroutine_resume(co, f) running_thread = running end return co end 协程挂起 -- suspend is local function function suspend(co, result, command) if not result then -- 执行co失败以后的处理 local session = session_coroutine_id[co] if session then -- coroutine may fork by others (session is nil) local addr = session_coroutine_address[co] if session ~= 0 then -- only call response error local tag = session_coroutine_tracetag[co] if tag then c.trace(tag, \u0026#34;error\u0026#34;) end c.send(addr, skynet.PTYPE_ERROR, session, \u0026#34;\u0026#34;) end session_coroutine_id[co] = nil end session_coroutine_address[co] = nil session_coroutine_tracetag[co] = nil skynet.fork(function() end) -- trigger command \u0026#34;SUSPEND\u0026#34; local tb = traceback(co,tostring(command)) coroutine.close(co) error(tb) end if command == \u0026#34;SUSPEND\u0026#34; then -- 挂起操作 return dispatch_wakeup() -- 如果有能够被唤醒的协程，就wakeup elseif command == \u0026#34;QUIT\u0026#34; then coroutine.close(co) -- service exit return elseif command == \u0026#34;USER\u0026#34; then -- See skynet.coutine for detail error(\u0026#34;Call skynet.coroutine.yield out of skynet.coroutine.resume\\n\u0026#34; .. traceback(co)) elseif command == nil then -- debug trace return else error(\u0026#34;Unknown command : \u0026#34; .. command .. \u0026#34;\\n\u0026#34; .. traceback(co)) end end\t协程销毁 主要是因为这种基础类型LUA_TTHREAD来决定怎么销毁\nLUA_TTHREAD 介绍:\n除了主线程以外，其它线程和其它Lua对象一样都是垃圾回收的对象。等待GC回收，当新建一个线程时，线程会压入栈，这样能确保新线程不会成为垃圾\n每次调用lua_newstate的时候都会创建一个新的luastate,不同的luastate完全独立，之间不共享任何数据\n创建一个线程就拥有一个独立的执行栈了，但是它与其线程共用虚拟机的全局状态\n协程提供了新的api接口和 lua_resetthread, coroutine.close 会使协程进入死亡状态,并且关闭所有的close变量\nsend.call 流程 API 相关 cluster cluster.call(node, address, ...) --远程调用node中的addr cluster.send(node, address, ...) --send调用远程node的addr cluster.open(port) --本地打开(监听)一个cluster结点，使其能在cluster中的其他结点发现 cluster.reload(config) --重载远程结点配置表，表中的cluster结点都open过，则可以通讯 cluster.proxy(node, name) --设置远程结点的代理，使得可以像调用本地RPC一样调用远程结点 cluster.snax(node, name, address) --生成一个远程的snax服务对象 cluster.register(name, addr) --注册一个cluster结点 cluster.query(node, name) --查找远程结点中注册过的结点是否存在 harbor harbor.link(id) --用来监控一个 slave 是否断开。如果 harbor id 对应的 slave 正常，这个 api 将阻塞。当 slave 断开时，会立刻返回。 harbor.linkmaster() --用来在 slave 上监控和 master 的连接是否正常。这个 api 多用于异常时的安全退出（因为当 slave 和 master 断开后，没有手段可以恢复）。 harbor.connect(id) --和 harbor.link 相反。如果 harbor id 对应的 slave 没有连接，这个 api 将阻塞，一直到它连上来才返回。 harbor.queryname(name) --可以用来查询全局名字或本地名字对应的服务地址。它是一个阻塞调用。 harbor.globalname(name, handle) --注册一个全局名字。如果 handle 为空，则注册自己。skynet.name 和 skynet.register 是用其实现的。 构建服务的一些基础接口 skynet.getenv(varName) --conf配置信息已经写入到注册表中，通过该函数获取注册表的变量值 skynet.setenv(varName, varValue) --设置注册表信息，varValue一般是number或string，但是不能设置已经存在的varname skynet.error(...) --打印函数 skynet.start(func) --用 func 函数初始化服务，并将消息处理函数注册到 C 层，让该服务可以工作。 skynet.init(func) --若服务尚未初始化完成，则注册一个函数等服务初始化阶段再执行；若服务已经初始化完成，则立刻运行该函数。 skynet.exit() --结束当前服务 skynet.self() --获取当前服务的句柄handler skynet.address(handler) --将handle转换成字符串 skynet.abort() --退出skynet进程 skynet.kill(address) ----强制杀死其他服务。可以用来强制关闭别的服务。但强烈不推荐这样做。因为对象会在任意一条消息处理完毕后，毫无征兆的退出。所以推荐的做法是，发送一条消息，让对方自己善后以及调用 skynet.exit 。注：skynet.kill(skynet.self()) 不完全等价于 skynet.exit() ，后者更安全。\t普通服务 skynet.newservice(luaServerName, ...)\t全局唯一服务 skynet.uniqueservice(servicename, ...) --当前的skynet节点全局唯一 skynet.uniqueservice(true, servicename, ...) --所有的节点全局唯一 skynet.queryservice(servicename, ...) --当前的skynet节点中查找 skynet.queryservice(true, servicename, ...) --所有的节点中查找 别名 别名分两种：\n本地别名 代表只能在当前skynet节点使用，本地别名用 .开头\n全局别名 可以在所有的skynet中使用 全局别名不能以. 开头\nskynet.register(aliasname) --给当前服务定一个别名，可以是全局别名，也可以是本地别名 skynet.name(aliasname, servicehandler) --给指定servicehandler的服务定一个别名，可以是全局别名，也可以是本地别名 --[[ 查询别名为aliasname的服务,可以是全局别名也可以是本地别名， 1、当查询本地别名时，返回servicehandler，不存在就返回nil 2、当查询全局别名时，返回servicehandler，不存在就阻塞等待到该服务初始化完成 ]]-- skynet.harbor.queryname(aliasname) skynet.localname(aliasname) --查询本地别名为aliasname的服务，返回servicehandler，不存在就返回nil skynet.kill(handle) --杀死带别名服务 服务调度 skynet.sleep(time) --让当前的任务等待 time * 0.01s 。 skynet.fork(func, ...) --启动一个新的任务去执行函数 func , 其实就是开了一个协程，函数调用完成将返回线程句柄 虽然你也可以使用原生的coroutine.create来创建协程，但是会打乱skynet的工作流程 skynet.yield() --让出当前的任务执行流程，使本服务内其它任务有机会执行，随后会继续运行。 skynet.wait() --让出当前的任务执行流程，直到用 wakeup 唤醒它。 skynet.wakeup(co) --唤醒用 wait 或 sleep 处于等待状态的任务。 skynet.timeout(time, func) --设定一个定时触发函数 func ，在 time * 0.01s 后触发。 skynet.starttime() --返回当前进程的启动 UTC 时间（秒）。 skynet.now() --返回当前进程启动后经过的时间 (0.01 秒) 。 skynet.time() --通过 starttime 和 now 计算出当前 UTC 时间（秒）。\t消息类型 #define PTYPE_TEXT 0 --文本 #define PTYPE_RESPONSE 1 --表示一个回应包 #define PTYPE_MULTICAST 2 --广播消息 #define PTYPE_CLIENT 3 --用来处理网络客户端的请求消息 #define PTYPE_SYSTEM 4 --系统消息 #define PTYPE_HARBOR 5 --集群内其他的 skynet 节点发来的消息 #define PTYPE_SOCKET 6 --套接字消息 #define PTYPE_ERROR 7 --错误消息，一般服务退出的时候会发送error消息给关联的服务 #define PTYPE_QUEUE 8 --队列方式 #define PTYPE_DEBUG 9 --调试 #define PTYPE_LUA 10 --lua类型的消息，最常用 #define PTYPE_SNAX 11 --snax服务消息 #define PTYPE_TAG_DONTCOPY 0x10000 --禁止拷贝 #define PTYPE_TAG_ALLOCSESSION 0x20000 --分配新的 session 打包解包 skynet.pack(...) --打包 skynet.unpack(msg, sz) --解包\t发送消息 -- 发送无需响应的消息 skynet.send(addr, type, ...) --用 type 类型向 addr 发送未打包的消息。该函数会自动把...参数列表进行打包，默认情况下lua消息使用skynet.pack打包。addr可以是服务句柄也可以是别名。自动打包与解包。） skynet.rawsend(addr, type, msg, sz) --用 type 类型向 addr 发送一个打包好的消息。addr可以是服务句柄也可以是别名。（需要自己打包与解包） -- 发送必须响应的消息 skynet.call(addr, type, ...) --用默认函数打包消息，向addr发送type类型的消息并等待返回响应，并对回应信息进行解包。（自动打包与解包。） skynet.rawcall(addr, type, msg, sz) --直接向addr发送type类型的msg,sz并等待返回响应，不对回应信息解包。（需要自己打包与解包） 响应消息 -- 同一个协成处理 skynet.ret() --目标服务消息处理后需要通过该函数将结果返回 skynet.retpack(...) --将消息用skynet.pack 打包，并调用 ret 回应。 --不在一个协成处理 local response = skynet.response(pack)--参数pack指定应答打包函数，不填默认使用skynet.pack, 必须根据接收到消息的打包函数一致 返回值是一个闭包函数 response(ok, ...) --参数ok的值可以是 \u0026#34;test\u0026#34;、true、false，为\u0026#34;test\u0026#34;时表示检查接收响应的服务是否存在，为true时表示发送应答PTYPE_RESPONSE，为false时表示发送PTYPE_ERROR错误消息。 消息冲入时序问题 skynet.queue() --帮助你回避这些服务重入或者伪并发引起的复杂性,但是明显降低了服务的并发处理能力，所以使用执行队列的时候尽量缩小临界区的颗粒度大小 协议转换 skynet.forward_type() --需要提供一张消息转换映射表forward_map, 其他的方法与skynet.start一样 伪造消息 skynet.redirect(dest,source,typename, session, msg, sz) --使用source服务地址，发送typename类型的消息给dest服务，不需要接收响应，（source，dest只能是服务ID）msg sz一般使用skynet.pack打包生成 组播 skynet.multicast -- 当组播的数据量较大时候可以节省内部的带宽 socket --建立一个 TCP 连接。返回一个数字 id 。 socket.open(address, port) --关闭一个连接，这个 API 有可能阻塞住执行流。因为如果有其它 coroutine --正在阻塞读这个 id 对应的连接，会先驱使读操作结束，close 操作才返回。 socket.close(id) --在极其罕见的情况下，需要粗暴的直接关闭某个连接，而避免 socket.close 的阻塞等待流程，可以使用它。 socket.close_fd(id) --强行关闭一个连接。和 close 不同的是，它不会等待可能存在的其它 coroutine 的读操作。 --一般不建议使用这个 API ，但如果你需要在 __gc 元方法中关闭连接的话， --shutdown 是一个比 close 更好的选择（因为在 gc 过程中无法切换 coroutine）。与close_fd类似 socket.shutdown(id) --[[ 从一个 socket 上读 sz 指定的字节数。 如果读到了指定长度的字符串，它把这个字符串返回。 如果连接断开导致字节数不够，将返回一个 false 加上读到的字符串。 如果 sz 为 nil ，则返回尽可能多的字节数，但至少读一个字节（若无新数据，会阻塞）。 --]] socket.read(id, sz) --从一个 socket 上读所有的数据，直到 socket 主动断开，或在其它 coroutine 用 socket.close 关闭它。 socket.readall(id) --从一个 socket 上读一行数据。sep 指行分割符。默认的 sep 为 \u0026#34;\\n\u0026#34;。读到的字符串是不包含这个分割符的。 --如果另外一端就关闭了，那么这个时候会返回一个nil，如果buffer中有未读数据则作为第二个返回值返回。 socket.readline(id, sep) --等待一个 socket 可读。 socket.block(id) --把一个字符串置入正常的写队列，skynet 框架会在 socket 可写时发送它。 socket.write(id, str) --把字符串写入低优先级队列。如果正常的写队列还有写操作未完成时，低优先级队列上的数据永远不会被发出。 --只有在正常写队列为空时，才会处理低优先级队列。但是，每次写的字符串都可以看成原子操作。 --不会只发送一半，然后转去发送正常写队列的数据。 socket.lwrite(id, str) --监听一个端口，返回一个 id ，供 start 使用。 socket.listen(address, port) --[[ accept 是一个函数。每当一个监听的 id 对应的 socket 上有连接接入的时候，都会调用 accept 函数。 这个函数会得到接入连接的 id 以及 ip 地址。你可以做后续操作。 每当 accept 函数获得一个新的 socket id 后，并不会立即收到这个 socket 上的数据。 这是因为，我们有时会希望把这个 socket 的操作权转让给别的服务去处理。accept(id, addr) ]]-- socket.start(id , accept) --[[ 任何一个服务只有在调用 socket.start(id) 之后，才可以读到这个 socket 上的数据。 向一个 socket id 写数据也需要先调用 start 。 socket 的 id 对于整个 skynet 节点都是公开的。也就是说，你可以把 id 这个数字 通过消息发送给其它服务，其他服务也可以去操作它。skynet 框架是根据调用 start 这个 api 的位置来决定把对应 socket 上的数据转发到哪里去的。 --]] socket.start(id) --清除 socket id 在本服务内的数据结构，但并不关闭这个 socket 。 --这可以用于你把 id 发送给其它服务，以转交 socket 的控制权。 socket.abandon(id) --[[ 当 id 对应的 socket 上待发的数据超过 1M 字节后，系统将回调 callback 以示警告。 function callback(id, size) 回调函数接收两个参数 id 和 size ，size 的单位是 K 。 如果你不设回调，那么将每增加 64K 利用 skynet.error 写一行错误信息。 --]] socket.warning(id, callback) socketChannel 用来支持双向传输，异步非堵塞处理数据 dns skynet.dns --调用了系统 api getaddrinfo ，有可能阻塞住整个 socket 线程 所以skynet封装了这个接口来解决dns查询时候造成的线程堵塞问题 skynet 的通信调试pack 客户端按大小端打包成二进制\nlocal result = string.pack(\u0026#34;\u0026gt;s2\u0026#34;,\u0026#34;string2pack\u0026#34;) pack \u0026gt; 表示按大端顺序。s2 表示按照2个字节打包。 我们知道string由char组成。1个char 是 0-255 之间的数，2^8 ,1char=8byte 需要注意的是，他除了被打包的部分之外，还会在前面加2个字节，表示长度。 如果要打包一个数字则需要转换。由2种办法 string.pack(\u0026#34;I2\u0026#34;,number)，会在前面二进制加2位表示长度的东西。 socket发送\nsocket.send 服务端接收\ngateserver已经有接收的代码了。 注意的是，socket会自动按pack的数据分段接收。也就是会根据pack的前面2位得到size。根据size去接收后面的数据。然后向上传递一份message。 接收到的message已经是去掉了前面2位的数据。 客户端接收\n户端接收到的数据目前我是用skynet提供的“client.socket”.没有netpack可用。 接收到的数据需要自行去除前面的2个字节的数据（string.pack产生的）。 skynet clientsocket 导致 io.read 无法正确工作的问题 https://blog.csdn.net/gneveek/article/details/78940693 ","permalink":"https://frog-game.github.io/posts/read/skynet/","summary":"linux编译 make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 网络流程图 work线程和次级队列 每个在线客户端在Skynet服务器上都对应有一个Socket与其连接，一个Socket","title":"skynet赏析"},{"content":"luadebug 实现多虚拟机原理 先从luahook原理说起\n在lua.h 当中我们有 lua_sethook函数来给们设置钩子\nLUA_API void (lua_sethook) (lua_State *L, lua_Hook func, int mask, int count); lua_State *L :虚拟机的地址\nlua_Hook func:我们设定的钩子回调函数\nmask: 状态掩码可以组合操作\nLUA_MASKCALL : 调用函数时回调 LUA_MASKRET :函数返回时回调 LUA_MASKLINE :执行一行代码时候回调 LUA_MASKCOUNT :每执行count条指令时候回调 count：只有掩码包含LUA_MASKCOUNT 这个状态时候才有效果，代表执行count次才会回调一次钩子函数\nLUA_MASKCALL 会在调用函数时回调 我们在追踪lua源码，可以发现在每次调用函数之前都回ldo.c 去调用luaD_precall 函数并检测是否设置了掩码标识，如果设置了 LUA_MASKCALL掩码状态，就会调用 luaD_hook 这个回调函数\nLUA_MASKRET :会在函数返回时回调 我们在追踪lua源码，可以发现在每次函数返回时候都会去ldo.c 里面调用luaD_poscall 里面的rethook函数 如果设置了就会调用LUA_MASKRET 掩码状态 ， 就会调用 luaD_hook这个回调函数\nLUA_MASKLINE:执行一行代码时候回调 我们在追踪lua源码，可以发现在每次执行一行指令都会去ldebug.c 去调用 luaG_traceexec 函数 如果设置了LUA_MASKLINE 掩码状态 那么久会调用luaD_hook 函数\nLUA_MASKCOUNT :执行count条指令时候回调 我们在追踪lua源码，可以发现每次执行一行指令都会去ldebug.c 去调用 luaG_traceexec 函数 这个函数需要和count参数配合才能发挥效果，可以看到如果 L-\u0026gt;hookcount 在一次次递减之后等于 0 了就会调用 luaD_hook 函数\n综合上述我们看到最终都会调用到luaD_hook 函数，仔细看源码观察可以看到在经过一系列判断以后会回调我们设置好的 L-\u0026gt;hook 函数\n回到我们第**2 **个参数\n/* Functions to be called by the debugger in specific events */ typedef void(*lua_Hook) (lua_State *L, lua_Debug *ar); 可以看到返回了一个lua_Debug 结构体 我们进入这个结构体\n这里为了兼容每个不同的lua版本，弄了个**union **联合体 写在了lua_api_loder.h里面\n我们进入 lua_Debug_54 结构体里面\n可以发现这里有许多的信息\n结构变量 解释 event Event codes 事件类型标识如下几种 [LUA_HOOKCALL,LUA_HOOKRET,LUA_HOOKLINE,LUA_HOOKCOUNT,LUA_HOOKTAILCALL] name 函数名字 namewhat 作用域的含义，比如是global，local，method，field 或者\u0026quot;\u0026quot; \u0026ldquo;\u0026ldquo;代表没有找到这个函数 what \u0026lt;span style=\u0026quot;display:inline-block;width: 600px\u0026quot;\u0026gt;函数的类型 一般为\u0026quot;lua\u0026rdquo; source 函数定义的位置，如果是loadstring载入的，source是string 如果是在一个文件中source标识带有前缀的@文件名字 srclen source的长度 currentline 当前函数所在的行 linedefined 函数定义的首行地址 \u0026lt;span style=\u0026quot;display:inline-block;width: 120px\u0026quot;\u0026gt; lastlinedefined 函数定义的最后一行的行号 nups 上值的个数 nparams 参数数量 isvararg 是不是可变参数 istailcall 是不是最后一个函数是一个函数调用 形如**function f(x) return g(x) end ** ftransfer 与第一个转移值的偏移量 主要用call/return方式 ntransfer 传输的值 主要用call/return方式 short_src source 的简短表示 i_ci 记录一个函数调用涉及到的栈引用，lua在调用函数的时候会把每个callinfo用双向链表串起来 综合上述原理我们可以看到每一个lua_sethook 被调用时候通过hook返回的信息有这么多，而且每一个lua_state 都是沙盒隔离，所以我们可以利用沙盒原理，通过在进程中创建一个debuggerManager的管理器把所有生成的lua_state的指针保存在这个管理器里面，这样在每次lua调用pcall执行脚本的时候都会去触发自己相对应的lua_sethook设置的hook函数，在里面获取当时触发的时候的上表返回的信息，然后给客服端显示\nluadebug 实现修改变量值 首先需要创建一个protobuf的cmd命令\n**MessageCMD::SetVariableReq ** //修改变量\n客服端设置变量逻辑\n服务器接收到请求逻辑核心逻辑如下\n第一步: 将此lua定义check 用luaL_dostring 进行load执行\nconst char* loadstr = \u0026#34;function dlua_setvarvalue (name, frame, val, level)\\n\u0026#34; \u0026#34; local found\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; -- try local variables\\n\u0026#34; \u0026#34; local i = 1\\n\u0026#34; \u0026#34; while true do\\n\u0026#34; \u0026#34; local n, v = debug.getlocal(frame + level, i)\\n\u0026#34; \u0026#34; if not n then\\n\u0026#34; \u0026#34; break\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if n == name then\\n\u0026#34; \u0026#34; debug.setlocal(frame + level, i, val)\\n\u0026#34; \u0026#34; found = true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; i = i + 1\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if found then\\n\u0026#34; \u0026#34; return true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; -- try upvalues\\n\u0026#34; \u0026#34; local func = debug.getinfo(frame + level).func\\n\u0026#34; \u0026#34; i = 1\\n\u0026#34; \u0026#34; while true do\\n\u0026#34; \u0026#34; local n, v = debug.getupvalue(func, i)\\n\u0026#34; \u0026#34; if not n then\\n\u0026#34; \u0026#34; break\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; if n == name then\\n\u0026#34; \u0026#34; debug.setupvalue(func, i, val)\\n\u0026#34; \u0026#34; return true\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34; i = i + 1\\n\u0026#34; \u0026#34; end\\n\u0026#34; \u0026#34;\\n\u0026#34; \u0026#34; return false\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; luaL_dostring(L, loadstr); 如果是set a=1类型\nstd::string loadstr = \u0026#34;if not dlua_setvarvalue(\\\u0026#34;\u0026#34; + val + \u0026#34;\\\u0026#34;,\u0026#34; + std::to_string(currentFrameId) + \u0026#34;,\u0026#34; + input + \u0026#34;, 3\u0026#34; + \u0026#34;) then\\n\u0026#34;; loadstr += val + \u0026#34;=\u0026#34; + input + \u0026#34;\\n\u0026#34;; loadstr += \u0026#34;end\\n\u0026#34;; int status = luaL_dostring(L, loadstr.c_str()); if (status != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } 如果是set [t1] t1.a=1 类型\nstd::string loadstr = \u0026#34;function dlua_set_val(\u0026#34;; for (auto it = inputval.begin(); it != inputval.end();) { loadstr = loadstr + it-\u0026gt;first; it++; if (it != inputval.end()) { loadstr = loadstr + \u0026#34;,\u0026#34;; } } loadstr = loadstr + \u0026#34;)\\n\u0026#34; + val + \u0026#34;=\u0026#34; + input + \u0026#34;\\n\u0026#34;; loadstr = loadstr + \u0026#34;return \u0026#34;; for (auto it = inputval.begin(); it != inputval.end();) { loadstr = loadstr + it-\u0026gt;first; it++; if (it != inputval.end()) { loadstr = loadstr + \u0026#34;,\u0026#34;; } } loadstr = loadstr + \u0026#34;\\n end\\n\u0026#34;; int status = luaL_dostring(L, loadstr.c_str()); if (status != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } lua_settop(L, oldn); lua_getglobal(L, \u0026#34;dlua_set_val\u0026#34;); if (!lua_isfunction(L, -1)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, \u0026#34;get dlua_set_val fail\u0026#34;); return -1; } for (auto it = inputval.begin(); it != inputval.end(); it++) { if (!FindAndPushVal(L, it-\u0026gt;first, currentFrameId)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, (std::string(\u0026#34;can not find val \u0026#34;) + it-\u0026gt;first).c_str()); return -1; } } int ret = lua_pcall(L, inputval.size(), inputval.size(), 0); if (ret != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } int index = -inputval.size(); for (auto it = inputval.begin(); it != inputval.end(); it++) { std::string name = it-\u0026gt;first; int curoldn = lua_gettop(L); lua_getglobal(L, \u0026#34;dlua_setvarvalue\u0026#34;); if (!lua_isfunction(L, -1)) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, \u0026#34;get dlua_setvarvalue fail\u0026#34;); return -1; } lua_pushstring(L, name.c_str()); lua_pushinteger(L,currentFrameId); lua_pushnil(L); lua_pushinteger(L, 2); lua_copy(L, index - 5, -2); ret = lua_pcall(L, 4, 1, 0); if (ret != 0) { std::string ret = lua_tostring(L, -1); lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, ret.c_str()); return -1; } bool suc = lua_toboolean(L, -1); if (!suc) { lua_settop(L, oldn); EmmyFacade::Get().SendLog(LogType::Error, (std::string(\u0026#34;dlua_setvarvalue set \u0026#34;) + name + \u0026#34; fail\u0026#34;).c_str()); return -1; } lua_settop(L, curoldn); index++; } 图片效果 真机调试 adb forward 原理 要想知道怎么真机调试我们首先应该知道adb调试的原理\n比如我现在调试安卓时候的使用的命令: adb forward tcp:8888 tcp:9966\n通过此端口转发我们就可以做到吧电脑tcp端口的消息转发到真机里面tcp9966端口上\n条件断点 条件断点分为\n1：表达式 2：命中次数\n3：日志断点\n首先需要在此结构中定义3个变量用于处理3中类型，然后通过vscode设置条件端点类型\n部分核心代码\nbool Debugger::ProcessBreakPoint(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { if (!bp-\u0026gt;condition.empty()) { auto ctx = std::make_shared\u0026lt;EvalContext\u0026gt;(); ctx-\u0026gt;expr = bp-\u0026gt;condition; ctx-\u0026gt;depth = 1; bool suc = DoEval(ctx); return suc \u0026amp;\u0026amp; ctx-\u0026gt;result-\u0026gt;valueType == LUA_TBOOLEAN \u0026amp;\u0026amp; ctx-\u0026gt;result-\u0026gt;value == \u0026#34;true\u0026#34;; } if (!bp-\u0026gt;logMessage.empty()) { DoLogMessage(bp); return false; } if (!bp-\u0026gt;hitCondition.empty()) { bp-\u0026gt;hitCount++; return DoHitCondition(bp); } return true; } bool Debugger::DoEval(std::shared_ptr\u0026lt;EvalContext\u0026gt; evalContext) { if (!currentL || !evalContext) { return false; } auto L = currentL; //auto* const L = L; // From \u0026#34;cacheId\u0026#34; if (evalContext-\u0026gt;cacheId \u0026gt; 0) { lua_getfield(L, LUA_REGISTRYINDEX, CACHE_TABLE_NAME); // 1: cacheTable|nil if (lua_type(L, -1) == LUA_TTABLE) { lua_getfield(L, -1, std::to_string(evalContext-\u0026gt;cacheId).c_str()); // 1: cacheTable, 2: value GetVariable(evalContext-\u0026gt;result, -1, evalContext-\u0026gt;depth); lua_pop(L, 2); return true; } lua_pop(L, 1); } // LOAD AS \u0026#34;return expr\u0026#34; std::string statement = \u0026#34;return \u0026#34;; statement.append(evalContext-\u0026gt;expr); int r = luaL_loadstring(L, statement.c_str()); if (r == LUA_ERRSYNTAX) { evalContext-\u0026gt;error = \u0026#34;syntax err: \u0026#34;; evalContext-\u0026gt;error.append(evalContext-\u0026gt;expr); return false; } // call const int fIdx = lua_gettop(L); // create env if (!CreateEnv(evalContext-\u0026gt;stackLevel)) return false; // setup env #ifndef EMMY_USE_LUA_SOURCE lua_setfenv(L, fIdx); #elif defined(EMMY_LUA_51) || defined(EMMY_LUA_JIT) lua_setfenv(L, fIdx); #else //52 \u0026amp; 53 lua_setupvalue(L, fIdx, 1); #endif assert(lua_gettop(L) == fIdx); // call function() return expr end r = lua_pcall(L, 0, 1, 0); if (r == LUA_OK) { evalContext-\u0026gt;result-\u0026gt;name = evalContext-\u0026gt;expr; GetVariable(evalContext-\u0026gt;result, -1, evalContext-\u0026gt;depth); lua_pop(L, 1); return true; } if (r == LUA_ERRRUN) { evalContext-\u0026gt;error = lua_tostring(L, -1); } return false; } void Debugger::DoLogMessage(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { std::string\u0026amp; logMessage = bp-\u0026gt;logMessage; // 为什么不用regex? // 因为gcc 4.8 regex还是空实现 // 而且后续版本的gcc中正则表达式行为似乎也不太正常 enum class ParseState { Normal, LeftBrace, RightBrace } state = ParseState::Normal; std::vector\u0026lt;LogMessageReplaceExpress\u0026gt; replaceExpresses; std::size_t leftBraceBegin = 0; std::size_t rightBraceBegin = 0; // 如果在表达式中出现左大括号 std::size_t exprLeftCount = 0; for (std::size_t index = 0; index != logMessage.size(); index++) { char ch = logMessage[index]; switch (state) { case ParseState::Normal: { if (ch == \u0026#39;{\u0026#39;) { state = ParseState::LeftBrace; leftBraceBegin = index; exprLeftCount = 0; } else if (ch == \u0026#39;}\u0026#39;) { state = ParseState::RightBrace; rightBraceBegin = index; } break; } case ParseState::LeftBrace: { if (ch == \u0026#39;{\u0026#39;) { // 认为是左双大括号转义为可见的\u0026#39;{\u0026#39; if (index == leftBraceBegin + 1) { replaceExpresses.emplace_back(\u0026#34;{\u0026#34;, leftBraceBegin, index, false); state = ParseState::Normal; } else { exprLeftCount++; } } else if (ch == \u0026#39;}\u0026#39;) { // 认为是表达式内的大括号 if (exprLeftCount \u0026gt; 0) { exprLeftCount--; continue; } replaceExpresses.emplace_back(logMessage.substr(leftBraceBegin + 1, index - leftBraceBegin - 1), leftBraceBegin, index, true); state = ParseState::Normal; } break; } case ParseState::RightBrace: { if (ch == \u0026#39;}\u0026#39; \u0026amp;\u0026amp; (index == rightBraceBegin + 1)) { replaceExpresses.emplace_back(\u0026#34;}\u0026#34;, rightBraceBegin, index, false); } else { //认为左右大括号失配，之前的不做处理，退格一位回去重新判断 index--; } state = ParseState::Normal; break; } } } std::stringstream message; if (replaceExpresses.empty()) { message \u0026lt;\u0026lt; logMessage; } else { // 拼接字符串 // 怎么replace 函数都没有啊 std::size_t start = 0; for (std::size_t index = 0; index != replaceExpresses.size(); index++) { auto\u0026amp; replaceExpress = replaceExpresses[index]; if (start \u0026lt; replaceExpress.StartIndex) { auto fragment = logMessage.substr(start, replaceExpress.StartIndex - start); message \u0026lt;\u0026lt; fragment; start = replaceExpress.StartIndex; } if (replaceExpress.NeedEval) { auto ctx = std::make_shared\u0026lt;EvalContext\u0026gt;(); ctx-\u0026gt;expr = std::move(replaceExpress.Expr); ctx-\u0026gt;depth = 1; bool succeed = DoEval(ctx); if (succeed) { message \u0026lt;\u0026lt; ctx-\u0026gt;result-\u0026gt;value; } else { message \u0026lt;\u0026lt; ctx-\u0026gt;error; } } else { message \u0026lt;\u0026lt; replaceExpress.Expr; } start = replaceExpress.EndIndex + 1; } if (start \u0026lt; logMessage.size()) { auto fragment = logMessage.substr(start, logMessage.size() - start); message \u0026lt;\u0026lt; fragment; } } std::string baseName = BaseName(bp-\u0026gt;file); EmmyFacade::Get().SendLog(LogType::Info, \u0026#34;[%s:%d] %s\u0026#34;, baseName.c_str(), bp-\u0026gt;line, message.str().c_str()); } bool Debugger::DoHitCondition(std::shared_ptr\u0026lt;BreakPoint\u0026gt; bp) { auto\u0026amp; hitCondition = bp-\u0026gt;hitCondition; enum class ParseState { ExpectedOperator, // 大于 Gt, // 小于 Le, // 单等号 Eq, ExpectedHitTimes, ParseDigit, ParseFinish } state = ParseState::ExpectedOperator; enum class Operator { // 大于 Gt, // 小于 Le, // 小于等于 LeEq, // 大于等于 GtEq, // 双等号 EqEq, } evalOperator = Operator::EqEq; unsigned long long hitTimes = 0; for (std::size_t index = 0; index != hitCondition.size(); index++) { char ch = hitCondition[index]; switch (state) { case ParseState::ExpectedOperator: { if (ch == \u0026#39; \u0026#39;) { continue; } if (ch == \u0026#39;=\u0026#39;) { state = ParseState::Eq; } else if (ch == \u0026#39;\u0026lt;\u0026#39;) { state = ParseState::Le; } else if (ch == \u0026#39;\u0026gt;\u0026#39;) { state = ParseState::Gt; } else { return false; } break; } case ParseState::Eq: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::EqEq; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::Gt: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::GtEq; state = ParseState::ExpectedHitTimes; } else if (isdigit(ch)) { evalOperator = Operator::Gt; hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else if (ch == \u0026#39; \u0026#39;) { evalOperator = Operator::Gt; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::Le: { if (ch == \u0026#39;=\u0026#39;) { evalOperator = Operator::LeEq; state = ParseState::ExpectedHitTimes; } else if (isdigit(ch)) { evalOperator = Operator::Le; hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else if (ch == \u0026#39; \u0026#39;) { evalOperator = Operator::Gt; state = ParseState::ExpectedHitTimes; } else { return false; } break; } case ParseState::ExpectedHitTimes: { if (ch == \u0026#39; \u0026#39;) { continue; } else if (isdigit(ch)) { hitTimes = ch - \u0026#39;0\u0026#39;; state = ParseState::ParseDigit; } else { return false; } break; } case ParseState::ParseDigit: { if (isdigit(ch)) { hitTimes = hitTimes * 10 + (ch - \u0026#39;0\u0026#39;); } else if (ch == \u0026#39; \u0026#39;) { state = ParseState::ParseFinish; } else { return false; } break; } case ParseState::ParseFinish: { if (ch == \u0026#39; \u0026#39;) { break; } else { return false; } break; } } } switch (evalOperator) { case Operator::EqEq: { return bp-\u0026gt;hitCount == hitTimes; } case Operator::Gt: { return bp-\u0026gt;hitCount \u0026gt; hitTimes; } case Operator::GtEq: { return bp-\u0026gt;hitCount \u0026gt;= hitTimes; } case Operator::Le: { return bp-\u0026gt;hitCount \u0026lt; hitTimes; } case Operator::LeEq: { return bp-\u0026gt;hitCount \u0026lt;= hitTimes; } } return false; } 视频效果展示 多虚拟机测试 linux测试 真机测试 插件下载地址 针对skynet这种微服器框架和自己从 0开发的frog微服务框架编写的lua调试器，感兴趣的可以去vscode商店进行\n下载使用，有任何问题可以加QQ私聊\n","permalink":"https://frog-game.github.io/posts/blog/vscode-lua-chajian/","summary":"luadebug 实现多虚拟机原理 先从luahook原理说起 在lua.h 当中我们有 lua_sethook函数来给们设置钩子 LUA_API void (lua_sethook) (lua_State *L, lua_Hook func, int mask, int count); lua_State *L :虚拟机","title":"微服务lua调试器"},{"content":"在service_snlua.c 中增加此函数 void addLuaState(struct snlua *l,const char *debug_ip,const char * debug_port) { if (NULL == debug_ip) { return; } if (NULL == debug_port) { return; } int port = strtol(debug_port, NULL, 10); const char *lua_dofunction = \u0026#34;function snlua_addLuaState()\\n\u0026#34; \u0026#34;local dbg = require(\u0026#39;frog_debug\u0026#39;)\\n\u0026#34; \u0026#34;dbg.startDebugServer(\u0026#39;%s\u0026#39;, %d)\\n\u0026#34; \u0026#34;dbg.addLuaState()\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; char loadstr[200]; sprintf(loadstr, lua_dofunction, debug_ip, port); int oldn = lua_gettop(l-\u0026gt;L); int status = luaL_dostring(l-\u0026gt;L, loadstr); if (status != 0) { const char *ret = lua_tostring(l-\u0026gt;L, -1); lua_settop(l-\u0026gt;L, oldn); skynet_error(l-\u0026gt;ctx, \u0026#34;[ERROR] addLuaState lua_tostring error!! err:%s\u0026#34;, ret); return; } lua_getglobal(l-\u0026gt;L, \u0026#34;snlua_addLuaState\u0026#34;); if (!lua_isfunction(l-\u0026gt;L, -1)) { const char *ret = lua_tostring(l-\u0026gt;L, -1); lua_settop(l-\u0026gt;L, oldn); skynet_error( l-\u0026gt;ctx, \u0026#34;[ERROR] addLuaState lua_getglobal addLuaState error!! err:%s\u0026#34;, ret); return; } status = lua_pcall(l-\u0026gt;L, 0, 0, 0); if (status != 0) { const char *ret = lua_tostring(l-\u0026gt;L, -1); lua_settop(l-\u0026gt;L, oldn); skynet_error(l-\u0026gt;ctx, \u0026#34;[ERROR] addLuaState lua_pcall addLuaState error!! err:%s\u0026#34;, ret); return; } } 将addLuaState函数插入到service_snlua.c对应位置 static int init_cb(struct snlua *l, struct skynet_context *ctx, const char * args, size_t sz) { lua_State *L = l-\u0026gt;L; l-\u0026gt;ctx = ctx; lua_gc(L, LUA_GCSTOP, 0); lua_pushboolean(L, 1); /* signal for libraries to ignore env. vars. */ lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;LUA_NOENV\u0026#34;); luaL_openlibs(L); luaL_requiref(L, \u0026#34;skynet.profile\u0026#34;, init_profile, 0); int profile_lib = lua_gettop(L); // replace coroutine.resume / coroutine.wrap lua_getglobal(L, \u0026#34;coroutine\u0026#34;); lua_getfield(L, profile_lib, \u0026#34;resume\u0026#34;); lua_setfield(L, -2, \u0026#34;resume\u0026#34;); lua_getfield(L, profile_lib, \u0026#34;wrap\u0026#34;); lua_setfield(L, -2, \u0026#34;wrap\u0026#34;); lua_settop(L, profile_lib-1); lua_pushlightuserdata(L, ctx); lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;skynet_context\u0026#34;); luaL_requiref(L, \u0026#34;skynet.codecache\u0026#34;, codecache , 0); lua_pop(L,1); lua_gc(L, LUA_GCGEN, 0, 0); const char *path = optstring(ctx, \u0026#34;lua_path\u0026#34;,\u0026#34;./lualib/?.lua;./lualib/?/init.lua\u0026#34;); lua_pushstring(L, path); lua_setglobal(L, \u0026#34;LUA_PATH\u0026#34;); const char *cpath = optstring(ctx, \u0026#34;lua_cpath\u0026#34;,\u0026#34;./luaclib/?.so\u0026#34;); lua_pushstring(L, cpath); lua_setglobal(L, \u0026#34;LUA_CPATH\u0026#34;); const char *service = optstring(ctx, \u0026#34;luaservice\u0026#34;, \u0026#34;./service/?.lua\u0026#34;); lua_pushstring(L, service); lua_setglobal(L, \u0026#34;LUA_SERVICE\u0026#34;); const char *preload = skynet_command(ctx, \u0026#34;GETENV\u0026#34;, \u0026#34;preload\u0026#34;); lua_pushstring(L, preload); lua_setglobal(L, \u0026#34;LUA_PRELOAD\u0026#34;); lua_pushcfunction(L, traceback); assert(lua_gettop(L) == 1); const char * loader = optstring(ctx, \u0026#34;lualoader\u0026#34;, \u0026#34;./lualib/loader.lua\u0026#34;); int r = luaL_loadfile(L,loader); if (r != LUA_OK) { skynet_error(ctx, \u0026#34;Can\u0026#39;t load %s : %s\u0026#34;, loader, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; } lua_pushlstring(L, args, sz); r = lua_pcall(L,1,0,1); if (r != LUA_OK) { skynet_error(ctx, \u0026#34;lua loader error : %s\u0026#34;, lua_tostring(L, -1)); report_launcher_error(ctx); return 1; } lua_settop(L,0); if (lua_getfield(L, LUA_REGISTRYINDEX, \u0026#34;memlimit\u0026#34;) == LUA_TNUMBER) { size_t limit = lua_tointeger(L, -1); l-\u0026gt;mem_limit = limit; skynet_error(ctx, \u0026#34;Set memory limit to %.2f M\u0026#34;, (float)limit / (1024 * 1024)); lua_pushnil(L); lua_setfield(L, LUA_REGISTRYINDEX, \u0026#34;memlimit\u0026#34;); } lua_pop(L, 1); addLuaState(l, optstring(ctx, \u0026#34;debug_ip\u0026#34;, NULL), optstring(ctx, \u0026#34;debug_port\u0026#34;, NULL));//调用函数放到这里 lua_gc(L, LUA_GCRESTART, 0); return 0; } 去vscode插件商场下载此插件并安装 远程调试 用everthing 找到 frog_debug.so 然后放到luaclib目录下上传到服务器 在config里面加上两个字段 debug_ip = \u0026#34;127.0.0.1\u0026#34; debug_port = \u0026#34;9966\u0026#34; 重编skynet代码 cd skynet make linux MALLOC_STATICLIB= SKYNET_DEFINES=-DNOUSE_JEMALLOC 在vscode上按如下填写 创建launch.json文件 { // 使用 IntelliSense 了解相关属性。 // 悬停以查看现有属性的描述。 // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387 \u0026#34;version\u0026#34;: \u0026#34;0.2.0\u0026#34;, \u0026#34;configurations\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;lua_remote\u0026#34;, \u0026#34;request\u0026#34;: \u0026#34;launch\u0026#34;, \u0026#34;name\u0026#34;: \u0026#34;远程调试\u0026#34;, \u0026#34;host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;port\u0026#34;: 9966, \u0026#34;ext\u0026#34;: [ \u0026#34;.lua\u0026#34;, \u0026#34;.lua.txt\u0026#34;, \u0026#34;.lua.bytes\u0026#34; ], \u0026#34;ideConnectDebugger\u0026#34;: true } ] } 我用的是wsl2,直接到你的skynet目录下启动 如果嫌弃麻烦,可以在github直接下载example example地址:https://github.com/frog-game/skynet-blueprint-debug.git\n然后按 6到8步骤执行就可以进行调试了\n利用nc命令调试skynet debug_console演示 调试展示 启动进程调试方法 ","permalink":"https://frog-game.github.io/posts/tech/vscode-chajian-zhidao/","summary":"在service_snlua.c 中增加此函数 void addLuaState(struct snlua *l,const char *debug_ip,const char * debug_port) { if (NULL == debug_ip) { return; } if (NULL == debug_port) { return; } int port = strtol(debug_port, NULL, 10); const char *lua_dofunction = \u0026#34;function snlua_addLuaState()\\n\u0026#34; \u0026#34;local dbg = require(\u0026#39;frog_debug\u0026#39;)\\n\u0026#34; \u0026#34;dbg.startDebugServer(\u0026#39;%s\u0026#39;, %d)\\n\u0026#34; \u0026#34;dbg.addLuaState()\\n\u0026#34; \u0026#34;end\u0026#34; \u0026#34;\u0026#34;; char loadstr[200]; sprintf(loadstr,","title":"skynet-blueprint-debug lua多虚拟机调试"},{"content":" 演示\n安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana\nzabbix 6.0 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf zabbix-sql-scripts zabbix-agent 创建初始数据库 mysql -uroot -p123456 mysql\u0026gt; create database zabbix character set utf8mb4 collate utf8mb4_bin; mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; mysql\u0026gt; grant all privileges on zabbix.* to zabbix@`%`; mysql\u0026gt; quit; 导入初始架构和数据，系统将提示您输入新创建的密码[默认密码现在设置为 123456 zcat /usr/share/doc/zabbix-sql-scripts/mysql/server.sql.gz | mysql -uzabbix -p -h10.40.38.67 zabbix # 指定本地的IP地址，不默认就会指向本地localhost 如果报ERROR 2003 (HY000): Can't connect to MySQL server on '10.40.38.67:3306' (111) 看第5章mysql操作指导，多半是因为权限和密码问题\n为Zabbix server配置数据库 sudo vim /etc/zabbix/zabbix_server.conf 修改 DBPassword=123456 启动Zabbix server和agent进程 sudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server sudo systemctl enable zabbix-server zabbix-agent apache2 grafana-server 连接web前端[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http://10.40.38.67/zabbix 默认的用户名是Admin(A是大写)，Password：zabbix 修改时区 sudo vi /etc/apache2/conf-enabled/zabbix.conf 修改标准时区为 Asia/Shanghai 中文显示 sudo apt install language-pack-zh-hans #安装中文语言包 sudo vim /etc/locale.gen #找到zh_CN.UTF-8 UTF-8 并取消#号注释，然后保存并退出 sudo locale-gen #编译语言包 sudo vim /etc/default/locale #修改默认语言为中文，将原来的内容改为 LANG=zh_CN.UTF-8 安装出现的问题 Minimum required size of PHP post is 16M (configuration option \u0026ldquo;post_max_size\u0026rdquo;). 解决步骤：\nsudo vi /etc/php/8.1/apache2/php.ini post_max_size8M 16M\nmax_execution_time30 300\nmax_input_time60 300\ndate.timezone = Asia/Shanghai\nsudo systemctl restart zabbix-server zabbix-agent apache2 grafana-server ERROR 1396 (HY000): Operation CREATE USER failed for 'zabbix'@'%' mysql\u0026gt; create user zabbix@`%` identified by \u0026#39;123456\u0026#39;; ERROR 1396 (HY000): Operation CREATE USER failed for \u0026#39;zabbix\u0026#39;@\u0026#39;%\u0026#39; 原因分析：\n已经存在了zabbix用户 在执行删除zabbix用户的时候没有删除干净 解决方法：\n重新进行删除。\ndrop user zabbix@\u0026#39;%\u0026#39;; flush privileges; 卸载 zabbix 删除软件\nsudo apt-get --purge remove zabbix-server-mysql -y sudo apt-get autoremove zabbix-server-mysql -y sudo apt-get --purge remove zabbix-frontend-php -y sudo apt-get autoremove zabbix-frontend-php -y sudo apt-get --purge remove abbix-apache-conf -y sudo apt-get autoremove abbix-apache-conf -y sudo apt-get --purge remove zabbix-agent -y #删除软件其配置 sudo apt-get autoremove zabbix-agent -y #删除软件依赖包 清理数据\nsudo dpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 删除以上apt-get下载的软件包\nsudo apt-get autoclean 删除缓存的所有软件包\nsudo apt-get clean 删除其他软件依赖的但现在已不用的软件包（保留配置文件）\nsudo apt-get autoremove 查询出冗余文件并删除\nsudo find / -name zabbix 执行rm-rf 删除冗余文件\nsudo rm -rf /run/zabbix sudo rm -rf /etc/zabbix sudo rm -rf /usr/share/zabbix sudo rm -rf /var/log/zabbix sudo rm -rf /var/lib/mysql/zabbix 删除包含zabbix关键字的文件或者文件夹\nsudo find / -name \u0026#34;zabbix*\u0026#34; | sudo xargs rm -rf grafana 下载grafana deb安装包 sudo apt-get install -y adduser libfontconfig1 sudo wget https://dl.grafana.com/enterprise/release/grafana-enterprise_8.5.4_amd64.deb sudo dpkg -i grafana-enterprise_8.5.4_amd64.deb 启动grafana-server sudo systemctl restart grafana-server sudo systemctl enable grafana-server 安装zabbix插件 grafana-cli plugins list-remote sudo grafana-cli plugins install alexanderzobnin-zabbix-app #重启grafana-server sudo systemctl restart grafana-server 也可以在grafana-\u0026gt;plugins这里安装\n登录grafana服务器[10.40.38.67 换成你的ip地址] [用谷歌浏览器或者microsoft Edge浏览器打开] http:/10.40.38.67:3000/ #默认用户名和密码为admin、admin grafana 配置zabbix数据源 grafana 配置zabbix监控面板 在点击完new dashboard 按钮以后 按ctrl + s 保存一个自己定义的仪表盘\ngrafana增加主题 安装插件：grafana-cli plugins install yesoreyeram-boomtheme-panel grafana主题地址：https://github.com/charles1503/grafana-theme/tree/master/CSS/themes/grafanas grafana更改主题教程：https://www.bilibili.com/read/cv7004400 视频教程：https://cloud.tencent.com/developer/video/11330 http://10.40.38.67:3000/public/themes/aquamarine.css 具体操作步骤：\n创建一个目录，用于存放下载对应主题的css文件\nsudo mkdir /usr/share/grafana/public/themes/ cd /usr/share/grafana/public/themes/ 使用一个for 循环下载对应的所有主题css文件\nfor f in grafana-base.css aquamarine.css hotline.css dark.css plex.css space-gray.css organizr-dashboard.css;do wget https://raw.githubusercontent.com/505384662/grafana-theme/master/CSS/themes/grafana/$f;done 为Grafana安装社区插件Boom Theme\nsudo grafana-cli plugins install yesoreyeram-boomtheme-panel sudo systemctl restart grafana-server 在Dashboard中添加Boom Theme\ngrafana 主题修改地址 cd /usr/share/grafana/public/themes grafana 加时钟 grafana-cli plugins install grafana-clock-panel systemctl restart grafana-server grafana flowcharting安装 sudo grafana-cli plugins install agenty-flowcharting-panel sudo systemctl restart grafana-server grafana 修改模板地址 https://grafana.com/grafana/dashboards zabbix 修改配置地址：http://192.168.70.130/zabbix/setup.php zabbix 展示地址：http://192.168.70.130/zabbix/zabbix.php?action=dashboard.view grafana 展示地址: http://192.168.70.130:3000/d/tYxzFya7z/test_zabbix?orgId=1 Grafana 匿名访问（免登录） 修改Grafana配置文件\n在Grafana的配置文件 /etc/grafana/grafana.ini 中，找到 [auth.anonymous] 配置块，将其下的匿名访问控制 enabled 设置为 true，组织权限设置为 Viewer\nViewer:**只读**模式\nEditor:**可编辑**模式\nAdmin:**管理员**模式\n#################################### Anonymous Auth ###################### # Set to true to disable (hide) the login form, useful if you use OAuth, defaults to false disable_login_form = true [auth.anonymous] # enable anonymous access enabled = true # specify organization name that should be used for unauthenticated users org_name = Main Org. # specify role for unauthenticated users org_role = Viewer 重启Grafana服务\n修改完配置文件，重启Grafana服务，命令如下：\nsudo systemctl restart grafana-server 卸载 grafana 查找到安装软件名\nsudo dpkg -l | grep grafana 删除软件\nsudo dpkg -r grafana-enterprise 查询出冗余文件并删除\nfind / -name grafana 用rm-rf 命令删除\nrm -rf /etc/grafana rm -rf /usr/share/grafana rm -rf /usr/share/grafana/public/themes/grafana-theme/CSS/themes/grafana rm -rf /var/log/grafana rm -rf /var/lib/grafana apache2 apache2启动报错 大致意思没有导入apache 环境变量 解决办法:\nsource /etc/apache2/envvars 还是报错\n大致意思是80端口被占用了 我选择的方法是kill占用进程在重启\nroot@hls:/root# netstat -lnp|grep 80 tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 950/nginx: master p tcp6 0 0 :::80 :::* LISTEN 950/nginx: master p unix 2 [ ACC ] STREAM LISTENING 41930 1228/zabbix-plugin_ /tmp/plugin835680808 root@hls:/root# kill -9 950 root@hls:/root# systemctl restart zabbix-server zabbix-agent apache2 卸载apache2 删除软件\n//1. 删除apache sudo apt-get --purge remove apache2 sudo apt-get --purge remove apache2.2-common //2.找到没有删除掉的配置文件，一并删除 sudo find /etc -name \u0026#34;*apache*\u0026#34; |xargs rm -rf sudo rm -rf /var/www sudo rm -rf /etc/libapache2-mod-jk //3.删除关联，这样就可以再次用apt-get install apache2 重装了 #dpkg -l |grep apache2|awk \u0026#39;{print $2}\u0026#39;|xargs dpkg -P//注意：这一步可能会报错，但也没关系 查询出冗余文件并删除\nsudo find / -name apache2 用rm -rf 命令删除\nNginx 官网下载地址 http://nginx.org/en/download.html 一些环境准备 安装编译工具\nsudo apt-get install build-essential 安装编译工具 安装gcc什么的好便于下面编译安装 安装pcre包\nsudo apt-get update sudo apt-get install libpcre3 libpcre3-dev sudo apt-get install openssl libssl-dev 安装 zlib 库\nsudo apt install zlib1g-dev 下载安装Nginx sudo wget http://nginx.org/download/nginx-1.21.6.tar.gz sudo tar -xzvf nginx-1.21.6.tar.gz cd nginx-1.21.6 sudo ./configure --prefix=/usr/local/nginx --with-http_ssl_module --with-stream --with-mail=dynamic #最好用 --prefix指定路径，便于后面删除[只需要删除prefix指定的文件夹就行了]，不指定的话后面删除比较麻烦 sudo make sudo make install 制作软连接 ln -s /usr/local/nginx/sbin/nginx /usr/local/sbin/ 配置环境变量 编辑/etc/profile并且追加Nginx的环境变量 # nginx export NGINX_HOME=/usr/local/nginx export PATH=$PATH:$NGINX_HOME/sbin 生效环境变量 source /etc/profile 测试是否安装成功 nginx -v 启动Nginx sudo nginx 强制停止Nginx sudo pkill -9 nginx 查看Nginx进程 ps aux|grep nginx 配置防火墙 sudo ufw allow \u0026#39;Nginx Full\u0026#39; 验证防火墙是否允许 出现下面两种情况都认为可以 Status: active To Action From -- ------ ---- 22/tcp ALLOW Anywhere Nginx Full ALLOW Anywhere 22/tcp (v6) ALLOW Anywhere (v6) Nginx Full (v6) ALLOW Anywhere (v6) sudo ufw status 状态：不活动 测试访问 http://192.168.70.132:7000 Nginx 相关文件位置 nginx path prefix: \u0026#34;/usr/local/nginx\u0026#34; nginx binary file: \u0026#34;/usr/local/nginx/sbin/nginx\u0026#34; nginx modules path: \u0026#34;/usr/local/nginx/modules\u0026#34; nginx configuration prefix: \u0026#34;/usr/local/nginx/conf\u0026#34; nginx configuration file: \u0026#34;/usr/local/nginx/conf/nginx.conf\u0026#34; nginx pid file: \u0026#34;/usr/local/nginx/logs/nginx.pid\u0026#34; nginx error log file: \u0026#34;/usr/local/nginx/logs/error.log\u0026#34; nginx http access log file: \u0026#34;/usr/local/nginx/logs/access.log\u0026#34; nginx http client request body temporary files: \u0026#34;client_body_temp\u0026#34; nginx http proxy temporary files: \u0026#34;proxy_temp\u0026#34; nginx http fastcgi temporary files: \u0026#34;fastcgi_temp\u0026#34; nginx http uwsgi temporary files: \u0026#34;uwsgi_temp\u0026#34; nginx http scgi temporary files: \u0026#34;scgi_temp\u0026#34; 卸载 Nginx sudo rm -rf /usr/local/nginx sudo rm -rf /usr/local/nginx/sbin/nginx #软连接也记得删除 如果想完全干净，/etc/profile 配置文件中指定的环境变量也可以删除 mysql 安装mysql sudo apt update sudo apt install mysql-server 安装完成后，MySQL服务将自动启动。要验证MySQL服务器正在运行，请输入：\nsudo systemctl status mysql 彻底卸载mysql方法 查看依赖包\ndpkg --list | grep mysql 先依次执行以下命令\nsudo apt-get remove mysql-common sudo apt-get autoremove --purge mysql-server-5.0 # 卸载 MySQL 5.x 使用, 非5.x版本可跳过该步骤 sudo apt-get autoremove --purge mysql-server 然后再用\ndpkg --list | grep mysql 查看一下依赖包最后用下面命令清除残留数据\ndpkg -l |grep ^rc|awk \u0026#39;{print $2}\u0026#39; |sudo xargs dpkg -P 查看从MySQL APT安装的软件列表, 执行后没有显示列表, 证明MySQL服务已完全卸载\ndpkg -l | grep mysql | grep i 博客地址\nhttps://blog.csdn.net/PY0312/article/details/89481421 MySQL在Ubuntu上启动出错Could not open ‘abstractions/mysql‘ rm -rf /etc/apparmor.d/abstractions/mysql rm -rf /etc/apparmor.d/cache/usr.sbin.mysqld find / -name \u0026#39;mysql*\u0026#39; -exec rm -rf {} \\; 连接MySql报错“can\u0026rsquo;t connect to local mysql server through socket \u0026lsquo;/var/run/mysqld/mysqld.sock\u0026rsquo; cd /etc/init.d sudo service mysql stop sudo service mysql start mysql Ubuntu 20.04 Access denied for user \u0026lsquo;root\u0026rsquo;@\u0026rsquo;localhost 首先输入以下指令 获取密码：\nsudo cat /etc/mysql/debian.cnf 再输入以下指令进入mysql\n查询user关键字段\nselect user, authentication_string,plugin,Host from mysql.user; 修改密码格式\nuse mysql; update user set plugin=\u0026#39;mysql_native_password\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 修改密码\nuse mysql; ALTER USER \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED WITH mysql_native_password BY \u0026#39;123456\u0026#39;; flush privileges; 输入\nmysql -uroot -p123456; 查看效果\n让别的ip能连上wsl数据库\nuse mysql; update user set Host=\u0026#39;%\u0026#39; where user=\u0026#39;root\u0026#39;; flush privileges; 输入\nselect user, authentication_string,plugin,Host from mysql.user; 查看效果\n开启远程访问\nsudo vi /etc/mysql/mysql.conf.d/mysqld.cnf # 注释 bind-address = 127.0.0.1 重启mysql\nsudo service mysql restart 效果\nELK 一些准备 官网地址 https://www.elastic.co/guide/en/elasticsearch/reference/8.0/deb.html#deb-repo 虚拟机 想要多开最好是克隆一份出来 比如2就是克隆的1的镜像\n修改 克隆的虚拟机网卡地址\nsudo vim /etc/netplan/00-installer-config.yaml 修改内容:\nnetwork: ethernets: ens33: #配置的网卡的名称 addresses: [192.168.70.130/24] #配置的静态ip地址和掩码 dhcp4: no #关闭DHCP，如果需要打开DHCP则写yes optional: true gateway4: 192.168.70.2 #网关地址 nameservers: addresses: [192.168.70.2,114.114.114.114] #DNS服务器地址，多个DNS服务器地址需要用英文逗号分隔开 version: 2 renderer: networkd #指定后端采用systemd-networkd或者Network Manager，可不填写则默认使用systemd-workd 使配置生效\nsudo netplan apply 注意事项\n1、ip地址和DNS服务器地址需要用[]括起来，但是网关地址不需要 2、注意每个冒号后边都要先加一个空格 3、注意每一层前边的缩进，至少比上一层多两个空格 安装java环境 安装java\nsudo apt install openjdk-8-jdk 查看java 版本\nsudo java -version 查看 java 路径\nsudo which java ls -l /usr/bin/java 看看这是否是个软连接，找出这个软连接指向的路径\nls -l /usr/bin/java 的确为软连接，继续往下找指向的路径\n至此，java 的安装路径即为 /usr/lib/jvm/java-11-openjdk-amd64/bin/java\n配置 java 环境\nsudo vim /etc/profile 在弹出的 vim 编辑器中输入\n# JAVA JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64 PATH=$JAVA_HOME/bin:$PATH export JAVA_HOME PATH esc 退出编辑模式，输入 :x后，单击回车退出。\n在终端输入\nsource /etc/profile 使之前的配置生效。\n验证\njava -version\n$JAVA_HOME/bin/java -version\npython3 [不是必须装主要是想使用 json.tool 格式化输出]\n安装python3.8\nsudo apt-get install python3.8 建立软连接\nsudo ln -s /usr/bin/python3.8 /usr/bin/python 如果想要删除软连接\nsudo rm -rf /usr/bin/python 格式化输出\ncurl -XGET http://192.168.70.131:9200/_mapping | python -m json.tool Elasticsearch 基础知识 和关系型数据库的比较 DBMS Elasticsearch database Index table type(在7.0之后type为固定值_doc) Row Document Column Field Schema Mapping SQL DSL(Descriptor Structure Language) 安装Elasticsearch deb包安装方式\nsudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb sudo wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.2.2-amd64.deb.sha512 shasum -a 512 -c elasticsearch-8.2.2-amd64.deb.sha512 sudo dpkg -i elasticsearch-8.2.2-amd64.deb 执行**sudo dpkg -i elasticsearch-8.2.2-amd64.deb** 回生成超级用户密码 0NgzdrlHquc1YdXrQout\n--------------------------- Security autoconfiguration information ------------------------------ Authentication and authorization are enabled. TLS for the transport and HTTP layers is enabled and configured. The generated password for the elastic built-in superuser is : 0NgzdrlHquc1YdXrQout If this node should join an existing cluster, you can reconfigure this with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reconfigure-node --enrollment-token \u0026lt;token-here\u0026gt;\u0026#39; after creating an enrollment token on your existing cluster. You can complete the following actions at any time: Reset the password of the elastic built-in superuser with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic\u0026#39;. Generate an enrollment token for Kibana instances with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana\u0026#39;. Generate an enrollment token for Elasticsearch nodes with \u0026#39;/usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s node\u0026#39;. ------------------------------------------------------------------------------------------------- 生成 ca 、生成 证书\n# 生成 ca # 根据提示： # 输入 ca 的密码（密码不要忘记，后面生成证书需要） # 输入生成 ca 的文件名（默认会让你输入 elastic-stack-ca.p12，这里就按照默认的来） sudo /usr/share/elasticsearch/bin/elasticsearch-certutil ca # 生成证书 # 根据提示： # 输入之前 ca 的密码 # 输入生成证书的文件名（默认让你输入 elastic-certificates.p12，这里就按照默认的来） # 输入生成证书的密码（密码不要忘记，这个密码在配置 ES keystore 的时候需要） # --ca 后面的文件是上面步骤生成的 elastic-stack-ca.p12 文件，如果修改了的话，这里也需要修改 sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca elastic-stack-ca.p12 ​\t为了方便管理，一般将 ca 与证书放到 ~/.config/certs 目录下\n# 创建目录并移动 ca 与证书 sudo mkdir -p ~/.config/certs \u0026amp;\u0026amp; sudo mv /usr/share/elasticsearch/elastic-stack-ca.p12 /usr/share/elasticsearch/elastic-certificates.p12 ~/.config/certs 启动 Elasticsearch ​\t[为了安全考虑Elasticsearch不允许使用root用户来启动]\n打开 elasticsearch 配置文件\nsudo vim /etc/elasticsearch/elasticsearch.yml #打开配置文件 修改 netWork.host, http.port 字段\nnetwork.host: 10.40.38.66 #注意 network.host:和10.40.38.66 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 http.port: 9200 #注意 http.port:和9200 之间需要空格要不启动会有问题，因为配置文件类型为key-vale格式 因为是内网测试暂时关闭 xpack 安全验证方面选项,以后需要再去开启\n启动Elasticsearch\nsudo systemctl start elasticsearch.service 开机启动elasticsearch\nsudo systemctl enable elasticsearch.service 连接grafana Elasticsearch 操作命令 用jps命令关闭Elasticsearch\n$ jps | grep Elasticsearch 14542 Elasticsearch kill -9 14542 查看 Elasticsearch 端口\nsudo netstat -tnlp |grep java 检测是否启动成功\ncurl -XGET \u0026#39;http://192.168.70.131:9200/\u0026#39; -H \u0026#39;Content-Type: application/json\u0026#39; 用journal 查看系统日志\nsudo journalctl -f 用 journal 查看elasticsearch 服务日志\nsudo journalctl --unit elasticsearch 用journal 查看elasticsearch 指定时间范围的日志\nsudo journalctl --unit elasticsearch --since \u0026#34;2022-02-01 18:17:16\u0026#34; 查看 elasticsearch.log\nsudo vim /var/log/elasticsearch/elasticsearch.log Elasticsearch 卸载 # 查看安装的软件 sudo dpkg -l | grep elasticsearch #查看安装关联 sudo dpkg -L elasticsearch #移除安装软件 sudo dpkg -P elasticsearch #继续查看未卸载的目录和文件 sudo find / -name elasticsearch #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/elasticsearch.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /var/log/elasticsearch \u0026amp;\u0026amp; sudo rm -rf /usr/share/elasticsearch #在此查看是否有关联的目录和文件 sudo find / -name elasticsearch Logstash 安装 Logstash 下载安装公共签名\nsudo wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Elasticsearch了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install logstash 插件地址 https://www.elastic.co/guide/en/logstash-versioned-plugins/current/index.html 配置表字段解释 https://blog.csdn.net/weixin_42073629/article/details/110154037?utm_medium=distribute.pc_aggpage_search_result.none-task-blog-2~aggregatepage~first_rank_ecpm_v1~rank_v31_ecpm-1-110154037.pc_agg_new_rank\u0026amp;utm_term=logstash%E5%8F%82%E6%95%B0convert\u0026amp;spm=1000.2123.3001.4430 查看安装的插件 sudo /usr/share/logstash/bin/logstash-plugin list 启动Lostash 修改 logstash.yml 配置\nsudo vim /etc/logstash/logstash.yml 导入数据[利用logstash 直接分析movies.csv 传送给elasticsearch方式] ​\t收集流程: movies.csv-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n下载ml-latest.zip 数据\nsudo wget https://files.grouplens.org/datasets/movielens/ml-latest.zip 解压 ml-latest.zip\nsudo unzip ml-latest.zip 在/etc/logstash 目录下创建logstash.conf 文件\nsudo vim /etc/logstash/logstash.conf 把以下内容写入logstash.conf\ninput { file { #监听文件的路径 path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/movies.csv\u0026#34; #监听文件的起始位置，默认是end start_position =\u0026gt; \u0026#34;beginning\u0026#34; #监听文件读取信息记录的位置 sincedb_path =\u0026gt; \u0026#34;/home/hls/downs/ml-latest/db_path.log\u0026#34; } } filter { csv { separator =\u0026gt; \u0026#34;,\u0026#34; columns =\u0026gt; [\u0026#34;id\u0026#34;,\u0026#34;content\u0026#34;,\u0026#34;genre\u0026#34;,\u0026#34;@timestamp\u0026#34;] } mutate { # split =\u0026gt; { \u0026#34;genre\u0026#34; =\u0026gt; \u0026#34;|\u0026#34; } # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;] #删除无用字段 } mutate { split =\u0026gt; [\u0026#34;content\u0026#34;, \u0026#34;(\u0026#34;] #左括号分割 add_field =\u0026gt; { \u0026#34;title\u0026#34; =\u0026gt; \u0026#34;%{[content][0]}\u0026#34;} #增加字段 add_field =\u0026gt; { \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;%{[content][1]}\u0026#34;} #增加字段 } mutate { convert =\u0026gt; { #year 转换成整型 \u0026#34;year\u0026#34; =\u0026gt; \u0026#34;integer\u0026#34; } strip =\u0026gt; [\u0026#34;title\u0026#34;] #去掉字段首尾的空格 # remove_field =\u0026gt; [\u0026#34;path\u0026#34;, \u0026#34;host\u0026#34;,\u0026#34;@timestamp\u0026#34;,\u0026#34;message\u0026#34;,\u0026#34;content\u0026#34;] #删除无用字段 } } output { elasticsearch { # 双引号中的内容为ES的地址，视实际情况而定 hosts =\u0026gt; \u0026#34;http://192.168.70.131:9200\u0026#34; index =\u0026gt; \u0026#34;movies\u0026#34; document_id =\u0026gt; \u0026#34;%{id}\u0026#34; #docId 等价于_id 字段 } stdout {} } 如果需要重新导入，先删除db_path.log 文件\nsudo rm -rf /var/lib/logstash/.lock sudo rm -rf /home/hls/downs/ml-latest/db_path.log sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf 报错\n执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nWARNING: Could not find logstash.yml which is typically located in $LS_HOME/config or /etc/logstash. You can specify the path using --path.settings. Continuing using the defaults 那么就创建软连接\ncd /usr/share/logstash sudo ln -s /etc/logstash ./config 执行命令**sudo /usr/share/logstash/bin/logstash -f /etc/logstash/logstash.conf** 后如果报错\nLogstash could not be started because there is already another instance using the configured data directory. If you wish to run multiple instances, you must change the \u0026#34;path.data\u0026#34; setting. 那么就去 logstash.yml 中path.data 指定的路径上去删除.lock文件\ncd /var/lib/logstash sudo ls -a sudo rm -rf .lock 或者直接一句话\nsudo rm -rf /var/lib/logstash/.lock 强制查看输出 logstash.conf 修改成你自己的文件 sudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --verbose --debug 查看数据 用Kibana的命令行工具执行 GET _cat/indices 命令，就能看见导入到Elasticsearch的索引\n用kibana的命令行工具执行**GET /lua_cpu_monitor-2022.06.03/_search**命令,就能看见导入到Elasticsearch的数据\n自动重新加载配置命令 logstash.conf 修改成你自己的文件\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.automatic 默认检测时间是**3**秒 可以通过下列命令修改 把\u0026lt;\u0026gt;号里面的2换成你想要的时间\nsudo /usr/share/logstash/bin/logstash /etc/logstash/logstash.conf --config.reload.interval \u0026lt;2\u0026gt; 卸载Logstash # 查看安装的软件 sudo dpkg -l | grep logstash #查看安装关联 sudo dpkg -L logstash #移除安装软件 sudo dpkg -P logstash #继续查看未卸载的目录和文件 sudo find / -name logstash #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/logstash \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/logstash.* \u0026amp;\u0026amp; sudo rm -rf /etc/default/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/init.d/logstash \u0026amp;\u0026amp; sudo rm -rf /etc/logstash \u0026amp;\u0026amp; sudo rm -rf /var/log/logstash \u0026amp;\u0026amp; sudo rm -rf /usr/share/logstash #在此查看是否有关联的目录和文件 sudo find / -name logstash Kibana 安装Kibana 下载安装公共签名\nwget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add - 接下安装 apt-transport-https 包\nsudo apt-get install apt-transport-https 将存储库保存到 /etc/apt/sources.list.d/elastic-8.x.list\necho \u0026#34;deb https://artifacts.elastic.co/packages/8.x/apt stable main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/elastic-8.x.list 然后你就能安装Kibana了\nsudo apt-get update \u0026amp;\u0026amp; sudo apt-get install kibana 启动Kibana 打开kibana.yml 文档\nsudo vim /etc/kibana/kibana.yml 修改 server.port,server.host 字段\n启动\nsudo systemctl start kibana.service 自启动\nsudo systemctl enable kibana.service 查看 kibana日志\nsudo vim /var/log/kibana 用谷歌或者微软自带浏览器打开地址\nhttp://10.40.38.66:5601 卸载Kibana # 查看安装的软件 sudo dpkg -l | grep kibana #查看安装关联 sudo dpkg -L kibana #移除安装软件 sudo dpkg -P kibana #继续查看未卸载的目录和文件 sudo find / -name kibana #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/kibana \u0026amp;\u0026amp; sudo rm -rf /var/lib/dpkg/info/kibana.* \u0026amp;\u0026amp; sudo rm -rf /etc/kibana #在此查看是否有关联的目录和文件 sudo find / -name kibana Filebeat 搭配filebeat主要使用收集nginx数据, 和上面的利用logstash解析movies.csv，然后收集数据给elasticsearch的方式不一样\n收集流程: nginx-\u0026gt;filebeat-\u0026gt;logstash-\u0026gt;elasticdearch-\u0026gt;grafana\n安装Filebeat sudo curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-8.2.2-amd64.deb sudo dpkg -i filebeat-8.2.2-amd64.deb 修改 filebat.yml 配置文件 sudo vim /etc/filebeat/filebeat.yml 修改下列几项\n# ============================== Filebeat inputs =============================== filebeat.inputs: - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_cpu_monitor.log tags: [\u0026#34;lua_cpu_monitor_log\u0026#34;] - type: filestream id: my-filestream-id enabled: true paths: - /home/hls/work/blueprint-server-runtime/log/lua_mem_monitor.log tags: [\u0026#34;lua_mem_monitor_log\u0026#34;] # ============================== Filebeat modules ============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 1 # ------------------------------ Logstash Output ------------------------------- output.logstash: # The Logstash hosts hosts: [\u0026#34;10.40.38.66:5555\u0026#34;] # ================================= Processors ================================= processors: - add_host_metadata: when.not.contains.tags: forwarded - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 测试filebeat启动后，查看相关输出信息 sudo filebeat -e -c /etc/filebeat/filebeat.yml -d \u0026#34;publish\u0026#34; 后台方式启动filebeat nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 \u0026amp; #将所有标准输出及标准错误输出到/dev/null空设备，即没有任何输出 nohup filebeat -e -c /etc/filebeat/filebeat.yml \u0026gt; filebeat.log \u0026amp; 停止filebeat ps -ef | grep filebeat kill -9 进程号 启动出现的问题 执行命令systemctl start filebeat.service就能够启动了。而后执行ps -ef|grep filebeat查看一下\n能够看到已经启动胜利了，如果你发现没有启动成功，那么就执行 cd /usr/bin，在这个目录下执行./filebeat -c /etc/filebeat/filebeat.yml -e，这样会提醒具体的错误信息。而用systemctl start filebeat.service启动的时候没有任何提醒，连在 /var/log/filebeat/ 和 /var/lib/filebeat/registry/filebeat/ 都没找到错误信息，这里属实有点坑。\n重新启动命令systemctl restart filebeat.service\n去安装logstash的机器启动logstash 增加 logstash_filebeat.conf 文档\nsudo vim /etc/logstash/conf.d/logstash_filebeat.conf 把以下内容粘贴上保存\ninput { beats { port =\u0026gt; 5555 #这个地址不能和logstash.yml 里面的api.http.host: 9600 一样，要不会出现地址已经被绑定的错误 } } output { if \u0026#34;lua_cpu_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_cpu_monitor-%{+YYYY.MM.dd}\u0026#34; } } if \u0026#34;lua_men_monitor_log\u0026#34; in [tags] { elasticsearch { hosts =\u0026gt; [\u0026#34;10.40.38.66:9200\u0026#34;] index =\u0026gt; \u0026#34;lua_men_monitor-%{+YYYY.MM.dd}\u0026#34; } } } 重新加载新的配置并启动logstash\n先启动logstash，然后在启动filebeat，不然的话filebeat会找不到beats插件的:5555端口\nsudo rm -rf /var/lib/logstash/.lock sudo /usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/logstash_filebeat.conf --verbose --debug 用filebeat 监控 nginx 修改 nginx conf 配置表\nsudo vim /usr/local/nginx/conf/nginx.conf 加入如下日志格式\nlog_format main \u0026#39;{\u0026#34;@timestamp\u0026#34;:\u0026#34;$time_iso8601\u0026#34;,\u0026#39; \u0026#39;\u0026#34;@source\u0026#34;:\u0026#34;$server_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;hostname\u0026#34;:\u0026#34;$hostname\u0026#34;,\u0026#39; \u0026#39;\u0026#34;ip\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;client\u0026#34;:\u0026#34;$remote_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request_method\u0026#34;:\u0026#34;$request_method\u0026#34;,\u0026#39; \u0026#39;\u0026#34;scheme\u0026#34;:\u0026#34;$scheme\u0026#34;,\u0026#39; \u0026#39;\u0026#34;domain\u0026#34;:\u0026#34;$server_name\u0026#34;,\u0026#39; \u0026#39;\u0026#34;referer\u0026#34;:\u0026#34;$http_referer\u0026#34;,\u0026#39; \u0026#39;\u0026#34;request\u0026#34;:\u0026#34;$request_uri\u0026#34;,\u0026#39; \u0026#39;\u0026#34;args\u0026#34;:\u0026#34;$args\u0026#34;,\u0026#39; \u0026#39;\u0026#34;size\u0026#34;:$body_bytes_sent,\u0026#39; \u0026#39;\u0026#34;status\u0026#34;: $status,\u0026#39; \u0026#39;\u0026#34;responsetime\u0026#34;:$request_time,\u0026#39; \u0026#39;\u0026#34;upstreamtime\u0026#34;:\u0026#34;$upstream_response_time\u0026#34;,\u0026#39; \u0026#39;\u0026#34;upstreamaddr\u0026#34;:\u0026#34;$upstream_addr\u0026#34;,\u0026#39; \u0026#39;\u0026#34;http_user_agent\u0026#34;:\u0026#34;$http_user_agent\u0026#34;,\u0026#39; \u0026#39;\u0026#34;https\u0026#34;:\u0026#34;$https\u0026#34;\u0026#39; \u0026#39;}\u0026#39;; 对比修改下图对应的3个红框地方\n重启 nginx\nsudo pkill -9 nginx \u0026amp;\u0026amp; sudo nginx 用 http:192.168.70.132:7000 登录nginx 网站生成登录日志，然后打开 access.log 日志\nsudo vim /usr/local/nginx/logs/access.log sudo tail -f /usr/local/nginx/logs/access.log 卸载Filebeat # 查看安装的软件 sudo dpkg -l | grep filebeat #查看安装关联 sudo dpkg -L filebeat #移除安装软件 sudo dpkg -P filebeat #继续查看未卸载的目录和文件 sudo find / -name filebeat #移除目录和文件具体参考自己的环境 sudo rm -rf /var/lib/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat/filebeat \u0026amp;\u0026amp; sudo rm -rf /var/log/filebeat \u0026amp;\u0026amp; sudo rm -rf /usr/share/filebeat #在此查看是否有关联的目录和文件 sudo find / -name filebeat ","permalink":"https://frog-game.github.io/posts/blog/zabbix-mysql8.0/","summary":"演示 安装环境 版本 Ubuntu 20.04 zabbix 6.0 mysql 8.0 Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafana zabbix 6.0 阿里云镜像地址 https://mirrors.aliyun.com/zabbix/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/ 下载 zabbix sudo wget https://repo.zabbix.com/zabbix/6.0/ubuntu/pool/main/z/zabbix-release/zabbix-release_6.0-1+ubuntu20.04_all.deb sudo dpkg -i zabbix-release_6.0-1+ubuntu20.04_all.deb sudo apt update 安装Zabbix server，Web前端，agent sudo apt install zabbix-server-mysql zabbix-frontend-php zabbix-apache-conf","title":"zabbix游戏日志监控"},{"content":"为啥选择帧同步 和写单机游戏类似，客服端收集自己的指令操作发送到服务器，服务器进行收集广播给所有的玩家，客服端本地通过收到的包来推进游戏进度\n服务器：每隔一段时间收集客服端的操作，发给客服端，然后继续采集下一次的操作，在发给客服端\n客服端：收到服务器的广播下来的操作\u0026mdash;-\u0026gt;计算逻辑\u0026mdash;\u0026gt;采集自己操作上报服务器\n帧同步适用于实时性要求高，人数较少的情况\n帧同步服务器每隔多久同步一次比较合适呢\n上限： 网络传输时间，比如我们的ping百度网站你得到的时间是10ms 那么 1000/10 100 帧\n下限：下发给玩家的速度，也就是玩家的体验，科学数据玩家在50 ms-100ms 之间人不会感觉到卡顿认为比较流畅\n那么就是[1000/50,1000/100]\u0026mdash;\u0026gt;[20,10] 所以王者荣耀一般取中间值15fps 也就是1秒15帧 一帧 1000/15 66ms\n算下带宽是多少，承受的了吗\n假设5000个人，按一个房间10人，那么就得500个房间\n假设**1秒的数据， 一帧我们每人16个字节的指令数据，那么16 * 10 * 15 * 500** \u0026mdash;\u0026gt;1,200,000Byte \u0026ndash;\u0026gt; 1172KB \u0026mdash;\u0026gt; **1MB**带宽，对于现在的服务器完全是可以承受的\n选用udp还是tcp tcp ：准确 丢包重传\n通常tcp也能做到做帧同步，但是很难因对网络波动，因为假如tcp有条链路发送了一个1号包过去，这个时候因为网络波动这个链路网速下降，这个时候可能会触发重传，在发送2号包过来的时候，就可能会卡主2号包，从而导致客服端收不到包数据\nudp：高效，可能丢包，乱序 假设1号包卡主了，那么udp不会去等待1号包是否发完，在下一次需要发送的时候就会再次通过新的链接发送2号包过去\n基于可靠传输的UDP，是指在UDP上加一层封装，自己去实现丢包处理，消息序列，重传等类似TCP的消息处理方式，保证上层逻辑在处理数据包的时候，不需要考虑包的顺序，丢包等。类似的实现有Enet，KCP等。\n冗余信息的UDP，是指需要上层逻辑自己处理丢包，乱序，重传等问题，底层直接用原始的UDP，或者用类似Enet的Unsequenced模式。常见的处理方式，就是两端的消息里面，带有确认帧信息，比如客户端（C）通知服务器（S）第100帧的数据，S收到后通知C，已收到C的第100帧，如果C一直没收到S的通知（丢包，乱序等原因），就会继续发送第100帧的数据给S，直到收到S的确认信息。\n一旦客户端没收到服务端已确认其发送的数据，就会一直重传直到服务端确认为止\n发送者维持一个发送队列，对每一次发送进行编号。每一次发送时，会将待发送的数据写入队列。然后将队列里的数据+编号发送给接收者。\n接收者收到数据后，会将该编号回送给发送者以确认。发送者收到确认编号后，会将该编号对应的数据包从队列中删除，否则该数据仍保存在发送队列中。\n下次发送时，会有新的数据进入队列。然后将队列中的数据+最新的编号发送给接收者。以此循环反复\n上图解析：\n第1次发送，在发送队列里只有Data1，于是将Data1和编号1（Seq=1）发送给接收者。收到确认编号1（Ack=1）后，将Data1从队列中删除。 第4到7次发送，由于从第4次发送开始就没有收到确认编号，于是队列中包含了Data4到Data7。第7次发送后，收到确认编号6，于是将Data4至Data6从队列中删除。 第8次发送，队列中包含Data7和Data8。发送后收到确认编号8，从而将Data7和Data8从队列中删除。 以上的关键点是，发送者未收到确认编号，并不一直等待，而是会继续下一次发送。结合图1：\n如果发送者是服务器，则会每隔66MS会将一个Frame数据写入发送队列，然后将该队列里的所有Frame数据一起发送给客户端 。 如果发送者是客户端，则会在玩家有操作时，将玩家的每一个OperateCmd数据写入发送队列，然后将该队列里的所有OperateCmd数据一起发送给服务器 。如果发送队列不为空，则每隔99MS重复发送。如果发送队列为空，则不再发送。直到玩家下一次操作。 由于服务器和客户端即是发送者，又是接收者。则服务器和客户端的每一次发送，除了会带上该次发送的编号，还会带上对对方发送编号的确认。 区别\n但是这两种方式，区别是巨大的。可靠传输的UDP，在帧同步中，个人认为是不合适的，因为他为了保证包的顺序和处理丢包重传等，在网络不佳的情况下，delay很大，将导致收发包处理都会变成类似tcp的效果，只是比TCP会好一些。必须要用冗余信息的UDP的方式，才能获得好的效果。并且实现并不复杂，只要和服务器商议好确认帧和如何重传即可，自己实现，有很大的优化空间\n帧同步运行前提 输入一致性\n确定性的碰撞，寻路结果 玩家操作顺序唯一 计算要一致性\n服务器针对每个单局游戏开局时间生成随机数种子，逻辑帧计算均为伪随机\n浮点数采用多个定点数保存和运算，确保浮点数计算结果一致\n每个网络包都包含自增序号，具体算法可根据项目自行定义\n严格控制静态变量（全局变量）的使用\n禁止使用不稳定的排序算法\n禁止使用顺序不确定的数据结构\n尽量不使用非开源的第三方库（无法确定第三方库中是否有上述的结果不一致算法）\n多线程问题\n主要是每个客服端多线程算出结果可能会不一致，比如A客服端用了3个线程来算你\t这个数据，b客服端用1个线程来算你这个数据导致最后A和B的结果不一致，除非你\t能保证最后结果一致，要不最好别用\n协程 (Coroutine)内写逻辑带来的不确定性也要注意\n开始演示代码前，要保证运行的多个客服端代码版本要一致，如果因为版本不一致导致运行结果不一样，然后查了很久bug那就太2了，如果当前线上存在多个版本，则只有同版本玩家可匹配到单局游戏中\nc#的dictionary遍历的时候是无序的，这个要注意,很容翻车\n如果同批发送的包比较多，尽量合并，减少包头信息的冗余\n业务层上面尽量减少数据结构包的大小\n逻辑帧的规则\n收到第N帧，只有当我收到第N+1帧的时候，第N这一帧我才可以执行。 服务器会按照一定的频率，不同的给大家同步帧编号，包括这一帧的输入带给客户端，如果带一帧给你的数据你拿到之后就执行，下一帧数据没来就不能执行，它的结果就是卡顿。\n战斗流畅保证方法 逻辑帧保证在15-18帧上下\n数据包冗余发送，发送数据量较少的当前帧时，可以把前几帧数据合并发送\n渲染帧保证在30帧以上\n常见的客户端预测，客户端插值，服务器延迟补偿方法保证客户端画面流畅\n帧同步流程 服务器:\n服务器的每个比赛对象，都有一个成员frameid 保持了当前的比赛，下一帧要进入的id，frameid =1\n我们在服务器上定义了一个数据结构 match_frames 用来保存我们所有玩家每帧的操作\n保存match_frames这个结构的作用:\n录像回放\n断线重连\n在不同步的情况下，看看有没有作弊\nudp丢包时序问题，丢包的时候需要补发给客服端\nnext_frame_opt 每帧服务器采集到的客服端操作\nnext_frame_opt = {frameid ,{1号操作玩家指令,2号操作玩家指令,3号操作玩家指令,4号操作玩家指令, ..}}\n服务器启动定时器 每隔66ms触发一次 on_logic_frame\n保存我们当前的操作到match_frames\n遍历每个玩家，给每个玩家发送我们的帧操作\n服务器进入下一帧 frameid = frameid + 1\n服务器进入采集下一帧的操作，清空上一帧采集到的客服端操作:也就是把next_frame_opt清空\nnext_frame_opt = {frameid ,{}}\n发送服务器认为这个玩家还没有同步的帧，每个玩家对象记录了一个变量 sync_frameid 用来记录这个客服端已经同步了多少帧\n同步的帧： sync_frameid + 1 TO 最新的帧 \u0026mdash;\u0026gt;主要是用来解决udp丢包和时序问题\n采用udp 将我们需要补发的帧同步给客服端[sync_frameid + 1,最新帧]\n客服端:\n通过网络受到网络受到帧同步的数据包以后,\n每个客服端也会有一个sync_frameid,用来记录一下你这个客服端真正已经同步到那个帧了\n如果收到的帧id小于客服端的帧id，那么直接丢弃这个帧\n为什么会出现需要丢弃这个帧的情况\n因为udp 时序问题 ：有先发后到，后发先到的可能\n为什么我们没有收到99帧，可以开始处理100帧，还能同步吗\n99帧没有处理，服务器发100帧的时候回补发99帧\n如果上一帧的操作不为空，那么这个时候，我们在处理下一帧之前，一定要先同步下上一帧的结果\n客服端A:|\u0026hellip;.|..66.3.|\u0026hellip;.|\n客服端B:|\u0026hellip;.|\u0026hellip;66.2.|\u0026hellip;.|\n在播放动画的帧与帧之间，我们会出现时间的差异，会导致位置不同步，\nlogic_pos 66ms \u0026ndash;\u0026gt;统一用66ms来计算新的位置和结果\n客服端A:|\u0026hellip;.|\u0026hellip;66.|\u0026hellip;.|\n客服端B:|\u0026hellip;.|\u0026hellip;66.|\u0026hellip;.|\n每帧都同步，处理下一帧之前，每帧都要同步，同样的输入\u0026mdash;\u0026gt;同样的输出\n跳帧 快速的同步完过时的帧，直到最新的帧\n控制我们的客服端，来根据操作，来播放动画，更新我们的逻辑推进，创建怪物，防御塔，等等逻辑\n采集你自己的操作，上报给客服端\n服务器:\n收到玩家的操作，更新服务器上认为玩家已经处理的帧id\n98处理完\u0026ndash;\u0026gt;99, 服务器发99帧-\u0026gt;客服端\u0026mdash;\u0026gt; 处理完99帧，客服端收集100帧操作，服务器收到100帧操作 100 - 1已经同步完了，这个时候就吧98变成99帧也就是 变成98\u0026ndash;\u0026gt;99\n如果收到玩家操作的帧id，next_frame_opts.frameid 等于马上要触发的帧id，说明收到了玩家过时的操作\n假设服务器已经处理完99帧，马上要下发100帧了，这个时候客服端还上传99帧，那么可以认为玩家因为网络或者特殊原因发送了过时的操作，所以直接丢弃\n这样丢弃会影响玩家的手感吗\n丢帧肯定会影响玩家的手感，但是基本不影响玩家操作，15fps，按一个按钮基本4次，中间丢一帧，不太会影响玩家整体，基本玩家感受不出来。\n保存玩家的操作，等待下一帧的触发，goto到逻辑4\n如何克服udp的时序和丢包问题 客服端: 丢包, 晚到，服务器会补发丢掉的帧\n服务器: 丢包, 没有太多的影响， 下一帧马上就可以处理\n防外挂 视野外挂\n划分地图区域 玩家信息分层 属性外挂 多客户端状态校验，客户端执行完每个逻辑帧后，根据游戏的状态计算出一个Hash值，用其标定一个具体的游戏状态。不同客户端通过对比这个值，即可判断客户端之间是否保持同步\n数据的加密处理\n输入的合理性检测\n服务器运行一个精简的可信赖的客户端环境，得到可信赖的数据\n反外挂是一个很大的议题。帧同步结构中，所有数据都在玩家本地，理论上玩家可以任意修改这些数据。这里不讨论传统的加壳及反调试技术。这里讨论在实际开发中，帧同步框架能够通过什么方法来解决该问题。框架能提供至少3种保护: a. 关键数据保护，b. 虚拟化, c. 服务器后验证。关键数据保护可以有很多技术，框架对核心数据，可以做内存加密，内存多拷贝冗余保护等。框架提供虚拟化技术，也是一个不错的选择，部分代码可以在虚拟机(lua)中直接执行，破解难度会增加(前提是资源保护足够)。服务器后验证是杀手锏，验证服务器能运行游戏录像，并直接得出游戏战斗结果，任何作弊都无所遁形。\n因此对于帧同步，反外挂相对是一件比较容易的事情。游戏过程中，玩家作弊只会影响到自己，不会影响到他人。游戏结算时，当服务器检测到玩家之间游戏结果不一致时，通过验证服务器，对游戏录像进行验证计算，很容易就能发现是哪个玩家发生了作弊。\n怎么优化卡顿的问题 buffer缓存\n本地插值平滑加逻辑与表现分离\n使用UDP（在手机环境下，弱网的情况下，TCP很难恢复重连）\n服务端Sleep(1)，并不是代表休息1ms，具体精度看操作系统。（windows约15ms，linux约1ms）\n要在windows上测试需要将全局设置高精度计时器 timeBeginPeriod(1)，有些别的软件开启时会设置全局的精度。\n当调用Sleep（1）时，CPU会进入睡眠状态，以节省电量，因此，如果CPU处于睡眠状态，操作系统（OS）如何唤醒你的线程？答案是硬件中断。操作系统对计时器芯片进行编程，然后该计时器芯片触发中断以唤醒CPU，然后操作系统可以调度线程\n计时器中断之间的间隔取决于Windows版本和你的硬件，但在我最近使用的每台计算机上，默认间隔为15.625毫秒（1,000毫秒除以64）。这意味着，如果你在某个随机时间调用Sleep（1），那么将来每当下一个中断触发时（或者如果下一个中断过早，则在此之后触发），你可能会在1.0毫秒至16.625毫秒之间的某个时间被唤醒。\n最近用ET框架遇到的问题 NLOG没有开启异步日志模式导致的周期性卡顿\n逻辑帧率是否越高越好 并非如此，建议15帧/秒。\n逻辑帧率增加带来的影响如下：\n逻辑层计算次数增多，cpu消耗越大。 网络流量消耗越多 对服务器CPU和带宽压力增大 利用预测回滚,客服端插值，对抗高延迟 预测 预测就是将玩家的输入立即应用到本地状态，而无需等待服务端返回。\n如果玩家的每一次操作如果都要等到服务端确认后才能生效，那么延迟将是不可避免的。解决方案就是：玩家做出任何操作后，立刻将输入应用到本地状态，并刷新表现层显示。例如按下了 “右”，那么就立即向右移动，而无需等待服务端返回，效果如图。\n现在，操作的延迟消失了。你按下 “左” 或者 “右” 都可以得到立刻的反馈。\n但问题似乎并没有完全解决，在移动过程中，你总是能感到来回的 “拉扯” 或者位置抖动。这是因为你在执行本地预测的时候，也在接收来自服务端的同步，而服务端发来的状态总是滞后的。\n例如：\n你的坐标是 (0,0) 你发出了 2 个 右移 指令（每次向右移动 1 个单位），服务器尚未返回，执行本地预测后，坐标变为 (2,0) 你又发出了 2 个 右移 指令，服务器尚未返回，执行本地预测后，坐标变为 (4,0) 服务端发回了你的前 2 个右移指令：从 (0,0) 执行 2 次右移，坐标变为 (2,0)，被拉回之前的位置 由于延迟的存在，服务端的同步总是滞后的，所以你总是被拉回之前的位置。如此往复，就是你在图中看到的抖动和拉扯。\n归根到底，是服务端同步过来的状态与本地预测的状态不一致，所以我们需要 “和解” 它们。\n和解 和解就是一个公式：预测状态 =权威状态 + 预测输入\n重要\n和解的概念最难理解，但也是实现无延迟感体验最重要的一步。你可以先简单记住上面的公式，应用到项目中试试看。\n权威和预测 一般我们认为服务器总是权威的，从服务端接收到的输入称为 权威输入，经权威输入计算出来的状态称为 权威状态。同样的，当我们发出一个输入，但尚未得到服务端的返回确认时，这个输入称为非权威输入，也叫 预测输入。\n在网络畅通的情况下，预测输入迟早会按发送顺序变成权威输入。我们需要知道发出去的输入，哪些已经变成了权威输入，哪些还是预测输入。在可靠的传输协议下（例如 WebSocket）你无需关注丢包和包序问题，所以只需简单地对比消息序号即可做到。\n和解过程 在前述预测的基础上，和解就是我们处理服务端同步的状态的方式。如果使用的是状态同步，那么这个过程是：\n收到服务端同步来的 权威状态 将本地状态立即设为此权威状态 在权威状态的基础上，应用当前所有 预测输入 如果使用的是帧同步，那么这个过程是：\n收到服务端同步来的权威输入 将本地状态立即 回滚 至 上一次的权威状态 将权威输入应用到当前状态，得到此次的 权威状态 在权威状态的基础上，应用当前所有 预测输入 由此可见，状态同步和帧同步只是网络传输的内容不同，但它们是完全可以相互替代的 —— 最终目的都是为了同步权威状态。\n例子 这有用吗？我们回看一下上面预测的例子，有了和解之后，会变成怎样：\n你的坐标是 (0,0)\n你发出了 2 个 右移 指令（每次向右移动 1 个单位），服务器尚未返回\n权威状态：(0,0) 预测输入：右移#1 右移#2 预测状态：(2,0) （权威状态 + 预测输入） 你又发出了 2 个 右移 指令，服务器尚未返回\n权威状态：(0,0) （未收到服务端同步，不变） 预测输入：右移#1 右移#2 右移#3 右移#4 预测状态：(4,0) （权威状态 + 预测输入） 服务端发回了你的前 2 个右移指令 （帧同步）\n上一次的权威状态：(0,0) 权威输入：右移#1 右移#2 权威状态：(2,0) （上一次的权威状态 + 权威输入） 预测输入：右移#3 右移#4 （#1、#2 变成了权威输入） 预测状态：(4,0) （权威状态 + 预测输入，之前的拉扯不见了） 看！虽然服务端同步来的权威状态是 “过去” 的，但有了和解之后，拉扯问题解决了，效果如图：\n预测 + 和解处理本地输入是非常通用的方式。你会发现，在没有冲突时，网络延迟可以完全不影响操作延迟，就跟单机游戏一样！例如上面移动的例子，如果不发生冲突（例如与它人碰撞），即便网络延迟有 10 秒，你也可以毫无延迟并且平滑的移动。这就是在有延迟的情况下，还能实现无延迟体验的魔术。\n冲突 那么冲突的情况会怎样呢？比如上面的例子，你发送了 4 次移动指令，但在服务端，第 2 次移动指令之后，服务端插入了一个新输入 —— “你被人一板砖拍晕了”。这意味着，你的后两次右移指令将不会生效（因为你晕了）。那么该过程会变成这样：\n你的坐标是 (0,0)\n你发出了 2 个 右移 指令（每次向右移动 1 个单位），服务器尚未返回\n权威状态：(0,0) 预测输入：右移#1 右移#2 预测状态：(2,0) 你又发出了 2 个 右移 指令，服务器尚未返回\n权威状态：(0,0) 预测输入：右移#1 右移#2 右移#3 右移#4 预测状态：(4,0) 服务端发回了你的前 2 个右移指令\n权威状态：(2,0) 预测输入：右移#3 右移#4 （#1、#2 变成了权威输入） 预测状态：(4,0) 服务端发回了与预期冲突的新输入\n上一次的权威状态：(2,0) 权威输入：你被拍晕了 右移#3 右移#4 权威状态：(2,0) （因为先被拍晕了，所以后两个右移指令无效） 预测输入：无 （所有预测输入都已变为权威输入） 预测状态：(2,0) 此时，之前的预测状态 (4,0) 与最新的预测状态 (2,0) 发生了冲突，客户端当然是以最新状态为主，所以你的位置被拉回了 (2,0) 并表现为晕眩。这就是网络延迟的代价 —— 冲突概率。\n插值 插值指在表现层更新 “其它人” 的状态变化时使用插值动画去平滑过渡。\n到目前为止，我们已经获得了自己在本地无延迟的丝滑体验。但在其它玩家的眼中，我们依旧是卡顿的。这是由于同步帧率和显示帧率不一致导致的，所以我们在更新其它人的状态时，并非一步到位的更新，而是通过插值动画来平滑过渡。\n预测+和解是解决 自己 的问题，发生在 逻辑层；插值是解决 其它人 的问题，发生在 表现层 。\n例如上面的例子，显示帧率是 30fps，服务端的同步帧率是 3 fps。收到服务端同步的其它玩家的状态后，不是立即设置 node.position，而是通过 Tween 使其在一个短暂的时间内从当前位置平滑移动到新位置。如此，在其它玩家眼中，我们看起来也是平滑的了：\n解决快节奏有冲突的同步，就是 预测、和解、插值 这 3 个核心思想，掌握了它们你应该就能举一反三，轻松应对各种场景。\n延迟不影响操作 从上面的几个例子中，我们可以得出几个重要的结论：\n在无冲突时，网络延迟并 不会 影响操作延迟，预测+和解能实现本地 零延迟 的操作体验 发生冲突时，本地状态立即重设到最新状态，画面跳变，只有此时玩家能明显感受到 “卡了” 网络延迟影响的是冲突概率：网络延迟越大，发生冲突的可能性越大 当使用了预测 + 和解之后，我们之前认为的 “网络延迟越大操作延迟越大”，就变成了一个 误解 。\n即便是一个 MOBA 游戏，你在打野，另外一名玩家在刷兵线 —— 你们之间不存在 “冲突” 的可能性。此时即便网络有很大延迟，你们各自的游戏体验也应该都是单机游戏般 零延迟 的！只有当你们在打团战时，才可能出现因为网络延迟导致技能判定等冲突；也只有当冲突出现时，你们才能直观感受到延迟的存在。\n延迟越小越好吗 服务端可以在收到客户端输入后立即广播出去，也可以通过 LockStep 的方式固定同步频率。除了网络之外，同步频率也会影响延迟。比如服务端逻辑帧率每秒同步 10 次，那么意味着即便局域网内也可能出现 100ms 的延迟。\n但网络延迟真的越低越好吗？其实，延迟小也有一个副作用：插值不平滑。\n假设你用 1 秒时间从 A 点匀速移动到 B 点，如果同步频率恰好是每秒 1 次，那么通过插值，其它玩家看到的应该是一个完全匀速的移动过程。但如果同步频率是每秒 60 次呢？理论上每 16ms 你就会收到一个新状态，然后每 16ms 就要更新一次插值动画。但就跟延迟一样，网络抖动也是客观存在的 。你大概率不是均匀的每 16ms 收到一次消息，而是很可能时而 200ms 才收到一条消息，时而 20ms 内就收到 N 条消息。如此，其它玩家看到的移动过程将是忽快忽慢的，这种不平滑的动画会带来直观的卡顿感。\n所以，延迟并非越小越好，这也是一个权衡利弊的过程：\n延迟大 ：插值更平滑，冲突概率更大 延迟小 ：插值不平滑，冲突概率更小 延迟和同步频率在多少是最好的呢？这个没有标准答案，应该根据实际玩法需要权衡利弊后决定。\n有延迟下的判定 在有延迟的情况下，技能命中的判定，该听谁的呢？来看一个简单的例子。\n场景举例\n在一片空地上，你拿起狙击枪瞄准一个正在移动的敌人头部。点下鼠标，一发弹道闪过 —— 你很确定，命中了！然而，由于网络延迟的存在，你看到的敌人，实际上是 200ms 以前的位置。在服务端的视角看来，你开枪的时刻敌人已经走远 —— 你打空了。那么此时，应当如何判定呢？我们分别来看看。\n假设我们选择以 服务端 的判定为准，那么你会很不爽。因为在你看来，明明打中了，敌人却没掉血，那对面肯定是开挂了。理论上，对面会很爽，因为服务端保护了他免于受伤。但事实上他没什么可开心的，因为他完全不知道服务端为他做了什么，他只会觉得 “对面真菜” 。\n那如果我们选择以 客户端 的判定为准呢？当然你会很爽，因为判定结果和你的预期一致，你觉得这个游戏丝滑流畅没延迟，爽爆了。理论上对面会不爽，因为从服务端视角来看，其实你没打中他。但事实上他并不知道实际上发生了什么，他只会觉得是你枪法不错，打中了他。虽然被打中了，但对于他而言，游戏体验是流畅和符合预期的，没什么不爽。\n所以看起来听客户端的大家都开心，那么是不是这样就万无一失了呢？也存在例外。\n假如对面不是在空地上跑，而是躲进了一堵墙后面。此时他认为自己是安全的，但由于网络延迟，你这边依旧判定打中了他。此时在墙后的他仍然受到了伤害，他肯定很不爽，要么是网卡了要么是你开了穿墙挂。所以并没有 100% 完美的解决方案，权衡利弊后，如果你觉得出现这种情况的概率比较小可以接受，那么可以选择以客户端判定为准从而带来更好的游戏体验。\n你也可以在客户端发送输入时带上游戏时间，由服务端根据实际延迟来决定由谁判定。比如延迟在 200ms 以内时由客户端判定，否则由服务端判定。\n断线重连 下面方法从低级到高级递增\n方法1:在玩家登录的时候把所有历史帧的数据发送给客户端，让客户去进行追帧\n方法2:客户端记录当前已经跑到了第几帧，把当前帧数据和状态值数据存入本地文档,并定时把文档数据MD5发送到服务器进行对比验证合法性,然后当断线重连的时候服务器把客户端的已经执行到的最新帧数发送到服务器进行请求,也就是只请求（客服端断线是最新帧,服务器现在跑到的帧数）发送给客户端进行追帧,极端情况下玩家在玩的途中，换新手机这个时候客户端已经没有本地存档了，那么我们就应该在服务器建立一个通过指令跑出断线客户端执行到了第几帧,如果能算出内存数据一下发给客户端最好,这也是方法3\n方法3: 服务器ECS进行数据分层,把客服端收集到的指令进行转换,存入C，当客户端断线重连的时候，可以把C里面的状态数据发给客户端,让客户端进行恢复,这样客户端也不需要在进行追帧操作，客户端也能很快的进入游戏，卡的关键点也只会是客户端的资源加载进度\n","permalink":"https://frog-game.github.io/posts/blog/zhentongbu/","summary":"为啥选择帧同步 和写单机游戏类似，客服端收集自己的指令操作发送到服务器，服务器进行收集广播给所有的玩家，客服端本地通过收到的包来推进游戏进度 服","title":"帧同步"},{"content":"前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑做不到，手机就更加不用说了 这类大地图，在客服端都是分区域进行加载，也就是会进行切割，比如像绝地求生这样的游戏，大概80公里左右大的地图，会被切割成100 *100 个格子，大概每个格子800米左右，每个格子会打上索引标记，当客服端在进行移动的时候就会根据视野，一般都是九宫格区域，然后根据视野新旧对地图块进行预加载和删除。 在绝地求生跳伞阶段，其实是整张地图进行加载的，但是这个时候不是加载的高精度地图块，而是一个经过简化的地图，而且这种地图块不会只有一份，一般会有多份，这种也叫多层LOD，也就是随着你跳伞以后，距离地面越来越近，程序会给你切换不同的地图块，这也就是为什么有时候你在跳伞的过程中有时候会看到闪烁情况，其实这个时候是程序在给你切换不同的地图块 构建大世界地图 利用bspTree原理对地图进行动态切割 分裂条件：\n人数达到上线 区域大小必须超过多大，比如必须达到50 *50 大小才能分裂 1.场景管理服务器启动以后会创建一个全局的space，假设大小是100 * 100，同时也创建一个同样大小的cell1\n假如按宽10进行分割，会形成 10 * 100,90 * 100 两个长方形\n假如按长90来对剩下的3进行分割\n一直往下切割的话，左边会越来越多，右儿子会越来越少，从而达到负载均衡的效果但是也有分割也有条件\n兄弟两都为叶子节点 左二子被分割后的大小不应该大于右儿子 利用bspTree原理对地图进行动态合并 合并条件:\nCell区域小于100(可配) 人数小于指定人数(可配) 待合并的2个结点必须是叶子结点 删除待合并的两个儿子结点，修改父亲结点的场景区域 合并前\n合并后\n当不管是分割还是合并发现他的实体已经不再当前cell了那么实体应该迁移到他合适的地方去\n边缝处理 假设我们现在有3个cellServer进程管理着各自的ABC3个cell块\n当上面的a角色到达边界的时候，我们这个时候就需要进行real和ghost的数据同步，开始在重叠区域进行转换，进行转换的区域一般要比自己的视野范围要大，比如现在的重叠转换区域就是那个红色圈，大于自己的视野黑色圈\n在entity aoi范围内，又不在同一cell的，在这个cell上创建同坐标的一个ghost 镜像，也就是上面的暗红色和绿色星星就是BC cell上面的ghost镜像 ghost 只能是只读的，每次去修改只能先修改real实体然后在去同步ghost属性 新的边缝处理方法 比如现在有A B两个cell 这个时候黄色的角色从A走向了B 现在过了边界，但是我们现在不用创建镜像和实体的方法来实现无缝地图，而是用传送的方式，传送触发的实际就是那根绿色线和边界的距离，比如5米，当玩家走到了这个触发范围我们就开始直接把人传送到B，这样也不用处理ghost和real之间定时同步，还有异步技能带来的各种异常情况，bug查找\n技能处理 攻击方一定要是real实体，被攻击方可以是real实体，也可以是ghost实体\n下方的数据同步可以写到核心框架，也就是定时同步real实体的信息到ghost实体上\n寻路 因为世界地图很大，所以我们可以用**路点+ 小段距离A星或者jps算法**来实现寻路\n先求路点，比如如下的地铁图，我们可以根据权重值或者时间的组合，通过**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法求出最短路径，这些路径可以离线先求出来，等使用的时候直接使用 还是以上面这图为例子现在你在红色小人那个位置也就是关庄下面小人的位置，这个时候如果障碍物多，你可以骑单车过来也就是用**A星算法寻路到惠新西街南口，如果障碍物少，那么你可以打车，或者坐大巴也就是jps算法到彗新西街南口，到了起始点之后，你就可以坐地铁也就是前面用Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算出的离线路径直接到达下面的地跌目的地南锣鼓巷\n到了南锣鼓巷以后，同样你也可以按2步骤，选择是**a星还是jps算法**到达公司\n如果地图超大，其实在用**Dijkstra(迪杰斯特拉)和floyd(弗洛伊德)**算法算地铁图的时候我们可以分几块区域算出各自地铁路线图，然后连接起来，举个栗子，比如可以划分，彗星西街南口到北土城是一个区域，北土城到鼓楼大街是个区域，鼓楼大街到南锣鼓巷是个区域，这3个区域各自算好，各自存储好，到时拼接起来就是惠新西街南口到南锣鼓巷的整条离线路线，如下图红，黑，黄三个框，代表3个区域\n","permalink":"https://frog-game.github.io/posts/blog/wufengdashijie/","summary":"前言 无缝大地图只是外在表现，其实都是有缝隙的，现在的电脑性能还不足以加载一张非常大的地图，比如80公里，甚至几百，几千公里这么大的地图，电脑","title":"无缝大世界"},{"content":"网络层 通过多reactor +多线程 + 协程池方式，实现win,linux,mac 3方跨平台的底层通讯,能轻松万级别QPS起步，应对高并发请求量大，IO密集型和CPU密集型业务都能处理\n进程 win\nlinux\nmac\nlua调试 插件能对微服务lua代码进行调试\n视频效果展示 多虚拟机测试 linux测试 真机测试 日志监控 利用Ubuntu20.04+mysql8.0+zabbix6.0+elk+filebeat+logstash+grafan 搭建的游戏日志监控系统 能快速的收集 查询 追踪 定位 报警问题\ngit hook 利用git_pre_commit git_pre_reveive 对提交的消息进行代码规范化检查,commit msg提交检查,lua语法检查,Excel检查\n自动化check,格式化,编译,部署,通知 利用gitlab cicd 能对上传以后的代码进行 check,格式化,编译,部署,通知\n自动化 check,格式化,编译,部署\n群通知\n个人通知\n在线exel协同开发 属性自动更新 lua的工程化强化 Teal Teal 和 Lua 的关系就类似 TypeScript 和 JavaScript 的关系，支持给已有的库进行类型标记，最终是翻译为 Lua 去实际使用的。\n类型标记可以写在 xx.d.tl 文件中，比如\nlocal record os exit: function(number) end return os 在 Teal 中主要新增了 record、array 和 map 类型，更多的语言特性可以见文档 https://github.com/teal-language/tl/blob/master/docs/tutorial.md\n代码样例\n-- record 类似其他语言中的结构体 local record arg_t github地址在下边\nteal-language/tl: The compiler for Teal, a typed dialect of Lua (github.com)\n叫青语言，\n安装颇费了一番功夫,主要是我对环境不熟悉\n需要luarocks，\n需要mingw（安装gcc），注意是mingw不是mingw-w64,这tm是完全不同的两个项目\n然后有什么用呢\n来看一段正常的lua代码\n//正常lua代码 local function add(a, b) return a + b end local s = add(1, 2) print(s) 这代码执行肯定返回3\n//bug lua代码 local function add(a, b) return a + b end local s = add(\u0026#34;ni\u0026#34;, 2) print(s) 然后来一段bug代码，这个bug代码 你用luac 肯定是没问题，等到执行期才会出问题，因为lua设计为一门动态语言，而且这从vm层次就决定了，这个情况有点像js，因为动态化，错误检查时机被拖到了运行时，不运行，无法发现问题（人眼除外）\n软件工程的实践中，代码静态检查能发现太多的问题（静态类型编程语言），js因为微软的typescript得到了极大的工程化加强。\n青语言就是对lua的类型化加强，和ts之于js是一样的概念。\n//青语言bug代码 local function add(a: number, b: number): number return a + b end local s = add(\u0026#34;a1\u0026#34;,2) print(s) 然后使用青语言，加上类型标注，标注的形式也像极了typescript\n然后就可以 tl check来检查这个青语言代码的问题了\n不用执行就可以提前知道第五行有个bug，这就是静态类型的功能所在。\n通过tl gen 指令 可以将青语言代码编译为lua，这个思路也是和ts=\u0026gt;js一致的。\n他的工程化优势参考ts带来的js革命性生态进化就可以想象一二。\n热更新 在代码复用和组织数据方面，面向对象可能是大家第一反应。面向对象三大特性继承，封装，多态，在一定程度上能解决不少代码复用，数据复用的问题。不过面向对象不是万能的，它也有极大的缺陷：\n数据结构耦合性极强 一旦父类中增加或删除某个字段，可能要影响到所有子类，影响到所有子类相关的逻辑。这显得非常不灵活，在一套复杂的继承体系中，往父类中改变字段会变得越来越麻烦，比方说ABC是D的子类，某天发现需要增加一个AB都有的数据，但是C没有，那么这个数据肯定不好放到父类中，只能将AB抽象出来一个父类E，E继承于D，AB共有的字段加到E中，一旦继承结构发生了变化，可能接口也要改变，比方说之前有个接口传入参数类型是E，当AB不再需要共用的那个字段，那么需要调整继承关系，让AB重新继承D，那么这个接口的传入参数类型需要改成D，其中的逻辑代码很可能也要发生调整。更可怕的是游戏逻辑变化非常复杂，非常频繁，可能今天加了个字段，明天又删掉了，假如每次都要去调整继承结构，这简直就是噩梦。继承结构面对频繁的数据结构调整感觉很无力\n难以热插拔 继承结构无法运行时增加删除字段，比如玩家Player平常是走路，使用坐骑后就骑马。问题是坐骑的相关信息就需要一直挂在Player对象上面。这就显得很不灵活，我不骑马的时候内存中为啥要有马的数据？接口也有同样的问题，一个类实现了一个接口，那么这个接口就永远粘在了这个类身上，你想甩掉她都不行，还是以骑马为例，玩家Player可以进行骑行，那么可能继承一个骑行的接口，问题是，当我这个Player从坐骑上下来时，玩家Player身上还是有骑行的接口，根本没法动态删掉这个接口！可能例子举得不是很对，但是道理表述的应该很清楚了\n使用面向对象可能导致灾难性后果，游戏开发中有新人有老人，有技术好的，有技术差的。人都是喜欢偷懒的，当你发现调整继承关系麻烦的时候，有可能AB中增加一个字段为了省事直接就放到父类D中去了。导致C莫名奇妙的多了一个无用的字段。关键还没法发现，最后导致父类D越来越大，到最后有可能干脆就不用ABC了，直接让所有对象都变成D，方便嘛！是的，很多游戏就是这么干的，开发到最后根本就不管继承关系了，因为想管也管不了了。\n面向对象在面对复杂的游戏逻辑时很无力，所以很多游戏开发者又倒退了回去，使用面向过程进行开发游戏，面向过程，简单粗暴，不考虑复杂的继承，不考虑抽象，不考虑多态，是开发届的freestyle，挽起袖子就开撸，但同时，代码逻辑的复用性，数据的复用性也大大降低。面向过程也不是一种好的游戏开发模式。\n组件模式很好的解决了面向对象以及面向过程的种种缺陷，在游戏客户端中使用非常广泛，Unity3d，虚幻4，等等都使用了组件模式。组件模式的特点： 1.高度模块化，一个组件就是一份数据加一段逻辑 2.组件可热插拔，需要就加上，不需要就删除 3.类型之间依赖极少，任何类型增加或删除组件不会影响到其它类型。\n但是目前只有极少有服务端使用了组件的设计，守望先锋服务端应该是使用了组件的设计，守望先锋的开发人员称之为ECS架构，其实就是组件模式的一个变种，E就是Entity，C就是Component，S是System，其实就是将组件Component的逻辑与数据剥离，逻辑部分叫System\n","permalink":"https://frog-game.github.io/posts/tech/kuangjia-work/","summary":"网络层 通过多reactor +多线程 + 协程池方式，实现win,linux,mac 3方跨平台的底层通讯,能轻松万级别QPS起步，应对高并发请求量","title":"服务器简介"},{"content":"网络编程流程 堵塞IO 非堵塞IO 信号驱动IO 异步io模型 多路复用 单reactor 代表作：redis 内存数据库\n注意：redis 6.0 以后是多线程\n单reactor 多进程模型 代表：nginx\n单reactor模型 + 任务队列 + 线程池 代表作:skynet\n主从 reactor 代表作：netty\n多reactor + 多线程 代表作：memcache\n多reactor + 多线程 +协程池 ","permalink":"https://frog-game.github.io/posts/read/wangluo_io_zhongjie/","summary":"网络编程流程 堵塞IO 非堵塞IO 信号驱动IO 异步io模型 多路复用 单reactor 代表作：redis 内存数据库 注意：redis 6.0 以后是多线程 单r","title":"网络IO模型总结"},{"content":"tcp 握手挥手 序列号: 在建立连接的时候有计算机生成的随机数并作为初始值，通过syn包传给接收端主机，每发一次数据，就累加一次该数据字节数的大小，主要是用来解决网络包乱序问题\n确认应答号:指下一次期望收到的数据的序列号，发送端收到这个确认应答以后可以认为这个序号之前的数据都被正常接收了，主要用来解决不丢包的问题\n控制位:\nACK: 该位为1的时候，确认应答字段变得有效，该字段规定除了最初开始建立连接时候syn包之外，改为必须设置为1\nRST:该位为1的时候，标识TCP连接中出现异常必须强制断开连接\nSYN:该为位1时候，表示希望建立连接，并在序列号的字段进行序列号初始值的设定\nFIN:该位为1的时候，表示今后不会再有数据发送，希望断开连接，当通讯结束希望端口连接时,通讯双方的主机之间可以相互交互FIN 位为1的TCP段\n为什么需要tcp协议，tcp工作在那一层 IP层是不可靠的，他不保证网络包的交互，不保证网络报的按序交互，也不保证网络包中的数据的完整性，如果需要保证数据的完整性那么就需要TCP层来负责 TCP有哪些特性 面向连接的，可靠的，基于字节流的\n建立一个tcp连接需要达成哪些共识 socket：由ip地址和端口号组成\n序列号：主要用来解决乱序问题\n窗口大小：主要用来做流量控制\nTCP四元组 有一个ip的服务器监听了一个端口，他的TCP的最大连接数是多少 对于IP4来说，客服端ip最多为2的32次方(4 294 967 296) 客服端的端口最多为2的16次方(65536) 也就是服务器单机最大的TCP链接数，约为2的48次方 最大tcp链接数 = 客服端ip数 * 客服端的端口数\n如果服务器不能达到理想数，一般是因为什么原因 首先是文件描述符的限制，Socket都是文件，所以首先要通过 ulimit 配置文件描述符的数目\n另一个就是内存限制，每个tcp链接都要占用一定的内存，操作系统的内存是有限的\nudp和tcp的区别 目标和源端口号：主要是告诉udp协议应该吧报文发给那个进程\n包长度：保存了UDP首部的长度跟数据的长度之和\n校验和：主要是位了提供可靠的udp首部和数据而设计的\n区别\n连接\nTCP是面向连接的传输层,传输数据前先要建立链接\nUDP是不需要连接的，即可传输数据\n服务对象\nTCP是一对一的两点服务器，即一条连接只有两个端点\nUDP是支持一对一，一对多，多对多的交互通信\n可靠性\nTCP是可交互数据的，可以无差错，不丢失，不重复，按需到达\nUDP是尽自己最大的努力交互，不保证可靠交互数据\n拥塞控制，流量控制\nTCP有拥塞控制和流量控制机制，保证数据传输的安全性\nUDP则没有，即使网络非常堵塞，也不会影响UDP的发送速率\n首部开销\nTCP首部长度较长，会有一定的开销，首部在没有使用选项的时候都能达到20字节，如果使用了选项则会变长 UDP首部只有8个字节，并且是固定不变的，开销较小\n传输方式\nTCP是流失传输，没有边界，但是保证顺序和可靠\nUDP是一个包一个包发送，是有边界的，但是可能会丢包和乱序\n分片不同\nMSS就是TCP报文段所允许传送的最大数据部分的长度，主机一般默认MSS为536字节(576IP最大字节数-20字节TCP协议头-20字节IP协议头=536字节)\nMTU 最大传输单元,一般1500\nTCP数据大小如果大于MSS大小，则会在传输层进行分片，目标主机收到后，也同样在传输层组装TCP数据包，如果中途丢失了一个分片，只需传输丢失的这个分片\nUDP的数据大小如果大于MTU大小，则会在IP层进行分片，目标主机在收到后，在IP进行组装数据，接着在传给传输层，但是如果中途丢了一个分片，在实现可靠传输的UDP时则需要重传所有的数据包，这样传输效率非常差，所以通常UDP的报文，应该小于MTU\n为什么UDP头部没有首部字段，而TCP头部有\n原因TCP有可变长的选项字段，而UDP头部长度则不会变化，无需多一个字节去记录UDP的首部长度\n为什么UDP头部有包长度，而tcp没有\nTCP数据的长度 = IP总长度 - IP首部长度 - TCP首部长度\n其中 IP 总⻓度 和 IP ⾸部⻓度，在 IP ⾸部格式是已知的。TCP ⾸部⻓度，则是在 TCP ⾸部格式已知的，所以就 可以求得 TCP 数据的⻓度。 ⼤家这时就奇怪了问：“ UDP 也是基于 IP 层的呀，那 UDP 的数据⻓度也可以通过这个公式计算呀？ 为何还要有 「包⻓度」呢？” 这么⼀问，确实感觉 UDP 「包⻓度」是冗余的。 因为为了⽹络设备硬件设计和处理⽅便，⾸部⻓度需要是 44 字节的整数倍。 如果去掉 UDP 「包⻓度」字段，那 UDP ⾸部⻓度就不是 4 字节的整数倍了，所以觉得这可能是为了补全 UDP ⾸部⻓度是 4 字节的整数倍，才补充了「包⻓度」字段\n为什么MTU是1500\n其实一个标准的以太网数据帧大小是：1518，头信息有14字节，尾部校验和FCS占了4字节，所以真正留给上层协议传输数据的大小就是：1518 - 14 - 4 = 1500，那么，1518这个值又是从哪里来的呢？\n最根本原因\n问题就出在路由器拨号，如果是PC拨号，那么PC会进行PPPoE的封装，会按照MTU:1492来进行以太网帧的封装，即使通过路由器，路由器这时候也只是转发而已，不会进行拆包。\n而当用路由器拨号时，PC并不知道路由器的通信方式，会以网卡的设置，默认1500的MTU来进行以太网帧的封装，到达路由器时，由于路由器需要进行PPPoE协议的封装，加上8字节的头信息，这样一来，就必须进行拆包，路由器把这一帧的内容拆成两帧发送，一帧是1492，一帧是8，然后分别加上PPPoE的头进行发送。\n平时玩游戏不卡，是因为数据量路由器还处理得过来，而当进行群怪AOE的时候，由于短时间数据量过大，路由器处理不过来，就会发生丢包卡顿的情况，也就掉线了。\n帖子里面提到的1480，猜测可能是尽量设小一点，避免二次拨号带来的又一次PPPoE的封装，因为时间久远，没办法回到当时的场景再去抓包了。\nTCP 连接建立(3次握手) 一开始客户端和服务器都处于close状态\n服务开始监听端口，这个时候服务器处于listen状态\n客户端会随机初始化序列号 client_isn，然后把这个初始值付给tcp首部的序列号字段，并把标识位syn设置成1，代表这是一个syn包，此包不包含应用层数据，发送出去以后，客服端处于sys_sent状态\n三次握手第一个报文 SYN 报文\n服务器收到客户端报文，首先服务器会随机初始化自己的server_isn ,将server _isn号存入序列号中，并把客服端的client_isn +1 存入确认应答号中，同时吧SYN和ACK标志位置为1，此包不会包含应用层数据，发送出去以后服务器进入syc_rcvd状态\n三次握手第二个报文 SYN + ACK报文\n客服端收到服务器发送的syn + ack 报文以后，最后还会向服务器发送一个ACK确认报文，并把server_isn 序列号 + 1 存入确认应答号，然后把ACK标志位设置成1，此包这个时候可以带应用层数据发过去，这个时候客户端进入进入established状态，服务器收到ACK确认应答包以后也进入established状态\n从这一步可以看出前两步是不带数据的，第三步可以带数据发送\n为什么握手是3次，不是2次,4次 主要是3个方面\n可以防止重复历史链接数\n同步双方初始序列号 四次握手其实也能够可靠的同步双方的初始化序号，但是由于第二步和第一步可以优化成一步，所以就成了3次握手，\n而两次握手只保证了一方的初始序列号能被对方成功接收，没办法保证双方序列号都能被确认接收\n避免资源浪费\n如果只有两次握手，当客服端的syn请求连接在网络中堵塞，客服端没有接收到ACK报文，就会重新发送syn，由于没有第三次握手，服务器不清楚客户端是否收到了自己发送链接的ack确认信号，所以只能自己创建链接，\n如果多次堵塞，多次发送syn，那么服务器就会多次创建，造成冗余的链接。\n总结：为什么不使用两次握手或者四次握手\n两次握手：无法防止历史链接的建立，会造成双方资源的浪费，也无法可靠的同步双方序列号\n四次握手：三次握手就已经理论上最少可靠链接建立，所以不需要使用更多的通信次数\n为什么客服端和服务器的isn号不相同 如果一个已经失效的历史报文残留在网络中，那么如果isn号码相同那么无法分辨到底是不是历史报文，如果历史报文被接受了那么就有可能产生数据错乱，所以每次建立连接前都会初始化一个序列号，好让分辨出来是不是历史报文，好丢弃掉 还有一个方面是为了安全，防止黑客伪造相同的tcp报文被对方接收 syn攻击 我们知道tcp链接需要3次握手，假设攻击者短时间内，伪造不同的ip地址syn报文，服务器每接收一个就进入syn_rcvd 状态，但服务器发送出去的ack + syn报文，无法得知位置ip主机的ack应答，久而久之就会占满服务器syn接收队列（未连接队列）使得服务器不能为正常用户服务\n解决办法一\n控制接收队列大小\nnet.core.netdev_max_backlog SYN_RCVD 状态连接的最大个数\nnet.ipv4.tcp_max_syn_backlog 超出处理能力时候对于新的syn 直接发送RST 丢弃链接\nnet.ipv4.tcp_max_syn_backlog 解决方法二\n首先是正常的3次握手流程\nTCP 连接断开 客服端，打算关闭连接，此时会发送一个tcp首部FIN标志为1的报文，之后客户端进入fin_wait1状态 服务器收到fin报文之后然后发送ack确认码给客服端，开始进入close_wait状态， 客服端收到ack确认码以后进入fin_wait2状态 服务器处理完数据发送fin报文给客服以后进入last_ack阶段 客服端收到fin报文以后发送ack确认码给服务器开始进入time_wait状态 服务器接到ack应答报文开始进入close状态 客服端经过2msl时间自动进入close状态 你可以看到每个方向都有fin报文和ack应答码，所以简称四次挥手\n只有主动关闭的一方才会进入time_wait 状态\n为什么挥手需要四次 客服端发送fin链接的时候，仅仅表示客户端不在发送数据，但是还能接收数据\n服务器收到fin报文以后，先回一个ack码，而服务器还有数据需要处理和发送，等服务器不在发送数据\n的时候才发送fin报文给客服端\n从上可知，因为要等待服务器处理完数据，所以服务器的ack和fin码会分开发\n为什么time_wait是2ML MSL是报文生存最大时间，他在任何报文在网络中存在的最大时间，超过这个时间，报文会被丢弃，因为tcp是基于\nIP协议的，在IP协议中有一个TTL字段，是IP层经过的最大路由器数，每经过一个处理，就会减1，一直到0，就把这\n个数据包进行丢弃，同时发送icmp报文通知主机\nMSL和TTL区别\nMSL单位是时间 TTL是路由跳数，所以MSL应该大于TTL消耗为0的时间，以保证报文是自然消亡\nTIME_WAIT等于2倍，是因为网络中可能存在发送方发过来的数据包，当这些发送方的数据包被接收方处理后，又会向对方发送响应，所以一来一回需要等待2倍的时间\n比如被动关闭方没有收到断开连接的最后的ACK报文，就会触发重发fin报文，另一方收到fin报文后，会重发ack应答码\n一来一回正好2ML\n2ML是客服端接受到FIN包以后发送ACK码开始计时的，如果在2ML时间内，服务器没有收到ACK确认码，重发了fin报文，那么这个时候客服端会重发ACK码并重新进入2ML计时\n2ML一般多长 linux 中一般设置为60s 也就是一个msl是30秒\n#define TCP_TIMEWAIT_LEN (60*HZ) /* how long to wait to destroy TIME-WAIT state, about 60 seconds */ time_wait 相关 time_wait 过多原因 大量高并发的短连接 程序错误，没有调用close关闭连接 ack码丢失，导致服务器重新发送fin报文，让time_wait重新进入计时，不会进入close 为什么需要time_wait状态 防止旧链接的数据包\n如上图的sql =301的包被网络延迟了，这个时候time_wait设置的时间很短，或者没有，上次的链接的被关闭\n这个时候如果重新建立相同端口号的连接被重用，而网络中还有seq =301的消息包这个时候抵达，那么这个\n时候客服端收到了旧的数据包，这个时候数据就会错乱，造成问题\n如果这个时候有2ML的time_wait时间，那么足够保证在建立新的相同端口连接时候，网络中旧的数据包消亡\n保证连接正确关闭\n如果最后的ack丢失了，服务器就会一直处于last_ack状态，如果这个时候客服端发起新的连接，那么这个时候服务器因为处于last_ack状态，所以会发送rst报文给客服端，让客服端直接终止链接\ntime_wait过多会怎么样 如果服务器有处于time_wait状态的tcp 那么说明是服务器主动发起的端开请求\n内存资源的占用 端口资源的占用，端口资源也是有限的 所以如果发起连接的一方time_wait状态过多，占满了所有资源端口，则会导致无法创建新的连接\n客户端 time_wait多的话，因为端口资源的限制，就会导致端口资源被占用，被占满就会导致无法创建新的链接\n服务器time_wait过多的话，因为系统资源的限制，由于一个四元组表示一个tcp连接，理论上服务器可以创建很多连接，服务器确实也可以监听一个端口，但是这些连接会扔给处理线程，理论上监听的端口可以被继续监听，但是线程池处理不了那么多的一直不断的连接，所以当出现大量time_wait的时候，系统资源就会被占满，导致处理不了新的连接\n怎么优化time_wait 打开 net.ipv4.tcp_tw_reuse 和 net.ipv4.tcp_timestamps 选项\ntcp_tw_reuse 功能只能⽤客户端（连接发起⽅），因为开启了该功能，在调⽤ connect() 函数时，内核会随机找⼀个 time_wait 状态超过 1 秒的连接给新的连接复⽤\nnet.ipv4.tcp_max_tw_buckets\n这个值默认为 18000，当系统中处于 TIME_WAIT 的连接⼀旦超过这个值时，系统就会将后⾯的 TIME_WAIT 连接 状态重置\n程序中使⽤ SO_LINGER ，应⽤强制使⽤ RST 关闭。\nclose_wait 相关 close_wait 多的原因 一般都是程序逻辑造成，在client发送fin过来的时候，这边进入了close_wait状态，但是因为程序逻辑问题，迟迟没有调用close()，或者shutdown函数进行关闭，导致close_wait超多\n如果已经建⽴了连接，但是客户端突然出现故障了怎么办 net.ipv4.tcp_keepalive_time=7200 #表示保活时间是 7200 秒（2⼩时），也就 2 ⼩时内如果没有任何连接相关的活 动，则会启动保活机制 net.ipv4.tcp_keepalive_intvl=75 #表示每次检测间隔 75 秒 net.ipv4.tcp_keepalive_probes=9 #表示检测 9 次⽆响应，认为对⽅是不可达的，从⽽中断本次的连接 主要是tcp的保活机制，如果在一段时间内，没有任何的连接相关的活动，tcp就会启动保活机制，每隔一段时间发送一个探测包，这个探测包数据量很小，如果连续几个探测包发过去都没有反应，那么就可以认为tcp连接已经死亡了\n开启了tcp保活机制以后，需要考虑一下几种情况\n对端程序正常工作，当tcp保活的探测包到达对方以后，对方正常响应，这个时候保活机制就会被重置 对端程序奔溃并重启，当tcp保活的探测包到达以后，由于对方没有相关的tcp连接信息，这个时候会发送rst报文给对方，这样很快就可以发现tcp连接已经重置了 如果对方一直奔溃，当tcp报文一直发送，发送几次后没有反馈，那么这个时候就可以认为tcp连接已经死亡 服务器主动关闭 服务器调用close(),不管什么数据一缕发送rst报文进行强制关闭 服务器调用shutdown() ，如果是正常数据还是走正常数据接收流程，一直到数据发送完毕，然后发送fin报文正常关闭\ntcp重传 超时重传 指的是我们在发送数据的时候，会设定一个定时器，当超过定时器设定的时间，我们在没有收到对方的ack确认码之后就会触发重传机制\n触发超时重传条件 数据包丢失，因为数据包丢失，所以B无法发送ack确认码下去，A无法收到ACK确认码，无法知道服务器是否收到数据就会在特定时间间隔内，触发重传\n确认应答丢失\n超时重传时间设置多少最好 RTT 包的往返时间\n时间设置的过长过短发生的情况\n当RTO较大时候，重发就满，丢了老半天才重发，没有效率，性能差\n当RTO较小时候，可能是因为波动大，然后设置RTO又短，这个时候触发了重传，但是旧包却很快恢复了传输\n所有综合上述，所以我们应该 RTO应该略大于RTT\n快速重传 这个不是以时间为驱动，而是以数据为驱动\n如上发了1，2，3，4，5 共5份数据\n1号数据发过去了，这个时候ACK变成了2\n2号数据这个时候丢失了，\n3号数据这个时候进行了发送，但是接收端回复ACK的时候不会是3而会还是原来丢包的那个ACK2\n4号数据这个时候进行了发送，还是发送ACK2\n5号数据这个时候进行了发送，还是发送ACK2\n这个时候发送端发现有3次相同的ack码就会触发重传，这个是seq2会在定时器过期之前重传过去了，这个时候接收端\n发现了seq2，3，4，5都收到了，那么就会把ACK设置成6\nSACK 解决快速重传应该重传所有还是重传丢失者问题\nSACK方法[如果能支持SACK，那么必须双方都打开]\nLeft Edge:代表已收到的第一个不连续的第一个序号\nRight Edge:表示已收到的不连续块的最后一个序号+1 即左闭右开区间，通过ACK和sack发送方就能很快的确定接收方有哪些数据没有被收到 如果上面触发了重传会这样处理\n直接重传300 -499丢失的块，然后把ack变成700再次触发快速重传把700 -899补上\nDACK 主要是告诉发送方，主要通过SACK告诉发送方有哪些数据被重复接受了\nACK 丢包\n接收方发送给发送方的2个ack都丢失了，所以发送方超时后，重传了第一个数据包3000 - 3499\n接收方发现数据是收到的是重复数据，于是回了一个sack= 3000 - 3500 告诉发送方3000 - 3500的\n数据早就被接受了，因为现在ack已经到了4000 所以意味着这个sack代表的是dack\n这样发送方就知道了数据其实没有丢，只是接收方的ack确认报文丢失了\n网络延迟\n数据包 1000- 1499 被网络延迟了，导致发送方没有收到ack1500的确认报文\n而后面收到了3个相同的ack报文，触发了快速重传，但是在重传以后，网络延迟的1000 -1499也抵达了接收方\n所以接收方回了一个ack3000 和sack 1000 -1500 所以这个时候sack代表的就是dack，代表这是一个重复的报文\n这样发送方就知道快速重传的原因不是发数据丢了，也不是ack丢了，只是网络延迟了\n可见dack有这么几个好处\n可以让发送方知道是包丢了 还是接收方的ack丢了 还是发送方的数据包被网络延迟了 可以知道网络中是不是把发送方的数据包给复制了 滑动窗口 我们知道TCP每发送一个数据，就会进行一次确认应答，当上一个数据包收到了应答，在发送下一个，这个模式有点像\n两个人聊天，你发一句，然后我给你个ack报文，我发一句，然后你给我一个ack报文，这样其实效率很低的。\n如果你说完一句话，我在处理别的事情，没有及时给你回复ack报文，那么你就只能干等着，一直等到我处理完事情，\t然后给你回复ack码，这样处理的话效率太低了，如果是这个逻辑，那么tcp协议也就不用在完了\n所以这样的传输方式很大的弊端：就是包的往返时间越长，网络的吞吐就越大\n为了解决这样的问题，TCP发明了一个牛逼的概念：****滑动窗口\n如果有了滑动窗口，那么就可以指定窗口的大小，窗口的大小无需等待对方的确认应答，就可以继续发送数据的最大值\n上面ack300 即使丢了，但是因为我们收到了ack400 那么我们就可以认为400之前的数据都收到了，这种方式我们称为累计确认\n窗口大小由哪一方决定 tcp头里面有个字段叫window 也就是窗口大小\n这个字段是接收方告诉发送方自己还有多少缓冲区可以接受数据，于是发送方就靠这个字段来知道接收方能接收多少数据，而不会导致接收方接收不过来\n所以窗口的大小，一般由接收方窗口的大小来决定\n发送方，发送的数据不能超过接收方窗口的大小，否则接收方就无法接受数据\n发送窗口 SND.WND : 表示发送窗口的大小,由接收窗口控制\nSND.UNA : 表示已发送但未确认ack报文的空间的第一个字节位置\nSND.NET : 表示未发送但是还在接收窗口可处理空间的第一个字节位置\n可用窗口大小 = SND.WND - (SND.NXT - SND.UNA)\n发送端窗口大小怎么控制的 取决于接收端的大小[rwnd]和拥塞窗口[cwnd]的大小\n发送窗口 = min{rwnd,cwnd}\n接收窗口 RCV.NXT : 希望从发送方发过来的下一个字节数据的序列号\nRCV.WND : 接收窗口的大小，会通过tcp头部报文里面的window字段，通知发送窗口大小\n接收窗口大小怎么控制的 接收窗口的大小系统，网速，未处理数据的大小都有关系\n发送窗口大小和接收窗口大小一样吗 不完全相等，一般接收窗口略等于发送窗口\n流量控制 发送方不是无脑的一直发送数据给接收方的，也要考虑接收方的接收能力。\n如果一直无脑的发数据给对方，但对方处理不过来，就会触发重传机制，从而导致网络流量的无端浪费\n为了解决这个问题，引入了流量控制\n固定窗口大小场景 假设接收端和发送端窗口相同，都为200 假设两个设备在传输过程中都保证窗口大小不变，不收外界影响 动态变化窗口大小场景 当发送方变成窗口变成0的时候其实发送方还会定时的发送探测报文，以便知道接收方改变了窗口\n丢包情况 当服务端系统资源⾮常紧张的时候，操⼼系统可能会直接减少了接收缓冲区⼤⼩，这时应⽤程序⼜⽆法及时读取缓 存数据，那么这时候就有严᯿的事情发⽣了，会出现数据包丢失的现象。\n为了避免这种情况 TCP规定不允许系统收缩缓存的时候同时减少窗口大小，而是采用先收缩窗口，过段时间在减少缓存的办法\n窗口关闭死锁问题 如果解决这种死锁问题 为了解决这种死锁问题，TCP为每个连接设有与一个持续定时器如果定时器超时就会发送窗口探测报文\n如果接收窗⼝仍然为 0，那么收到这个报⽂的⼀⽅就会᯿新启动持续计时器； 如果接收窗⼝不是 0，那么死锁的局⾯就可以被打破了。 窗⼝探测的次数⼀般为 3 次，每次⼤约 30-60 秒（不同的实现可能会不⼀样）。如果 3 次过后接收窗⼝还是 0 的 话，有的 TCP 实现就会发 RST 报⽂来中断连接。\n糊涂窗口综合症 于是，要解决糊涂窗⼝综合症，就解决上⾯两个问题就可以了\n让接收⽅不通告⼩窗⼝给发送⽅ 让发送⽅避免发送⼩数据 怎么让接收⽅不通告⼩窗⼝呢？\n接收⽅通常的策略\n当「窗⼝⼤⼩」⼩于 min( MSS，缓存空间/2 ) ，也就是⼩于 MSS 与 1/2 缓存⼤⼩中的最⼩值时，就会向发送⽅通 告窗⼝为 0 ，也就阻⽌了发送⽅再发数据过来。 等到接收⽅处理了⼀些数据后，窗⼝⼤⼩ \u0026gt;= MSS，或者接收⽅缓存空间有⼀半可以使⽤，就可以把窗⼝打开让发 送⽅发送数据过来。\n怎么让发送⽅避免发送⼩数据呢？\n发送方策略\n使⽤ Nagle 算法，该算法的思路是延时处理，它满⾜以下两个条件中的⼀条才可以发送数据：\n要等到窗⼝⼤⼩ \u0026gt;= MSS 或是 数据⼤⼩ \u0026gt;= MSS 收到之前发送数据的 ack 回包 拥塞控制 前面的流量控制主要是为了解决发送方到接收方的缓存，但是不知道网络中发生了什么\n一般来说，计算机网络是个共享的环境，因此也有可能会因为其他主机之间的通信，而是网络堵塞\n如果在网络堵塞的时候继续发送大量的数据包，那么就可能导致数据包的时延，丢失等，这个时候tcp就会重传数据，但是一重传，就会导致网络的负担更重，于是就会导致更大的延迟和丢包，甚至进入恶性循环\n于是现在就有了拥塞控制手段，这个手段主要控制的是控制发送方数据充满网络\n为了让发送方控制发送数据的量，于是就有了拥塞窗口的概念\n拥塞窗口和发送窗口的关系 拥塞窗口cwnd是发送方维护的一个状态变量，他会根据网络动态变化\n前面我们提到的swnd和rwnd是约等于的关系，那么假如cwnd概念以后，此时发送窗口的值是\nswnd = min(cwnd,rwnd)\n拥塞窗口的变化规则 只要网络中没有堵塞，那么就加大cwnd的数值 如果网络中出现了拥塞，cwnd就减少 怎么知道当前网络出现了拥塞 只要发送方在没有规定的时间内接受到ack确认码，也就是发生了超时重传，就认为网络中出现了拥塞\n拥塞控制有哪些算法 慢启动 拥塞避免 拥塞发生 快速恢复 慢启动 慢启动的算法就是，当发送方每收到一个ack，拥塞窗口cwnd的大小就加1\n那么慢启动什么时候是个头呢，\n有一个叫慢启动的门限ssthresh\n当 cwnd \u0026lt; ssthresh 时使用慢启动\n当 cwnd \u0026gt;= sssthresh 时启动拥塞避免\n拥塞避免 它的规则是：每当收到⼀个 ACK 时，cwnd 增加 1/cwnd\n拥塞避免算法就是将原本慢启动算法的指数增⻓变成了线性增⻓，还是增⻓阶段，但是增⻓ 速度缓慢了⼀些。 就这么⼀直增⻓着后，⽹络就会慢慢进⼊了拥塞的状况了，于是就会出现丢包现象，这时就需要对丢失的数据包进 ⾏᯿传。 当触发了᯿传机制，也就进⼊了拥塞发⽣算法\n拥塞发生 其实这个时候就是写的tcp重传机制主要是两种\n超时重传\n因为想途中的cwnd从12突然变到了1，然后开始慢启动，可以看到此种方法很容易马上回到解放前，方法也很激进，容易造成网络卡顿，那么发生这种情况我们还有没有更好的办法呢，其实有的也就是前面写的快速重传\n在收到3次相同的ack码的时候我们可以在超时重传还没发生之前就重传数据过去，而不必等到超时重传\n这个时候tcp认为这中情况也不是很严重那么我们可以这样设置参数\ncwnd = cwnd/2 ，也就是设置为原来的⼀半 ssthresh = cwnd 进⼊快速恢复算法 快速恢复 由于进入快速恢复之前 cwnd和ssthresh已经进行了更新\ncwnd = cwnd/2 ，也就是设置为原来的⼀半\nssthresh = cwnd\n快速恢复算法如下\n拥塞窗口 cwnd = ssthresh + 3 3的意思代表确认有3个数据包已经收到了 重传丢失的数据包 如果在收到重复的数据包那么cwnd + 1 如果收到新数据的ack 那么吧cwnd 设置成第一个不的ssthresh的值，原因是该ack已经确认了新的数据，说明从dack时候的数据已经都收到了，该恢复过程已经结束，那么就可以恢复到之前的状态了，也就是可以再次进入拥塞避免状态 粘包 粘包的问题是不知道消息的边界在哪里，如果知道边界在哪里就好办了。所以有如下3种方法解决\n固定长度 就是规定每一个包固定的长度，比如20KB，当收到了20KB的数据满了之后，就认为是一个包,但是这种方法灵活性不高，用的很少\n特殊字符做边界 比如像HTTP这种直接在尾部加回车，换行来作为数据的边界，但是这种方法有个问题，就是如果特殊字符是内容，那么就需要对这个数据做特殊处理\n自定义消息结构 我们可以自己定义消息结构，由包头 + 数据组成 在包头里面有一个字段是用来表示数据包的大小的，如下:\nstruct { int32 message_length; char message_data[]; } message; 这样当客服端可以先解析包头里面消息的长度，然后在读满这个长度大小的数据，就可以认为收到了一个完整的包\nRST 标识 收到RST应用层处理情况 如果应用层尝试去读，比如 recv 应用层就会收到 Connection reset by peer 意思是连接被重置 如果应用层尝试去写，比如 send 应用层就会收到 Broken pipe 意思是这个通道已经坏了 RST出现的场景 RST 一般出现在异常情况，一般为 对端的端口不可用和 socket 提前关闭\n端口不可用 端口未监听\n服务器 Listen方法会创建一个 sock放入全局的 哈希表中，当客服端来连接的时候，会根据 ip和 端口从这个 hash表中去获取 sock\n端口未监听一定会发送 RST吗 不一定因为在知道服务器没有 listen过，不会立马发送 RST报文，而是会进行 校验和检查,只有在校验和没有问题的时候才会发 RST给对端\n校验和可以验证数据从端到端是否出现了异常，由发送端计算，然后接收端效验，计算范围覆盖数据包的 tcp首部和 tcp数据\n为什么一定要先进行效验和，通过以后才发送RST 一般校验和出现了问题这个时候一般都是包被篡改了，或者是一个数据紊乱伪造的包\n在网络的5层协议中，如果出现这中问题，一般的做法都是丢弃，而不是傻乎乎的恢复一个包给对方\n如果是 TCP协议，因为是可靠的，所以丢了也没有事情，当没有接到对端的 ACK的时候，会重传\n如果是 UDP协议，因为是不可靠传输的，接收端已经接收了不可靠的这中情况，那么丢了就丢了\n程序启动了但是崩了 这个和端口未监听差不多，因为程序崩了，资源就会释放，那么就会进入 Close状态，重启了以后，客服端新的连接进来的时候去全局的 hash表根据 IP地址和 端口查找，却找不到 Sock这个时候如果校验和通过了，那么也会发送 RST报文过去\nsocket提前关闭 本端提前关闭 如果本端 socket接收缓冲区还有数据，此时提前 close() socket 那么本端会先把接 收缓冲区的数据清空，然后给远端一个 RST\n远端提前关闭 远端已经 close()这个时候本地还尝试给远端发送数据，这个时候远端会给本端回一个 RST\n大家知道，TCP是全双工通信，意思是发送数据的同时，还可以接收数据。\nClose()的含义是，此时要同时关闭发送和接收消息的功能。\n客户端执行 close()， 正常情况下，会发出第一次挥手FIN，然后服务端回第二次挥手 ACK。如果在第二次和第三次挥手之间，如果服务方还尝试传数据给客户端，那么客户端不仅不收这个消息，还会发一个 RST消息到服务端。直接结束掉这次连接。\nRST包丢了怎么办 RST丢了，问题不大，比如说上方的图，服务器发了 RST之后，就认为服务器连接不可用了\n如果发送 RST之前，客服端发送了数据，客服端没有等到 ACK确认码，这个时候就会重发，重发的时候，服务器也会返回 RST包\n如果在发送 RST之前，客服端没有发送数据，那么因为有 keepalive 机制，会定期发送探活包，这种数据到了服务器，可以触发一个 RST包\n收到RST一定会端开吗 不一定会端开，因为在收到 RST之后，会进行检查 seq是否合法，其实也是看这个 seq是不是在合法的接收范围内，如果不在就丢弃这个 RST包\n至于这个接收窗口是啥，如下图\n为什么一定要校验在范围内 因为如果不校验的话，不怀好意的第三方伪造了 seq的包，这个时候就会让客服端或者服务断开连接，如果效验的话毕竟因为窗口是在不断变化的，seq也在不断的变化，所以在范围内的 seq很难被伪造出来\nsocket recv和send 情况 如果接收缓冲区有数据，这个时候close 如果接收缓冲区还有数据未读，会先把接收缓冲区的数据清空，然后给对端发送一个 RST\n如果接收缓存区是空的，那么就会发送 FIN，开始正常的四次挥手过程\n如果发送缓冲区有数据，这个时候close socket 是个先进先出的队列，这个时候内核会把最后一块数据的标识置位 FIN，然后安静的等待内核把数据都发出去\nUDP udp有发送缓冲区吗 udp也是socket， 只要是socket就会有发和收两个缓冲区，和什么协议无关\nudp用发送缓冲区吗 一般情况下，会把数据拷贝到发送缓存区后直接发送\n一些网络异常回答 在没有开启 TCP keepalive，且双方一直没有数据交互的情况下，如果客户端的「主机崩溃」了，会发生什么。 即使没有开启 TCP keepalive，且双方也没有数据交互的情况下，如果其中一方的进程发生了崩溃，这个过程操作系统是可以感知的到的，于是就会发送 FIN 报文给对方，然后与对方进行 TCP 四次挥手\n如果有数据传输，那么就的分两种情况\n客户端宕机，然后立马重启。\n在客户宕机的时候，服务器一直接不到 ACK确认码，这个时候就会触发重传\n如果客户端没有进程监听这个 TCP报文的目标端口号，由于找不到目标端口号，那么客服端就会发送 RST包，重置改连接\n如果客户端有进程监听这个 TCP报文，这个时候重启，之前的 TCP连接的 socket结构体数据都会丢失，这个时候客户端找不到该 TCP相关的 socket数据，也会发送 RST包\n客户端宕机，一直没有重启\n服务器就会触发超时重传报文机制，一般 15次，不过 tcp超时重传不止基于 15次判断，还会基于最大超时时间来判定，也就是先达到最大超传次数或者最大超时时间，就会判定 TCP有问题，就会停止重传\n","permalink":"https://frog-game.github.io/posts/read/wangluozongjie/","summary":"tcp 握手挥手 序列号: 在建立连接的时候有计算机生成的随机数并作为初始值，通过syn包传给接收端主机，每发一次数据，就累加一次该数据字节数的大小，","title":"网络底层总结"},{"content":" frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客 ","permalink":"https://frog-game.github.io/links/","summary":"frog\u0026#39;s Blog 一个记录技术、阅读、生活的博客","title":"🤝友链"},{"content":"关于我\n英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山 ","permalink":"https://frog-game.github.io/about/","summary":"关于我 英文名: frog 职业: 码农 运动: 跑步、乒乓球、爬山","title":"🙋🏻‍♂️关于"}]